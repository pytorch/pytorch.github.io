<!DOCTYPE html>
<html lang="en">
  <head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
  <!-- End Google Tag Manager -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      PyTorch Conference 2022 | PyTorch
    
  </title>
  <meta name="robots" content="index, follow" />

<meta name="description" content="" />

  <meta property="og:image" content="https://pytorch.org/assets/images/social-share.jpg" />
  <meta name="twitter:image" content="https://pytorch.org/assets/images/social-share.jpg" />

<meta property="og:locale" content="en_US" />
<meta property="og:type" content="website" />
<meta property="og:title" content="PyTorch Conference 2022" />
<meta property="og:description" content="" />
<meta property="og:site_name" content="PyTorch" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="PyTorch Conference 2022" />
<meta name="twitter:description" content="" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
  
    <script
  async
  src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"
></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());
  gtag("config", "UA-117752657-2");
</script>

    <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window,document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '243028289693773');
    fbq('track', 'PageView');
</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

    <!-- Twitter universal website tag code -->
<img height="1" width="1" style="display:none;" alt="" src="https://analytics.twitter.com/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__analytics.twitter.com_i_adsct-3Fp-5Fid-3DTwitter-26p-5Fuser-5Fid-3D0-26txn-5Fid-3Do2gi1-26events-3D-255B-255B-2522pageview-2522-252Cnull-255D-255D-26tw-5Fsale-5Famount-3D0-26tw-5Forder-5Fquantity-3D0&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=o6i4D0V0088WH2RnzIoqiF-vj45PL-2sTrsxQ0SNO3A&e=)" />
<img height="1" width="1" style="display:none;" alt="" src="//t.co/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__linkprotect.cudasvc.com_url-3Fa-3Dhttp-253a-252f-252ft.co-252fi-252fadsct-253fp-5Fid-253dTwitter-2526p-5Fuser-5Fid-253d0-2526txn-5Fid-253do2gi1-2526events-253d-25255B-25255B-252522pageview-252522-25252Cnull-25255D-25255D-2526tw-5Fsale-5Famount-253d0-2526tw-5Forder-5Fquantity-253d0-26c-3DE-2C1-2CC33dLwIhtuEcl5FhdztSnUwsioeej5k-2DWy0RYREBAq51kGji32A2Cw94YU9vQBpY5tPN3AukEw3C-5F-2DlbtndnLoR7-5FA-5FLoH0Rr7zLtP1ykptN-26typo-3D1&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=Abgc3XBkhESv8XBYtLchdDZyISGsK6v_BB6cLMJGyCw&e=)" />
<!-- End Twitter universal website tag code -->

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Pythorch Blog Posts" />
</head>

  <body class="ecosystem">
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <div class="hello-bar">
  <div class="container">
    Join us in Silicon Valley September 18-19 at the 2024 PyTorch Conference. <a target="_blank" href="https://events.linuxfoundation.org/pytorch-conference/?utm_source=www&utm_medium=homepage&utm_campaign=Pytorch-Conference-2024&utm_content=hello">Learn more</a>.
  </div>
</div>
<div class="container-fluid header-holder ecosystem-header">
  <div class="container">
    

<div class="header-container">
  <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Learn
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/get-started">
            <span class=dropdown-title>Get Started</span>
            <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/">
            <span class="dropdown-title">Tutorials</span>
            <p>Whats new in PyTorch tutorials</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
            <span class="dropdown-title">Learn the Basics</span>
            <p>Familiarize yourself with PyTorch concepts and modules</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
            <span class="dropdown-title">PyTorch Recipes</span>
            <p>Bite-size, ready-to-deploy PyTorch code examples</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
            <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
            <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Ecosystem 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
            <span class="dropdown-title">Tools</span>
            <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="https://github.com/pytorch-fdn/ecosystem" target="_blank">
            <span class="dropdown-title">Join the Ecosystem</span>
          </a>
          <a class="nav-dropdown-item" href="/#community-module">
            <span class=dropdown-title>Community</span>
            <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
          </a>
          <a class="nav-dropdown-item" href="https://discuss.pytorch.org" target="_blank">
            <span class=dropdown-title>Forums</span>
            <p>A place to discuss PyTorch code, issues, install, research</p>
          </a>
          <a class="nav-dropdown-item" href="/resources">
            <span class=dropdown-title>Developer Resources</span>
            <p>Find resources and get questions answered</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/contributor-awards-2024">
            <span class="dropdown-title">Contributor Awards - 2024</span>
            <p>Award winners announced at this year's PyTorch Conference</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Edge 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/edge">
            <span class="dropdown-title">About PyTorch Edge</span>
            <p>Build innovative and privacy-aware AI experiences for edge devices</p>
          </a>
          <a class="nav-dropdown-item" href="/executorch-overview">
            <span class="dropdown-title">ExecuTorch</span>
            <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
          </a>
          <a class="nav-dropdown-item" target="_blank" href="https://pytorch.org/executorch/stable/index.html">
            <span class="dropdown-title">ExecuTorch Documentation</span>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="docsDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Docs
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="https://pytorch.org/docs">
            <span class="dropdown-title">PyTorch</span>
            <p>Explore the documentation for comprehensive guidance on how to use PyTorch.</p>
          </a>
          <a class="nav-dropdown-item" href="/pytorch-domains">
            <span class="dropdown-title">PyTorch Domains</span>
            <p> Read the PyTorch Domains documentation to learn more about domain-specific libraries.</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Blog & News
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/blog">
            <span class="dropdown-title">PyTorch Blog</span>
            <p>Catch up on the latest technical news and happenings</p>
          </a>
          <a class="nav-dropdown-item" href="/community-blog">
            <span class="dropdown-title">Community Blog</span>
            <p>Stories from the PyTorch ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="/videos">
            <span class="dropdown-title">Videos</span>
            <p>Learn about the latest PyTorch tutorials, new, and more </p>
          </a>
          <a class="nav-dropdown-item" href="/community-stories">
            <span class="dropdown-title">Community Stories</span>
            <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
          </a>
          <a class="nav-dropdown-item" href="/events">
            <span class=dropdown-title>Events</span>
            <p>Find events, webinars, and podcasts</p>
          </a>
          <a class="nav-dropdown-item" href="/newsletter">
            <span class=dropdown-title>Newsletter</span>
            <p>Stay up-to-date with the latest updates</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          About
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/foundation">
            <span class=dropdown-title>PyTorch Foundation</span>
            <p>Learn more about the PyTorch Foundation.</p>
          </a>
          <a class="nav-dropdown-item" href="/governing-board">
            <span class=dropdown-title>Governing Board</span>
          </a>
          <a class="nav-dropdown-item" href="/credits">
            <span class=dropdown-title>Cloud Credit Program</span>
          </a>
          <a class="nav-dropdown-item" href="/tac">
            <span class=dropdown-title>Technical Advisory Council</span>
          </a>
          <a class="nav-dropdown-item" href="/staff">
            <span class=dropdown-title>Staff</span>
          </a>
          <a class="nav-dropdown-item" href="/contact-us">
            <span class=dropdown-title>Contact Us</span>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <a href="/join" data-cta="join">
        Become a Member
      </a>
    </li>

    <li class="main-menu-item" id="github-main-menu-link">
      <a href="https://github.com/pytorch/pytorch" title="Go to PyTorch GitHub">
        <div id="topnav-gh-icon"></div>
      </a>
    </li>

    <li class="navSearchWrapper reactNavSearchWrapper" key="search">
      <div class="search-border">
        <div id="search-icon"></div>
        <input
          id="search-input"
          type="text"
          title="Search"
        />
        <div id="close-search">X</div>
      </div>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

  </div>
</div>


    <div class="main-background features-background"></div>

    <div class="jumbotron jumbotron-fluid contributor-jumbotron">
  <div class="contributor-jumbo-text container">
    <h1>PyTorch Conference</h1>
    <h1 class="lead">2022</h1>
  </div>
</div>

<div class="main-content-wrapper">
  <div class="main-content">
    <div class="container">
      <div class="input-group mb-3">
        <input
          type="text"
          id="pted-filter"
          placeholder="Filter..."
          class="form-control"
        />
      </div>
      <hr />
      <div class="row">
        <h1>Posters</h1>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/A01.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/A01-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/A01.pdf">Enabling State-of-the-art Interpretability for Medical Imaging Using PyTorch</a>
              
            </h5>
            <h6 class="card-subtitle">Dinkar Juyal, Syed Asher Javed, Harshith Padigela, Limin Yu, Aaditya Prakash, Logan Kilpatrick, Anand Sampat, PathAI</h6>
            <p class="card-text">PathAI is a Boston based company focussed on improving patient care using AI powered pathology. We heavily use PyTorch for building our ML systems, specifically training and deploying models on large gigapixel pathology images. In this case study, we highlight our use of PyTorch to build, experiment and deploy Additive Multiple Instance Learning (MIL) models. Additive MIL is a novel MIL technique built using PyTorch Lightning which allows end-to-end learning from millions of pixels while providing granular interpretability of spatial heatmaps. These models allow for the exact computation of the extent to which each smaller region in the gigapixel-sized image contributes to the final model prediction. This enables class-wise excitatory and inhibitory contributions to be visualized on top of the pathology image. This informs the practitioners of model failures and guides the pathologists to areas of interest. All this is made possible due to PyTorch's rapid research-to-prototype-to-deployment iteration cycle.</p>
            
            <p class="card-text">
              <small class="text-muted">COMPUTER VISION</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B01.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B01-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B01.pdf">TorchUnmix: Automatic Stain Unmixing and Augmentation for Histopathology Images in PyTorch</a>
              
            </h5>
            <h6 class="card-subtitle">Erik Hagendorn</h6>
            <p class="card-text">TorchUnmix is a library which aims to provide automatic stain unmixing and augmentation for histopathology whole slide images. Separation of histochemical stains (unmixing) is performed by orthonormal transformation of the RGB pixel data from predefined light absorption coefficients called stain vectors [1]. Precomputed publicly available stain vector definitions are often used, but inter-laboratory variation due to the histology and/or image acquisition process is common, yielding suboptimal unmixing results. Classical stain vector estimation methods rely on abundant distribution of stains, making them less practical for sparser distributions as observed from immunohistochemical stains. Geis et al. proposed a method based on k-means clustering of pixel values in the hue-saturation-density color space to determine optimal stain vectors which has been used in this work [2]. While stain vectors may be used for quantification of individual stains, TorchUnmix also provides functionalities to perform stain augmentation. Stain augmentation is a method used during the training process of deep learning models to improve generalization by unmixing the image, stochastically modifying the individual stains, and then compositing the stains into the final augmented image [3]. To our knowledge, no other libraries fully implement the above methods in PyTorch, utilizing GPU-acceleration. Additionally, TorchUnmix has extended all calculations used to perform the automatic stain unmixing and augmentation to operate on batches of images, drastically accelerating execution performance speeds in comparison to other libraries.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B02.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B02-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B02.pdf">Scalable Training and Inference With Ray AIR</a>
              
            </h5>
            <h6 class="card-subtitle">Kai Fricke, Balaji Veeramani</h6>
            <p class="card-text">Scaling machine learning is hard: Cloud platform solutions like SageMaker can limit flexibility, but a custom distributed framework is often too hard to implement. In effect, ML engineers struggle to scale their workloads from local prototyping to the cloud. 
 The Ray AI Runtime ('Ray AIR') is an integrated collection of machine learning libraries built around distributed computing framework Ray. It provides an easy to use interface for scalable data processing, training, tuning, batch prediction, and online serving. Adapting existing PyTorch training loops to Ray AIR's PyTorch integration needs as little as 10 lines of code changes. And scaling from local development to the cloud needs no code changes at all.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B03.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B03-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B03.pdf">AutoMAD: Mixed Mode Autodiff for PyTorch Models</a>
              
            </h5>
            <h6 class="card-subtitle">Jan Hückelheim</h6>
            <p class="card-text">Mixed Mode autodiff combines back-propagation and forward differentiation. Both modes have pros and cons: Back-propagation is efficient for scalar functions with many trainable parameters. Back-propagation uses memory for intermediate results, requires data flow reversal, scales poorly for many output variables. Forward differentiation is straightforward to implement, memory-efficient, and easy to vectorize/parallelize or port to new hardware. Forward mode scales poorly with large number of trainable parameters. AutoMAD makes it possible to combine both modes. Use forward differentiation for some layers, while using back-prop for others.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B04.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B04-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B04.pdf">xFormers: Building Blocks for Efficient Transformers</a>
              
            </h5>
            <h6 class="card-subtitle">Daniel Haziza, Francisco Massa, Jeremy Reizenstein, Patrick Labatut, Diana Liskovich</h6>
            <p class="card-text">We present xFormers, a toolbox to accelerate research on Transformers. It contains efficient components, like an exact memory-efficient multi-head attention that can accelerate trainings 2x while using a fraction of the memory. xFormers components are also customizable and can be combined together to build variations of Transformers. Our hope is to enable the next generation of research based on Transformers.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B05.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B05-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B05.pdf">linear_operator - Structured Linear Algebra in PyTorch</a>
              
            </h5>
            <h6 class="card-subtitle">Max Balandat</h6>
            <p class="card-text">linear_operator (https://github.com/cornellius-gp/linear_operator) is a library for structured linear algebra built on PyTorch. It provides a LinearOperator class that represents a tensor that is never instantiated but is instead accessed through operations like matrix multiplication, solves, decompositions, and indexing. These objects use custom linear algebra operations that can exploit particular matrix structure (e.g. diagonal, block-diagonal, triangular, Kronecker, etc.) in computations in order to achieve substantial (many orders of magnitude) improvements in time and memory complexity. Moreover, many efficient linear algebra operations (e.g. solves, decompositions, indexing, etc.) can be automatically generated from the LinearOperator's matmul function. This makes it extremely easy to compose or implement custom LinearOperators. 
 The key aspect that makes linear_operator easy to use in PyTorch code is its integration with the `__torch_function__` interface - Common linear algebra operations (such as matrix multiplication, solve, SVD) are mapped to the respective torch functions (`__matmul__`, `torch.linalg.solve`, `torch.linalg.svd`), so that LinearOperator objects can be used as drop-in replacements for dense tensors even in existing code. LinearOperator operations themselves may return LinearOperator objects, automatically keeping track of algebraic structure after each computation. As a result, users never need to reason about what efficient linear algebra routines to use (so long as the input elements defined by the user encode known input structure).</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B06.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B06-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B06.pdf">Declarative Machine Learning with Ludwig: End-to-end Machine Learning Pipelines Using Simple and Flexible Data-driven Configurations</a>
              
            </h5>
            <h6 class="card-subtitle">Justin Zhao</h6>
            <p class="card-text">Ludwig is a declarative machine learning framework that makes it easy to define and compare machine learning pipelines using a simple and flexible data-driven configuration system. The minimal configuration declares the input and output features with their respective data types. Users can specify additional parameters to preprocess, encode, and decode features, load from pre-trained models, compose the internal model architecture, set training parameters, or run hyperparameter optimization. Ludwig will build an end-to-end machine learning pipeline automatically, using whatever is explicitly specified in the configuration, while falling back to smart defaults for any parameters that are not. Scientists, engineers, and researchers use Ludwig to explore state-of-the-art model architectures, run hyperparameter search, and scale up to larger than available memory datasets and multi-node clusters, on a variety of problems using structured and unstructured features. Ludwig has 8.5K+ stars on Github and is built on top of PyTorch, Horovod, and Ray.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B07.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B07-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B07.pdf">Generalized Shapes: Block Sparsity, MaskedTensor, NestedTensor</a>
              
            </h5>
            <h6 class="card-subtitle">Christian Puhrsch</h6>
            <p class="card-text">This poster presents an overview of available and ongoing developments related to sparse memory formats, masked computation, and support for collections of variably shaped data. In particular it contains a case study of block sparse memory formats, MaskedTensor, and NestedTensor.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B08.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B08-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B08.pdf">Betty: An Automatic Differentiation Library for Generalized Meta Learning</a>
              
            </h5>
            <h6 class="card-subtitle">Sang Keun Choe</h6>
            <p class="card-text">Betty is a simple, scalable and modular library for generalized meta-learning (GML) and multilevel optimization (MLO), built upon PyTorch, that allows a unified programming interface for a number of GML/MLO applications including few-shot learning, hyperparameter optimization, neural architecture search, data reweighting, and many more. The internal autodiff mechanism and the software design of Betty are developed by the novel interpretation of GML/MLO as a dataflow graph.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B09.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B09-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B09.pdf">Functorch: Composable Function Transforms in Pytorch</a>
              
            </h5>
            <h6 class="card-subtitle">Samantha Andow, Richard Zhou, Horace He, Animesh Jain</h6>
            <p class="card-text">Inspired by Google JAX, functorch is a library in Pytorch that offers composable vmap (vectorization) and autodiff transforms (grad, vjp, jvp). Since its first release alongside Pytorch 1.11, combining these transforms has helped users develop and explore new techniques that were previously tricky to write in Pytorch, like Neural Tangent Kernels and non-linear optimizations (see Theseus, also from PyTorch). This will go through some basic usages and highlight some research that leverages functorch.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B10.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B10-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B10.pdf">Large-Scale Neural Solvers for Partial Differential Equations</a>
              
            </h5>
            <h6 class="card-subtitle">Patrick Stiller, Jeyhun Rustamov, Friedrich Bethke, Maksim Zhdanov, Raj Sutarya, Mahnoor Tanveer, Karan Shah, Richard Pausch, Sunna Torge, Alexander Debus, Attila Cangi, Peter Steinbach, Michael Bussmann, Nico Hoffmann</h6>
            <p class="card-text">Our open-source Neural Solvers framework provides data-free ML-based solvers for the study and analysis of phenomena in natural sciences built on top of Pytorch. We were the first to show that certain quantum systems modeled by the 2d Schr√∂dinger equation can be accurately solved while retaining strong scaling. We also developed a novel neural network architecture, GatedPINN [1], introducing adaptable domain decomposition into the training of Physics-informed Neural Networks based on the Mixture-of-Experts paradigm. Distributed large-scale training of our GatedPINN is facilitated by Horovod, resulting in excellent GPU utilization making Neural Solvers ready for the upcoming exascale era. Upcoming projects involve higher dimensional problems such as 3d laser systems and coupled models to study the Vlasov-Maxwell system. Further experiments on novel very scalable compute hardware paves the way for applications of high-fidelity Neural Solvers to real-world applications such as Inverse Scattering Problems.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B11.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B11-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B11.pdf">PyTorch Video: A Deep Learning Library for Video Understanding</a>
              
            </h5>
            <h6 class="card-subtitle">Haoqi Fan</h6>
            <p class="card-text">PyTorchVideo is the deep learning library for video understanding research in PyTorch.                                                                                                                                                                                                                                                                                                                                                 
</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B12.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B12-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B12.pdf">Model Preparation Federated Learning and Device Computation</a>
              
            </h5>
            <h6 class="card-subtitle">Zhihan Fang</h6>
            <p class="card-text">Federated Learning with Differential Privacy has witnessed an increased adoption as one of the most promising ways to train machine learning models while preserving user privacy. Existing models in Meta around people attributes are mostly built on traditional centralized machine learning methods. Recently, due to the increasing concerns about user privacy internally and externally, Machine Learning teams at Meta are experiencing either signal loss or restriction on applying new features in models to further improve model performance. In this paper, we are introducing a generic framework we built for preparing and generating models for federated learning. The model preparation process is to utilize traditional machine learning to understand model structure and hyperparameters for the target problems including training, inference, evaluations. It also requires a simulation process to train the target model structure and understand the simulated environment on the server side to tune FL specific hyperparameters. 
 The model generation process is to generate device compatible models, which can be used directly on users’ devices for federated learning. We applied the FL framework on our on-device models, and integrated with device signals to improve user experience and protect user privacy.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B13.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B13-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B13.pdf">Constrained Optimization in PyTorch With Cooper</a>
              
            </h5>
            <h6 class="card-subtitle">Jose Gallego-Posada, Juan Camilo Ramirez</h6>
            <p class="card-text">Cooper (https://github.com/cooper-org/cooper) is a general-purpose, deep learning-first constrained optimization library in PyTorch. Cooper is (almost!) seamlessly integrated with PyTorch and preserves the usual loss  backward  step workflow. If you are already familiar with PyTorch, using Cooper will be a breeze! 
 This library aims to encourage and facilitate the study of constrained optimization problems in deep learning. Cooper focuses on non-convex constrained optimization problems for which the loss or constraints are not necessarily “nicely behaved” or “theoretically tractable”. Moreover, Cooper has been designed to play nicely with mini-batched/stochastic estimates for the objective and constraint functions. 
 Cooper implements several popular constrained optimization protocols so you can focus on your project, while we handle the nitty-gritty behind the scenes.</p>
            
            <p class="card-text">
              <a href="https://github.com/cooper-org/cooper">https://github.com/cooper-org/cooper</a>
            </p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B14.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B14-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B14.pdf">Two Dimensional Parallelism Using Distributed Tensors</a>
              
            </h5>
            <h6 class="card-subtitle">Wanchao Liang, Junjie Wang</h6>
            <p class="card-text">This talk will introduce 2-dimensional parallelism with PyTorch (Data Parallelism + Tensor Parallelism) using Distributed Tensor, a fundamental distributed primitive offered by PyTorch Distributed that empowers Tensor Parallelism. We have proven that using FSDP + Tensor Parallelism together could enable us to train large models like Transformer, and increase training performance. We offer end to end training techniques that enable you to train models in 2-D parallelism fashion, and checkpoint save/load models in a distributed manner.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B15.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B15-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B15.pdf">PyTorch Tabular: A Framework for Deep Learning with Tabular Data</a>
              
            </h5>
            <h6 class="card-subtitle">Manu Joseph</h6>
            <p class="card-text">In spite of showing unreasonable effectiveness in modalities like text and image, Deep Learning has always lagged Gradient Boosting in tabular data- both in popularity and performance. But recently there have been newer models created specifically for tabular data, which is pushing the performance bar. Popularity is still a challenge, however, because there is no easy, ready-to-use library like Sci-Kit Learn for deep learning. PyTorch Tabular aims to change that by being an easy-to-use and flexible framework which makes using SOTA model architectures in tabular data as easy as Sci-Kit Learn.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B17.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B17-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B17.pdf">Better Transformer: Accelerating Transformer Inference in PyTorch</a>
              
            </h5>
            <h6 class="card-subtitle">Michael Gschwind, Christian Puhrsch, Driss Guessous, Rui Zhu, Daniel Haziza, Francisco Massa</h6>
            <p class="card-text">We introduce Better Transformer, the PyTorch project to accelerate Transformers for inference and training with out-of-the-box enablement by implementing the Better Transformer ‘fastpath’. Fastpath accelerates many of the most commonly executed functions in Transformer models. Starting with PyTorch 1.13, the PyTorch Core API is implemented with accelerated operations to deliver up to 2x-4x speedups on many Transformer models, such as BERT and XLM-R. Accelerated operations are based on (1) operator and kernel fusion and (2) exploiting sparsity created by variable sequence-length NLP batches. In addition to improving MultiHeadAttention with fastpath, the model also includes sparsity support for MultiHeadAttention and TransformerEncoder modules to take advantage of variable sequence-length information with Nested Tensors for NLP models. 
 At present, we enable torchtext and Hugging Face domain libraries with Better Transformer, delivering significant speedups for text, image, and audio models. Starting with the next release, PyTorch core will include even faster fused kernels and training support. You can preview these features today with PyTorch Nightlies, the nightly preview builds of the upcoming PyTorch release.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B18.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/B18-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/B18.pdf">PiPPy: Automated Pipeline Parallelism for PyTorch</a>
              
            </h5>
            <h6 class="card-subtitle">Ke Wen, Pavel Belevich, Anjali Sridhar</h6>
            <p class="card-text">PiPPy is a library that provides automated pipeline parallelism for PyTorch models. With compiler techniques, PiPPy splits a model into pipeline stages without requiring model changes. PiPPy also provides a distributed runtime that distributes the split stages to multiple devices and hosts and orchestrates micro-batch execution in an overlapped fashion. We demonstrate application of PiPPy to Hugging Face models achieving 3x speedup on cloud platforms.</p>
            
            <p class="card-text">
              <small class="text-muted">LIBRARIES</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/C01.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/C01-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/C01.pdf">Practical Guide on PyTorch Inference Using AWS Inferentia</a>
              
            </h5>
            <h6 class="card-subtitle">Keita Watanabe</h6>
            <p class="card-text">In this session we will go through step-by-step how to conduct the inference process of machine learning models using Inferentia. In addition, we compare the inference performance with GPU and discuss the cost advantage. In the later part of the session, we will also cover model deployment on Kubernetes.</p>
            
            <p class="card-text">
              <small class="text-muted">OPTIMIZATION</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/C02.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/C02-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/C02.pdf">PyG Performance Optimization for CPU</a>
              
            </h5>
            <h6 class="card-subtitle">Mingfei Ma</h6>
            <p class="card-text">Accelerating PyG CPU performance with faster sparse aggregation.
PyG is a library built upon PyTorch to easily write and train Graph Neural Networks, which heavily relies on the mechanism of Message Passing for information aggregation. We have optimized critical bottlenecks of Message Passing from PyTorch, including: 1. Scatter Reduce: maps to classic PyG use case when the EdgeIndex is stored in COO memory format. 2. SpMM Reduce: maps to the usage case when the EdgeIndex is stored in CSR memory format.</p>
            
            <p class="card-text">
              <small class="text-muted">OPTIMIZATION</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/C03.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/C03-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/C03.pdf">Quantization in PyTorch 2.0 Export</a>
              
            </h5>
            <h6 class="card-subtitle">Jerry Zhang</h6>
            <p class="card-text">Currently, PyTorch Architecture Optimization (torch.ao) offers two quantization flow tools: eager mode quantization (beta) and fx graph mode quantization (prototype). With PyTorch 2.0 coming up, we are going to redesign quantization on top of the PyTorch 2.0 export path, this talk will introduce our plans for supporting quantization in PyTorch 2.0 export path, its main advantages over the previous tools, and how modeling developers and backend developers will be interacting with this flow.</p>
            
            <p class="card-text">
              <small class="text-muted">OPTIMIZATION</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/C04.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/C04-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/C04.pdf">Torch-TensorRT: A Compiler for Accelerating PyTorch Inference Using TensorRT</a>
              
            </h5>
            <h6 class="card-subtitle">Naren Dasan, Dheeraj Peri, Bo Wang, Apurba Bose, George Stefanakis, Nick Comly, Wei Wei, Shirong Wu, Yinghai Lu</h6>
            <p class="card-text">Torch-TensorRT is an open-source compiler targeting NVIDIA GPUs for high-performance deep-learning inference in PyTorch. It combines the usability of PyTorch with the performance of TensorRT allowing for easy optimization of inference workloads on NVIDIA GPUs. Torch-TensorRT supports all classes of optimizations in TensorRT including reduced mixed precision down to INT8, through simple Python & C++ APIs designed to work directly from PyTorch. Torch-TensorRT outputs standard PyTorch modules as well as the TorchScript format to allow for a completely self-contained, portable, & static module with TensorRT engines embedded. We present recent improvements to Torch-TensorRT including the new FX frontend which allows developers to use a full Python workflow for optimizing models and extend Torch-TensorRT in Python, the unified Torch-TensorRT Runtime which enables hybrid FX + TorchScript workflows and discuss future work for the project.</p>
            
            <p class="card-text">
              <small class="text-muted">OPTIMIZATION</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/G01.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/G01-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/G01.pdf">Accelerating Inference with PyTorch by Leveraging Graph Fusions With oneDNN Graph</a>
              
            </h5>
            <h6 class="card-subtitle">Sanchit Jain</h6>
            <p class="card-text">The open-source oneDNN Graph library extends oneDNN with a flexible graph API to maximize the optimization opportunities for generating efficient code on AI hardware (currently x86-64 CPUs, but GPU support is on the way). It automatically identifies the graph partitions to be accelerated via fusion. Its fusion patterns entail fusing compute-intensive operations such as convolution, matmul and their neighbor operations for both inference and training use cases. Since PyTorch 1.12, oneDNN Graph has been supported as an experimental feature to speed up inference with Float32 datatype on x86-64 CPUs. Support for inference with oneDNN Graph using BFloat16 datatype exists in the PyTorch master branch, and hence also in nightly PyTorch releases. Intel Extension for PyTorch is an open-source library that builds on top of PyTorch, and can be thought of as a 'staging-ground' for optimizations in PyTorch from Intel. It leverages oneDNN Graph for inference with int8 datatype. This poster presents reproducible results with PyTorch’s TorchBench benchmarking suite to demonstrate the inference speedup achieved with PyTorch & oneDNN Graph using Float32, BFloat16 & int8 datatypes.</p>
            
            <p class="card-text">
              <small class="text-muted">OPTIMIZATION</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/D01.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/D01-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/D01.pdf">Back to Python: Extending PyTorch Without Touching C++</a>
              
            </h5>
            <h6 class="card-subtitle">Alban Desmaison</h6>
            <p class="card-text">This poster presents the new extension points that the PyTorch team has designed to allow users to extend PyTorch from Python. We will cover an introduction to Tensor Subclassing, Modes and torch library. We will briefly describe each extension point and talk through examples such as memory profiling, logging used operators, quantization and custom sparse kernel all in less than 100 LOC. We will also introduce the new ways you can add new devices and author kernels without the need to modify PyTorch directly.</p>
            
            <p class="card-text">
              <small class="text-muted">OTHER</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/D02.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/D02-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/D02.pdf">Functionalization in PyTorch</a>
              
            </h5>
            <h6 class="card-subtitle">Brian Hirsh</h6>
            <p class="card-text">Functionalization is a way to remove mutations from arbitrary PyTorch programs sent to downstream compilers. The PyTorch 2.0 stack is all about capturing graphs of PyTorch operations and sending them off to a compiler to get better performance. PyTorch programs can mutate and alias state, making them unfriendly to compilers. Functionalization is a technique to take a program full of PyTorch operators, including mutable and aliasing operators, and remove all mutations from the program while preserving semantics.</p>
            
            <p class="card-text">
              <small class="text-muted">OTHER</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/D03.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/D03-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/D03.pdf">Walmart Search: Serving Models at a Scale on TorchServe</a>
              
            </h5>
            <h6 class="card-subtitle">Pankaj Takawale, Dagshayani Kamalaharan, Zbigniew Gasiorek, Rahul Sharnagat</h6>
            <p class="card-text">Walmart Search has embarked on the journey of adopting Deep Learning in the Search ecosystem for improving Search relevance in various parts. As our pilot use case, we wanted to serve the computationally intensive Bert Base model at runtime with an objective to achieve low latency and high throughput. We had JVM hosted web applications loading and serving multiple models. The experimental models were being loaded onto the same applications. These models are large in size and computation is expensive. 
 We were facing the following limitations with this approach: Refreshing model with the latest version or adding new experimental model would need application deployment. Increased memory pressure on a single application. Slow startup time due to loading multiple ML models during startup. Concurrency was not beneficial due to limited CPU (Metrics on concurrent model prediction vs sequential).</p>
            
            <p class="card-text">
              <small class="text-muted">OTHER</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/E01.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/E01-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/E01.pdf">TorchX: From Local Development to Kubernetes and Back</a>
              
            </h5>
            <h6 class="card-subtitle">Joe Doliner, Jimmy Whitaker</h6>
            <p class="card-text">TorchX is incredibly useful for developing PyTorch applications quickly. But when it comes to deployment, nothing is easy. With docker development, Kubernetes, and customer schedulers, there’s a lot to learn. In this talk, we’ll discuss how organizations can deploy to production, why TorchX is a great system for this, and lessons we learned so you can avoid hitting them too.</p>
            
            <p class="card-text">
              <small class="text-muted">PRODUCTION</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/E02.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/E02-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/E02.pdf">Training at Scale Using Fully Sharded Data Parallel (FSDP) with PyTorch/XLA</a>
              
            </h5>
            <h6 class="card-subtitle">Shauheen Zahirazami, Jack Cao, Blake Hechtman, Alex Wertheim, Ronghang Hu</h6>
            <p class="card-text">PyTorch/XLA enables PyTorch users to run their models on XLA devices including Google's Cloud TPUs. The latest improvements in PyTorch/XLA enables training PyTorch models using FSDP to train very large models. In this work we present benchmarks and Hardware Flops Utilization of training HuggingFace GPT-2 on Cloud TPU v4.</p>
            
            <p class="card-text">
              <small class="text-muted">PRODUCTION</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/E03.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/E03-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/E03.pdf">FSDP Production Readiness</a>
              
            </h5>
            <h6 class="card-subtitle">Rohan Varma, Andrew Gu</h6>
            <p class="card-text">This talk dives into recent advances in PyTorch Fully Sharded Data Parallel (FSDP) that have enabled better throughput, memory savings, and extensibility. These improvements have unblocked using FSDP for models of different modalities and for varying model and data sizes. We will share best practices to apply these features to specific use cases such as XLMR, FLAVA, ViT, DHEN, and GPT3-style models.</p>
            
            <p class="card-text">
              <small class="text-muted">PRODUCTION</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/E04.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/E04-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/E04.pdf">Orchestrating Pytorch Workflows With Kubeflow Pipelines and TorchX</a>
              
            </h5>
            <h6 class="card-subtitle">Erwin Huizenga, Nikita Namjoshi</h6>
            <p class="card-text">TorchX is a universal job launcher for PyTorch applications that helps ML practitioners speed up iteration time and support end to end production. In this talk, we show you how to build and run TorchX components as a pipeline using the Kubeflow Pipeline (KFL) DSL. We go into detail on how to use KFP and TorchX to build components and how to use KFP DSL to orchestrate and run ML workflows.</p>
            
            <p class="card-text">
              <small class="text-muted">PRODUCTION</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/H01.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/H01-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/H01.pdf">A Community- led and OSS Ecosystem of ML Compiler and Infrastructure Projects</a>
              
            </h5>
            <h6 class="card-subtitle">Shauheen Zahirazami, James Rubin, Mehdi Amini, Thea Lamkin, Eugene Burmako, Navid Khajouei</h6>
            <p class="card-text">ML development is often stymied by incompatibilities between frameworks and hardware, forcing developers to compromise on technologies when building ML solutions. OpenXLA is a community-led and open-source ecosystem of ML compiler and infrastructure projects being co-developed by AI/ML leaders including Alibaba, Amazon Web Services, AMD, Arm, Apple, Google, Intel, Meta, NVIDIA, and more. It will address this challenge by letting ML developers build their models on leading frameworks and execute them with high performance across any hardware backend. This flexibility will let developers make the right choice for their project, rather than being locked into decisions by closed systems. Our community will start by collaboratively evolving the XLA compiler and StableHLO, a portable ML compute operation set that makes frameworks easier to deploy across different hardware options.</p>
            
            <p class="card-text">
              <small class="text-muted">PRODUCTION</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/F01.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/F01-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/F01.pdf">Squeezing GPU Memory Usage in PyTorch</a>
              
            </h5>
            <h6 class="card-subtitle">Mao Lin, Keren Zhou, Penfei Su</h6>
            <p class="card-text">The limited GPU memory resources can often hinder the performance of GPU-accelerated applications. While PyTorch’s Caching Allocator aims to minimize the number of expensive memory allocations and deallocations and maximize the efficient utilization of GPU memory resources, our study of common deep learning models revealed significant memory fragmentation problems. In some cases, up to 50% of GPU memory is wasted. To better understand the root causes of memory fragmentation, we developed a tool that visualizes GPU memory usage in two ways: the allocator view and the block view. The allocator view presents memory usage with each allocation or deallocation event, and the block view shows the changes in specific memory blocks over time. Our analysis revealed the considerable potential to save GPU memory, which would relieve the bottleneck of limited resources. By employing strategies such as swapping, activation recomputation, and memory defragmentation, we were able to reduce GPU memory waste significantly.</p>
            
            <p class="card-text">
              <small class="text-muted">TOOLS</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/F02.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/F02-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/F02.pdf">'Brainchop': In Browser MRI Volumetric Segmentation and Rendering</a>
              
            </h5>
            <h6 class="card-subtitle">Mohamed Masoud, Farfalla Hu, Sergey Plis</h6>
            <p class="card-text">In brainchop project, we bring high fidelity pre-trained deep learning models for volumetric analysis of structural magnetic resonance imaging (MRI) right to the browsers of scientists and clinicians with no requirement on their technical skills in setting up AI-solutions. All of this in an extensible open-source framework. Our tool is the first front-end MRI segmentation tool on the web that supports full brain volumetric processing in a single pass inside a browser. This property is powered by our lightweight and reliable deep learning model Meshnet that enables volumetric processing of the entire brain at once, which leads to increased accuracy with modest computational requirements. High-quality client-side processing solves the privacy problem, as the data does not need to leave the client. Moreover, browser-based implementation is able to take advantage of available hardware acceleration regardless of the brand or architecture.
 GitHub: https://github.com/neuroneural/brainchop</p>
            
            <p class="card-text">
              <a href="https://github.com/neuroneural/brainchop">https://github.com/neuroneural/brainchop</a>
            </p>
            
            <p class="card-text">
              <small class="text-muted">TOOLS</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/F03.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/F03-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/F03.pdf">TorchBench: Quantifying PyTorch Performance During the Development Loop</a>
              
            </h5>
            <h6 class="card-subtitle">Xu Zhao, Will Constable, David Berard, Taylor Robie, Eric Han, Adnan Aziz</h6>
            <p class="card-text">Holding the line of performance is challenging for ML frameworks like PyTorch. The existing AI benchmarks like MLPerf are end-to-end, therefore require large volumes of datasets, at-scale GPU clusters, and long benchmarking time. We develop TorchBench, a novel AI benchmark suite which highlights with minimal data inputs, single GPU, and milliseconds-per-test latencies. TorchBench is now deployed as part of the PyTorch nightly release process, guarding performance/correctness regressions and testing experimental PyTorch features on SOTA machine learning models.</p>
            
            <p class="card-text">
              <small class="text-muted">TOOLS</small>
            </p>
          </div>
        </div>
        
        <div class="card">
          <div class="card-body">
            
            <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/F04.pdf"
              ><img src="https://pytorch.org/assets/images/ptc2022/F04-thumb.png"
            /></a>
            
            <h5 class="card-title">
              
              <a href="https://pytorch.s3.amazonaws.com/posters/ptc2022/F04.pdf">Democratizing AI for Biology With OpenFold</a>
              
            </h5>
            <h6 class="card-subtitle">Gustaf Ahdritz, Sachin Kadyan, Will Gerecke, Luna Xia, Nazim Bouatta, Mohammed AlQuraishi</h6>
            <p class="card-text">OpenFold, developed by Columbia University, is an open-source protein structure prediction model implemented with PyTorch. The goal of OpenFold is to verify that AlphaFold 2 — DeepMind's protein structure prediction model — can be reproduced from scratch and beyond that, make components of the system available to like-minded researchers and academics so they can build on top of it. During this research, Weights & Biases was used to accelerate OpenFold’s reproduction of AlphaFold 2. The collaborative nature of W&B allowed for insights to scale from a single researcher to the entire team and helped solve the reproducibility challenge in ML.</p>
            
            <p class="card-text">
              <small class="text-muted">TOOLS</small>
            </p>
          </div>
        </div>
        
      </div>
    </div>
  </div>
</div>

<style>
  .card {width: 75.5rem;}
</style>


<script type="text/javascript">
  // this isn't efficient please don't use for more than a few hundred items
  $("#pted-filter").on("keyup", function () {
    var input = $(this).val().toLowerCase();

    $(".card").filter(function () {
      $(this).toggle($(this).text().toLowerCase().indexOf(input) > -1);
    });
  });
</script>

    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="/docs">View Docs</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p
        class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and the latest news</p>
    
    
        <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
        <script>
          hbspt.forms.create({
            region: "na1",
            portalId: "8112310",
            formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
          });
        </script>
        
    
      <p
        class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its projects regarding their events, training, research, developments, and related announcements. I understand that I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
        
    </div>
    


    <div class="lf-grid">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org" class="footer-logo">
          <img src="/assets/images/logo-icon.svg" alt="PyTorch logo" width="40">
        </a>
      </div>

      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook"><path fill="currentColor" d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z"/></svg>	
        </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X"><path fill="currentColor" d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66"/></svg>
        </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube"><path fill="currentColor" d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z"/></svg>	
        </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn"><rect width="512" height="512" rx="0" fill="currentColor"/><circle fill="#000" cx="142" cy="138" r="37"/><path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198"/><path fill="#000" d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
        </a></li>
        <li><a href="https://join.slack.com/t/pytorch/shared_invite/zt-2j2la612p-miUinTTaxXczKOJw48poHA" target="_blank" title="PyTorch Slack">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack"><path fill="currentColor" d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z"></path></svg>
        </a></li>
        <li><a href="/wechat" title="PyTorch on WeChat">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat"><path fill="currentColor" d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z"></path><path fill="currentColor" d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z"></path></svg>
        </a></li>
      </ul>
    </div>

    <div class="privacy-policy">
      <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation. 
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see 
          <a href="https://www.linuxfoundation.org/legal/policies/">Linux Foundation Policies</a>. The PyTorch Foundation supports the PyTorch open source 
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC, 
          please see <a href="https://www.lfprojects.org/policies/">LF Projects, LLC Policies</a>. <a href="https://www.linuxfoundation.org/privacy">Privacy Policy</a> and <a href="https://www.linuxfoundation.org/terms">Terms of Use</a>.</p>
      </div>
    </div>
  </div>
  <img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>
        <li class="navSearchWrapper reactNavSearchWrapper tabletSearchWrapper" key="search">
          <div class="mobile-search-border">
            <input
              id="mobile-search-input"
              type="text"
              title="Search"
            />
            <div id="mobile-search-icon"></div>
          </div>
        </li>

        <li class="resources-mobile-menu-title">
          <a>Learn</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/get-started">Get Started</a> 
          </li>
          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Ecosystem</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Tools</a>
          </li>
          <li>
            <a href="https://github.com/pytorch-fdn/ecosystem">Join the Ecosystem</a>
          </li>
          <li>
            <a href="/#community-module">Community</a>
          </li>
          <li>
            <a href="https://discuss.pytorch.org">Forums</a>
          </li>
          <li>
            <a href="/resources">Developer Resources</a>
          </li>
          <li>
            <a href="/ecosystem/contributor-awards-2024">Contributor Awards - 2024</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Edge</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/edge">About PyTorch Edge</a>
          </li>
          <li>
            <a href="/executorch-overview">ExecuTorch</a>
          </li>
          <li>
            <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Docs</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/docs">PyTorch</a>
          </li>
          <li>
            <a href="/pytorch-domains">PyTorch Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/blog">PyTorch Blog</a>
          </li>
          <li>
            <a href="/community-blog">Community Blog</a>
          </li>
          <li>
            <a href="/videos">Videos</a>
          </li>
          <li>
            <a href="/community-stories">Community Stories</a>
          </li>
          <li>
            <a href="/events">Events</a>
          </li>
          <li>
            <a href="/newsletter">Newsletter</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="/credits">Cloud Credit Program</a>
          </li>
          <li>          
            <a href="/tac">Technical Advisory Council</a>
          </li>
          <li>
            <a href="/staff">Staff</a>
          </li>
          <li>
            <a href="/contact-us">Contact Us</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a href="/join">Become a Member</a>
        </li>
        <li class="resources-mobile-menu-title">
          <a href="https://github.com/pytorch/pytorch" title="Go to PyTorch GitHub"><div id="topnav-gh-icon"></div></a>
        </li>
      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>

  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script>

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header, .announcement-header, .comm-stories-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>


  <script src="/assets/track-events.js"></script>
  <script>trackEvents.bind();</script>



<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="/assets/images/pytorch-x.svg">
  </div>
</div>


  </body>
</html>
