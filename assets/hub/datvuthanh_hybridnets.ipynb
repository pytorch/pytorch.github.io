{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9c70e74",
   "metadata": {},
   "source": [
    "### This notebook is optionally accelerated with a GPU runtime.\n",
    "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "# HybridNets\n",
    "\n",
    "*Author: Dat Vu Thanh*\n",
    "\n",
    "**HybridNets - End2End Perception Network**\n",
    "\n",
    "## Before You Start\n",
    "\n",
    "Start from a **Python>=3.7** environment with **PyTorch>=1.10** installed. To install PyTorch see [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/). To install HybridNets dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -qr https://raw.githubusercontent.com/datvuthanh/HybridNets/main/requirements.txt  # install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf5575",
   "metadata": {},
   "source": [
    "## Model Description\n",
    " \n",
    "<img width=\"100%\" src=\"https://github.com/datvuthanh/HybridNets/raw/main/images/hybridnets.jpg\">  \n",
    "\n",
    "HybridNets is an end2end perception network for multi-tasks. Our work focused on traffic object detection, drivable area segmentation and lane detection.  HybridNets can run real-time on embedded systems, and obtains SOTA Object Detection, Lane Detection on BDD100K Dataset.\n",
    "\n",
    "### Results\n",
    "\n",
    "### Traffic Object Detection\n",
    "\n",
    "|        Model       |  Recall (%)  |   mAP@0.5 (%)   |\n",
    "|:------------------:|:------------:|:---------------:|\n",
    "|     `MultiNet`     |     81.3     |       60.2      |\n",
    "|      `DLT-Net`     |     89.4     |       68.4      |\n",
    "|   `Faster R-CNN`   |     77.2     |       55.6      |\n",
    "|      `YOLOv5s`     |     86.8     |       77.2      |\n",
    "|       `YOLOP`      |     89.2     |       76.5      |\n",
    "|  **`HybridNets`**  |   **92.8**   |     **77.3**    |\n",
    "\n",
    "<img src=\"https://github.com/datvuthanh/HybridNets/raw/main/images/det1.jpg\" width=\"50%\" /><img src=\"https://github.com/datvuthanh/HybridNets/raw/main/images/det2.jpg\" width=\"50%\" />\n",
    " \n",
    "### Drivable Area Segmentation\n",
    "\n",
    "|       Model      | Drivable mIoU (%) |\n",
    "|:----------------:|:-----------------:|\n",
    "|    `MultiNet`    |        71.6       |\n",
    "|     `DLT-Net`    |        71.3       |\n",
    "|     `PSPNet`     |        89.6       |\n",
    "|      `YOLOP`     |        91.5       |\n",
    "| **`HybridNets`** |      **90.5**     |\n",
    "\n",
    "<img src=\"https://github.com/datvuthanh/HybridNets/raw/main/images/road1.jpg\" width=\"50%\" /><img src=\"https://github.com/datvuthanh/HybridNets/raw/main/images/road2.jpg\" width=\"50%\" />\n",
    " \n",
    "### Lane Line Detection\n",
    "\n",
    "|      Model       | Accuracy (%) | Lane Line IoU (%) |\n",
    "|:----------------:|:------------:|:-----------------:|\n",
    "|      `Enet`      |     34.12    |       14.64       |\n",
    "|      `SCNN`      |     35.79    |       15.84       |\n",
    "|    `Enet-SAD`    |     36.56    |       16.02       |\n",
    "|      `YOLOP`     |     70.5     |        26.2       |\n",
    "| **`HybridNets`** |   **85.4**   |      **31.6**     |\n",
    "\n",
    "<img src=\"https://github.com/datvuthanh/HybridNets/raw/main/images/lane1.jpg\" width=\"50%\" /><img src=\"https://github.com/datvuthanh/HybridNets/raw/main/images/lane2.jpg\" width=\"50%\" />\n",
    "  \n",
    "<img width=\"100%\" src=\"https://github.com/datvuthanh/HybridNets/raw/main/images/full_video.gif\">\n",
    " \n",
    " \n",
    "### Load From PyTorch Hub\n",
    "\n",
    "This example loads the pretrained **HybridNets** model and passes an image for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# load model\n",
    "model = torch.hub.load('datvuthanh/hybridnets', 'hybridnets', pretrained=True)\n",
    "\n",
    "#inference\n",
    "img = torch.randn(1,3,640,384)\n",
    "features, regression, classification, anchors, segmentation = model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff44a7fe",
   "metadata": {},
   "source": [
    "### Citation\n",
    "\n",
    "If you find our [paper](https://arxiv.org/abs/2203.09035) and [code](https://github.com/datvuthanh/HybridNets) useful for your research, please consider giving a star and citation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e5edee",
   "metadata": {
    "attributes": {
     "classes": [
      "BibTeX"
     ],
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "@misc{vu2022hybridnets,\n",
    "      title={HybridNets: End-to-End Perception Network}, \n",
    "      author={Dat Vu and Bao Ngo and Hung Phan},\n",
    "      year={2022},\n",
    "      eprint={2203.09035},\n",
    "      archivePrefix={arXiv},\n",
    "      primaryClass={cs.CV}\n",
    "}"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
