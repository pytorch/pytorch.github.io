{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3dc9dea",
   "metadata": {},
   "source": [
    "### This notebook is optionally accelerated with a GPU runtime.\n",
    "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "# Silero Voice Activity Detector\n",
    "\n",
    "*Author: Silero AI Team*\n",
    "\n",
    "**Pre-trained Voice Activity Detector**\n",
    "\n",
    "<img src=\"https://pytorch.org/assets/images/silero_vad_performance.png\" alt=\"alt\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98662789",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# this assumes that you have a proper version of PyTorch already installed\n",
    "pip install -q torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494402d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "from IPython.display import Audio\n",
    "from pprint import pprint\n",
    "# download example\n",
    "torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\n",
    "\n",
    "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                              model='silero_vad',\n",
    "                              force_reload=True)\n",
    "\n",
    "(get_speech_timestamps,\n",
    " _, read_audio,\n",
    " *_) = utils\n",
    "\n",
    "sampling_rate = 16000 # also accepts 8000\n",
    "wav = read_audio('en_example.wav', sampling_rate=sampling_rate)\n",
    "# get speech timestamps from full audio file\n",
    "speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)\n",
    "pprint(speech_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b556e277",
   "metadata": {},
   "source": [
    "### Model Description\n",
    "\n",
    "Silero VAD: pre-trained enterprise-grade Voice Activity Detector (VAD). Enterprise-grade Speech Products made refreshingly simple (see our STT models). **Each model is published separately**.\n",
    "\n",
    "Currently, there are hardly any high quality / modern / free / public voice activity detectors except for WebRTC Voice Activity Detector (link). WebRTC though starts to show its age and it suffers from many false positives.\n",
    "\n",
    "**(!!!) Important Notice (!!!)** - the models are intended to run on CPU only and were optimized for performance on 1 CPU thread. Note that the model is quantized.\n",
    "\n",
    "\n",
    "### Additional Examples and Benchmarks\n",
    "\n",
    "For additional examples and other model formats please visit this [link](https://github.com/snakers4/silero-vad) and please refer to the extensive examples in the Colab format (including the streaming examples).\n",
    "\n",
    "### References\n",
    "\n",
    "VAD model architectures are based on similar STT architectures.\n",
    "\n",
    "- [Silero VAD](https://github.com/snakers4/silero-vad)\n",
    "- [Alexander Veysov, \"Toward's an ImageNet Moment for Speech-to-Text\", The Gradient, 2020](https://thegradient.pub/towards-an-imagenet-moment-for-speech-to-text/)\n",
    "- [Alexander Veysov, \"A Speech-To-Text Practitionerâ€™s Criticisms of Industry and Academia\", The Gradient, 2020](https://thegradient.pub/a-speech-to-text-practitioners-criticisms-of-industry-and-academia/)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
