<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
  <!-- End Google Tag Manager -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      PyTorch 2.1 Contains New Performance Features for AI Developers | PyTorch
    
  </title>
  <meta name="robots" content="index, follow" />

<meta name="description" content="We are excited to see the release of PyTorch 2.1. In this blog, we discuss the five features for which Intel made significant contributions to PyTorch 2.1:

" />

  <meta property="og:image" content="https://pytorch.org/assets/images/social-share.jpg" />
  <meta name="twitter:image" content="https://pytorch.org/assets/images/social-share.jpg" />

<meta property="og:locale" content="en_US" />
<meta property="og:type" content="website" />
<meta property="og:title" content="PyTorch 2.1 Contains New Performance Features for AI Developers" />
<meta property="og:description" content="We are excited to see the release of PyTorch 2.1. In this blog, we discuss the five features for which Intel made significant contributions to PyTorch 2.1:

" />
<meta property="og:site_name" content="PyTorch" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="PyTorch 2.1 Contains New Performance Features for AI Developers" />
<meta name="twitter:description" content="We are excited to see the release of PyTorch 2.1. In this blog, we discuss the five features for which Intel made significant contributions to PyTorch 2.1:

" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
  
    <script
  async
  src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"
></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());
  gtag("config", "UA-117752657-2");
</script>

    <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window,document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '243028289693773');
    fbq('track', 'PageView');
</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

    <!-- Twitter universal website tag code -->
<img height="1" width="1" style="display:none;" alt="" src="https://analytics.twitter.com/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__analytics.twitter.com_i_adsct-3Fp-5Fid-3DTwitter-26p-5Fuser-5Fid-3D0-26txn-5Fid-3Do2gi1-26events-3D-255B-255B-2522pageview-2522-252Cnull-255D-255D-26tw-5Fsale-5Famount-3D0-26tw-5Forder-5Fquantity-3D0&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=o6i4D0V0088WH2RnzIoqiF-vj45PL-2sTrsxQ0SNO3A&e=)" />
<img height="1" width="1" style="display:none;" alt="" src="//t.co/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__linkprotect.cudasvc.com_url-3Fa-3Dhttp-253a-252f-252ft.co-252fi-252fadsct-253fp-5Fid-253dTwitter-2526p-5Fuser-5Fid-253d0-2526txn-5Fid-253do2gi1-2526events-253d-25255B-25255B-252522pageview-252522-25252Cnull-25255D-25255D-2526tw-5Fsale-5Famount-253d0-2526tw-5Forder-5Fquantity-253d0-26c-3DE-2C1-2CC33dLwIhtuEcl5FhdztSnUwsioeej5k-2DWy0RYREBAq51kGji32A2Cw94YU9vQBpY5tPN3AukEw3C-5F-2DlbtndnLoR7-5FA-5FLoH0Rr7zLtP1ykptN-26typo-3D1&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=Abgc3XBkhESv8XBYtLchdDZyISGsK6v_BB6cLMJGyCw&e=)" />
<!-- End Twitter universal website tag code -->

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Pythorch Blog Posts" />
</head>


<body class="blog">
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <div class="main-background blog-background blog-detail-background"></div>

    <div class="container-fluid header-holder blog-detail-header">
        <div class="container">
            

<div class="header-container">
  <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item ">
      <a href="/get-started">Get Started</a>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow">
          Ecosystem 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/ecosystem">
            <span class="dropdown-title">Tools</span>
            <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/ptc/2022">
            <span class="dropdown-title">PyTorch Conference - 2022</span>
            <p>See the posters presented at PyTorch Conference - 2022</p>
          </a>
          <a class="nav-dropdown-item" href="https://events.linuxfoundation.org/pytorch-conference/">
            <span class="dropdown-title">PyTorch Conference - 2023</span>
            <p>October 16-17 in San Francisco</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/contributor-awards-2023">
            <span class="dropdown-title">Contributor Awards - 2023</span>
            <p>Award winners announced at this year's PyTorch Conference</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow">
          PyTorch Edge 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/edge">
            <span class="dropdown-title">About PyTorch Edge</span>
          </a>
          <a class="nav-dropdown-item" href="/executorch-overview">
            <span class="dropdown-title">ExecuTorch</span>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item active">
      <a href="/blog">Blog</a>
    </li>

    <li class="main-menu-item">
      <a href="https://pytorch.org/tutorials">Tutorials</a>
    </li>

    <li class="main-menu-item">
      <div id="docsDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow">
          Docs
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/docs">
            <span class="dropdown-title docs-title">PyTorch</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/audio">
            <span class="dropdown-title docs-title">torchaudio</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/text">
            <span class="dropdown-title docs-title">torchtext</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/vision">
            <span class="dropdown-title docs-title">torchvision</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/torcharrow">
            <span class="dropdown-title docs-title">torcharrow</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/data">
            <span class="dropdown-title docs-title">TorchData</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/torchrec">
            <span class="dropdown-title docs-title">TorchRec</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/serve">
            <span class="dropdown-title docs-title">TorchServe</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/xla/release/1.6/index.html">
            <span class="dropdown-title docs-title">PyTorch on XLA Devices</span>
            <p></p>
          </a>
        </div>
      </div>
    </li>

    

    <li class="main-menu-item ">

      <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow">
          Resources
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/features">
            <span class=dropdown-title>About</span>
            <p>Learn about PyTorch’s features and capabilities</p>
          </a>
          <a class="nav-dropdown-item" href="/foundation">
            <span class=dropdown-title>PyTorch Foundation</span>
            <p>Learn more about the PyTorch Foundation.</p>
          </a>
          <a class="nav-dropdown-item" href="/#community-module">
            <span class=dropdown-title>Community</span>
            <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
          </a>
          <a class="nav-dropdown-item" href="/community-stories">
            <span class=dropdown-title>Community stories</span>
            <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
          </a>
          <a class="nav-dropdown-item" href="/resources">
            <span class=dropdown-title>Developer Resources</span>
            <p>Find resources and get questions answered</p>
          </a>
          <a class="nav-dropdown-item" href="/events">
            <span class=dropdown-title>Events</span>
            <p>Find events, webinars, and podcasts</p>
          </a>
          <a class="nav-dropdown-item" href="https://discuss.pytorch.org" target="_blank">
            <span class=dropdown-title>Forums</span>
            <p>A place to discuss PyTorch code, issues, install, research</p>
          </a>
          <a class="nav-dropdown-item" href="/hub">
            <span class=dropdown-title>Models (Beta)</span>
            <p>Discover, publish, and reuse pre-trained models</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item" id="github-main-menu-link">
      <a href="https://github.com/pytorch/pytorch">GitHub</a>
    </li>

    <li class="navSearchWrapper reactNavSearchWrapper" key="search">
      <div class="search-border">
        <div id="search-icon"></div>
        <input
          id="search-input"
          type="text"
          title="Search"
        />
        <div id="close-search">X</div>
      </div>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

        </div>
    </div>

    <div class="jumbotron jumbotron-fluid blog-detail-jumbotron">
        <div class="container blog-detail-container">
            <p class="featured-post">November 29, 2023</p>
            <h1>
                <a class="blog-title">PyTorch 2.1 Contains New Performance Features for AI Developers</a>
            </h1>
        </div>
    </div>

    <div class="main-content-wrapper blog-detail-wrapper">
        <div class="main-content blog-detail-content">
            <div class="container">
                <img src="/assets/images/logo-icon.svg" class="img-fluid author-icon">
                <article class="pytorch-article">
                    <p class="author">
                      by
                      
                        Intel
                      
                    </p>
                    <p>We are excited to see the release of PyTorch 2.1. In this blog, we discuss the five features for which Intel made significant contributions to PyTorch 2.1:</p>

<ol>
  <li>TorchInductor-CPU optimizations including Bfloat16 inference path for torch.compile</li>
  <li>CPU dynamic shape inference path for torch.compile</li>
  <li>C++ wrapper (prototype)</li>
  <li>Flash-attention-based scaled dot product algorithm for CPU</li>
  <li>PyTorch 2 export post-training auantization with an x86 back end through an inductor</li>
</ol>

<p>At Intel, we are delighted to be part of the PyTorch community and appreciate the collaboration with and feedback from our colleagues at Meta* as we co-developed these features.</p>

<p>Let’s get started.</p>

<h2 id="torchinductor-cpu-optimizations">TorchInductor-CPU Optimizations</h2>

<p>This feature optimizes bfloat16 inference performance for TorchInductor. The 3rd and 4th generation Intel® Xeon® Scalable processors have built-in hardware accelerators for speeding up dot-product computation with the bfloat16 data type. Figure 1 shows a code snippet of how to specify the BF16 inference path.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user_model = ...

user_model.eval()
with torch.no_grad(), torch.autocast("cpu"):
	compiled_model = torch.compile(user_model)
	y = compiled_model(x)
</code></pre></div></div>

<p>Figure 1. Code snippet showing the use of BF16 inference with TorchInductor \</p>

<p>We measured the performance on three TorchInductor benchmark suites—TorchBench, Hugging Face<em>, and TIMM—and the results are as follows in Table 1. Here we see that performance in graph mode (TorchInductor) outperforms eager mode by factors ranging from 1.25x to 2.35x.</em></p>

<p>Table 1. Bfloat16 performance geometric mean speedup in graph mode, compared with eager mode</p>

<table class="table table-bordered">
  <tr>
   <td colspan="4">
<strong>Bfloat16 Geometric Mean Speedup (Single-Socket Multithreads)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
torchbench
   </td>
   <td>
huggingface
   </td>
   <td>
timm_models
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.81x
   </td>
   <td>
1.25x
   </td>
   <td>
2.35x
   </td>
  </tr>
</table>

<table class="table table-bordered">
  <tr>
   <td colspan="4">
<strong>Bfloat16 Geometric Mean Speedup (Single-Core Single Thread)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
torchbench
   </td>
   <td>
huggingface
   </td>
   <td>
timm_models
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.74x
   </td>
   <td>
1.28x
   </td>
   <td>
1.29x
   </td>
  </tr>
</table>

<p>Developers can fully deploy their models on 4th generation Intel Xeon processors to take advantage of the Intel® Advanced Matrix Extensions (Intel® AMX) feature to get peak performance for <code class="language-plaintext highlighter-rouge">torch.compile</code>. Intel AMX has two primary components: tiles and tiled matrix multiplication (TMUL). The tiles store large amounts of data in eight two-dimensional registers, each one kilobyte in size. TMUL is an accelerator engine attached to the tiles that contain instructions to compute larger matrices in a single operation.</p>

<h2 id="cpu-dynamic-shapes-inference-path-for-torchcompile">CPU Dynamic Shapes Inference Path for torch.compile</h2>

<p>Dynamic shapes is one of the key features in PyTorch 2.0. PyTorch 2.0 assumes everything is static by default. If we recompile because a size changed, we will instead attempt to recompile that size as being dynamic (sizes that have changed are likely to change in the future). Dynamic shapes support is required for popular models like large language models (LLM). Dynamic shapes that provide support for a broad scope of models can help users get more benefit from torch.compile. For dynamic shapes, we provide the post-op fusion for conv/gemm operators and vectorization code-gen for non-conv/gemm operators.</p>

<p>Dynamic shapes is supported by both the inductor Triton back end for CUDA* and the C++ back end for CPU. The scope covers improvements for both functionality (as measured by model passing rate) and performance (as measured by inference latency/throughput). Figure 2 shows a code snippet for the use of dynamic shape inference with TorchInductor.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>user_model = ...

# Training example
compiled_model = torch.compile(user_model)
y = compiled_model(x_size1)
# Here trigger the recompile because the input size changed
y = compiled_model(x_size2)


# Inference example
user_model.eval()
compiled_model = torch.compile(user_model)
with torch.no_grad():
	y = compiled_model(x_size1)
 # Here trigger the recompile because the input size changed
 y = compiled_model(x_size2)
</code></pre></div></div>

<p>Figure 2. Code snippet showing the use of dynamic shape inference with TorchInductor</p>

<p>We again measured the performance on the three TorchInductor benchmark suites—TorchBench, Hugging Face, and TIMM—and the results are in Table 2. Here we see that performance in graph mode outperforms eager mode by factors ranging from 1.15x to 1.79x.</p>

<p>Table 2. Dynamic shape geometric mean speedup compared with Eager mode</p>

<table class="table table-bordered">
  <tr>
   <td colspan="4">
<strong>Dynamic Shape Geometric Mean Speedup (Single-Socket Multithreads)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
torchbench
   </td>
   <td>
huggingface
   </td>
   <td>
timm_models
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.35x
   </td>
   <td>
1.15x
   </td>
   <td>
1.79x
   </td>
  </tr>
</table>

<table class="table table-bordered">
  <tr>
   <td colspan="4">
<strong>Dynamic Shape Geometric Mean Speedup (Single-Core Single-Thread)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
torchbench
   </td>
   <td>
huggingface
   </td>
   <td>
timm_models
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.48x
   </td>
   <td>
1.15x
   </td>
   <td>
1.48x
   </td>
  </tr>
</table>

<h2 id="c-wrapper-prototype">C++ Wrapper (Prototype)</h2>

<p>The feature generates C++ code instead of Python* code to invoke the generated kernels and external kernels in TorchInductor to reduce Python overhead. It is also an intermediate step to support deployment in environments without Python.</p>

<p>To enable this feature, use the following configuration:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import torch
import torch._inductor.config as config
config.cpp_wrapper = True
</code></pre></div></div>

<p>For light workloads where the overhead of the Python wrapper is more dominant, C++ wrapper demonstrates a higher performance boost ratio. We grouped the models in TorchBench, Hugging Face, and TIMM per the average inference time of one iteration and categorized them into small, medium, and large categories. Table 3 shows the geometric mean speedups achieved by the C++ wrapper in comparison to the default Python wrapper.</p>

<p>Table 3. C++ wrapper geometric mean speedup compared with Eager mode</p>

<table class="table table-bordered">
  <tr>
   <td colspan="4">
<strong>FP32 Static Shape Mode Geometric Mean Speedup (Single-Socket Multithreads)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
Small (t &lt;= 0.04s)
   </td>
   <td>
Medium (0.04s &lt; t &lt;= 1.5s)
   </td>
   <td>
Large (t &gt; 1.5s)
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.06x
   </td>
   <td>
1.01x
   </td>
   <td>
1.00x
   </td>
  </tr>
</table>

<table class="table table-bordered">
  <tr>
   <td colspan="4">
<strong>FP32 Static Shape Mode Geometric Mean Speedup (Single-Core Single-Thread)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
Small (t &lt;= 0.04s)
   </td>
   <td>
Medium (0.04s &lt; t &lt;= 1.5s)
   </td>
   <td>
Large (t &gt; 1.5s)
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.13x
   </td>
   <td>
1.02x
   </td>
   <td>
1.01x
   </td>
  </tr>
</table>

<table class="table table-bordered">
  <tr>
   <td colspan="4">
<strong>FP32 Dynamic Shape Mode Geometric Mean Speedup (Single-Socket Multithreads)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
Small (t &lt;= 0.04s)
   </td>
   <td>
Medium (0.04s &lt; t &lt;= 1.5s)
   </td>
   <td>
Large (t &gt; 1.5s)
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.05x
   </td>
   <td>
1.01x
   </td>
   <td>
1.00x
   </td>
  </tr>
</table>

<table class="table table-bordered">
  <tr>
   <td colspan="4">
<strong>FP32 Dynamic Shape Mode Geometric Mean Speedup (Single-Core Single-Thread)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
Small (t &lt;= 0.04s)
   </td>
   <td>
Medium (0.04s &lt; t &lt;= 1.5s)
   </td>
   <td>
Large (t &gt; 1.5s)
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.14x
   </td>
   <td>
1.02x
   </td>
   <td>
1.01x
   </td>
  </tr>
</table>

<table class="table table-bordered">
  <tr>
   <td colspan="4">
<strong>BF16 Static Shape Mode Geometric Mean Speedup (Single-Socket Multithreads)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
Small (t &lt;= 0.04s)
   </td>
   <td>
Medium (0.04s &lt; t &lt;= 1.5s)
   </td>
   <td>
Large (t &gt; 1.5s)
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.09x
   </td>
   <td>
1.03x
   </td>
   <td>
1.04x
   </td>
  </tr>
</table>

<table class="table table-bordered">
  <tr>
   <td colspan="4">
<strong>BF16 Static Shape Mode Geometric Mean Speedup (Single-Core Single-Thread)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
Small (t &lt;= 0.04s)
   </td>
   <td>
Medium (0.04s &lt; t &lt;= 1.5s)
   </td>
   <td>
Large (t &gt; 1.5s)
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.17x
   </td>
   <td>
1.04x
   </td>
   <td>
1.03x
   </td>
  </tr>
</table>

<h2 id="flash-attention-based-scaled-dot-product-algorithm-for-cpu">Flash-Attention-Based Scaled Dot Product Algorithm for CPU</h2>

<p>Scaled dot product attention (SDPA) is one of the flagship features of PyTorch 2.0 that helps speed up transformer models. It is accelerated with optimal CUDA kernels while still lacking optimized CPU kernels. This flash-attention implementation targets both training and inference, with both FP32 and Bfloat16 data types supported. There is no front-end use change for users to leverage this SDPA optimization. When calling SDPA, a specific implementation will be chosen automatically, including this new implementation.</p>

<p>We have measured the SDPA-related models in Hugging Face, and they are proven effective when compared to the unfused SDPA. Shown in Table 4 are the geometric mean speedups for SDPA optimization. \</p>

<p>Table 4. SDPA optimization performance geometric mean speedup</p>

<table class="table table-bordered">
  <tr>
   <td colspan="3">
<strong>SDPA Geometric Mean Speedup (Single-Socket Multithreads)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
Geometric Speedup FP32
   </td>
   <td>
Geometric Speedup BF16
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.15x, 20/20
   </td>
   <td>
1.07x, 20/20
   </td>
  </tr>
</table>

<table class="table table-bordered">
  <tr>
   <td colspan="3">
<strong>SDPA Geometric Mean Speedup (Single-Core Single-Thread)</strong>
   </td>
  </tr>
  <tr>
   <td>
Compiler
   </td>
   <td>
Geometric Speedup FP32
   </td>
   <td>
Geometric Speedup BF16
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
1.02x, 20/20
   </td>
   <td>
1.04x, 20/20
   </td>
  </tr>
</table>

<h2 id="pytorch-2-export-post-training-quantization-with-x86-back-end-through-inductor">PyTorch 2 Export Post-Training Quantization with x86 Back End through Inductor</h2>

<p>PyTorch provides a new quantization flow in the PyTorch 2.0 export. This feature uses TorchInductor with an x86 CPU device as the back end for post-training static quantization with this new quantization flow. An example code snippet is shown in Figure 3.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import torch
import torch._dynamo as torchdynamo
from torch.ao.quantization.quantize_pt2e import convert_pt2e, prepare_pt2e
import torch.ao.quantization.quantizer.x86_inductor_quantizer as xiq

model = ... 

model.eval()
with torch.no_grad():
 # Step 1: Trace the model into an FX graph of flattened ATen operators
 exported_graph_module, guards = torchdynamo.export(
	 model,
	 *copy.deepcopy(example_inputs),
	 aten_graph=True,
 )

 # Step 2: Insert observers or fake quantize modules
 quantizer = xiq.X86InductorQuantizer()
 operator_config = xiq.get_default_x86_inductor_quantization_config()
 quantizer.set_global(operator_config)
 prepared_graph_module = prepare_pt2e(exported_graph_module, quantizer)

 # Doing calibration here.

 # Step 3: Quantize the model
 convert_graph_module = convert_pt2e(prepared_graph_module)

 # Step 4: Lower Quantized Model into the backend
 compile_model = torch.compile(convert_graph_module)
</code></pre></div></div>

<p>Figure 3. Code snippet showing the use of Inductor as back end for PyTorch 2 export post-training quantization</p>

<p>All convolutional neural networks (CNN) models from the TorchBench test suite have been measured and proven effective when compared with the Inductor FP32 inference path. Performance metrics are shown in Table 5.</p>

<table class="table table-bordered">
  <tr>
   <td>
<strong>Compiler</strong>
   </td>
   <td>
<strong>Geometric Speedup</strong>
   </td>
   <td>
<strong>Geometric Related Accuracy Loss</strong>
   </td>
  </tr>
  <tr>
   <td>
inductor
   </td>
   <td>
3.25x, 12/12
   </td>
   <td>
0.44%, 12/12
   </td>
  </tr>
</table>

<h2 id="next-steps">Next Steps</h2>

<h3 id="get-the-software">Get the Software</h3>

<p>Try out <a href="https://github.com/pytorch/pytorch/releases/tag/v2.1.0">PyTorch 2.1</a> and realize the performance benefits for yourself from these features contributed by Intel.</p>

<p>We encourage you to check out Intel’s other <a href="https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/tools.html">AI Tools</a> and <a href="https://www.intel.com/content/www/us/en/developer/tools/frameworks/overview.html">framework</a> optimizations and learn about the open, standards-based <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/overview.html">oneAPI</a> multiarchitecture, multivendor programming model that forms the foundation of Intel’s AI software portfolio.</p>

<p>For more details about the 4th generation Intel Xeon Scalable processor, visit the <a href="https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/platform.html">AI platform</a> where you can learn how Intel is empowering developers to run high-performance, efficient end-to-end AI pipelines.</p>

<h3 id="pytorch-resources">PyTorch Resources</h3>

<ul>
  <li><a href="http://pytorch.org/get-started/pytorch-2.0/">PyTorch Get Started</a></li>
  <li><a href="http://dev-discuss.pytorch.org/t/pytorch-release-2-0-execution-update/1077">Dev Discussions</a></li>
  <li><a href="http://pytorch.org/docs/2.0/">Documentation</a></li>
</ul>

<h3 id="product-and-performance-information">Product and Performance Information</h3>

<p>1 Amazon EC2* m7i.16xlarge: 1-node, Intel Xeon Platinum 8488C processor with 256 GB memory (1 x 256 GB DDR5 4800 MT/s), microcode 0x2b000461, hyperthreading on, turbo on, Ubuntu* 22.04.3 LTS, kernel 6.2.0-1011-aws, GCC* 11.3.0, Amazon Elastic Block Store 200 GB, BIOS Amazon EC2 1.0 10/16/2017; Software: <a href="https://github.com/pytorch/pytorch/tree/release/2.1">PyTorch 2.1.0_rc4</a>, <a href="https://github.com/oneapi-src/oneDNN/tree/v3.1.1">Intel® oneAPI Deep Neural Network Library (oneDNN) version 3.1.1</a>, <a href="https://github.com/pytorch/benchmark/commit/ffbbebb9">TorchBench</a>, <a href="https://github.com/pytorch/vision/commit/8636bf3">TorchVision</a>, <a href="https://github.com/pytorch/text/commit/142d029">TorchText</a>, <a href="https://github.com/pytorch/audio/commit/475b6ae">TorchAudio</a>, <a href="https://github.com/pytorch/data/commit/eb9bf61">TorchData</a>, <a href="https://github.com/pytorch/pytorch/tree/release/2.1/benchmarks/dynamo">TorchDynamo Benchmarks</a>, tested by Intel on 9/12/2023.</p>

<p>2 Amazon EC2 c6i.16xlarge: 1-node, Intel Xeon Platinum 8375C processor with 128 GB memory (1 x 128 GB DDR4 3200 MT/s), microcode 0xd0003a5, hyperthreading on, turbo on, Ubuntu 22.04.2 LTS, kernel 6.2.0-1011-aws, gcc 11.3.0, Amazon Elastic Block Store 200 GB, BIOS Amazon EC2 1.010/16/2017; Software: <a href="https://github.com/pytorch/pytorch/tree/release/2.1">PyTorch 2.1.0_rc4</a>, <a href="https://github.com/oneapi-src/oneDNN/tree/v3.1.1">oneDNN version 3.1.1</a>, <a href="https://github.com/pytorch/benchmark/commit/ffbbebb9">TorchBench</a>, <a href="https://github.com/pytorch/vision/commit/8636bf3">TorchVision</a>, <a href="https://github.com/pytorch/text/commit/142d029">TorchText</a>, <a href="https://github.com/pytorch/audio/commit/475b6ae">TorchAudio</a>, <a href="https://github.com/pytorch/data/commit/eb9bf61">TorchData</a>, <a href="https://github.com/pytorch/pytorch/tree/release/2.1/benchmarks/dynamo">TorchDynamo Benchmarks</a>, <a href="https://github.com/pytorch/benchmark/tree/chuanqiw/inductor_quant/userbenchmark/cpu">TorchBench cpu userbenchmark</a>, tested by Intel on 9/12/2023.</p>

                </article>
            </div>
        </div>
    </div>

<!--    


 -->
    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="/docs">View Docs</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.org" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.org">PyTorch</a></li>
          <li><a href="/get-started">Get Started</a></li>
          <li><a href="/features">Features</a></li>
          <li><a href="/ecosystem">Ecosystem</a></li>
          <li><a href="/blog">Blog</a></li>
          <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          <li><a href="https://github.com/pytorch/pytorch/security/policy" target="_blank">Security</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="/resources">Resources</a></li>
          <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
          <li><a href="/docs">Docs</a></li>
          <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
          <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">GitHub Issues</a></li>
          <li><a href="/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><p>Stay up to date</p></li>
          <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
          <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
          <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
          <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          <li><a href="https://social.lfx.dev/@pytorch" rel="me" target="_blank">Mastodon</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><p>PyTorch Podcasts</p></li>
          <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
          <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
          <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
          <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
        </ul>
      </div>
    </div>

    <div class="privacy-policy">
      <ul>
        <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
        <li class="privacy-policy-links">|</li>
        <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
      </ul>
      <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation. 
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see 
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source 
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC, 
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
    </div>
  </div>
  <img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>
        <li class="navSearchWrapper reactNavSearchWrapper tabletSearchWrapper" key="search">
          <div class="mobile-search-border">
            <input
              id="mobile-search-input"
              type="text"
              title="Search"
            />
            <div id="mobile-search-icon"></div>
          </div>
        </li>

        <li class="">
          <a href="/get-started">Get Started</a>
        </li>

        <li class="resources-mobile-menu-title">
          <a>Ecosystem</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/ecosystem">Tools</a>
          </li>
          <li>
            <a href="/ecosystem/ptc/2022">PyTorch Conference - 2022</a>
          </li>
          <li>
            <a href="https://events.linuxfoundation.org/pytorch-conference/">PyTorch Conference - 2023</a>
          </li>
          <li>
            <a href="/ecosystem/contributor-awards-2023">Contributor Awards - 2023</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>PyTorch Edge </a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/edge">About PyTorch Edge</a>
          </li>
          <li>
            <a href="/executorch-overview">ExecuTorch</a>
          </li>
        </ul>

        <li class="active">
          <a href="/blog">Blog</a>
        </li>

        <li>
          <a href="https://pytorch.org/tutorials">Tutorials</a>
        </li>

        <li class="resources-mobile-menu-title">
          <a href="/docs">Docs</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li class="">
            <a href="/docs">PyTorch</a>
          </li>

          <li class="">
            <a href="/audio">torchaudio</a>
          </li>

          <li class="">
            <a href="/text">torchtext</a>
          </li>

          <li class="">
            <a href="/vision">torchvision</a>
          </li>

          <li class="">
            <a href="/torcharrow">torcharrow</a>
          </li>

          <li class="">
            <a href="/data">TorchData</a>
          </li> 

          <li class="">
            <a href="/torchrec">TorchRec</a>
          </li>

          <li class="">
            <a href="/serve">TorchServe</a>
          </li>

          <li class="">
            <a href="/xla/release/1.6/index.html">PyTorch on XLA Devices</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          Resources
        </li>

        <ul class="resources-mobile-menu-items">
          <li class="">
            <a href="/features">About</a>
          </li>

          <li>
            <a href="/foundation">PyTorch Foundation</a>
          </li>
          
          <li>
            <a href="/#community-module">Community</a>
          </li>
          
          <li class="">
            <a href="/community-stories">Community stories</a>
          </li>

          <li class="">
            <a href="/resources">Developer Resources</a>
          </li>

          <li>
            <a href="/events">Events</a>
          </li>

          <li>
            <a href="https://discuss.pytorch.org">Forum</a>
          </li>

          <li class="">
            <a href="/hub">Models (Beta)</a>
          </li>

        </ul>

        <li id="github-mobile-menu-link">
          <a href="https://github.com/pytorch/pytorch">GitHub</a>
        </li>
      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>

  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script>

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>


  <script src="/assets/track-events.js"></script>
  <script>trackEvents.bind();</script>



<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="/assets/images/pytorch-x.svg">
  </div>
</div>


</body>

</html>
