<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
  <!-- End Google Tag Manager -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      The Path to Achieve PyTorch Performance Boost on Windows CPU | PyTorch
    
  </title>
  <meta name="robots" content="index, follow" />

<meta name="description" content="The challenge of PyTorch’s lower CPU performance on Windows compared to Linux has been a significant issue. There are multiple factors leading to this performance disparity. Through our investigation, we’ve identified several reasons for poor CPU performance on Windows, two primary issues have been pinpointed: the inefficiency of the Windows default malloc memory allocator and the absence of SIMD for vectorization optimizations on the Windows platform. In this article, we show how PyTorch CPU performance on Windows has improved from the previous releases and where it stands as of PyTorch 2.4.1.

Memory Allocation Optimization in PyTorch 2.1.2 and later

In versions prior to PyTorch 2.1.2, PyTorch relied on the operating system’s default malloc function for memory allocation. The default malloc memory allocation on the Windows platform was less efficient compared to the malloc implementation mechanism on the Linux platform, leading to increased memory allocation times and reduced performance. To address this, we have substituted the default Windows malloc with mimalloc, a more efficient memory allocator developed by Microsoft. This update, included with the release of PyTorch 2.1.2 and later, has significantly enhanced the CPU performance of PyTorch on Windows, as shown in Figure 1.1.



PyTorch CPU Performance Improvement on Windows with Memory Allocation Optimization

Figure 1.1: Relative throughput improvement achieved by upgrading from Windows PyTorch version 2.0.1 to 2.1.2 (higher is better).

The graph illustrates that with the release of PyTorch 2.1.2, there has been a notable enhancement in CPU performance on the Windows platform. The degree of improvement varies across different models, which can be attributed to the diverse mix of operations they perform and their corresponding memory access patterns. While the BERT model shows a modest performance gain, models like ResNet50 and MobileNet-v3 Large benefit from more pronounced improvements.

On a high-performance CPU, memory allocation becomes a performance bottleneck. This is also why addressing this issue has led to such significant performance improvements.

As shown in the graphs below, we see that PyTorch CPU performance on Windows can significantly be improved. However, there is still a noticeable gap when compared to its performance on Linux. The absence of vectorization optimizations in the Windows variant of PyTorch CPU is a key factor to the remaining performance gap.



Windows vs Linux Performance on PyTorch 2.0.1

Figure 1.2: Relative performance of Windows vs Linux with PyTorch version 2.0.1 (higher is better).



Windows vs Linux Performance on PyTorch 2.1.2

Figure 1.3: Relative performance of Windows vs Linux with PyTorch version 2.1.2 (higher is better).

Vectorization Optimization in PyTorch 2.4.1 and later

Prior to PyTorch 2.4.1, the Windows build of PyTorch lacked SIMD for vectorization optimizations, a feature that the Linux build leveraged for improved performance. This discrepancy was due to the SLEEF Library’s integration issues on Windows, which is a SIMD Library for Evaluating Elementary Functions, vectorized libm and DFT and is essential for efficient trigonometric calculations. Through a collaborative effort with engineers from ARM and Qualcomm, these challenges were resolved, enabling the integration of SIMD into PyTorch for Windows. The PyTorch 2.4.1 update has thus significantly enhanced PyTorch’s CPU performance on Windows, as shown in Figure 2.1.



PyTorch CPU Performance Improvement on Windows with Vertorization Optimization

Figure 2.1: Relative throughput improvement achieved by upgrading from PyTorch CPU version 2.1.2 to 2.4.1 (higher is better).

As shown in the graph below, we see that PyTorch CPU performance on Windows ahieved the performance on Linux.



Windows vs Linux Performance on PyTorch 2.4.1

Figure 2.2: Relative performance of Windows vs Linux with PyTorch version 2.4.1 (higher is better).

CONCLUSION

From PyTorch 2.0.1 to PyTorch 2.4.1, the CPU performance gap between Windows and Linux has been continuously narrowing. We compared the ratio of CPU performance on Windows to CPU performance on Linux across different versions, and the results are shown in the following graph.



Windows vs Linux Performance on different version of PyTorch

Figure 3: Performance Ratio for Windows to Linux with different version of PyTorch (higher is better).

The graph shows that with PyTorch 2.4.1, CPU performance on Windows has nearly converged with that on Linux, and on some models, it has even surpassed Linux. For example, in the case of DistillBERT and RoBERTa models, the CPU performance ratio of Windows to Linux has achieved a remarkable 102%. However, certain models, including MobileNet-v3, still show a performance discrepancy. Intel engineers will continue to collaborate with Meta engineers, to reduce the performance gap of PyTorch CPU between Windows and Linux.

HOW TO TAKE ADVANTAGE OF THE OPTIMIZATIONS

Install PyTorch CPU 2.4.1 or later on Windows from the official repository, and you may automatically experience a performance boost with memory allocation and vectorizations.

ACKNOWLEDGMENTS

The results presented in this blog post was achieved through the collaborative effort of the Intel PyTorch team and Meta. We would like to express our sincere gratitude to Xu Han, Jiong Gong, Haozhe Zhu, Mingfei Ma, Chuanqi Wang, Guobing Chen and Eikan Wang. Their expertise and dedication have been instrumental in achieving the optimizations and performance improvements discussed here. Thanks to Jiachen Pu from community for his participation in the issue discussion and suggesting the use of mimalloc. We’d also like to express our gratitude to Microsoft for providing such an easily integrated and performant mallocation library. Thanks to Pierre Blanchard , Nathan Sircombe from ARM and Alex Reinking from Adobe for their contribution in overcome the compatibility issues with the sleef integrated to PyTorch Windows. Finally we want to thank Jing Xu, Weizhuo Zhang and Zhaoqiong Zheng for their contributions to this blog.

Product and Performance Information

The configurations in the table are collected with svr-info. Test by Intel on August 30, 2024.


  
   Specification
   
   Configuration1
   
   Configuration2
   
  
  
   Name
   
   ThinkBook 14 G5+ IRH
   
   ThinkBook 14 G5+ IRH
   
  
  
   Time
   
   Fri Aug 30 02:43:02 PM UTC 2024
   
   Fri Aug 30 02:43:02 PM UTC 2024
   
  
  
   System
   
   LENOVO
   
   LENOVO
   
  
  
   Baseboard
   
   LENOVO
   
   LENOVO
   
  
  
   Chassis
   
   LENOVO
   
   LENOVO
   
  
  
   CPU Model
   
   13th Gen Intel(R) Core(TM) i7-13700H
   
   13th Gen Intel(R) Core(TM) i7-13700H
   
  
  
   Microarchitecture
   
   Unknown Intel
   
   Unknown Intel
   
  
  
   Sockets
   
   1
   
   1
   
  
  
   Cores per Socket
   
   14
   
   14
   
  
  
   Hyperthreading
   
   Enabled
   
   Enabled
   
  
  
   CPUs
   
   20
   
   20
   
  
  
   Intel Turbo Boost
   
   Enabled
   
   Enabled
   
  
  
   Base Frequency
   
   2.4GHz
   
   2.4GHz
   
  
  
   All-core Maximum Frequency
   
   4.7GHz
   
   4.7GHz
   
  
  
   Maximum Frequency
   
   4.8GHz
   
   4.8GHz
   
  
  
   NUMA Nodes
   
   1
   
   1
   
  
  
   Prefetchers
   
   L2 HW: Enabled, L2 Adj.: Enabled, DCU HW: Enabled, DCU IP: Enabled
   
   L2 HW: Enabled, L2 Adj.: Enabled, DCU HW: Enabled, DCU IP: Enabled
   
  
  
   PPINs
   
   -
   
   -
   
  
  
   Accelerators
   
   DLB, DSA, IAA, QAT
   
   DLB, DSA, IAA, QAT
   
  
  
   Installed Memory
   
   32GB (8x4GB LPDDR4 7400 MT/s [5200 MT/s])
   
   32GB (8x4GB LPDDR4 7400 MT/s [5200 MT/s])
   
  
  
   Hugepagesize
   
   2048kb
   
   2048kb
   
  
  
   Transparent Huge Pages
   
   madvise
   
   madvise
   
  
  
   Automatic NUMA Balancing
   
   Disabled
   
   Disabled
   
  
  
   NIC
   
   “1. Raptor Lake PCH CNVi WiFi 2. Intel Corporation”
   
   “1. Raptor Lake PCH CNVi WiFi 2. Intel Corporation”
   
  
  
   Disk
   
   Micron MTFDKBA512TFH 500G
   
   Micron MTFDKBA512TFH 500G
   
  
  
   BIOS
   
   LBCN22WW
   
   LBCN22WW
   
  
  
   Microcode
   
   0x411c
   
   0x411c
   
  
  
   OS
   
   Windows 11 Desktop
   
   Ubuntu 23.10
   
  
  
   Kernel
   
   OS Build 19045.4412
   
   6.5.0-27-generic
   
  
  
   TDP
   
   200 watts
   
   200 watts
   
  
  
   Power &amp; Perf Policy
   
   Normal Powersave (7)
   
   Normal Powersave (7)
   
  
  
   Frequency Governor
   
   performance
   
   performance
   
  
  
   Frequency Driver
   
   intel_pstate
   
   intel_pstate
   
  
  
   Max C-State
   
   9
   
   9
   
  


Notices and Disclaimers

Performance varies by use, configuration and other factors. Learn more on the Performance Index site.

Performance results are based on testing as of dates shown in configurations and may not reflect all publicly available updates. See backup for configuration details. No product or component can be absolutely secure. Your costs and results may vary. Intel technologies may require enabled hardware, software or service activation.

Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.
" />

  <meta property="og:image" content="https://pytorch.org/assets/images/social-share.jpg" />
  <meta name="twitter:image" content="https://pytorch.org/assets/images/social-share.jpg" />

<meta property="og:locale" content="en_US" />
<meta property="og:type" content="website" />
<meta property="og:title" content="The Path to Achieve PyTorch Performance Boost on Windows CPU" />
<meta property="og:description" content="The challenge of PyTorch’s lower CPU performance on Windows compared to Linux has been a significant issue. There are multiple factors leading to this performance disparity. Through our investigation, we’ve identified several reasons for poor CPU performance on Windows, two primary issues have been pinpointed: the inefficiency of the Windows default malloc memory allocator and the absence of SIMD for vectorization optimizations on the Windows platform. In this article, we show how PyTorch CPU performance on Windows has improved from the previous releases and where it stands as of PyTorch 2.4.1.

Memory Allocation Optimization in PyTorch 2.1.2 and later

In versions prior to PyTorch 2.1.2, PyTorch relied on the operating system’s default malloc function for memory allocation. The default malloc memory allocation on the Windows platform was less efficient compared to the malloc implementation mechanism on the Linux platform, leading to increased memory allocation times and reduced performance. To address this, we have substituted the default Windows malloc with mimalloc, a more efficient memory allocator developed by Microsoft. This update, included with the release of PyTorch 2.1.2 and later, has significantly enhanced the CPU performance of PyTorch on Windows, as shown in Figure 1.1.



PyTorch CPU Performance Improvement on Windows with Memory Allocation Optimization

Figure 1.1: Relative throughput improvement achieved by upgrading from Windows PyTorch version 2.0.1 to 2.1.2 (higher is better).

The graph illustrates that with the release of PyTorch 2.1.2, there has been a notable enhancement in CPU performance on the Windows platform. The degree of improvement varies across different models, which can be attributed to the diverse mix of operations they perform and their corresponding memory access patterns. While the BERT model shows a modest performance gain, models like ResNet50 and MobileNet-v3 Large benefit from more pronounced improvements.

On a high-performance CPU, memory allocation becomes a performance bottleneck. This is also why addressing this issue has led to such significant performance improvements.

As shown in the graphs below, we see that PyTorch CPU performance on Windows can significantly be improved. However, there is still a noticeable gap when compared to its performance on Linux. The absence of vectorization optimizations in the Windows variant of PyTorch CPU is a key factor to the remaining performance gap.



Windows vs Linux Performance on PyTorch 2.0.1

Figure 1.2: Relative performance of Windows vs Linux with PyTorch version 2.0.1 (higher is better).



Windows vs Linux Performance on PyTorch 2.1.2

Figure 1.3: Relative performance of Windows vs Linux with PyTorch version 2.1.2 (higher is better).

Vectorization Optimization in PyTorch 2.4.1 and later

Prior to PyTorch 2.4.1, the Windows build of PyTorch lacked SIMD for vectorization optimizations, a feature that the Linux build leveraged for improved performance. This discrepancy was due to the SLEEF Library’s integration issues on Windows, which is a SIMD Library for Evaluating Elementary Functions, vectorized libm and DFT and is essential for efficient trigonometric calculations. Through a collaborative effort with engineers from ARM and Qualcomm, these challenges were resolved, enabling the integration of SIMD into PyTorch for Windows. The PyTorch 2.4.1 update has thus significantly enhanced PyTorch’s CPU performance on Windows, as shown in Figure 2.1.



PyTorch CPU Performance Improvement on Windows with Vertorization Optimization

Figure 2.1: Relative throughput improvement achieved by upgrading from PyTorch CPU version 2.1.2 to 2.4.1 (higher is better).

As shown in the graph below, we see that PyTorch CPU performance on Windows ahieved the performance on Linux.



Windows vs Linux Performance on PyTorch 2.4.1

Figure 2.2: Relative performance of Windows vs Linux with PyTorch version 2.4.1 (higher is better).

CONCLUSION

From PyTorch 2.0.1 to PyTorch 2.4.1, the CPU performance gap between Windows and Linux has been continuously narrowing. We compared the ratio of CPU performance on Windows to CPU performance on Linux across different versions, and the results are shown in the following graph.



Windows vs Linux Performance on different version of PyTorch

Figure 3: Performance Ratio for Windows to Linux with different version of PyTorch (higher is better).

The graph shows that with PyTorch 2.4.1, CPU performance on Windows has nearly converged with that on Linux, and on some models, it has even surpassed Linux. For example, in the case of DistillBERT and RoBERTa models, the CPU performance ratio of Windows to Linux has achieved a remarkable 102%. However, certain models, including MobileNet-v3, still show a performance discrepancy. Intel engineers will continue to collaborate with Meta engineers, to reduce the performance gap of PyTorch CPU between Windows and Linux.

HOW TO TAKE ADVANTAGE OF THE OPTIMIZATIONS

Install PyTorch CPU 2.4.1 or later on Windows from the official repository, and you may automatically experience a performance boost with memory allocation and vectorizations.

ACKNOWLEDGMENTS

The results presented in this blog post was achieved through the collaborative effort of the Intel PyTorch team and Meta. We would like to express our sincere gratitude to Xu Han, Jiong Gong, Haozhe Zhu, Mingfei Ma, Chuanqi Wang, Guobing Chen and Eikan Wang. Their expertise and dedication have been instrumental in achieving the optimizations and performance improvements discussed here. Thanks to Jiachen Pu from community for his participation in the issue discussion and suggesting the use of mimalloc. We’d also like to express our gratitude to Microsoft for providing such an easily integrated and performant mallocation library. Thanks to Pierre Blanchard , Nathan Sircombe from ARM and Alex Reinking from Adobe for their contribution in overcome the compatibility issues with the sleef integrated to PyTorch Windows. Finally we want to thank Jing Xu, Weizhuo Zhang and Zhaoqiong Zheng for their contributions to this blog.

Product and Performance Information

The configurations in the table are collected with svr-info. Test by Intel on August 30, 2024.


  
   Specification
   
   Configuration1
   
   Configuration2
   
  
  
   Name
   
   ThinkBook 14 G5+ IRH
   
   ThinkBook 14 G5+ IRH
   
  
  
   Time
   
   Fri Aug 30 02:43:02 PM UTC 2024
   
   Fri Aug 30 02:43:02 PM UTC 2024
   
  
  
   System
   
   LENOVO
   
   LENOVO
   
  
  
   Baseboard
   
   LENOVO
   
   LENOVO
   
  
  
   Chassis
   
   LENOVO
   
   LENOVO
   
  
  
   CPU Model
   
   13th Gen Intel(R) Core(TM) i7-13700H
   
   13th Gen Intel(R) Core(TM) i7-13700H
   
  
  
   Microarchitecture
   
   Unknown Intel
   
   Unknown Intel
   
  
  
   Sockets
   
   1
   
   1
   
  
  
   Cores per Socket
   
   14
   
   14
   
  
  
   Hyperthreading
   
   Enabled
   
   Enabled
   
  
  
   CPUs
   
   20
   
   20
   
  
  
   Intel Turbo Boost
   
   Enabled
   
   Enabled
   
  
  
   Base Frequency
   
   2.4GHz
   
   2.4GHz
   
  
  
   All-core Maximum Frequency
   
   4.7GHz
   
   4.7GHz
   
  
  
   Maximum Frequency
   
   4.8GHz
   
   4.8GHz
   
  
  
   NUMA Nodes
   
   1
   
   1
   
  
  
   Prefetchers
   
   L2 HW: Enabled, L2 Adj.: Enabled, DCU HW: Enabled, DCU IP: Enabled
   
   L2 HW: Enabled, L2 Adj.: Enabled, DCU HW: Enabled, DCU IP: Enabled
   
  
  
   PPINs
   
   -
   
   -
   
  
  
   Accelerators
   
   DLB, DSA, IAA, QAT
   
   DLB, DSA, IAA, QAT
   
  
  
   Installed Memory
   
   32GB (8x4GB LPDDR4 7400 MT/s [5200 MT/s])
   
   32GB (8x4GB LPDDR4 7400 MT/s [5200 MT/s])
   
  
  
   Hugepagesize
   
   2048kb
   
   2048kb
   
  
  
   Transparent Huge Pages
   
   madvise
   
   madvise
   
  
  
   Automatic NUMA Balancing
   
   Disabled
   
   Disabled
   
  
  
   NIC
   
   “1. Raptor Lake PCH CNVi WiFi 2. Intel Corporation”
   
   “1. Raptor Lake PCH CNVi WiFi 2. Intel Corporation”
   
  
  
   Disk
   
   Micron MTFDKBA512TFH 500G
   
   Micron MTFDKBA512TFH 500G
   
  
  
   BIOS
   
   LBCN22WW
   
   LBCN22WW
   
  
  
   Microcode
   
   0x411c
   
   0x411c
   
  
  
   OS
   
   Windows 11 Desktop
   
   Ubuntu 23.10
   
  
  
   Kernel
   
   OS Build 19045.4412
   
   6.5.0-27-generic
   
  
  
   TDP
   
   200 watts
   
   200 watts
   
  
  
   Power &amp; Perf Policy
   
   Normal Powersave (7)
   
   Normal Powersave (7)
   
  
  
   Frequency Governor
   
   performance
   
   performance
   
  
  
   Frequency Driver
   
   intel_pstate
   
   intel_pstate
   
  
  
   Max C-State
   
   9
   
   9
   
  


Notices and Disclaimers

Performance varies by use, configuration and other factors. Learn more on the Performance Index site.

Performance results are based on testing as of dates shown in configurations and may not reflect all publicly available updates. See backup for configuration details. No product or component can be absolutely secure. Your costs and results may vary. Intel technologies may require enabled hardware, software or service activation.

Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.
" />
<meta property="og:site_name" content="PyTorch" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="The Path to Achieve PyTorch Performance Boost on Windows CPU" />
<meta name="twitter:description" content="The challenge of PyTorch’s lower CPU performance on Windows compared to Linux has been a significant issue. There are multiple factors leading to this performance disparity. Through our investigation, we’ve identified several reasons for poor CPU performance on Windows, two primary issues have been pinpointed: the inefficiency of the Windows default malloc memory allocator and the absence of SIMD for vectorization optimizations on the Windows platform. In this article, we show how PyTorch CPU performance on Windows has improved from the previous releases and where it stands as of PyTorch 2.4.1.

Memory Allocation Optimization in PyTorch 2.1.2 and later

In versions prior to PyTorch 2.1.2, PyTorch relied on the operating system’s default malloc function for memory allocation. The default malloc memory allocation on the Windows platform was less efficient compared to the malloc implementation mechanism on the Linux platform, leading to increased memory allocation times and reduced performance. To address this, we have substituted the default Windows malloc with mimalloc, a more efficient memory allocator developed by Microsoft. This update, included with the release of PyTorch 2.1.2 and later, has significantly enhanced the CPU performance of PyTorch on Windows, as shown in Figure 1.1.



PyTorch CPU Performance Improvement on Windows with Memory Allocation Optimization

Figure 1.1: Relative throughput improvement achieved by upgrading from Windows PyTorch version 2.0.1 to 2.1.2 (higher is better).

The graph illustrates that with the release of PyTorch 2.1.2, there has been a notable enhancement in CPU performance on the Windows platform. The degree of improvement varies across different models, which can be attributed to the diverse mix of operations they perform and their corresponding memory access patterns. While the BERT model shows a modest performance gain, models like ResNet50 and MobileNet-v3 Large benefit from more pronounced improvements.

On a high-performance CPU, memory allocation becomes a performance bottleneck. This is also why addressing this issue has led to such significant performance improvements.

As shown in the graphs below, we see that PyTorch CPU performance on Windows can significantly be improved. However, there is still a noticeable gap when compared to its performance on Linux. The absence of vectorization optimizations in the Windows variant of PyTorch CPU is a key factor to the remaining performance gap.



Windows vs Linux Performance on PyTorch 2.0.1

Figure 1.2: Relative performance of Windows vs Linux with PyTorch version 2.0.1 (higher is better).



Windows vs Linux Performance on PyTorch 2.1.2

Figure 1.3: Relative performance of Windows vs Linux with PyTorch version 2.1.2 (higher is better).

Vectorization Optimization in PyTorch 2.4.1 and later

Prior to PyTorch 2.4.1, the Windows build of PyTorch lacked SIMD for vectorization optimizations, a feature that the Linux build leveraged for improved performance. This discrepancy was due to the SLEEF Library’s integration issues on Windows, which is a SIMD Library for Evaluating Elementary Functions, vectorized libm and DFT and is essential for efficient trigonometric calculations. Through a collaborative effort with engineers from ARM and Qualcomm, these challenges were resolved, enabling the integration of SIMD into PyTorch for Windows. The PyTorch 2.4.1 update has thus significantly enhanced PyTorch’s CPU performance on Windows, as shown in Figure 2.1.



PyTorch CPU Performance Improvement on Windows with Vertorization Optimization

Figure 2.1: Relative throughput improvement achieved by upgrading from PyTorch CPU version 2.1.2 to 2.4.1 (higher is better).

As shown in the graph below, we see that PyTorch CPU performance on Windows ahieved the performance on Linux.



Windows vs Linux Performance on PyTorch 2.4.1

Figure 2.2: Relative performance of Windows vs Linux with PyTorch version 2.4.1 (higher is better).

CONCLUSION

From PyTorch 2.0.1 to PyTorch 2.4.1, the CPU performance gap between Windows and Linux has been continuously narrowing. We compared the ratio of CPU performance on Windows to CPU performance on Linux across different versions, and the results are shown in the following graph.



Windows vs Linux Performance on different version of PyTorch

Figure 3: Performance Ratio for Windows to Linux with different version of PyTorch (higher is better).

The graph shows that with PyTorch 2.4.1, CPU performance on Windows has nearly converged with that on Linux, and on some models, it has even surpassed Linux. For example, in the case of DistillBERT and RoBERTa models, the CPU performance ratio of Windows to Linux has achieved a remarkable 102%. However, certain models, including MobileNet-v3, still show a performance discrepancy. Intel engineers will continue to collaborate with Meta engineers, to reduce the performance gap of PyTorch CPU between Windows and Linux.

HOW TO TAKE ADVANTAGE OF THE OPTIMIZATIONS

Install PyTorch CPU 2.4.1 or later on Windows from the official repository, and you may automatically experience a performance boost with memory allocation and vectorizations.

ACKNOWLEDGMENTS

The results presented in this blog post was achieved through the collaborative effort of the Intel PyTorch team and Meta. We would like to express our sincere gratitude to Xu Han, Jiong Gong, Haozhe Zhu, Mingfei Ma, Chuanqi Wang, Guobing Chen and Eikan Wang. Their expertise and dedication have been instrumental in achieving the optimizations and performance improvements discussed here. Thanks to Jiachen Pu from community for his participation in the issue discussion and suggesting the use of mimalloc. We’d also like to express our gratitude to Microsoft for providing such an easily integrated and performant mallocation library. Thanks to Pierre Blanchard , Nathan Sircombe from ARM and Alex Reinking from Adobe for their contribution in overcome the compatibility issues with the sleef integrated to PyTorch Windows. Finally we want to thank Jing Xu, Weizhuo Zhang and Zhaoqiong Zheng for their contributions to this blog.

Product and Performance Information

The configurations in the table are collected with svr-info. Test by Intel on August 30, 2024.


  
   Specification
   
   Configuration1
   
   Configuration2
   
  
  
   Name
   
   ThinkBook 14 G5+ IRH
   
   ThinkBook 14 G5+ IRH
   
  
  
   Time
   
   Fri Aug 30 02:43:02 PM UTC 2024
   
   Fri Aug 30 02:43:02 PM UTC 2024
   
  
  
   System
   
   LENOVO
   
   LENOVO
   
  
  
   Baseboard
   
   LENOVO
   
   LENOVO
   
  
  
   Chassis
   
   LENOVO
   
   LENOVO
   
  
  
   CPU Model
   
   13th Gen Intel(R) Core(TM) i7-13700H
   
   13th Gen Intel(R) Core(TM) i7-13700H
   
  
  
   Microarchitecture
   
   Unknown Intel
   
   Unknown Intel
   
  
  
   Sockets
   
   1
   
   1
   
  
  
   Cores per Socket
   
   14
   
   14
   
  
  
   Hyperthreading
   
   Enabled
   
   Enabled
   
  
  
   CPUs
   
   20
   
   20
   
  
  
   Intel Turbo Boost
   
   Enabled
   
   Enabled
   
  
  
   Base Frequency
   
   2.4GHz
   
   2.4GHz
   
  
  
   All-core Maximum Frequency
   
   4.7GHz
   
   4.7GHz
   
  
  
   Maximum Frequency
   
   4.8GHz
   
   4.8GHz
   
  
  
   NUMA Nodes
   
   1
   
   1
   
  
  
   Prefetchers
   
   L2 HW: Enabled, L2 Adj.: Enabled, DCU HW: Enabled, DCU IP: Enabled
   
   L2 HW: Enabled, L2 Adj.: Enabled, DCU HW: Enabled, DCU IP: Enabled
   
  
  
   PPINs
   
   -
   
   -
   
  
  
   Accelerators
   
   DLB, DSA, IAA, QAT
   
   DLB, DSA, IAA, QAT
   
  
  
   Installed Memory
   
   32GB (8x4GB LPDDR4 7400 MT/s [5200 MT/s])
   
   32GB (8x4GB LPDDR4 7400 MT/s [5200 MT/s])
   
  
  
   Hugepagesize
   
   2048kb
   
   2048kb
   
  
  
   Transparent Huge Pages
   
   madvise
   
   madvise
   
  
  
   Automatic NUMA Balancing
   
   Disabled
   
   Disabled
   
  
  
   NIC
   
   “1. Raptor Lake PCH CNVi WiFi 2. Intel Corporation”
   
   “1. Raptor Lake PCH CNVi WiFi 2. Intel Corporation”
   
  
  
   Disk
   
   Micron MTFDKBA512TFH 500G
   
   Micron MTFDKBA512TFH 500G
   
  
  
   BIOS
   
   LBCN22WW
   
   LBCN22WW
   
  
  
   Microcode
   
   0x411c
   
   0x411c
   
  
  
   OS
   
   Windows 11 Desktop
   
   Ubuntu 23.10
   
  
  
   Kernel
   
   OS Build 19045.4412
   
   6.5.0-27-generic
   
  
  
   TDP
   
   200 watts
   
   200 watts
   
  
  
   Power &amp; Perf Policy
   
   Normal Powersave (7)
   
   Normal Powersave (7)
   
  
  
   Frequency Governor
   
   performance
   
   performance
   
  
  
   Frequency Driver
   
   intel_pstate
   
   intel_pstate
   
  
  
   Max C-State
   
   9
   
   9
   
  


Notices and Disclaimers

Performance varies by use, configuration and other factors. Learn more on the Performance Index site.

Performance results are based on testing as of dates shown in configurations and may not reflect all publicly available updates. See backup for configuration details. No product or component can be absolutely secure. Your costs and results may vary. Intel technologies may require enabled hardware, software or service activation.

Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.
" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
  
    <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window,document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '243028289693773');
    fbq('track', 'PageView');
</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

    <!-- Twitter universal website tag code -->
<img height="1" width="1" style="display:none;" alt="" src="https://analytics.twitter.com/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__analytics.twitter.com_i_adsct-3Fp-5Fid-3DTwitter-26p-5Fuser-5Fid-3D0-26txn-5Fid-3Do2gi1-26events-3D-255B-255B-2522pageview-2522-252Cnull-255D-255D-26tw-5Fsale-5Famount-3D0-26tw-5Forder-5Fquantity-3D0&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=o6i4D0V0088WH2RnzIoqiF-vj45PL-2sTrsxQ0SNO3A&e=)" />
<img height="1" width="1" style="display:none;" alt="" src="//t.co/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__linkprotect.cudasvc.com_url-3Fa-3Dhttp-253a-252f-252ft.co-252fi-252fadsct-253fp-5Fid-253dTwitter-2526p-5Fuser-5Fid-253d0-2526txn-5Fid-253do2gi1-2526events-253d-25255B-25255B-252522pageview-252522-25252Cnull-25255D-25255D-2526tw-5Fsale-5Famount-253d0-2526tw-5Forder-5Fquantity-253d0-26c-3DE-2C1-2CC33dLwIhtuEcl5FhdztSnUwsioeej5k-2DWy0RYREBAq51kGji32A2Cw94YU9vQBpY5tPN3AukEw3C-5F-2DlbtndnLoR7-5FA-5FLoH0Rr7zLtP1ykptN-26typo-3D1&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=Abgc3XBkhESv8XBYtLchdDZyISGsK6v_BB6cLMJGyCw&e=)" />
<!-- End Twitter universal website tag code -->

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Pythorch Blog Posts" />
</head>


<body class="blog">
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <div class="main-background blog-background blog-detail-background"></div>
    <div class="hello-bar">
        <div class="container">
            Join us at PyTorch Conference in San Francisco, October 22-23. CFP open now! <a target="_blank" href="https://events.linuxfoundation.org/pytorch-conference/">Learn more</a>.
        </div>
      </div>
      
    <div class="container-fluid header-holder blog-detail-header">
        <div class="container">
            

<div class="header-container">
  <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Learn
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/get-started">
            <span class=dropdown-title>Get Started</span>
            <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/">
            <span class="dropdown-title">Tutorials</span>
            <p>Whats new in PyTorch tutorials</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
            <span class="dropdown-title">Learn the Basics</span>
            <p>Familiarize yourself with PyTorch concepts and modules</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
            <span class="dropdown-title">PyTorch Recipes</span>
            <p>Bite-size, ready-to-deploy PyTorch code examples</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
            <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
            <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Ecosystem 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
            <span class="dropdown-title">Tools</span>
            <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="https://github.com/pytorch-fdn/ecosystem" target="_blank">
            <span class="dropdown-title">Join the Ecosystem</span>
          </a>
          <a class="nav-dropdown-item" href="/#community-module">
            <span class=dropdown-title>Community</span>
            <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
          </a>
          <a class="nav-dropdown-item" href="https://discuss.pytorch.org" target="_blank">
            <span class=dropdown-title>Forums</span>
            <p>A place to discuss PyTorch code, issues, install, research</p>
          </a>
          <a class="nav-dropdown-item" href="/resources">
            <span class=dropdown-title>Developer Resources</span>
            <p>Find resources and get questions answered</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/contributor-awards-2024">
            <span class="dropdown-title">Contributor Awards - 2024</span>
            <p>Award winners announced at this year's PyTorch Conference</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Edge 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/edge">
            <span class="dropdown-title">About PyTorch Edge</span>
            <p>Build innovative and privacy-aware AI experiences for edge devices</p>
          </a>
          <a class="nav-dropdown-item" href="/executorch-overview">
            <span class="dropdown-title">ExecuTorch</span>
            <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
          </a>
          <a class="nav-dropdown-item" target="_blank" href="https://pytorch.org/executorch/stable/index.html">
            <span class="dropdown-title">ExecuTorch Documentation</span>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="docsDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Docs
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="https://pytorch.org/docs">
            <span class="dropdown-title">PyTorch</span>
            <p>Explore the documentation for comprehensive guidance on how to use PyTorch.</p>
          </a>
          <a class="nav-dropdown-item" href="/pytorch-domains">
            <span class="dropdown-title">PyTorch Domains</span>
            <p> Read the PyTorch Domains documentation to learn more about domain-specific libraries.</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Blog & News
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/blog">
            <span class="dropdown-title">PyTorch Blog</span>
            <p>Catch up on the latest technical news and happenings</p>
          </a>
          <a class="nav-dropdown-item" href="/community-blog">
            <span class="dropdown-title">Community Blog</span>
            <p>Stories from the PyTorch ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="/videos">
            <span class="dropdown-title">Videos</span>
            <p>Learn about the latest PyTorch tutorials, new, and more </p>
          </a>
          <a class="nav-dropdown-item" href="/community-stories">
            <span class="dropdown-title">Community Stories</span>
            <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
          </a>
          <a class="nav-dropdown-item" href="/events">
            <span class=dropdown-title>Events</span>
            <p>Find events, webinars, and podcasts</p>
          </a>
          <a class="nav-dropdown-item" href="/newsletter">
            <span class=dropdown-title>Newsletter</span>
            <p>Stay up-to-date with the latest updates</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          About
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/foundation">
            <span class=dropdown-title>PyTorch Foundation</span>
            <p>Learn more about the PyTorch Foundation.</p>
          </a>
          <a class="nav-dropdown-item" href="/governing-board">
            <span class=dropdown-title>Governing Board</span>
          </a>
          <a class="nav-dropdown-item" href="/credits">
            <span class=dropdown-title>Cloud Credit Program</span>
          </a>
          <a class="nav-dropdown-item" href="/tac">
            <span class=dropdown-title>Technical Advisory Council</span>
          </a>
          <a class="nav-dropdown-item" href="/staff">
            <span class=dropdown-title>Staff</span>
          </a>
          <a class="nav-dropdown-item" href="/contact-us">
            <span class=dropdown-title>Contact Us</span>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <a href="/join" data-cta="join">
        Become a Member
      </a>
    </li>

    <li class="main-menu-item" id="github-main-menu-link">
      <a href="https://github.com/pytorch/pytorch" title="Go to PyTorch GitHub">
        <div id="topnav-gh-icon"></div>
      </a>
    </li>

    <li class="navSearchWrapper reactNavSearchWrapper" key="search">
      <div class="search-border">
        <div id="search-icon"></div>
        <input
          id="search-input"
          type="text"
          title="Search"
        />
        <div id="close-search">X</div>
      </div>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

        </div>
    </div>

    <div class="jumbotron jumbotron-fluid blog-detail-jumbotron">
        <div class="container blog-detail-container">
            <p class="featured-post">October 15, 2024</p>
            <h1>
                <a class="blog-title">The Path to Achieve PyTorch Performance Boost on Windows CPU</a>
            </h1>
        </div>
    </div>

    <div class="main-content-wrapper blog-detail-wrapper">
        <div class="main-content blog-detail-content">
            <div class="container">
                <img src="/assets/images/logo-icon.svg" class="img-fluid author-icon">
                <article class="pytorch-article">
                    <p class="author">
                      by
                      
                        Intel Corporation
                      
                    </p>
                    <p>The challenge of PyTorch’s lower CPU performance on Windows compared to Linux has been a significant issue. There are multiple factors leading to this performance disparity. Through our investigation, we’ve identified several reasons for poor CPU performance on Windows, two primary issues have been pinpointed: the inefficiency of the Windows default malloc memory allocator and the absence of <a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">SIMD</a> for vectorization optimizations on the Windows platform. In this article, we show how PyTorch CPU performance on Windows has improved from the previous releases and where it stands as of PyTorch 2.4.1.</p>

<h2 id="memory-allocation-optimization-in-pytorch-212-and-later">Memory Allocation Optimization in PyTorch 2.1.2 and later</h2>

<p>In versions prior to PyTorch 2.1.2, PyTorch relied on the operating system’s default malloc function for memory allocation. The default malloc memory allocation on the Windows platform was less efficient compared to the malloc implementation mechanism on the Linux platform, leading to increased memory allocation times and reduced performance. To address this, we have substituted the default Windows malloc with mimalloc, a more efficient memory allocator developed by Microsoft. This update, included with the release of PyTorch 2.1.2 and later, has significantly enhanced the CPU performance of PyTorch on Windows, as shown in Figure 1.1.</p>

<p><img src="/assets/images/performance-boost-windows/fg1.png" alt="performance comparison chart" style="width:100%" /></p>

<p><em>PyTorch CPU Performance Improvement on Windows with Memory Allocation Optimization</em></p>

<p><em>Figure 1.1: Relative throughput improvement achieved by upgrading from Windows PyTorch version 2.0.1 to 2.1.2 (higher is better).</em></p>

<p>The graph illustrates that with the release of PyTorch 2.1.2, there has been a notable enhancement in CPU performance on the Windows platform. The degree of improvement varies across different models, which can be attributed to the diverse mix of operations they perform and their corresponding memory access patterns. While the BERT model shows a modest performance gain, models like ResNet50 and MobileNet-v3 Large benefit from more pronounced improvements.</p>

<p>On a high-performance CPU, memory allocation becomes a performance bottleneck. This is also why addressing this issue has led to such significant performance improvements.</p>

<p>As shown in the graphs below, we see that PyTorch CPU performance on Windows can significantly be improved. However, there is still a noticeable gap when compared to its performance on Linux. The absence of vectorization optimizations in the Windows variant of PyTorch CPU is a key factor to the remaining performance gap.</p>

<p><img src="/assets/images/performance-boost-windows/fg2.png" alt="performance comparison chart" style="width:100%" /></p>

<p><em>Windows vs Linux Performance on PyTorch 2.0.1</em></p>

<p><em>Figure 1.2: Relative performance of Windows vs Linux with PyTorch version 2.0.1 (higher is better).</em></p>

<p><img src="/assets/images/performance-boost-windows/fg3.png" alt="performance comparison chart" style="width:100%; margin-top: 50px;" /></p>

<p><em>Windows vs Linux Performance on PyTorch 2.1.2</em></p>

<p><em>Figure 1.3: Relative performance of Windows vs Linux with PyTorch version 2.1.2 (higher is better).</em></p>

<h2 id="vectorization-optimization-in-pytorch-241-and-later">Vectorization Optimization in PyTorch 2.4.1 and later</h2>

<p>Prior to PyTorch 2.4.1, the Windows build of PyTorch lacked <a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">SIMD</a> for vectorization optimizations, a feature that the Linux build leveraged for improved performance. This discrepancy was due to the <a href="https://github.com/shibatch/sleef">SLEEF</a> Library’s integration issues on Windows, which is a SIMD Library for Evaluating Elementary Functions, vectorized libm and DFT and is essential for efficient trigonometric calculations. Through a collaborative effort with engineers from ARM and Qualcomm, these challenges were resolved, enabling the integration of SIMD into PyTorch for Windows. The PyTorch 2.4.1 update has thus significantly enhanced PyTorch’s CPU performance on Windows, as shown in Figure 2.1.</p>

<p><img src="/assets/images/performance-boost-windows/fg4.png" alt="performance comparison chart" style="width:100%" /></p>

<p><em>PyTorch CPU Performance Improvement on Windows with Vertorization Optimization</em></p>

<p><em>Figure 2.1: Relative throughput improvement achieved by upgrading from PyTorch CPU version 2.1.2 to 2.4.1 (higher is better).</em></p>

<p>As shown in the graph below, we see that PyTorch CPU performance on Windows ahieved the performance on Linux.</p>

<p><img src="/assets/images/performance-boost-windows/fg5.png" alt="performance comparison chart" style="width:100%" /></p>

<p><em>Windows vs Linux Performance on PyTorch 2.4.1</em></p>

<p><em>Figure 2.2: Relative performance of Windows vs Linux with PyTorch version 2.4.1 (higher is better).</em></p>

<h2 id="conclusion">CONCLUSION</h2>

<p>From PyTorch 2.0.1 to PyTorch 2.4.1, the CPU performance gap between Windows and Linux has been continuously narrowing. We compared the ratio of CPU performance on Windows to CPU performance on Linux across different versions, and the results are shown in the following graph.</p>

<p><img src="/assets/images/performance-boost-windows/fg6.png" alt="performance comparison chart" style="width:100%" /></p>

<p><em>Windows vs Linux Performance on different version of PyTorch</em></p>

<p><em>Figure 3: Performance Ratio for Windows to Linux with different version of PyTorch (higher is better).</em></p>

<p>The graph shows that with PyTorch 2.4.1, CPU performance on Windows has nearly converged with that on Linux, and on some models, it has even surpassed Linux. For example, in the case of DistillBERT and RoBERTa models, the CPU performance ratio of Windows to Linux has achieved a remarkable 102%. However, certain models, including MobileNet-v3, still show a performance discrepancy. Intel engineers will continue to collaborate with Meta engineers, to reduce the performance gap of PyTorch CPU between Windows and Linux.</p>

<h2 id="how-to-take-advantage-of-the-optimizations">HOW TO TAKE ADVANTAGE OF THE OPTIMIZATIONS</h2>

<p>Install PyTorch CPU 2.4.1 or later on Windows from the <a href="https://pytorch.org/get-started/locally/">official repository</a>, and you may automatically experience a performance boost with memory allocation and vectorizations.</p>

<h2 id="acknowledgments">ACKNOWLEDGMENTS</h2>

<p>The results presented in this blog post was achieved through the collaborative effort of the Intel PyTorch team and Meta. We would like to express our sincere gratitude to <a href="https://github.com/xuhancn">Xu Han</a>, <a href="https://github.com/jgong5">Jiong Gong</a>, <a href="https://github.com/zhuhaozhe">Haozhe Zhu</a>, <a href="https://github.com/mingfeima">Mingfei Ma</a>, <a href="https://github.com/chuanqi129">Chuanqi Wang</a>, <a href="https://github.com/Guobing-Chen">Guobing Chen</a> and <a href="https://github.com/EikanWang">Eikan Wang</a>. Their expertise and dedication have been instrumental in achieving the optimizations and performance improvements discussed here. Thanks to <a href="https://github.com/peterjc123">Jiachen Pu</a> from community for his participation in the issue discussion and suggesting the use of <a href="https://github.com/microsoft/mimalloc">mimalloc</a>. We’d also like to express our gratitude to Microsoft for providing such an easily integrated and performant mallocation library. Thanks to <a href="https://github.com/blapie">Pierre Blanchard</a> , <a href="https://github.com/nSircombe">Nathan Sircombe</a> from ARM and <a href="https://github.com/alexreinking">Alex Reinking</a> from Adobe for their contribution in overcome the compatibility issues with the <a href="https://github.com/shibatch/sleef">sleef</a> integrated to PyTorch Windows. Finally we want to thank <a href="https://github.com/jingxu10">Jing Xu</a>, <a href="https://github.com/WeizhuoZhang-intel">Weizhuo Zhang</a> and <a href="https://github.com/ZhaoqiongZ">Zhaoqiong Zheng</a> for their contributions to this blog.</p>

<h3 id="product-and-performance-information">Product and Performance Information</h3>

<p>The configurations in the table are collected with <a href="https://github.com/intel/svr-info">svr-info</a>. Test by Intel on August 30, 2024.</p>

<table class="table table-bordered">
  <tr>
   <td><strong>Specification</strong>
   </td>
   <td><strong>Configuration1</strong>
   </td>
   <td><strong>Configuration2</strong>
   </td>
  </tr>
  <tr>
   <td>Name
   </td>
   <td>ThinkBook 14 G5+ IRH
   </td>
   <td>ThinkBook 14 G5+ IRH
   </td>
  </tr>
  <tr>
   <td>Time
   </td>
   <td>Fri Aug 30 02:43:02 PM UTC 2024
   </td>
   <td>Fri Aug 30 02:43:02 PM UTC 2024
   </td>
  </tr>
  <tr>
   <td>System
   </td>
   <td>LENOVO
   </td>
   <td>LENOVO
   </td>
  </tr>
  <tr>
   <td>Baseboard
   </td>
   <td>LENOVO
   </td>
   <td>LENOVO
   </td>
  </tr>
  <tr>
   <td>Chassis
   </td>
   <td>LENOVO
   </td>
   <td>LENOVO
   </td>
  </tr>
  <tr>
   <td>CPU Model
   </td>
   <td>13th Gen Intel(R) Core(TM) i7-13700H
   </td>
   <td>13th Gen Intel(R) Core(TM) i7-13700H
   </td>
  </tr>
  <tr>
   <td>Microarchitecture
   </td>
   <td>Unknown Intel
   </td>
   <td>Unknown Intel
   </td>
  </tr>
  <tr>
   <td>Sockets
   </td>
   <td>1
   </td>
   <td>1
   </td>
  </tr>
  <tr>
   <td>Cores per Socket
   </td>
   <td>14
   </td>
   <td>14
   </td>
  </tr>
  <tr>
   <td>Hyperthreading
   </td>
   <td>Enabled
   </td>
   <td>Enabled
   </td>
  </tr>
  <tr>
   <td>CPUs
   </td>
   <td>20
   </td>
   <td>20
   </td>
  </tr>
  <tr>
   <td>Intel Turbo Boost
   </td>
   <td>Enabled
   </td>
   <td>Enabled
   </td>
  </tr>
  <tr>
   <td>Base Frequency
   </td>
   <td>2.4GHz
   </td>
   <td>2.4GHz
   </td>
  </tr>
  <tr>
   <td>All-core Maximum Frequency
   </td>
   <td>4.7GHz
   </td>
   <td>4.7GHz
   </td>
  </tr>
  <tr>
   <td>Maximum Frequency
   </td>
   <td>4.8GHz
   </td>
   <td>4.8GHz
   </td>
  </tr>
  <tr>
   <td>NUMA Nodes
   </td>
   <td>1
   </td>
   <td>1
   </td>
  </tr>
  <tr>
   <td>Prefetchers
   </td>
   <td>L2 HW: Enabled, L2 Adj.: Enabled, DCU HW: Enabled, DCU IP: Enabled
   </td>
   <td>L2 HW: Enabled, L2 Adj.: Enabled, DCU HW: Enabled, DCU IP: Enabled
   </td>
  </tr>
  <tr>
   <td>PPINs
   </td>
   <td>-
   </td>
   <td>-
   </td>
  </tr>
  <tr>
   <td>Accelerators
   </td>
   <td>DLB, DSA, IAA, QAT
   </td>
   <td>DLB, DSA, IAA, QAT
   </td>
  </tr>
  <tr>
   <td>Installed Memory
   </td>
   <td>32GB (8x4GB LPDDR4 7400 MT/s [5200 MT/s])
   </td>
   <td>32GB (8x4GB LPDDR4 7400 MT/s [5200 MT/s])
   </td>
  </tr>
  <tr>
   <td>Hugepagesize
   </td>
   <td>2048kb
   </td>
   <td>2048kb
   </td>
  </tr>
  <tr>
   <td>Transparent Huge Pages
   </td>
   <td>madvise
   </td>
   <td>madvise
   </td>
  </tr>
  <tr>
   <td>Automatic NUMA Balancing
   </td>
   <td>Disabled
   </td>
   <td>Disabled
   </td>
  </tr>
  <tr>
   <td>NIC
   </td>
   <td>“1. Raptor Lake PCH CNVi WiFi 2. Intel Corporation”
   </td>
   <td>“1. Raptor Lake PCH CNVi WiFi 2. Intel Corporation”
   </td>
  </tr>
  <tr>
   <td>Disk
   </td>
   <td>Micron MTFDKBA512TFH 500G
   </td>
   <td>Micron MTFDKBA512TFH 500G
   </td>
  </tr>
  <tr>
   <td>BIOS
   </td>
   <td>LBCN22WW
   </td>
   <td>LBCN22WW
   </td>
  </tr>
  <tr>
   <td>Microcode
   </td>
   <td>0x411c
   </td>
   <td>0x411c
   </td>
  </tr>
  <tr>
   <td>OS
   </td>
   <td>Windows 11 Desktop
   </td>
   <td>Ubuntu 23.10
   </td>
  </tr>
  <tr>
   <td>Kernel
   </td>
   <td>OS Build 19045.4412
   </td>
   <td>6.5.0-27-generic
   </td>
  </tr>
  <tr>
   <td>TDP
   </td>
   <td>200 watts
   </td>
   <td>200 watts
   </td>
  </tr>
  <tr>
   <td>Power &amp; Perf Policy
   </td>
   <td>Normal Powersave (7)
   </td>
   <td>Normal Powersave (7)
   </td>
  </tr>
  <tr>
   <td>Frequency Governor
   </td>
   <td>performance
   </td>
   <td>performance
   </td>
  </tr>
  <tr>
   <td>Frequency Driver
   </td>
   <td>intel_pstate
   </td>
   <td>intel_pstate
   </td>
  </tr>
  <tr>
   <td>Max C-State
   </td>
   <td>9
   </td>
   <td>9
   </td>
  </tr>
</table>

<h2 id="notices-and-disclaimers">Notices and Disclaimers</h2>

<p>Performance varies by use, configuration and other factors. Learn more on the <a href="https://edc.intel.com/content/www/us/en/products/performance/benchmarks/overview/">Performance Index site</a>.</p>

<p>Performance results are based on testing as of dates shown in <a href="#product-and-performance-information">configurations</a> and may not reflect all publicly available updates. See backup for configuration details. No product or component can be absolutely secure. Your costs and results may vary. Intel technologies may require enabled hardware, software or service activation.</p>

<p>Intel Corporation. Intel, the Intel logo, and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.</p>

                </article>
            </div>
        </div>
    </div>

<!--    


 -->
    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="/docs">View Docs</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p
        class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and the latest news</p>
    
    
        <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
        <script>
          hbspt.forms.create({
            region: "na1",
            portalId: "8112310",
            formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
          });
        </script>
        
    
      <p
        class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its projects regarding their events, training, research, developments, and related announcements. I understand that I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
        
    </div>
    


    <div class="lf-grid">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org" class="footer-logo">
          <img src="/assets/images/logo-icon.svg" alt="PyTorch logo" width="40">
        </a>
      </div>

      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook"><path fill="currentColor" d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z"/></svg>	
        </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X"><path fill="currentColor" d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66"/></svg>
        </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube"><path fill="currentColor" d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z"/></svg>	
        </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn"><rect width="512" height="512" rx="0" fill="currentColor"/><circle fill="#000" cx="142" cy="138" r="37"/><path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198"/><path fill="#000" d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
        </a></li>
        <li><a href="https://join.slack.com/t/pytorch/shared_invite/zt-2j2la612p-miUinTTaxXczKOJw48poHA" target="_blank" title="PyTorch Slack">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack"><path fill="currentColor" d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z"></path></svg>
        </a></li>
        <li><a href="/wechat" title="PyTorch on WeChat">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat"><path fill="currentColor" d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z"></path><path fill="currentColor" d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z"></path></svg>
        </a></li>
      </ul>
    </div>

    <div class="privacy-policy">
      <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation. 
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see 
          <a href="https://www.linuxfoundation.org/legal/policies/">Linux Foundation Policies</a>. The PyTorch Foundation supports the PyTorch open source 
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC, 
          please see <a href="https://www.lfprojects.org/policies/">LF Projects, LLC Policies</a>. <a href="https://www.linuxfoundation.org/privacy">Privacy Policy</a> and <a href="https://www.linuxfoundation.org/terms">Terms of Use</a>.</p>
      </div>
    </div>
  </div>
  <img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>
        <li class="navSearchWrapper reactNavSearchWrapper tabletSearchWrapper" key="search">
          <div class="mobile-search-border">
            <input
              id="mobile-search-input"
              type="text"
              title="Search"
            />
            <div id="mobile-search-icon"></div>
          </div>
        </li>

        <li class="resources-mobile-menu-title">
          <a>Learn</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/get-started">Get Started</a> 
          </li>
          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Ecosystem</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Tools</a>
          </li>
          <li>
            <a href="https://github.com/pytorch-fdn/ecosystem">Join the Ecosystem</a>
          </li>
          <li>
            <a href="/#community-module">Community</a>
          </li>
          <li>
            <a href="https://discuss.pytorch.org">Forums</a>
          </li>
          <li>
            <a href="/resources">Developer Resources</a>
          </li>
          <li>
            <a href="/ecosystem/contributor-awards-2024">Contributor Awards - 2024</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Edge</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/edge">About PyTorch Edge</a>
          </li>
          <li>
            <a href="/executorch-overview">ExecuTorch</a>
          </li>
          <li>
            <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Docs</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/docs">PyTorch</a>
          </li>
          <li>
            <a href="/pytorch-domains">PyTorch Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/blog">PyTorch Blog</a>
          </li>
          <li>
            <a href="/community-blog">Community Blog</a>
          </li>
          <li>
            <a href="/videos">Videos</a>
          </li>
          <li>
            <a href="/community-stories">Community Stories</a>
          </li>
          <li>
            <a href="/events">Events</a>
          </li>
          <li>
            <a href="/newsletter">Newsletter</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="/credits">Cloud Credit Program</a>
          </li>
          <li>          
            <a href="/tac">Technical Advisory Council</a>
          </li>
          <li>
            <a href="/staff">Staff</a>
          </li>
          <li>
            <a href="/contact-us">Contact Us</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a href="/join">Become a Member</a>
        </li>
        <li class="resources-mobile-menu-title">
          <a href="https://github.com/pytorch/pytorch" title="Go to PyTorch GitHub"><div id="topnav-gh-icon"></div></a>
        </li>
      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>

  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script>

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header, .announcement-header, .comm-stories-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>


  <script src="/assets/track-events.js"></script>
  <script>trackEvents.bind();</script>



<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="/assets/images/pytorch-x.svg">
  </div>
</div>


</body>

</html>
