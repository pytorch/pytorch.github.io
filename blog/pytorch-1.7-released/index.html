<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-52DXT37');</script>
  <!-- End Google Tag Manager -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      PyTorch 1.7 released w/ CUDA 11, New APIs for FFTs, Windows support for Distributed training and more | PyTorch
    
  </title>
  
  <meta property="og:title" content="PyTorch" />
  <meta
    name="description"
    property="og:description"
    content="An open source machine learning framework that accelerates the path from research prototyping to production deployment."
  />
  <meta
  property="og:image"
  content="https://pytorch.org/assets/images/pytorch-logo.png"
  />
  <meta property="og:url" content="https://www.pytorch.org" />


<meta property="og:type" content="website" />
<meta name="robots" content="index, follow" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
  
    <script
  async
  src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"
></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());
  gtag("config", "UA-117752657-2");
</script>

    <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window,document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '243028289693773');
    fbq('track', 'PageView');
</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

    <!-- Twitter universal website tag code -->
<img height="1" width="1" style="display:none;" alt="" src="https://analytics.twitter.com/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__analytics.twitter.com_i_adsct-3Fp-5Fid-3DTwitter-26p-5Fuser-5Fid-3D0-26txn-5Fid-3Do2gi1-26events-3D-255B-255B-2522pageview-2522-252Cnull-255D-255D-26tw-5Fsale-5Famount-3D0-26tw-5Forder-5Fquantity-3D0&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=o6i4D0V0088WH2RnzIoqiF-vj45PL-2sTrsxQ0SNO3A&e=)" />
<img height="1" width="1" style="display:none;" alt="" src="//t.co/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__linkprotect.cudasvc.com_url-3Fa-3Dhttp-253a-252f-252ft.co-252fi-252fadsct-253fp-5Fid-253dTwitter-2526p-5Fuser-5Fid-253d0-2526txn-5Fid-253do2gi1-2526events-253d-25255B-25255B-252522pageview-252522-25252Cnull-25255D-25255D-2526tw-5Fsale-5Famount-253d0-2526tw-5Forder-5Fquantity-253d0-26c-3DE-2C1-2CC33dLwIhtuEcl5FhdztSnUwsioeej5k-2DWy0RYREBAq51kGji32A2Cw94YU9vQBpY5tPN3AukEw3C-5F-2DlbtndnLoR7-5FA-5FLoH0Rr7zLtP1ykptN-26typo-3D1&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=Abgc3XBkhESv8XBYtLchdDZyISGsK6v_BB6cLMJGyCw&e=)" />
<!-- End Twitter universal website tag code -->

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Pythorch Blog Posts" />
</head>


<body class="blog">
    <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-52DXT37"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <div class="main-background blog-background blog-detail-background"></div>

    <div class="container-fluid header-holder blog-detail-header">
        <div class="container">
            

<div class="header-container">
  <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item ">
      <a href="/get-started">Get Started</a>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow" href="/ecosystem">
          Ecosystem 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/ecosystem">
            <span class="dropdown-title">Tools</span>
            <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/pted/2021">
            <span class="dropdown-title">Ecosystem Day - 2021</span>
            <p>See the posters presented at ecosystem day 2021</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/ptdd/2021">
            <span class="dropdown-title">Developer Day - 2021</span>
            <p>See the posters presented at developer day 2021</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/ptc/2022">
            <span class="dropdown-title">PyTorch Conference - 2022</span>
            <p>See the posters presented at PyTorch conference - 2022</p>
          </a>

        </div>
      </div>
    </li>

    <li class="main-menu-item ">
      <a href="/mobile">Mobile</a>
    </li>

    <li class="main-menu-item active">
      <a href="/blog">Blog</a>
    </li>

    <li class="main-menu-item">
      <a href="https://pytorch.org/tutorials">Tutorials</a>
    </li>

    <li class="main-menu-item">
      <div id="docsDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="doc-option with-down-arrow">
          Docs
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/docs">
            <span class="dropdown-title docs-title">PyTorch</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/audio">
            <span class="dropdown-title docs-title">torchaudio</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/text">
            <span class="dropdown-title docs-title">torchtext</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/vision">
            <span class="dropdown-title docs-title">torchvision</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/torcharrow">
            <span class="dropdown-title docs-title">torcharrow</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/data">
            <span class="dropdown-title docs-title">TorchData</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/torchrec">
            <span class="dropdown-title docs-title">TorchRec</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/serve">
            <span class="dropdown-title docs-title">TorchServe</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/xla/release/1.6/index.html">
            <span class="dropdown-title docs-title">PyTorch on XLA Devices</span>
            <p></p>
          </a>
        </div>
      </div>
    </li>

    

    <li class="main-menu-item ">

      <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow">
          Resources
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/features">
            <span class=dropdown-title>About</span>
            <p>Learn about PyTorch’s features and capabilities</p>
          </a>
          <a class="nav-dropdown-item" href="/foundation">
            <span class=dropdown-title>PyTorch Foundation</span>
            <p>Learn more about the PyTorch Foundation.</p>
          </a>
          <a class="nav-dropdown-item" href="/#community-module">
            <span class=dropdown-title>Community</span>
            <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
          </a>
          <a class="nav-dropdown-item" href="/community-stories">
            <span class=dropdown-title>Community stories</span>
            <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
          </a>
          <a class="nav-dropdown-item" href="/resources">
            <span class=dropdown-title>Developer Resources</span>
            <p>Find resources and get questions answered</p>
          </a>
          <a class="nav-dropdown-item" href="/events">
            <span class=dropdown-title>Events</span>
            <p>Find events, webinars, and podcasts</p>
          </a>
          <a class="nav-dropdown-item" href="https://discuss.pytorch.org" target="_blank">
            <span class=dropdown-title>Forums</span>
            <p>A place to discuss PyTorch code, issues, install, research</p>
          </a>
          <a class="nav-dropdown-item" href="/hub">
            <span class=dropdown-title>Models (Beta)</span>
            <p>Discover, publish, and reuse pre-trained models</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item" id="github-main-menu-link">
      <a href="https://github.com/pytorch/pytorch">GitHub</a>
    </li>

    <li class="navSearchWrapper reactNavSearchWrapper" key="search">
      <div class="search-border">
        <div id="search-icon"></div>
        <input
          id="search-input"
          type="text"
          title="Search"
        />
        <div id="close-search">X</div>
      </div>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

        </div>
    </div>

    <div class="jumbotron jumbotron-fluid blog-detail-jumbotron">
        <div class="container blog-detail-container">
            <p class="featured-post">October 27, 2020</p>
            <h1>
                <a class="blog-title">PyTorch 1.7 released w/ CUDA 11, New APIs for FFTs, Windows support for Distributed training and more</a>
            </h1>
        </div>
    </div>

    <div class="main-content-wrapper blog-detail-wrapper">
        <div class="main-content blog-detail-content">
            <div class="container">
                <img src="/assets/images/logo-icon.svg" class="img-fluid author-icon">
                <article class="pytorch-article">
                    <p class="author">
                      by
                      
                        Team PyTorch
                      
                    </p>
                    <p>Today, we’re announcing the availability of PyTorch 1.7, along with updated domain libraries. The PyTorch 1.7 release includes a number of new APIs including support for NumPy-Compatible FFT operations, profiling tools and major updates to both distributed data parallel (DDP) and remote procedure call (RPC) based distributed training. In addition, several features moved to <a href="https://pytorch.org/docs/stable/index.html#pytorch-documentation">stable</a> including custom C++ Classes, the memory profiler, extensions via custom tensor-like objects, user async functions in RPC and a number of other features in torch.distributed such as Per-RPC timeout, DDP dynamic bucketing and RRef helper.</p>

<p>A few of the highlights include:</p>
<ul>
  <li>CUDA 11 is now officially supported with binaries available at <a href="http://pytorch.org/">PyTorch.org</a></li>
  <li>Updates and additions to profiling and performance for RPC, TorchScript and Stack traces in the autograd profiler</li>
  <li>(Beta) Support for NumPy compatible Fast Fourier transforms (FFT) via torch.fft</li>
  <li>(Prototype) Support for Nvidia A100 generation GPUs and native TF32 format</li>
  <li>(Prototype) Distributed training on Windows now supported</li>
  <li>torchvision
    <ul>
      <li>(Stable) Transforms now support Tensor inputs, batch computation, GPU, and TorchScript</li>
      <li>(Stable) Native image I/O for JPEG and PNG formats</li>
      <li>(Beta) New Video Reader API</li>
    </ul>
  </li>
  <li>torchaudio
    <ul>
      <li>(Stable) Added support for speech rec (wav2letter), text to speech (WaveRNN) and source separation (ConvTasNet)</li>
    </ul>
  </li>
</ul>

<p>To reiterate, starting PyTorch 1.6, features are now classified as stable, beta and prototype. You can see the detailed announcement <a href="https://pytorch.org/blog/pytorch-feature-classification-changes/">here</a>. Note that the prototype features listed in this blog are available as part of this release.</p>

<p>Find the full release notes <a href="https://github.com/pytorch/pytorch/releases">here</a>.</p>

<h1 id="front-end-apis">Front End APIs</h1>
<h2 id="beta-numpy-compatible-torchfft-module">[Beta] NumPy Compatible torch.fft module</h2>
<p>FFT-related functionality is commonly used in a variety of scientific fields like signal processing. While PyTorch has historically supported a few FFT-related functions, the 1.7 release adds a new torch.fft module that implements FFT-related functions with the same API as NumPy.</p>

<p>This new module must be imported to be used in the 1.7 release, since its name conflicts with the historic (and now deprecated) torch.fft function.</p>

<p><strong>Example usage:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">torch.fft</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span>
<span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">fft</span><span class="p">.</span><span class="n">fft</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">6.</span><span class="o">+</span><span class="mf">0.j</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="o">+</span><span class="mf">2.j</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="o">+</span><span class="mf">0.j</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.</span><span class="o">-</span><span class="mf">2.j</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mf">0.</span><span class="o">+</span><span class="mf">1.j</span><span class="p">,</span> <span class="mf">2.</span><span class="o">+</span><span class="mf">3.j</span><span class="p">,</span> <span class="mf">4.</span><span class="o">+</span><span class="mf">5.j</span><span class="p">,</span> <span class="mf">6.</span><span class="o">+</span><span class="mf">7.j</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">fft</span><span class="p">.</span><span class="n">fft</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="mf">12.</span><span class="o">+</span><span class="mf">16.j</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.</span><span class="o">+</span><span class="mf">0.j</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.</span><span class="o">-</span><span class="mf">4.j</span><span class="p">,</span>  <span class="mf">0.</span><span class="o">-</span><span class="mf">8.j</span><span class="p">])</span>
</code></pre></div></div>

<ul>
  <li><a href="https://pytorch.org/docs/stable/fft.html#torch-fft">Documentation</a></li>
</ul>

<h2 id="beta-c-support-for-transformer-nn-modules">[Beta] C++ Support for Transformer NN Modules</h2>
<p>Since <a href="https://pytorch.org/blog/pytorch-1-dot-5-released-with-new-and-updated-apis/">PyTorch 1.5</a>, we’ve continued to maintain parity between the python and C++ frontend APIs. This update allows developers to use the nn.transformer module abstraction from the C++ Frontend. And moreover, developers no longer need to save a module from python/JIT and load into C++ as it can now be used it in C++ directly.</p>
<ul>
  <li><a href="https://pytorch.org/cppdocs/api/classtorch_1_1nn_1_1_transformer_impl.html#_CPPv4N5torch2nn15TransformerImplE">Documentation</a></li>
</ul>

<h2 id="beta-torchset_deterministic">[Beta] torch.set_deterministic</h2>
<p>Reproducibility (bit-for-bit determinism) may help identify errors when debugging or testing a program. To facilitate reproducibility, PyTorch 1.7 adds the  <code class="language-plaintext highlighter-rouge">torch.set_deterministic(bool)</code> function that can direct PyTorch operators to select deterministic algorithms when available, and to throw a runtime error if an operation may result in nondeterministic behavior. By default, the flag this function controls is false and there is no change in behavior, meaning PyTorch may implement its operations nondeterministically by default.</p>

<p>More precisely, when this flag is true:</p>
<ul>
  <li>Operations known to not have a deterministic implementation throw a runtime error;</li>
  <li>Operations with deterministic variants use those variants (usually with a performance penalty versus the non-deterministic version); and</li>
  <li><code class="language-plaintext highlighter-rouge">torch.backends.cudnn.deterministic = True</code> is set.</li>
</ul>

<p>Note that this is necessary, <strong>but not sufficient</strong>, for determinism <strong>within a single run of a PyTorch program</strong>. Other sources of randomness like random number generators, unknown operations, or asynchronous or distributed computation may still cause nondeterministic behavior.</p>

<p>See the documentation for <code class="language-plaintext highlighter-rouge">torch.set_deterministic(bool)</code> for the list of affected operations.</p>
<ul>
  <li><a href="https://github.com/pytorch/pytorch/issues/15359">RFC</a></li>
  <li><a href="https://pytorch.org/docs/stable/generated/torch.set_deterministic.html">Documentation</a></li>
</ul>

<h1 id="performance--profiling">Performance &amp; Profiling</h1>
<h2 id="beta-stack-traces-added-to-profiler">[Beta] Stack traces added to profiler</h2>
<p>Users can now see not only operator name/inputs in the profiler output table but also where the operator is in the code. The workflow requires very little change to take advantage of this capability. The user uses the <a href="https://pytorch.org/docs/stable/autograd.html#profiler">autograd profiler</a> as before but with optional new parameters: <code class="language-plaintext highlighter-rouge">with_stack</code> and <code class="language-plaintext highlighter-rouge">group_by_stack_n</code>. Caution: regular profiling runs should not use this feature as it adds significant overhead.</p>
<ul>
  <li><a href="https://github.com/pytorch/pytorch/pull/43898/">Detail</a></li>
  <li><a href="https://pytorch.org/docs/stable/autograd.html">Documentation</a></li>
</ul>

<h1 id="distributed-training--rpc">Distributed Training &amp; RPC</h1>
<h2 id="stable-torchelastic-now-bundled-into-pytorch-docker-image">[Stable] TorchElastic now bundled into PyTorch docker image</h2>
<p>Torchelastic offers a strict superset of the current <code class="language-plaintext highlighter-rouge">torch.distributed.launch</code> CLI with the added features for fault-tolerance and elasticity. If the user is not be interested in fault-tolerance, they can get the exact functionality/behavior parity by setting <code class="language-plaintext highlighter-rouge">max_restarts=0</code> with the added convenience of auto-assigned <code class="language-plaintext highlighter-rouge">RANK</code> and <code class="language-plaintext highlighter-rouge">MASTER_ADDR|PORT</code> (versus manually specified in <code class="language-plaintext highlighter-rouge">torch.distributed.launch)</code>.</p>

<p>By bundling <code class="language-plaintext highlighter-rouge">torchelastic</code> in the same docker image as PyTorch, users can start experimenting with TorchElastic right-away without having to separately install <code class="language-plaintext highlighter-rouge">torchelastic</code>. In addition to convenience, this work is a nice-to-have when adding support for elastic parameters in the existing Kubeflow’s distributed PyTorch operators.</p>
<ul>
  <li><a href="https://pytorch.org/elastic/0.2.0/examples.html">Usage examples and how to get started</a></li>
</ul>

<h2 id="beta-support-for-uneven-dataset-inputs-in-ddp">[Beta] Support for uneven dataset inputs in DDP</h2>
<p>PyTorch 1.7 introduces a new context manager to be used in conjunction with models trained using <code class="language-plaintext highlighter-rouge">torch.nn.parallel.DistributedDataParallel</code> to enable training with uneven dataset size across different processes. This feature enables greater flexibility when using DDP and prevents the user from having to manually ensure dataset sizes are the same across different process. With this context manager, DDP will handle uneven dataset sizes automatically, which can prevent errors or hangs at the end of training.</p>
<ul>
  <li><a href="https://github.com/pytorch/pytorch/issues/38174">RFC</a></li>
  <li><a href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.join">Documentation</a></li>
</ul>

<h2 id="beta-nccl-reliability---async-errortimeout-handling">[Beta] NCCL Reliability - Async Error/Timeout Handling</h2>
<p>In the past, NCCL training runs would hang indefinitely due to stuck collectives, leading to a very unpleasant experience for users. This feature will abort stuck collectives and throw an exception/crash the process if a potential hang is detected. When used with something like torchelastic (which can recover the training process from the last checkpoint), users can have much greater reliability for distributed training. This feature is completely opt-in and sits behind an environment variable that needs to be explicitly set in order to enable this functionality (otherwise users will see the same behavior as before).</p>
<ul>
  <li><a href="https://github.com/pytorch/pytorch/issues/46874">RFC</a></li>
  <li><a href="https://pytorch.org/docs/stable/distributed.html?highlight=init_process_group#torch.distributed.init_process_group">Documentation</a></li>
</ul>

<h2 id="beta-torchscript-rpc_remote-and-rpc_sync">[Beta] TorchScript <code class="language-plaintext highlighter-rouge">rpc_remote</code> and <code class="language-plaintext highlighter-rouge">rpc_sync</code></h2>
<p><code class="language-plaintext highlighter-rouge">torch.distributed.rpc.rpc_async</code> has been available in TorchScript in prior releases. For PyTorch 1.7, this functionality will be extended the remaining two core RPC APIs, <code class="language-plaintext highlighter-rouge">torch.distributed.rpc.rpc_sync</code> and <code class="language-plaintext highlighter-rouge">torch.distributed.rpc.remote</code>. This will complete the major RPC APIs targeted for support in TorchScript, it allows users to use the existing python RPC APIs within TorchScript (in a script function or script method, which releases the python Global Interpreter Lock) and could possibly improve application performance in multithreaded environment.</p>
<ul>
  <li><a href="https://pytorch.org/docs/stable/rpc.html#rpc">Documentation</a></li>
  <li><a href="https://github.com/pytorch/pytorch/blob/58ed60c259834e324e86f3e3118e4fcbbfea8dd1/torch/testing/_internal/distributed/rpc/jit/rpc_test.py#L505-L525">Usage examples</a></li>
</ul>

<h2 id="beta-distributed-optimizer-with-torchscript-support">[Beta] Distributed optimizer with TorchScript support</h2>
<p>PyTorch provides a broad set of optimizers for training algorithms, and these have been used repeatedly as part of the python API. However, users often want to use multithreaded training instead of multiprocess training as it provides better resource utilization and efficiency in the context of large scale distributed training (e.g. Distributed Model Parallel) or any RPC-based training application). Users couldn’t do this with with distributed optimizer before because we need to get rid of the python Global Interpreter Lock (GIL) limitation to achieve this.</p>

<p>In PyTorch 1.7, we are enabling the TorchScript support in distributed optimizer to remove the GIL, and make it possible to run optimizer in multithreaded applications. The new distributed optimizer has the exact same interface as before but it automatically converts optimizers within each worker into TorchScript to make each GIL free. This is done by leveraging a functional optimizer concept and allowing the distributed optimizer to convert the computational portion of the optimizer into TorchScript. This will help use cases like distributed model parallel training and improve performance using multithreading.</p>

<p>Currently, the only optimizer that supports automatic conversion with TorchScript is <code class="language-plaintext highlighter-rouge">Adagrad</code> and all other optimizers will still work as before without TorchScript support. We are working on expanding the coverage to all PyTorch optimizers and expect more to come in future releases. The usage to enable TorchScript support is automatic and exactly the same with existing python APIs, here is an example of how to use this:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch.distributed.autograd</span> <span class="k">as</span> <span class="n">dist_autograd</span>
<span class="kn">import</span> <span class="nn">torch.distributed.rpc</span> <span class="k">as</span> <span class="n">rpc</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torch.distributed.optim</span> <span class="kn">import</span> <span class="n">DistributedOptimizer</span>

<span class="k">with</span> <span class="n">dist_autograd</span><span class="p">.</span><span class="n">context</span><span class="p">()</span> <span class="k">as</span> <span class="n">context_id</span><span class="p">:</span>
  <span class="c1"># Forward pass.
</span>  <span class="n">rref1</span> <span class="o">=</span> <span class="n">rpc</span><span class="p">.</span><span class="n">remote</span><span class="p">(</span><span class="s">"worker1"</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">3</span><span class="p">))</span>
  <span class="n">rref2</span> <span class="o">=</span> <span class="n">rpc</span><span class="p">.</span><span class="n">remote</span><span class="p">(</span><span class="s">"worker1"</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">add</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">))</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">rref1</span><span class="p">.</span><span class="n">to_here</span><span class="p">()</span> <span class="o">+</span> <span class="n">rref2</span><span class="p">.</span><span class="n">to_here</span><span class="p">()</span>

  <span class="c1"># Backward pass.
</span>  <span class="n">dist_autograd</span><span class="p">.</span><span class="n">backward</span><span class="p">(</span><span class="n">context_id</span><span class="p">,</span> <span class="p">[</span><span class="n">loss</span><span class="p">.</span><span class="nb">sum</span><span class="p">()])</span>

  <span class="c1"># Optimizer, pass in optim.Adagrad, DistributedOptimizer will
</span>  <span class="c1"># automatically convert/compile it to TorchScript (GIL-free)
</span>  <span class="n">dist_optim</span> <span class="o">=</span> <span class="n">DistributedOptimizer</span><span class="p">(</span>
     <span class="n">optim</span><span class="p">.</span><span class="n">Adagrad</span><span class="p">,</span>
     <span class="p">[</span><span class="n">rref1</span><span class="p">,</span> <span class="n">rref2</span><span class="p">],</span>
     <span class="n">lr</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">dist_optim</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">context_id</span><span class="p">)</span>
</code></pre></div></div>
<ul>
  <li><a href="https://github.com/pytorch/pytorch/issues/46883">RFC</a></li>
  <li><a href="https://pytorch.org/docs/stable/rpc.html#module-torch.distributed.optim">Documentation</a></li>
</ul>

<h2 id="beta-enhancements-to-rpc-based-profiling">[Beta] Enhancements to RPC-based Profiling</h2>
<p>Support for using the PyTorch profiler in conjunction with the RPC framework was first introduced in PyTorch 1.6. In PyTorch 1.7, the following enhancements have been made:</p>
<ul>
  <li>Implemented better support for profiling TorchScript functions over RPC</li>
  <li>Achieved parity in terms of profiler features that work with RPC</li>
  <li>Added support for asynchronous RPC functions on the server-side (functions decorated with <code class="language-plaintext highlighter-rouge">rpc.functions.async_execution)</code>.</li>
</ul>

<p>Users are now able to use familiar profiling tools such as with <code class="language-plaintext highlighter-rouge">torch.autograd.profiler.profile()</code> and <code class="language-plaintext highlighter-rouge">with torch.autograd.profiler.record_function</code>, and this works transparently with the RPC framework with full feature support, profiles asynchronous functions, and TorchScript functions.</p>
<ul>
  <li><a href="https://github.com/pytorch/pytorch/issues/39675">Design doc</a></li>
  <li><a href="https://pytorch.org/tutorials/recipes/distributed_rpc_profiling.html">Usage examples</a></li>
</ul>

<h2 id="prototype-windows-support-for-distributed-training">[Prototype] Windows support for Distributed Training</h2>
<p>PyTorch 1.7 brings prototype support for <code class="language-plaintext highlighter-rouge">DistributedDataParallel</code> and collective communications on the Windows platform. In this release, the support only covers Gloo-based <code class="language-plaintext highlighter-rouge">ProcessGroup</code> and <code class="language-plaintext highlighter-rouge">FileStore</code>.</p>

<p>To use this feature across multiple machines, please provide a file from a shared file system in <code class="language-plaintext highlighter-rouge">init_process_group</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># initialize the process group
</span><span class="n">dist</span><span class="p">.</span><span class="n">init_process_group</span><span class="p">(</span>
    <span class="s">"gloo"</span><span class="p">,</span>
    <span class="c1"># multi-machine example:
</span>    <span class="c1"># init_method = "file://////{machine}/{share_folder}/file"
</span>    <span class="n">init_method</span><span class="o">=</span><span class="s">"file:///{your local file path}"</span><span class="p">,</span>
    <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
    <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">local_model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>
</code></pre></div></div>
<ul>
  <li><a href="https://github.com/pytorch/pytorch/issues/42095">Design doc</a></li>
  <li><a href="https://pytorch.org/docs/master/distributed.html#backends-that-come-with-pytorch">Documentation</a></li>
  <li>Acknowledgement (<a href="https://github.com/gunandrose4u">gunandrose4u</a>)</li>
</ul>

<h1 id="mobile">Mobile</h1>
<p>PyTorch Mobile supports both <a href="https://pytorch.org/mobile/ios">iOS</a> and <a href="https://pytorch.org/mobile/android/">Android</a> with binary packages available in <a href="https://cocoapods.org/">Cocoapods</a> and <a href="https://mvnrepository.com/repos/jcenter">JCenter</a> respectively. You can learn more about PyTorch Mobile <a href="https://pytorch.org/mobile/home/">here</a>.</p>

<h2 id="beta-pytorch-mobile-caching-allocator-for-performance-improvements">[Beta] PyTorch Mobile Caching allocator for performance improvements</h2>
<p>On some mobile platforms, such as Pixel, we observed that memory is returned to the system more aggressively. This results in frequent page faults as PyTorch being a functional framework does not maintain state for the operators. Thus outputs are allocated dynamically on each execution of the op, for the most ops. To ameliorate performance penalties due to this, PyTorch 1.7 provides a simple caching allocator for CPU. The allocator caches allocations by tensor sizes and, is currently, available only via the PyTorch C++ API. The caching allocator itself is owned by client and thus the lifetime of the allocator is also maintained by client code. Such a client owned caching allocator can then be used with scoped guard, <code class="language-plaintext highlighter-rouge">c10::WithCPUCachingAllocatorGuard</code>, to enable the use of cached allocation within that scope.
<strong>Example usage:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#include &lt;c10/mobile/CPUCachingAllocator.h&gt;
</span><span class="p">.....</span>
<span class="n">c10</span><span class="p">::</span><span class="n">CPUCachingAllocator</span> <span class="n">caching_allocator</span><span class="p">;</span>
  <span class="o">//</span> <span class="n">Owned</span> <span class="n">by</span> <span class="n">client</span> <span class="n">code</span><span class="p">.</span> <span class="n">Can</span> <span class="n">be</span> <span class="n">a</span> <span class="n">member</span> <span class="n">of</span> <span class="n">some</span> <span class="n">client</span> <span class="k">class</span> <span class="nc">so</span> <span class="k">as</span> <span class="n">to</span> <span class="n">tie</span> <span class="n">the</span>
  <span class="o">//</span> <span class="n">the</span> <span class="n">lifetime</span> <span class="n">of</span> <span class="n">caching</span> <span class="n">allocator</span> <span class="n">to</span> <span class="n">that</span> <span class="n">of</span> <span class="n">the</span> <span class="n">class</span><span class="p">.</span>
<span class="p">.....</span>
<span class="p">{</span>
  <span class="n">c10</span><span class="p">::</span><span class="n">optional</span><span class="o">&lt;</span><span class="n">c10</span><span class="p">::</span><span class="n">WithCPUCachingAllocatorGuard</span><span class="o">&gt;</span> <span class="n">caching_allocator_guard</span><span class="p">;</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">FLAGS_use_caching_allocator</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">caching_allocator_guard</span><span class="p">.</span><span class="n">emplace</span><span class="p">(</span><span class="o">&amp;</span><span class="n">caching_allocator</span><span class="p">);</span>
  <span class="p">}</span>
  <span class="p">....</span>
  <span class="n">model</span><span class="p">.</span><span class="n">forward</span><span class="p">(..);</span>
<span class="p">}</span>
<span class="p">...</span>
</code></pre></div></div>
<p><strong>NOTE</strong>: Caching allocator is only available on mobile builds, thus the use of caching allocator outside of mobile builds won’t be effective.</p>
<ul>
  <li><a href="https://github.com/pytorch/pytorch/blob/master/c10/mobile/CPUCachingAllocator.h#L13-L43">Documentation</a></li>
  <li><a href="https://github.com/pytorch/pytorch/blob/master/binaries/speed_benchmark_torch.cc#L207">Usage examples</a></li>
</ul>

<h1 id="torchvision">torchvision</h1>
<h2 id="stable-transforms-now-support-tensor-inputs-batch-computation-gpu-and-torchscript">[Stable] Transforms now support Tensor inputs, batch computation, GPU, and TorchScript</h2>
<p>torchvision transforms are now inherited from <code class="language-plaintext highlighter-rouge">nn.Module</code> and can be torchscripted and applied on torch Tensor inputs as well as on PIL images. They also support Tensors with batch dimensions and work seamlessly on CPU/GPU devices:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="n">T</span>

<span class="c1"># to fix random seed, use torch.manual_seed
# instead of random.seed
</span><span class="n">torch</span><span class="p">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>

<span class="n">transforms</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">T</span><span class="p">.</span><span class="n">RandomCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">T</span><span class="p">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">),</span>
    <span class="n">T</span><span class="p">.</span><span class="n">ConvertImageDtype</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nb">float</span><span class="p">),</span>
    <span class="n">T</span><span class="p">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
<span class="p">)</span>
<span class="n">scripted_transforms</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="n">script</span><span class="p">(</span><span class="n">transforms</span><span class="p">)</span>
<span class="c1"># Note: we can similarly use T.Compose to define transforms
# transforms = T.Compose([...]) and 
# scripted_transforms = torch.jit.script(torch.nn.Sequential(*transforms.transforms))
</span>
<span class="n">tensor_image</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="c1"># works directly on Tensors
</span><span class="n">out_image1</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">tensor_image</span><span class="p">)</span>
<span class="c1"># on the GPU
</span><span class="n">out_image1_cuda</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">tensor_image</span><span class="p">.</span><span class="n">cuda</span><span class="p">())</span>
<span class="c1"># with batches
</span><span class="n">batched_image</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="n">out_image_batched</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">batched_image</span><span class="p">)</span>
<span class="c1"># and has torchscript support
</span><span class="n">out_image2</span> <span class="o">=</span> <span class="n">scripted_transforms</span><span class="p">(</span><span class="n">tensor_image</span><span class="p">)</span>
</code></pre></div></div>
<p>These improvements enable the following new features:</p>
<ul>
  <li>support for GPU acceleration</li>
  <li>batched transformations e.g. as needed for videos</li>
  <li>transform multi-band torch tensor images (with more than 3-4 channels)</li>
  <li>torchscript transforms together with your model for deployment
<strong>Note:</strong> Exceptions for TorchScript support includes <code class="language-plaintext highlighter-rouge">Compose</code>, <code class="language-plaintext highlighter-rouge">RandomChoice</code>, <code class="language-plaintext highlighter-rouge">RandomOrder</code>, <code class="language-plaintext highlighter-rouge">Lambda</code> and those applied on PIL images, such as <code class="language-plaintext highlighter-rouge">ToPILImage</code>.</li>
</ul>

<h2 id="stable-native-image-io-for-jpeg-and-png-formats">[Stable] Native image IO for JPEG and PNG formats</h2>
<p>torchvision 0.8.0 introduces native image reading and writing operations for JPEG and PNG formats. Those operators support TorchScript and return <code class="language-plaintext highlighter-rouge">CxHxW</code> tensors in <code class="language-plaintext highlighter-rouge">uint8</code> format, and can thus be now part of your model for deployment in C++ environments.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torchvision.io</span> <span class="kn">import</span> <span class="n">read_image</span>

<span class="c1"># tensor_image is a CxHxW uint8 Tensor
</span><span class="n">tensor_image</span> <span class="o">=</span> <span class="n">read_image</span><span class="p">(</span><span class="s">'path_to_image.jpeg'</span><span class="p">)</span>

<span class="c1"># or equivalently
</span><span class="kn">from</span> <span class="nn">torchvision.io</span> <span class="kn">import</span> <span class="n">read_file</span><span class="p">,</span> <span class="n">decode_image</span>
<span class="c1"># raw_data is a 1d uint8 Tensor with the raw bytes
</span><span class="n">raw_data</span> <span class="o">=</span> <span class="n">read_file</span><span class="p">(</span><span class="s">'path_to_image.jpeg'</span><span class="p">)</span>
<span class="n">tensor_image</span> <span class="o">=</span> <span class="n">decode_image</span><span class="p">(</span><span class="n">raw_data</span><span class="p">)</span>

<span class="c1"># all operators are torchscriptable and can be
# serialized together with your model torchscript code
</span><span class="n">scripted_read_image</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="n">script</span><span class="p">(</span><span class="n">read_image</span><span class="p">)</span>
</code></pre></div></div>
<h2 id="stable-retinanet-detection-model">[Stable] RetinaNet detection model</h2>
<p>This release adds pretrained models for RetinaNet with a ResNet50 backbone from <a href="https://arxiv.org/abs/1708.02002">Focal Loss for Dense Object Detection</a>.</p>

<h2 id="beta-new-video-reader-api">[Beta] New Video Reader API</h2>
<p>This release introduces a new video reading abstraction, which gives more fine-grained control of iteration over videos. It supports image and audio, and implements an iterator interface so that it is interoperable with other the python libraries such as itertools.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torchvision.io</span> <span class="kn">import</span> <span class="n">VideoReader</span>

<span class="c1"># stream indicates if reading from audio or video
</span><span class="n">reader</span> <span class="o">=</span> <span class="n">VideoReader</span><span class="p">(</span><span class="s">'path_to_video.mp4'</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="s">'video'</span><span class="p">)</span>
<span class="c1"># can change the stream after construction
# via reader.set_current_stream
</span>
<span class="c1"># to read all frames in a video starting at 2 seconds
</span><span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="c1"># frame is a dict with "data" and "pts" metadata
</span>    <span class="k">print</span><span class="p">(</span><span class="n">frame</span><span class="p">[</span><span class="s">"data"</span><span class="p">],</span> <span class="n">frame</span><span class="p">[</span><span class="s">"pts"</span><span class="p">])</span>

<span class="c1"># because reader is an iterator you can combine it with
# itertools
</span><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">takewhile</span><span class="p">,</span> <span class="n">islice</span>
<span class="c1"># read 10 frames starting from 2 seconds
</span><span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">islice</span><span class="p">(</span><span class="n">reader</span><span class="p">.</span><span class="n">seek</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="mi">10</span><span class="p">):</span>
    <span class="k">pass</span>
    
<span class="c1"># or to return all frames between 2 and 5 seconds
</span><span class="k">for</span> <span class="n">frame</span> <span class="ow">in</span> <span class="n">takewhile</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="s">"pts"</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">,</span> <span class="n">reader</span><span class="p">):</span>
    <span class="k">pass</span>
</code></pre></div></div>
<p><strong>Notes:</strong></p>
<ul>
  <li>In order to use the Video Reader API beta, you must compile torchvision from source and have ffmpeg installed in your system.</li>
  <li>The VideoReader API is currently released as beta and its API may change following user feedback.</li>
</ul>

<h1 id="torchaudio">torchaudio</h1>
<p>With this release, torchaudio is expanding its support for models and <a href="https://github.com/pytorch/audio/tree/master/examples">end-to-end applications</a>, adding a wav2letter training pipeline and end-to-end text-to-speech and source separation pipelines. Please file an issue on <a href="https://github.com/pytorch/audio/issues/new?template=questions-help-support.md">github</a> to provide feedback on them.</p>

<h2 id="stable-speech-recognition">[Stable] Speech Recognition</h2>
<p>Building on the addition of the wav2letter model for speech recognition in the last release, we’ve now added an <a href="https://github.com/pytorch/audio/tree/master/examples/pipeline_wav2letter">example wav2letter training pipeline</a> with the LibriSpeech dataset.</p>

<h2 id="stable-text-to-speech">[Stable] Text-to-speech</h2>
<p>With the goal of supporting text-to-speech applications, we added a vocoder based on the WaveRNN model, based on the implementation from <a href="https://github.com/fatchord/WaveRNN">this repository</a>. The original implementation was introduced in “Efficient Neural Audio Synthesis”. We also provide an <a href="https://github.com/pytorch/audio/tree/master/examples/pipeline_wavernn">example WaveRNN training pipeline</a> that uses the LibriTTS dataset added to torchaudio in this release.</p>

<h2 id="stable-source-separation">[Stable] Source Separation</h2>
<p>With the addition of the ConvTasNet model, based on the paper “Conv-TasNet: Surpassing Ideal Time-Frequency Magnitude Masking for Speech Separation,” torchaudio now also supports source separation. An <a href="https://github.com/pytorch/audio/tree/master/examples/source_separation">example ConvTasNet training pipeline</a> is provided with the wsj-mix dataset.</p>

<p>Cheers!</p>

<p>Team PyTorch</p>

                </article>
            </div>
        </div>
    </div>

<!--    


 -->
    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="/docs">View Docs</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.org" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.org">PyTorch</a></li>
          <li><a href="/get-started">Get Started</a></li>
          <li><a href="/features">Features</a></li>
          <li><a href="/ecosystem">Ecosystem</a></li>
          <li><a href="/blog">Blog</a></li>
          <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          <li><a href="https://github.com/pytorch/pytorch/security/policy" target="_blank">Security</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="/resources">Resources</a></li>
          <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
          <li><a href="/docs">Docs</a></li>
          <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
          <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">GitHub Issues</a></li>
          <li><a href="/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><p>Stay up to date</p></li>
          <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
          <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
          <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
          <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          <li><a href="https://social.lfx.dev/@pytorch" rel="me" target="_blank">Mastodon</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><p>PyTorch Podcasts</p></li>
          <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
          <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
          <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
          <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
        </ul>
      </div>
    </div>

    <div class="privacy-policy">
      <ul>
        <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
        <li class="privacy-policy-links">|</li>
        <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
      </ul>
      <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation. 
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see 
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source 
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC, 
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
    </div>
  </div>
  <img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>
        <li class="navSearchWrapper reactNavSearchWrapper tabletSearchWrapper" key="search">
          <div class="mobile-search-border">
            <input
              id="mobile-search-input"
              type="text"
              title="Search"
            />
            <div id="mobile-search-icon"></div>
          </div>
        </li>

        <li class="">
          <a href="/get-started">Get Started</a>
        </li>

        <li class="resources-mobile-menu-title">
          <a href="/ecosystem">Ecosystem</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/ecosystem">Tools</a>
          </li>
          <li>
            <a href="/ecosystem/pted/2021">Ecosystem Day 2021</a>
          </li>
          <li>
            <a href="/ecosystem/ptdd/2021">Developer Day 2021</a>
          </li>
        </ul>

        <li class="">
          <a href="/mobile">Mobile</a>
        </li>

        <li class="active">
          <a href="/blog">Blog</a>
        </li>

        <li>
          <a href="https://pytorch.org/tutorials">Tutorials</a>
        </li>

        <li class="resources-mobile-menu-title">
          <a href="/docs">Docs</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li class="">
            <a href="/docs">PyTorch</a>
          </li>

          <li class="">
            <a href="/audio">torchaudio</a>
          </li>

          <li class="">
            <a href="/text">torchtext</a>
          </li>

          <li class="">
            <a href="/vision">torchvision</a>
          </li>

          <li class="">
            <a href="/torcharrow">torcharrow</a>
          </li>

          <li class="">
            <a href="/data">TorchData</a>
          </li> 

          <li class="">
            <a href="/torchrec">TorchRec</a>
          </li>

          <li class="">
            <a href="/serve">TorchServe</a>
          </li>

          <li class="">
            <a href="/xla/release/1.6/index.html">PyTorch on XLA Devices</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          Resources
        </li>

        <ul class="resources-mobile-menu-items">
          <li class="">
            <a href="/features">About</a>
          </li>

          <li>
            <a href="/foundation">PyTorch Foundation</a>
          </li>
          
          <li>
            <a href="/#community-module">Community</a>
          </li>
          
          <li class="">
            <a href="/community-stories">Community stories</a>
          </li>

          <li class="">
            <a href="/resources">Developer Resources</a>
          </li>

          <li>
            <a href="/events">Events</a>
          </li>

          <li>
            <a href="https://discuss.pytorch.org">Forum</a>
          </li>

          <li class="">
            <a href="/hub">Models (Beta)</a>
          </li>

        </ul>

        <li id="github-mobile-menu-link">
          <a href="https://github.com/pytorch/pytorch">GitHub</a>
        </li>
      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>

  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script>

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>


  <script src="/assets/track-events.js"></script>
  <script>trackEvents.bind();</script>



<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="/assets/images/pytorch-x.svg">
  </div>
</div>


</body>

</html>
