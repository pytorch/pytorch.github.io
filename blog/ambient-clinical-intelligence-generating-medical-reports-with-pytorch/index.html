<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
  <!-- End Google Tag Manager -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      Ambient Clinical Intelligence: Generating Medical Reports with PyTorch | PyTorch
    
  </title>
  <meta name="robots" content="index, follow" />

<meta name="description" content="Introduction

" />

  <meta property="og:image" content="https://pytorch.org/" />
  <meta name="twitter:image" content="https://pytorch.org/" />

<meta property="og:locale" content="en_US" />
<meta property="og:type" content="website" />
<meta property="og:title" content="Ambient Clinical Intelligence: Generating Medical Reports with PyTorch" />
<meta property="og:description" content="Introduction

" />
<meta property="og:site_name" content="PyTorch" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="Ambient Clinical Intelligence: Generating Medical Reports with PyTorch" />
<meta name="twitter:description" content="Introduction

" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
  
    <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window,document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '243028289693773');
    fbq('track', 'PageView');
</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

    <!-- Twitter universal website tag code -->
<img height="1" width="1" style="display:none;" alt="" src="https://analytics.twitter.com/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__analytics.twitter.com_i_adsct-3Fp-5Fid-3DTwitter-26p-5Fuser-5Fid-3D0-26txn-5Fid-3Do2gi1-26events-3D-255B-255B-2522pageview-2522-252Cnull-255D-255D-26tw-5Fsale-5Famount-3D0-26tw-5Forder-5Fquantity-3D0&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=o6i4D0V0088WH2RnzIoqiF-vj45PL-2sTrsxQ0SNO3A&e=)" />
<img height="1" width="1" style="display:none;" alt="" src="//t.co/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__linkprotect.cudasvc.com_url-3Fa-3Dhttp-253a-252f-252ft.co-252fi-252fadsct-253fp-5Fid-253dTwitter-2526p-5Fuser-5Fid-253d0-2526txn-5Fid-253do2gi1-2526events-253d-25255B-25255B-252522pageview-252522-25252Cnull-25255D-25255D-2526tw-5Fsale-5Famount-253d0-2526tw-5Forder-5Fquantity-253d0-26c-3DE-2C1-2CC33dLwIhtuEcl5FhdztSnUwsioeej5k-2DWy0RYREBAq51kGji32A2Cw94YU9vQBpY5tPN3AukEw3C-5F-2DlbtndnLoR7-5FA-5FLoH0Rr7zLtP1ykptN-26typo-3D1&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=Abgc3XBkhESv8XBYtLchdDZyISGsK6v_BB6cLMJGyCw&e=)" />
<!-- End Twitter universal website tag code -->

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Pythorch Blog Posts" />
</head>


<body class="blog">
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <div class="main-background blog-background blog-detail-background"></div>
    <div class="hello-bar">
        <div class="container">
            Join us at PyTorch Conference in San Francisco, October 22-23. CFP open now! <a target="_blank" href="https://events.linuxfoundation.org/pytorch-conference/">Learn more</a>.
        </div>
      </div>
      
    <div class="container-fluid header-holder blog-detail-header">
        <div class="container">
            

<div class="header-container">
  <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Learn
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/get-started">
            <span class=dropdown-title>Get Started</span>
            <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/">
            <span class="dropdown-title">Tutorials</span>
            <p>Whats new in PyTorch tutorials</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
            <span class="dropdown-title">Learn the Basics</span>
            <p>Familiarize yourself with PyTorch concepts and modules</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
            <span class="dropdown-title">PyTorch Recipes</span>
            <p>Bite-size, ready-to-deploy PyTorch code examples</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
            <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
            <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
          </a>
          <a class="nav-dropdown-item" href="/new">
            <span class="dropdown-title">New to PyTorch Foundation</span>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Ecosystem 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="https://landscape.pytorch.org/" target="_blank">
            <span class="dropdown-title">Tools</span>
            <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="/join-ecosystem">
            <span class="dropdown-title">Join the Ecosystem</span>
          </a>
          <a class="nav-dropdown-item" href="/#community-module">
            <span class=dropdown-title>Community</span>
            <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
          </a>
          <a class="nav-dropdown-item" href="https://discuss.pytorch.org" target="_blank">
            <span class=dropdown-title>Forums</span>
            <p>A place to discuss PyTorch code, issues, install, research</p>
          </a>
          <a class="nav-dropdown-item" href="/resources">
            <span class=dropdown-title>Developer Resources</span>
            <p>Find resources and get questions answered</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/contributor-awards-2024">
            <span class="dropdown-title">Contributor Awards - 2024</span>
            <p>Award winners announced at this year's PyTorch Conference</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Edge 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/edge">
            <span class="dropdown-title">About PyTorch Edge</span>
            <p>Build innovative and privacy-aware AI experiences for edge devices</p>
          </a>
          <a class="nav-dropdown-item" href="/executorch-overview">
            <span class="dropdown-title">ExecuTorch</span>
            <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
          </a>
          <a class="nav-dropdown-item" target="_blank" href="https://pytorch.org/executorch/stable/index.html">
            <span class="dropdown-title">ExecuTorch Documentation</span>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="docsDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Docs
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="https://pytorch.org/docs">
            <span class="dropdown-title">PyTorch</span>
            <p>Explore the documentation for comprehensive guidance on how to use PyTorch.</p>
          </a>
          <a class="nav-dropdown-item" href="/pytorch-domains">
            <span class="dropdown-title">PyTorch Domains</span>
            <p> Read the PyTorch Domains documentation to learn more about domain-specific libraries.</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Blog & News
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/blog">
            <span class="dropdown-title">PyTorch Blog</span>
            <p>Catch up on the latest technical news and happenings</p>
          </a>
          <a class="nav-dropdown-item" href="/community-blog">
            <span class="dropdown-title">Community Blog</span>
            <p>Stories from the PyTorch ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="/videos">
            <span class="dropdown-title">Videos</span>
            <p>Learn about the latest PyTorch tutorials, new, and more </p>
          </a>
          <a class="nav-dropdown-item" href="/community-stories">
            <span class="dropdown-title">Community Stories</span>
            <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
          </a>
          <a class="nav-dropdown-item" href="/events">
            <span class=dropdown-title>Events</span>
            <p>Find events, webinars, and podcasts</p>
          </a>
          <a class="nav-dropdown-item" href="/newsletter">
            <span class=dropdown-title>Newsletter</span>
            <p>Stay up-to-date with the latest updates</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          About
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/foundation">
            <span class=dropdown-title>PyTorch Foundation</span>
            <p>Learn more about the PyTorch Foundation.</p>
          </a>
          <a class="nav-dropdown-item" href="/governing-board">
            <span class=dropdown-title>Governing Board</span>
          </a>
          <a class="nav-dropdown-item" href="/credits">
            <span class=dropdown-title>Cloud Credit Program</span>
          </a>
          <a class="nav-dropdown-item" href="/tac">
            <span class=dropdown-title>Technical Advisory Council</span>
          </a>
          <a class="nav-dropdown-item" href="/staff">
            <span class=dropdown-title>Staff</span>
          </a>
          <a class="nav-dropdown-item" href="/contact-us">
            <span class=dropdown-title>Contact Us</span>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <a href="/join" data-cta="join">
        Become a Member
      </a>
    </li>

    <li class="main-menu-item" id="github-main-menu-link">
      <a href="https://github.com/pytorch/pytorch" title="Go to PyTorch GitHub">
        <div id="topnav-gh-icon"></div>
      </a>
    </li>

    <li class="navSearchWrapper reactNavSearchWrapper" key="search">
      <div class="search-border">
        <div id="search-icon"></div>
        <input
          id="search-input"
          type="text"
          title="Search"
        />
        <div id="close-search">X</div>
      </div>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

        </div>
    </div>

    <div class="jumbotron jumbotron-fluid blog-detail-jumbotron">
        <div class="container blog-detail-container">
            <p class="featured-post">May 12, 2022</p>
            <h1>
                <a class="blog-title">Ambient Clinical Intelligence: Generating Medical Reports with PyTorch</a>
            </h1>
        </div>
    </div>

    <div class="main-content-wrapper blog-detail-wrapper">
        <div class="main-content blog-detail-content">
            <div class="container">
                <img src="/assets/images/logo-icon.svg" class="img-fluid author-icon">
                <article class="pytorch-article">
                    <p class="author">
                      by
                      
                        Miguel Del-Agua, Principal Research Scientist, Nuance and Jeremy Jancsary, Senior Principal Research Scientist, Nuance
                      
                    </p>
                    <h2 id="introduction">Introduction</h2>

<p>Complete and accurate clinical documentation is an essential tool for tracking patient care. It allows for treatment plans to be shared among care teams to aid in continuity of care and ensures a transparent and effective process for reimbursement.</p>

<p>Physicians are responsible for documenting patient care. Traditional clinical documentation methods have resulted in a sub-par patient-provider experience, less time interacting with patients, and decreased work-life balance.  A significant amount of physicians’ time is spent in front of the computer doing administrative tasks. As a result, patients are less satisfied with the overall experience, and physicians, who prepare for years studying medicine, cannot practice at the top of their license and are burned out. Every hour physicians provide direct clinical face time to patients results in nearly two additional hours spent on EHR and desk work within the clinic day. Outside office hours, physicians <a href="https://www.acpjournals.org/doi/10.7326/m16-0961">spend another 1 to 2 hours of personal</a> time each night doing additional computer and other clerical work.</p>

<ul>
  <li><a href="https://www.medscape.com/slideshow/2020-lifestyle-burnout-6012460">42% of all physicians reported having burnout. – Medscape</a></li>
  <li><a href="https://www.aafp.org/journals/fpm/blogs/inpractice/entry/covid_burnout_survey.html#:~:text=Physician%20burnout%20was%20already%20a,5%2C000%20%E2%80%94%20practice%20in%20the%20U.S.">The problem has grown worse due to the pandemic with 64% of U.S. physicians now reporting burnout. - AAFP</a></li>
  <li><a href="https://login.medscape.com/login/sso/getlogin?urlCache=aHR0cHM6Ly93d3cubWVkc2NhcGUuY29tL3NsaWRlc2hvdy8yMDIwLWxpZmVzdHlsZS1idXJub3V0LTYwMTI0NjA%3D&amp;ac=401">“Too many bureaucratic tasks e.g., charting and paperwork” is the leading contribution to burnout, increased computerization ranks 4th.</a> - Medscape</li>
  <li><a href="https://www.businesswire.com/news/home/20200218005006/en/75-of-U.S.-Consumers-Wish-Their-Healthcare-Experiences-Were-More-Personalized-Redpoint-Global-Survey-Reveals">75% of U.S. Consumers Wish Their Healthcare Experiences Were More Personalized,</a>- Business Wire</li>
  <li><a href="https://www.businesswire.com/news/home/20200218005006/en/75-of-U.S.-Consumers-Wish-Their-Healthcare-Experiences-Were-More-Personalized-Redpoint-Global-Survey-Reveals">61% of patients would visit their healthcare provider more often if the communication experience felt more personalized.</a>  – Business Wire</li>
</ul>

<p>Physician burnout is one of the primary causes for increased <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6175626/">medical errors</a>, malpractice suits, turnover, and decreased access to care. Burnout leads to an increase in healthcare costs and a decrease in overall patient satisfaction. <a href="https://www.nejm.org/doi/full/10.1056/NEJMp2003149">Burnout costs the United States $4.6 billion a year.</a></p>

<p>What can we do to bring back trust, joy, and humanity to the delivery of healthcare? A significant portion of the administrative work consists of entering patient data into Electronic Health Records (EHRs) and creating clinical documentation. Clinical documentation is created from information already in the EHR as well as from the patient-provider encounter conversation.</p>

<p>This article will showcase how the Nuance Dragon Ambient eXperience (DAX), an AI-powered, voice-enabled, ambient clinical intelligence solution, automatically documents patient encounters accurately and efficiently at the point of care and the technologies that enable it.</p>

<p>Nuance DAX enhances the quality of care and patient experience, increases provider efficiency and satisfaction, and improves financial outcomes. It can be used in office and telehealth settings in all ambulatory specialties, including primary and urgent care.</p>

<p align="center">
  <img src="/assets/images/nuance-dragon-ambient-experience.png" width="60%" />
</p>

<h2 id="natural-language-processing">Natural Language Processing</h2>

<p>Natural Language Processing (NLP) is one of the most challenging fields in Artificial Intelligence (AI). It comprehends a set of algorithms that allow computers to understand or generate the language used by humans. These algorithms can process and analyze vast amounts of natural language data from different sources (either sound or text) to build models that can understand, classify, or even generate natural language as humans would. Like other fields in AI, NLP has significantly progressed thanks to the advent of Deep Learning (DL), which has resulted in models that can obtain results on par with humans in some tasks.</p>

<p>These advanced NLP techniques are being applied in healthcare. During a typical patient-provider encounter, a conversation ensues where the doctor constructs, through questions and answers, a chronological description of the development of the patient’s presenting illness or symptoms. A physician examines the patient and makes clinical decisions to establish a diagnosis and determine a treatment plan. This conversation, and data in the EHR, provide the required information for physicians to generate the clinical documentation, referred to as medical reports.</p>

<p>Two main NLP components play a role in automating the creation of clinical documentation. The first component, Automatic Speech Recognition (ASR), is used to translate speech into text. It takes the audio recording of the encounter and generates a conversation transcription (cf. Figure 2). The second component, Automatic Text Summarization, helps generate summaries from large text documents. This component is responsible for understanding and capturing the nuances and most essential aspects from the transcribed conversation into a final report in narrative form (cf. Figure 3), structured form, or a combination of both.</p>

<p>We will focus on this second component, Automatic Text Summarization, which is a difficult task with many challenges:</p>

<ul>
  <li>Its performance is tied to the ASR quality from multiple speakers (noisy input).</li>
  <li>The input is conversational in nature and contains layman’s terms.</li>
  <li>Protected Health Information (PHI) regulations limit medical data access.</li>
  <li>The information for one output sentence is potentially spread across multiple conversation turns.</li>
  <li>There is no explicit sentence alignment between input and output.</li>
  <li>Various medical specialties, encounter types, and EHR systems constitute a broad and complex output space.</li>
  <li>Physicians have different styles of conducting encounters and have their preferences for medical reports; there is no standard.</li>
  <li>Standard summarization metrics might differ from human judgment of quality.</li>
</ul>

<p align="center">
 <img src="/assets/images/ambient_clinical_intel_fig2.png" width="60%" />
</p>

<p align="center">
Figure 2: Transcript of a patient-doctor conversation
</p>

<p align="center">
 <img src="/assets/images/ambient_clinical_intel_fig3.png" width="60%" />
</p>

<p align="center">
Figure 3: Excerpt of an AI-generated medical report. HPI stands for History of present illness.
</p>

<h2 id="text-summarization-with-pytorch-and-fairseq">Text Summarization with PyTorch and Fairseq</h2>

<p><a href="https://pytorch.org/">PyTorch</a> is an open-source machine learning framework developed by Facebook that helps researchers prototype Deep Learning models. The <a href="https://github.com/pytorch/fairseq">Fairseq</a> toolkit is built on top of PyTorch and focuses on sequence generation tasks, such as Neural Machine Translation (NMT) or Text Summarization. Fairseq features an active community that is continuously providing reference implementations of state-of-the-art models. It contains many built-in components (model architectures, modules, loss functions, and optimizers) and is easily extendable with plugins.</p>

<p>Text summarization constitutes a significant challenge in NLP. We need models capable of generating a short version of a document while retaining the key points and avoiding uninformative content. These  challenges can be addressed with  different approaches. 1). Abstractive text summarization aimed at training models that can generate a summary in narrative form. 2). Extractive methods where the models are trained to select the most important parts from the input text. 3). A combination of the two, where the essential parts from the input are selected and then summarized in an abstractive fashion. Hence, summarization can be accomplished via a single end-to-end network or as a pipeline of extractive and abstractive components. To that end, Fairseq provides all the necessary tools to be successful in our endeavor. It features either end-to-end models such as the classical Transformer, different types of Language Models and pre-trained versions that enable researchers to focus on what matters most—to build state-of-the-art models that generate valuable reports.</p>

<p>However, we are not just summarizing the transcribed conversation; we generate high-quality medical reports, which have many considerations.</p>

<ul>
  <li>Every section of a medical report is different in terms of content, structure, fluency, etc.</li>
  <li>All medical facts mentioned in the conversation should be present in the report, for example, a particular treatment or dosage.</li>
  <li>In the healthcare domain, the vocabulary is extensive, and models need to deal with medical terminology.</li>
  <li>Patient-doctor conversations are usually much longer than the final report.</li>
</ul>

<p>All these challenges require our researchers to run a battery of extensive experiments. Thanks to the flexibility of PyTorch and Fairseq, their productivity has greatly increased. Further, the ecosystem offers an easy path from ideation, implementation, experimentation, and final roll-out to production. Using multiple GPUs or CPUs is as simple as providing an additional argument to the tools, and because of the tight Python integration, PyTorch code can be easily debugged.</p>

<p>In our continuous effort to contribute to the open-source community, features have been developed at Nuance and pushed to the Fairseq GitHub repository.  These try to overcome some of the challenges mentioned such as, facilitating copying of, especially rare or unseen, words from the input to summary, training speedups by improving Tensor Core utilization, and ensuring TorchScript compatibility of different Transformer configurations. Following, we will show an example of how to train a Transformer model with a Pointer Generator mechanism (Transformer-PG), which can copy words from the input.</p>

<h2 id="how-to-build-a-transformer-model-with-a-pointer-generator-mechanism">How to build a Transformer model with a Pointer Generator mechanism</h2>

<p>In this step-by-step guide, it is assumed the user has already installed PyTorch and Fairseq.</p>

<h3 id="1-create-a-vocabulary-and-extend-it-with-source-position-markers">1. Create a vocabulary and extend it with source position markers:</h3>

<p>These markers will allow the model to point to any word in the input sequence.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">vocab_size</span><span class="o">=&lt;</span><span class="n">vocab_size</span><span class="o">&gt;</span>
<span class="n">position_markers</span><span class="o">=</span><span class="mi">512</span>
<span class="n">export</span> <span class="n">LC_ALL</span><span class="o">=</span><span class="n">C</span>
<span class="n">cat</span> <span class="n">train</span><span class="p">.</span><span class="n">src</span> <span class="n">train</span><span class="p">.</span><span class="n">tgt</span> <span class="o">|</span>
  <span class="n">tr</span> <span class="o">-</span><span class="n">s</span> <span class="s">'[:space:]'</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span> <span class="o">|</span>
  <span class="n">sort</span> <span class="o">|</span>
  <span class="n">uniq</span> <span class="o">-</span><span class="n">c</span> <span class="o">|</span>
  <span class="n">sort</span> <span class="o">-</span><span class="n">k1</span><span class="p">,</span><span class="mi">1</span><span class="n">bnr</span> <span class="o">-</span><span class="n">k2</span> <span class="o">|</span>
  <span class="n">head</span> <span class="o">-</span><span class="n">n</span> <span class="s">"$((vocab_size - 4))"</span> <span class="o">|</span>
  <span class="n">awk</span> <span class="s">'{ print $2 " " $1 }'</span> <span class="o">&gt;</span> <span class="nb">dict</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">txt</span>
<span class="n">python3</span> <span class="o">-</span><span class="n">c</span> <span class="s">"[print('&lt;unk-{}&gt; 0'.format(n)) for n in range($position_markers)]"</span> <span class="o">&gt;&gt;</span> <span class="nb">dict</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">txt</span>
</code></pre></div></div>

<p>This will create a file “dict.pg.txt” that contains the &lt;vocab_size&gt; most frequent words followed by 512 position markers named from “&lt;unk-0&gt;” to “&lt;unk-511&gt;”.</p>

<p>In case we have an input like</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">src</span> <span class="o">=</span> <span class="s">"Hello, I'm The Dogtor"</span>
</code></pre></div></div>

<p>it could happen that our model has been trained without the word “Dogtor” in its vocabulary. Therefore, when we feed this sequence into the model, it should be converted to:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">src</span> <span class="o">=</span> <span class="s">"Hello, I'm The &lt;unk-3&gt;"</span>
</code></pre></div></div>

<p>Now, “&lt;unk-3&gt;” is part of our vocabulary and could be predicted by the model (this is where the pointer-generator comes in). In such a case, we will only need to post-process the output to replace “&lt;unk-3&gt;” by the word at input position 3.</p>

<h3 id="2-preprocess-the-text-data-to-replace-unknown-words-by-its-positional-markers">2. Preprocess the text data to replace unknown words by its positional markers:</h3>

<p>We can use the scripts from <a href="https://github.com/pytorch/fairseq/tree/master/examples/pointer_generator">https://github.com/pytorch/fairseq/tree/master/examples/pointer_generator</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Considering we have our data in:
# train_src = /path/to/train.src
# train_tgt = /path/to/train.tgt
# valid_src = /path/to/valid.src
# valid_tgt = /path/to/valid.tgt
</span><span class="p">.</span><span class="o">/</span><span class="n">preprocess</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">source</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">train</span><span class="p">.</span><span class="n">src</span> \
                <span class="o">--</span><span class="n">target</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">train</span><span class="p">.</span><span class="n">tgt</span> \
                <span class="o">--</span><span class="n">vocab</span> <span class="o">&lt;</span><span class="p">(</span><span class="n">cut</span> <span class="o">-</span><span class="n">d</span><span class="s">' '</span> <span class="o">-</span><span class="n">f1</span> <span class="nb">dict</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">txt</span><span class="p">)</span> \
                <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">out</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">train</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">src</span> \
                <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">out</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">train</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">tgt</span>

<span class="p">.</span><span class="o">/</span><span class="n">preprocess</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">source</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">valid</span><span class="p">.</span><span class="n">src</span> \
                <span class="o">--</span><span class="n">target</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">valid</span><span class="p">.</span><span class="n">tgt</span> \
                <span class="o">--</span><span class="n">vocab</span> <span class="o">&lt;</span><span class="p">(</span><span class="n">cut</span> <span class="o">-</span><span class="n">d</span><span class="s">' '</span> <span class="o">-</span><span class="n">f1</span> <span class="nb">dict</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">txt</span><span class="p">)</span> \
                <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">out</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">valid</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">src</span> \
                <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">out</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">valid</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">tgt</span>

<span class="p">.</span><span class="o">/</span><span class="n">preprocess</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">source</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">test</span><span class="p">.</span><span class="n">src</span> \
                <span class="o">--</span><span class="n">vocab</span> <span class="o">&lt;</span><span class="p">(</span><span class="n">cut</span> <span class="o">-</span><span class="n">d</span><span class="s">' '</span> <span class="o">-</span><span class="n">f1</span> <span class="nb">dict</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">txt</span><span class="p">)</span> \
                <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">out</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">test</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">src</span>
</code></pre></div></div>

<h3 id="3-now-lets-binarize-the-data-so-that-it-can-be-processed-faster">3. Now let’s binarize the data, so that it can be processed faster:</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fairseq</span><span class="o">-</span><span class="n">preprocess</span> <span class="o">--</span><span class="n">task</span> <span class="s">"translation"</span> \
                   <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">lang</span> <span class="s">"pg.src"</span> \
                   <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">lang</span> <span class="s">"pg.tgt"</span> \
                   <span class="o">--</span><span class="n">trainpref</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">train</span> \
                   <span class="o">--</span><span class="n">validpref</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">valid</span> \
                   <span class="o">--</span><span class="n">srcdict</span> <span class="nb">dict</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">txt</span> \
                   <span class="o">--</span><span class="n">cpu</span> \
                   <span class="o">--</span><span class="n">joined</span><span class="o">-</span><span class="n">dictionary</span> \
                   <span class="o">--</span><span class="n">destdir</span> <span class="o">&lt;</span><span class="n">data_dir</span><span class="o">&gt;</span>
</code></pre></div></div>

<p>You might notice the type of task is “translation”. This is because there is no “summarization” task available; we could understand it as a kind of NMT task where the input and output languages are shared and the output (summary) is shorter than the input.</p>

<h3 id="4-now-we-can-train-the-model">4. Now we can train the model:</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fairseq</span><span class="o">-</span><span class="n">train</span> <span class="o">&lt;</span><span class="n">data_dir</span><span class="o">&gt;</span> \
              <span class="o">--</span><span class="n">save</span><span class="o">-</span><span class="nb">dir</span> <span class="o">&lt;</span><span class="n">model_dir</span><span class="o">&gt;</span> \
              <span class="o">--</span><span class="n">task</span> <span class="s">"translation"</span> \
              <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">lang</span> <span class="s">"src"</span> \
              <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">lang</span> <span class="s">"tgt"</span> \
              <span class="o">--</span><span class="n">arch</span> <span class="s">"transformer_pointer_generator"</span> \
              <span class="o">--</span><span class="nb">max</span><span class="o">-</span><span class="n">source</span><span class="o">-</span><span class="n">positions</span> <span class="mi">512</span> \
              <span class="o">--</span><span class="nb">max</span><span class="o">-</span><span class="n">target</span><span class="o">-</span><span class="n">positions</span> <span class="mi">128</span> \
              <span class="o">--</span><span class="n">truncate</span><span class="o">-</span><span class="n">source</span> \
              <span class="o">--</span><span class="nb">max</span><span class="o">-</span><span class="n">tokens</span> <span class="mi">2048</span> \
              <span class="o">--</span><span class="n">required</span><span class="o">-</span><span class="n">batch</span><span class="o">-</span><span class="n">size</span><span class="o">-</span><span class="n">multiple</span> <span class="mi">1</span> \
              <span class="o">--</span><span class="n">required</span><span class="o">-</span><span class="n">seq</span><span class="o">-</span><span class="nb">len</span><span class="o">-</span><span class="n">multiple</span> <span class="mi">8</span> \
              <span class="o">--</span><span class="n">share</span><span class="o">-</span><span class="nb">all</span><span class="o">-</span><span class="n">embeddings</span> \
              <span class="o">--</span><span class="n">dropout</span> <span class="mf">0.1</span> \
              <span class="o">--</span><span class="n">criterion</span> <span class="s">"cross_entropy"</span> \
              <span class="o">--</span><span class="n">optimizer</span> <span class="n">adam</span> \
              <span class="o">--</span><span class="n">adam</span><span class="o">-</span><span class="n">betas</span> <span class="s">'(0.9, 0.98)'</span> \
              <span class="o">--</span><span class="n">adam</span><span class="o">-</span><span class="n">eps</span> <span class="mf">1e-9</span> \
              <span class="o">--</span><span class="n">update</span><span class="o">-</span><span class="n">freq</span> <span class="mi">4</span> \
              <span class="o">--</span><span class="n">lr</span> <span class="mf">0.004</span> \
              <span class="c1"># Pointer Generator
</span>              <span class="o">--</span><span class="n">alignment</span><span class="o">-</span><span class="n">layer</span> <span class="o">-</span><span class="mi">1</span> \
              <span class="o">--</span><span class="n">alignment</span><span class="o">-</span><span class="n">heads</span> <span class="mi">1</span> \
              <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">position</span><span class="o">-</span><span class="n">markers</span> <span class="mi">512</span>
</code></pre></div></div>

<p>This configuration makes use of features Nuance has contributed back to Fairseq:</p>

<ul>
  <li>Transformer with a Pointer Generator mechanism to facilitate copying of words from the input.</li>
  <li>Sequence length padded to a multiple of 8 to better use tensor cores and reduce training time.</li>
</ul>

<h3 id="5-now-lets-take-a-look-at-how-to-generate-a-summary-with-our-new-medical-report-generation-system">5. Now let’s take a look at how to generate a summary with our new medical report generation system:</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">examples.pointer_generator.pointer_generator_src.transformer_pg</span> <span class="kn">import</span> <span class="n">TransformerPointerGeneratorModel</span>

<span class="c1"># Patient-Doctor conversation
</span><span class="nb">input</span> <span class="o">=</span> <span class="s">"[doctor] Lisa Simpson, thirty six year old female, presents to the clinic today because "</span> \
        <span class="s">"she has severe right wrist pain"</span>

<span class="c1"># Load the model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">TransformerPointerGeneratorModel</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">data_name_or_path</span><span class="o">=&lt;</span><span class="n">data_dir</span><span class="o">&gt;</span><span class="p">,</span>
                                                         <span class="n">model_name_or_path</span><span class="o">=&lt;</span><span class="n">model_dir</span><span class="o">&gt;</span><span class="p">,</span>
                                                         <span class="n">checkpoint_file</span><span class="o">=</span><span class="s">"checkpoint_best.pt"</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">translate</span><span class="p">([</span><span class="nb">input</span><span class="p">],</span> <span class="n">beam</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">Ms</span><span class="p">.</span> <span class="o">&lt;</span><span class="n">unk</span><span class="o">-</span><span class="mi">2</span><span class="o">&gt;</span> <span class="ow">is</span> <span class="n">a</span> <span class="mi">36</span><span class="o">-</span><span class="n">year</span><span class="o">-</span><span class="n">old</span> <span class="n">female</span> <span class="n">who</span> <span class="n">presents</span> <span class="n">to</span> <span class="n">the</span> <span class="n">clinic</span> <span class="n">today</span> <span class="k">for</span> <span class="n">evaluation</span> <span class="n">of</span> <span class="n">her</span> <span class="n">right</span> <span class="n">wrist</span><span class="p">.</span>
</code></pre></div></div>

<h3 id="6-alternatively-we-can-use-fairseq-interactive-and-a-postprocessing-tool-to-substitute-positional-unknown-tokens-by-its-words-from-the-input">6. Alternatively, we can use fairseq-interactive and a postprocessing tool to substitute positional unknown tokens by its words from the input:</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fairseq</span><span class="o">-</span><span class="n">interactive</span> <span class="o">&lt;</span><span class="n">data_dir</span><span class="o">&gt;</span> \
              <span class="o">--</span><span class="n">batch</span><span class="o">-</span><span class="n">size</span> <span class="o">&lt;</span><span class="n">batch_size</span><span class="o">&gt;</span> \
              <span class="o">--</span><span class="n">task</span> <span class="n">translation</span> \
              <span class="o">--</span><span class="n">source</span><span class="o">-</span><span class="n">lang</span> <span class="n">src</span> \
              <span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">lang</span> <span class="n">tgt</span> \
              <span class="o">--</span><span class="n">path</span> <span class="o">&lt;</span><span class="n">model_dir</span><span class="o">&gt;/</span><span class="n">checkpoint_last</span><span class="p">.</span><span class="n">pt</span> \
              <span class="o">--</span><span class="nb">input</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">test</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">src</span> \
              <span class="o">--</span><span class="nb">buffer</span><span class="o">-</span><span class="n">size</span> <span class="mi">20</span> \
              <span class="o">--</span><span class="nb">max</span><span class="o">-</span><span class="nb">len</span><span class="o">-</span><span class="n">a</span> <span class="mi">0</span> \
              <span class="o">--</span><span class="nb">max</span><span class="o">-</span><span class="nb">len</span><span class="o">-</span><span class="n">b</span> <span class="mi">128</span> \
              <span class="o">--</span><span class="n">beam</span> <span class="mi">2</span> \
              <span class="o">--</span><span class="n">skip</span><span class="o">-</span><span class="n">invalid</span><span class="o">-</span><span class="n">size</span><span class="o">-</span><span class="n">inputs</span><span class="o">-</span><span class="n">valid</span><span class="o">-</span><span class="n">test</span> <span class="o">|</span> <span class="n">tee</span> <span class="n">generate</span><span class="p">.</span><span class="n">out</span>

<span class="n">grep</span> <span class="s">"^H-"</span> <span class="n">generate</span><span class="p">.</span><span class="n">out</span> <span class="o">|</span> <span class="n">cut</span> <span class="o">-</span><span class="n">f</span> <span class="mi">3</span><span class="o">-</span> <span class="o">&gt;</span> <span class="n">generate</span><span class="p">.</span><span class="n">hyp</span>

<span class="p">.</span><span class="o">/</span><span class="n">postprocess</span><span class="p">.</span><span class="n">py</span> \
	<span class="o">--</span><span class="n">source</span> <span class="o">&lt;</span><span class="p">(</span><span class="n">awk</span> <span class="s">'NF&lt;512'</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">test</span><span class="p">.</span><span class="n">pg</span><span class="p">.</span><span class="n">src</span><span class="p">)</span> \
	<span class="o">--</span><span class="n">target</span> <span class="n">generate</span><span class="p">.</span><span class="n">hyp</span> \
	<span class="o">--</span><span class="n">target</span><span class="o">-</span><span class="n">out</span> <span class="n">generate</span><span class="p">.</span><span class="n">hyp</span><span class="p">.</span><span class="n">processed</span>
</code></pre></div></div>

<p>Now we have the final set of reports in “generate.hyp.processed”, with “&lt;unk-N&gt;” replaced by the original word from the input sequence.</p>

<h2 id="model-deployment">Model Deployment</h2>

<p>PyTorch offers great flexibility in modeling and a rich surrounding ecosystem. However, while several recent articles have suggested that the use of PyTorch in research and academia may be close to surpassing TensorFlow, there seems to be an overall sense of TensorFlow being the preferred platform for deployment to production. Is this still the case in 2021? Teams looking to serve their PyTorch models in production have a few options.</p>

<p>Before describing our journey, let’s take a brief detour and define the term model.</p>

<h3 id="models-as-computation-graphs">Models as computation graphs</h3>

<p>A few years back, it was still common for machine learning toolkits to support only particular classes of models of a rather fixed and rigid structure, with only a few degrees of freedom (like the kernel of a support vector machine or the number of hidden layers of a neural network). Inspired by foundational work in Theano, toolkits like Microsoft’s CNTK or Google’s TensorFlow were among the first to popularize a more flexible view on models, as computation graphs with associated parameters that can be estimated from data. This view blurred the boundaries between popular types of models (such as DNNs or SVMs), as it became easy to blend the characteristics of each into your type of graph. Still, such a graph had to be defined upfront before estimating its parameters, and it was pretty static. This made it easy to save models to a self-contained bundle, like a TensorFlow SavedModel (such a bundle simply contains the structure of the graph, as well as the concrete values of the estimated parameters). However, debugging such models can be difficult because the statements in the Python code that build the graph are logically separate from the lines that execute it. Researchers also long for easier ways of expressing dynamic behavior, such as the computation steps of the forward pass of a model being conditionally dependent on its input data (or its previous output).</p>

<p>Most recently, the above limitations have led to a second revolution spearheaded by PyTorch and TensorFlow 2. The computation graph is no longer defined explicitly. Instead, it will be populated implicitly as the Python code executes operations on tensor arguments. An essential technique that powers this development is automatic differentiation. As the computation graph is being built implicitly while executing the steps of the forward pass, all the necessary data will be tracked for later computation of the gradient concerning the model parameters. This allows for great flexibility in training a model, but it raises an important question. If the computation happening inside a model is only implicitly defined through our Python code’s steps as it executes concrete data, what is it that we want to save as a model? The answer – at least initially – was the Python code with all its dependencies, along with the estimated parameters. This is undesirable for practical reasons. For instance, there is a danger that the team working on model deployment does not exactly reproduce the Python code dependencies used during training, leading to subtly divergent behavior. The solution typically consists of combining two techniques, scripting and tracing, that is, extra annotations in your Python code and execution of your code on exemplary input data, allowing PyTorch to define and save the graph that should be executed during later inference on new, unseen data. This requires some discipline by whoever creates the model code (arguably voiding some of the original flexibility of eager execution), but it results in a self-contained model bundle in TorchScript format. The solution in TensorFlow 2 is remarkably similar.</p>

<h3 id="serving-our-report-generation-models">Serving our report generation models</h3>

<p>Our journey in deploying the report generation models reflects the above discussion. We started out serving our models by deploying the model code and its dependencies along with the parameter checkpoints in a custom Docker image exposing a gRPC service interface. However, we soon noticed that it became error-prone to replicate the exact code and environment used by the modeling team while estimating the parameters. Moreover, this approach prevented us from leveraging high-performance model serving frameworks like NVIDIA’s Triton, which is written in C++ and requires self-contained models that can be used without a Python interpreter. At this stage, we were facing a choice between attempting to export our PyTorch models to ONNX or TorchScript format. ONNX is an open specification for representing machine learning models that increasingly finds adoption. It is powered by a high-performance runtime developed by Microsoft (ONNX Runtime). While we were able to achieve performance acceleration for our TensorFlow BERT-based model using ONNX Runtime, at the time one of our PyTorch model required some operators that weren’t yet supported in ONNX. Rather than implement these using custom operators, we decided to look into TorchScript for the time being.</p>

<h3 id="a-maturing-ecosystem">A maturing ecosystem</h3>

<p>Is it all roses? No, it has been a rockier journey than we expected. We encountered what seems to be a memory leak in the MKL libraries used by PyTorch while serving the PyTorch code directly. We encountered deadlocks in trying to load multiple models from multiple threads. We had difficulties exporting our models to ONNX and TorchScript formats. Models would not work out-of-the-box on hardware with multiple GPUs, they always accessed the particular GPU device on which they were exported. We encountered excessive memory usage in the Triton inference server while serving TorchScript models, which we found out was due to automatic differentiation accidentally being enabled during the forward pass. However, the ecosystem keeps improving, and there is a helpful and vibrant open-source community eager to work with us to mitigate such issues.</p>

<p>Where to go from here? For those that require the flexibility of serving PyTorch code directly, without going through the extra step of exporting self-contained models, it is worth pointing out that the TorchServe project now provides a way of bundling the code together with parameter checkpoints into a single servable archive, greatly reducing the risk of code and parameters running apart. To us, however, exporting models to TorchScript has proven beneficial. It provides a clear interface between modeling and deployment teams, and TorchScript further reduces the latency when serving models on GPU via its just-in-time compilation engine.</p>

<h3 id="scaling-at-large-and-the-future">Scaling at large and the future</h3>

<p>Finally, efficient deployment to the cloud is about more than just computing the response of a single model instance efficiently. Flexibility is needed in managing, versioning and updating models. High-level scalability must be achieved via techniques such as load-balancing, horizontal scaling and vertical scaling. If many models are involved, scale-to-zero quickly becomes a topic as it is unacceptable to pay for serving models that do not answer any requests. Providing such extra functionality on top of a low-level inference server like Triton is the job of an orchestration framework. After gaining some first experience with KubeFlow, to that end, we decided to turn our attention to Azure ML, which provides similar functionality but integrates more deeply with the Azure platform, on which we crucially rely for large parts of our technology stack already. This part of our journey has just begun.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Academia has long recognized that we are “standing on the shoulders of giants.” As Artificial Intelligence is maturing from a scientific discipline into technology, the same spirit of collaboration that originally fueled its scientific foundation has carried over into the world of software engineering. Open-source enthusiasts join technology companies worldwide to build open software ecosystems that allow for new angles at solving some of the most pressing challenges of modern society. In this article, we’ve taken a look at Nuance’s <a href="http://www.nuance.com/ambient">Dragon Ambient eXperience</a>, an AI-powered, voice-enabled solution that automatically documents patient care, reducing healthcare providers’ administrative burdens. Nuance DAX improves the patient-provider experience, reduces physician burnout, and improves financial outcomes. It brings back trust, joy, and humanity to the delivery of healthcare. Fairseq and PyTorch have proven to be an incredible platform for powering this AI technology, and in turn, Nuance has contributed back some of its innovations in this space. For further reading, we invite you to take a look at our recent <a href="https://www.aclweb.org/anthology/2020.nlpmc-1.4/">ACL publication</a> and the Nuance “What’s Next” blog.</p>

                </article>
            </div>
        </div>
    </div>

<!--    


 -->
    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="/docs">View Docs</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">

    <div class="newsletter" id="newsletter">

      <p
        class="newsletter__title is-style-max-width-800"><strong>Stay in touch</strong> for updates, event info, and the latest news</p>
    
    
        <script charset="utf-8" type="text/javascript" src="//js.hsforms.net/forms/embed/v2.js"></script>
        <script>
          hbspt.forms.create({
            region: "na1",
            portalId: "8112310",
            formId: "2fb2231c-000b-4ec5-88a0-1ab242549c9e"
          });
        </script>
        
    
      <p
        class="newsletter__privacy">By submitting this form, I consent to receive marketing emails from the LF and its projects regarding their events, training, research, developments, and related announcements. I understand that I can unsubscribe at any time using the links in the footers of the emails I receive. <a href="https://www.linuxfoundation.org/privacy/">Privacy Policy</a>.</p>
        
    </div>
    


    <div class="lf-grid">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org" class="footer-logo">
          <img src="/assets/images/logo-icon.svg" alt="PyTorch logo" width="40">
        </a>
      </div>

      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook"><path fill="currentColor" d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z"/></svg>	
        </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X"><path fill="currentColor" d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66"/></svg>
        </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube"><path fill="currentColor" d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z"/></svg>	
        </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn"><rect width="512" height="512" rx="0" fill="currentColor"/><circle fill="#000" cx="142" cy="138" r="37"/><path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198"/><path fill="#000" d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
        </a></li>
        <li><a href="https://join.slack.com/t/pytorch/shared_invite/zt-2j2la612p-miUinTTaxXczKOJw48poHA" target="_blank" title="PyTorch Slack">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.16 -0.03 21.19 21.19" aria-label="Slack"><path fill="currentColor" d="M4.896 13.27a2.147 2.147 0 0 1-2.141 2.142A2.147 2.147 0 0 1 .613 13.27c0-1.178.963-2.141 2.142-2.141h2.141v2.141zm1.08 0c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.363a2.147 2.147 0 0 1-2.142 2.141 2.147 2.147 0 0 1-2.141-2.142V13.27zm2.141-8.6a2.147 2.147 0 0 1-2.141-2.14c0-1.18.962-2.142 2.141-2.142s2.142.963 2.142 2.141v2.142H8.117zm0 1.08c1.179 0 2.141.962 2.141 2.141a2.147 2.147 0 0 1-2.141 2.142H2.755A2.147 2.147 0 0 1 .613 7.89c0-1.179.963-2.141 2.142-2.141h5.362zm8.599 2.141c0-1.179.963-2.141 2.141-2.141 1.179 0 2.143.962 2.143 2.14a2.147 2.147 0 0 1-2.142 2.142h-2.141V7.89zm-1.08 0a2.147 2.147 0 0 1-2.141 2.142 2.147 2.147 0 0 1-2.141-2.142V2.53c0-1.178.962-2.141 2.141-2.141s2.142.963 2.142 2.141v5.362zm-2.141 8.6c1.179 0 2.142.962 2.142 2.14a2.147 2.147 0 0 1-2.142 2.142 2.147 2.147 0 0 1-2.141-2.141V16.49h2.141zm0-1.08a2.147 2.147 0 0 1-2.141-2.141c0-1.179.962-2.142 2.141-2.142h5.362c1.179 0 2.142.963 2.142 2.142a2.147 2.147 0 0 1-2.142 2.142h-5.362z"></path></svg>
        </a></li>
        <li><a href="/wechat" title="PyTorch on WeChat">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0.14 -0.17 38.02 33.02" aria-label="WeChat"><path fill="currentColor" d="M26.289 10.976a12.972 12.972 0 0 0-8.742 3.53 10.386 10.386 0 0 0-3.224 8.795c-1.326-.164-2.535-.345-3.75-.448a2.332 2.332 0 0 0-1.273.216c-1.18.666-2.311 1.418-3.652 2.255.246-1.112.405-2.087.687-3.024a1.15 1.15 0 0 0-.523-1.52C1.737 17.902.02 13.601 1.307 9.165c1.189-4.1 4.11-6.587 8.077-7.884A13.54 13.54 0 0 1 24.18 5.617a10.135 10.135 0 0 1 2.109 5.359zM10.668 9.594a1.564 1.564 0 0 0-2.095-1.472 1.52 1.52 0 0 0-.895 1.964 1.502 1.502 0 0 0 1.391.966 1.545 1.545 0 0 0 1.598-1.46v.002zm8.15-1.566a1.567 1.567 0 0 0-1.528 1.543 1.528 1.528 0 0 0 1.571 1.492 1.52 1.52 0 0 0 1.375-2.117 1.518 1.518 0 0 0-1.415-.919l-.003.001z"></path><path fill="currentColor" d="M33.914 32.137c-1.075-.478-2.062-1.196-3.11-1.306-1.049-.11-2.145.494-3.24.605a10.821 10.821 0 0 1-8.781-2.864c-4.682-4.33-4.013-10.97 1.403-14.518 4.811-3.154 11.874-2.102 15.268 2.273a8.671 8.671 0 0 1-1.002 12.095c-1.046.929-1.422 1.693-.751 2.917.102.257.174.525.213.798zM21.68 20.292a1.264 1.264 0 1 0 .01-2.528 1.264 1.264 0 0 0-.01 2.528zm7.887-2.526a1.266 1.266 0 0 0-1.256 1.21 1.247 1.247 0 1 0 1.256-1.21z"></path></svg>
        </a></li>
      </ul>
    </div>

    <div class="privacy-policy">
      <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation. 
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see 
          <a href="https://www.linuxfoundation.org/legal/policies/">Linux Foundation Policies</a>. The PyTorch Foundation supports the PyTorch open source 
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC, 
          please see <a href="https://www.lfprojects.org/policies/">LF Projects, LLC Policies</a>. <a href="https://www.linuxfoundation.org/privacy">Privacy Policy</a> and <a href="https://www.linuxfoundation.org/terms">Terms of Use</a>.</p>
      </div>
    </div>
  </div>
</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>
        <li class="navSearchWrapper reactNavSearchWrapper tabletSearchWrapper" key="search">
          <div class="mobile-search-border">
            <input
              id="mobile-search-input"
              type="text"
              title="Search"
            />
            <div id="mobile-search-icon"></div>
          </div>
        </li>

        <li class="resources-mobile-menu-title">
          <a>Learn</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/get-started">Get Started</a> 
          </li>
          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
          </li>
          <li>
            <a href="/new">New to PyTorch Foundation</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Ecosystem</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://landscape.pytorch.org/">Tools</a>
          </li>
          <li>
            <a href="/join-ecosystem">Join the Ecosystem</a>
          </li>
          <li>
            <a href="/#community-module">Community</a>
          </li>
          <li>
            <a href="https://discuss.pytorch.org">Forums</a>
          </li>
          <li>
            <a href="/resources">Developer Resources</a>
          </li>
          <li>
            <a href="/ecosystem/contributor-awards-2024">Contributor Awards - 2024</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Edge</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/edge">About PyTorch Edge</a>
          </li>
          <li>
            <a href="/executorch-overview">ExecuTorch</a>
          </li>
          <li>
            <a href="https://pytorch.org/executorch/stable/index.html">ExecuTorch Documentation</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Docs</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/docs">PyTorch</a>
          </li>
          <li>
            <a href="/pytorch-domains">PyTorch Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/blog">PyTorch Blog</a>
          </li>
          <li>
            <a href="/community-blog">Community Blog</a>
          </li>
          <li>
            <a href="/videos">Videos</a>
          </li>
          <li>
            <a href="/community-stories">Community Stories</a>
          </li>
          <li>
            <a href="/events">Events</a>
          </li>
          <li>
            <a href="/newsletter">Newsletter</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="/governing-board">Governing Board</a>
          </li>
          <li>
            <a href="/credits">Cloud Credit Program</a>
          </li>
          <li>          
            <a href="/tac">Technical Advisory Council</a>
          </li>
          <li>
            <a href="/staff">Staff</a>
          </li>
          <li>
            <a href="/contact-us">Contact Us</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a href="/join">Become a Member</a>
        </li>
        <li class="resources-mobile-menu-title">
          <a href="https://github.com/pytorch/pytorch" title="Go to PyTorch GitHub"><div id="topnav-gh-icon"></div></a>
        </li>
      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>

  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script>

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header, .announcement-header, .comm-stories-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>


  <script src="/assets/track-events.js"></script>
  <script>trackEvents.bind();</script>



<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="/assets/images/pytorch-x.svg">
  </div>
</div>


</body>

</html>
