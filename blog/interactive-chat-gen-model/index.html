<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
  <!-- End Google Tag Manager -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      How to Build an Interactive Chat-Generation Model using DialoGPT and PyTorch | PyTorch
    
  </title>
  
  <meta property="og:title" content="PyTorch" />
  <meta
    name="description"
    property="og:description"
    content="An open source machine learning framework that accelerates the path from research prototyping to production deployment."
  />
  <meta
  property="og:image"
  content="https://pytorch.org/assets/images/pytorch-logo.png"
  />
  <meta property="og:url" content="https://www.pytorch.org" />


<meta property="og:type" content="website" />
<meta name="robots" content="index, follow" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
  
    <script
  async
  src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"
></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());
  gtag("config", "UA-117752657-2");
</script>

    <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window,document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '243028289693773');
    fbq('track', 'PageView');
</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

    <!-- Twitter universal website tag code -->
<img height="1" width="1" style="display:none;" alt="" src="https://analytics.twitter.com/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__analytics.twitter.com_i_adsct-3Fp-5Fid-3DTwitter-26p-5Fuser-5Fid-3D0-26txn-5Fid-3Do2gi1-26events-3D-255B-255B-2522pageview-2522-252Cnull-255D-255D-26tw-5Fsale-5Famount-3D0-26tw-5Forder-5Fquantity-3D0&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=o6i4D0V0088WH2RnzIoqiF-vj45PL-2sTrsxQ0SNO3A&e=)" />
<img height="1" width="1" style="display:none;" alt="" src="//t.co/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__linkprotect.cudasvc.com_url-3Fa-3Dhttp-253a-252f-252ft.co-252fi-252fadsct-253fp-5Fid-253dTwitter-2526p-5Fuser-5Fid-253d0-2526txn-5Fid-253do2gi1-2526events-253d-25255B-25255B-252522pageview-252522-25252Cnull-25255D-25255D-2526tw-5Fsale-5Famount-253d0-2526tw-5Forder-5Fquantity-253d0-26c-3DE-2C1-2CC33dLwIhtuEcl5FhdztSnUwsioeej5k-2DWy0RYREBAq51kGji32A2Cw94YU9vQBpY5tPN3AukEw3C-5F-2DlbtndnLoR7-5FA-5FLoH0Rr7zLtP1ykptN-26typo-3D1&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=Abgc3XBkhESv8XBYtLchdDZyISGsK6v_BB6cLMJGyCw&e=)" />
<!-- End Twitter universal website tag code -->

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Pythorch Blog Posts" />
</head>


<body class="blog">
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <div class="main-background blog-background blog-detail-background"></div>

    <div class="container-fluid header-holder blog-detail-header">
        <div class="container">
            

<div class="header-container">
  <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item ">
      <a href="/get-started">Get Started</a>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow" href="/ecosystem">
          Ecosystem 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/ecosystem">
            <span class="dropdown-title">Tools</span>
            <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/pted/2021">
            <span class="dropdown-title">Ecosystem Day - 2021</span>
            <p>See the posters presented at ecosystem day 2021</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/ptdd/2021">
            <span class="dropdown-title">Developer Day - 2021</span>
            <p>See the posters presented at developer day 2021</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/ptc/2022">
            <span class="dropdown-title">PyTorch Conference - 2022</span>
            <p>See the posters presented at PyTorch conference - 2022</p>
          </a>

        </div>
      </div>
    </li>

    <li class="main-menu-item ">
      <a href="/mobile">Mobile</a>
    </li>

    <li class="main-menu-item active">
      <a href="/blog">Blog</a>
    </li>

    <li class="main-menu-item">
      <a href="https://pytorch.org/tutorials">Tutorials</a>
    </li>

    <li class="main-menu-item">
      <div id="docsDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="doc-option with-down-arrow">
          Docs
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/docs">
            <span class="dropdown-title docs-title">PyTorch</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/audio">
            <span class="dropdown-title docs-title">torchaudio</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/text">
            <span class="dropdown-title docs-title">torchtext</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/vision">
            <span class="dropdown-title docs-title">torchvision</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/torcharrow">
            <span class="dropdown-title docs-title">torcharrow</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/data">
            <span class="dropdown-title docs-title">TorchData</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/torchrec">
            <span class="dropdown-title docs-title">TorchRec</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/serve">
            <span class="dropdown-title docs-title">TorchServe</span>
            <p></p>
          </a>
          <a class="nav-dropdown-item" href="/xla/release/1.6/index.html">
            <span class="dropdown-title docs-title">PyTorch on XLA Devices</span>
            <p></p>
          </a>
        </div>
      </div>
    </li>

    

    <li class="main-menu-item ">

      <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="resource-option with-down-arrow">
          Resources
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/features">
            <span class=dropdown-title>About</span>
            <p>Learn about PyTorch’s features and capabilities</p>
          </a>
          <a class="nav-dropdown-item" href="/foundation">
            <span class=dropdown-title>PyTorch Foundation</span>
            <p>Learn more about the PyTorch Foundation.</p>
          </a>
          <a class="nav-dropdown-item" href="/#community-module">
            <span class=dropdown-title>Community</span>
            <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
          </a>
          <a class="nav-dropdown-item" href="/community-stories">
            <span class=dropdown-title>Community stories</span>
            <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
          </a>
          <a class="nav-dropdown-item" href="/resources">
            <span class=dropdown-title>Developer Resources</span>
            <p>Find resources and get questions answered</p>
          </a>
          <a class="nav-dropdown-item" href="/events">
            <span class=dropdown-title>Events</span>
            <p>Find events, webinars, and podcasts</p>
          </a>
          <a class="nav-dropdown-item" href="https://discuss.pytorch.org" target="_blank">
            <span class=dropdown-title>Forums</span>
            <p>A place to discuss PyTorch code, issues, install, research</p>
          </a>
          <a class="nav-dropdown-item" href="/hub">
            <span class=dropdown-title>Models (Beta)</span>
            <p>Discover, publish, and reuse pre-trained models</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item" id="github-main-menu-link">
      <a href="https://github.com/pytorch/pytorch">GitHub</a>
    </li>

    <li class="navSearchWrapper reactNavSearchWrapper" key="search">
      <div class="search-border">
        <div id="search-icon"></div>
        <input
          id="search-input"
          type="text"
          title="Search"
        />
        <div id="close-search">X</div>
      </div>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

        </div>
    </div>

    <div class="jumbotron jumbotron-fluid blog-detail-jumbotron">
        <div class="container blog-detail-container">
            <p class="featured-post">October 03, 2023</p>
            <h1>
                <a class="blog-title">How to Build an Interactive Chat-Generation Model using DialoGPT and PyTorch</a>
            </h1>
        </div>
    </div>

    <div class="main-content-wrapper blog-detail-wrapper">
        <div class="main-content blog-detail-content">
            <div class="container">
                <img src="/assets/images/logo-icon.svg" class="img-fluid author-icon">
                <article class="pytorch-article">
                    <p class="author">
                      by
                      
                        Intel
                      
                    </p>
                    <p>The focus on interactive chat-generation (or conversational response-generation) models has greatly increased in the past several months. Conversational response-generation models such as ChatGPT and Google Bard have taken the AI world by storm. The purpose of interactive chat generation is to answer various questions posed by humans, and these AI based models use natural language processing (NLP) to generate conversations almost indistinguishable from those generated by humans.</p>

<p>This article showcases a <a href="http://github.com/oneapi-src/oneAPI-samples/blob/master/AI-and-Analytics/Features-and-Functionality/IntelPytorch_Interactive_Chat_Quantization/IntelPytorch_Interactive_Chat_Quantization.ipynb">code sample</a> on how to create interactive chats based on a pre-trained DialoGPT model from Hugging Face with the addition of the <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/optimization-for-pytorch.html">Intel® Extension for PyTorch</a> to perform dynamic quantization on the model.</p>

<h2 id="get-started">Get Started</h2>

<h3 id="why-dialogpt">Why DialoGPT?</h3>

<p>DialoGPT (<strong>Dialo</strong>gue <strong>G</strong>enerative <strong>P</strong>re-trained <strong>T</strong>ransformer) is a large-scale, pre-trained dialogue-response-generation model trained on 147M conversation-like exchanges pulled out from Reddit comment chains and discussion threads. <a href="http://github.com/microsoft/DialoGPT">DialoGPT</a> was proposed by Microsoft in 2019. The main goal was to create open-domain chatbots capable of producing natural responses to a variety of conversational topics. The conversational response-generation systems that leverage DialoGPT generate more applicable, resourceful, diverse, and context-specific replies.</p>

<h3 id="dialogpt-architecture">DialoGPT Architecture</h3>

<p>DialoGPT architecture is based on the GPT-2 model. It is formulated as an autoregressive language model and uses a multi-layer transformer as the model architecture. GPT-2 was proposed by OpenAI. GPT-2 models are trained on general text data whereas DialoGPT is trained on Reddit discussion threads.</p>

<p>Let’s look at the GPT-2 architecture. There are two types of blocks in general transformer architecture:</p>

<ul>
  <li>Encoder - contains self-attention layer and feed-forward neural network</li>
  <li>Decoder - similar to encoder, but the self-attention layer is masked</li>
</ul>

<p>The self-attention layer allows a position to peak at tokens to the right of the current word (the successive words in text), whereas masked self-attention layer prevents that from happening.</p>

<p><img src="/assets/images/f1-self-attention-vs-masked.png" alt="self-attention layer vs masked self-attention layer" style="width:100%; max-width: 845px; display: block; margin-left: auto; margin-right: auto" /></p>

<p>GPT-2 is built using transformer decoder blocks. This means that the following layers are used in the architecture:</p>

<ol>
  <li>Embedding Layer – responsible for converting input text into embeddings (each word is converted to a fixed-length vector representation)</li>
  <li>Transformer Decoder – includes multiple decoder blocks with masked self-attention and feed forward neural network layers</li>
  <li>Output Layer – responsible for converting embeddings obtained from the decoder into words</li>
</ol>

<p>GPT-2 architecture (and DialoGPT architecture) is shown below.</p>

<p><img src="/assets/images/f2-dialogpt-article.png" alt="GPT-2 architecture" style="width:100%; max-width: 651px; display: block; margin-left: auto; margin-right: auto" /></p>

<p>As the model is based on transformers architecture, it has the issue of repetition and copying the inputs. To avoid repetition, we can use Top-K sampling and Top-p sampling.</p>

<ul>
  <li>Top-K sampling - filters the K most likely next words and redistributes the probability mass among only those K next words.</li>
  <li>Top-p sampling - rather than selecting only the most likely K words, selects the smallest possible set of words whose cumulative probability exceeds the probability p.</li>
</ul>

<p>The probability mass is then redistributed among the words in the set. As a result, the size of the set of words can be dynamically increased and decreased based on the probability distribution of the next word.</p>

<h3 id="quantization-using-intel-extension-for-pytorch">Quantization using Intel® Extension for PyTorch</h3>

<p><strong>What is Quantization?</strong></p>

<p>Quantization is a systematic reduction of the precision of all or several layers within the model. This means a higher-precision type, such as the single-precision floating-point (FP32) mostly used in deep learning, is converted into a lower-precision type such as FP16 (16 bits) or INT8 (8 bits).</p>

<p>This helps in achieving,</p>

<ul>
  <li>lower memory bandwidth</li>
  <li>lower storage</li>
  <li>higher performance with minimum-to-zero accuracy loss</li>
</ul>

<p>Quantization is especially important with large models such as those based on the Transformer architecture like BERT or GPT.</p>

<p>There are two types of quantization:</p>

<ul>
  <li>Static – Static quantization quantizes the weights and activations of the model. This quantization is used when both memory bandwidth and compute savings are important.</li>
  <li>Dynamic – In dynamic quantization, the weights are quantized ahead of time, but the activations are dynamically quantized during inference.</li>
</ul>

<p><strong>Intel Extension for PyTorch:</strong> The Intel Extension extends PyTorch with up-to-date features and optimizations for an extra performance boost on Intel® hardware. Learn how to <a href="http://github.com/intel/intel-extension-for-pytorch#installation">install it standalone</a> or get it a part of the <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/ai-analytics-toolkit.html">Intel® AI Analytics Toolkit</a>.</p>

<p>The extension can be loaded as a Python* module or linked as a C++ library. Python users can enable it dynamically by importing intel_extension_for_pytorch.</p>

<ul>
  <li>This <a href="http://intel.github.io/intel-extension-for-pytorch/cpu/latest/">CPU tutorial</a> gives detailed information about Intel Extension for PyTorch for Intel CPUs. Source code is available at the <a href="http://github.com/intel/intel-extension-for-pytorch/tree/master">master branch</a>.</li>
  <li>This <a href="http://intel.github.io/intel-extension-for-pytorch/xpu/latest/">GPU tutorial</a> gives detailed information about Intel Extension for PyTorch for Intel GPUs. Source code is available at the <a href="http://github.com/intel/intel-extension-for-pytorch/tree/xpu-master">xpu-master branch</a>.</li>
</ul>

<p><strong>How to perform dynamic quantization using Intel Extension for PyTorch?</strong></p>

<p>Here are the steps to quantize the existing FP32 model to INT8 model using dynamic quantization:</p>

<ol>
  <li>Prepare quantization configuration - We can use default dynamic quantization configuration with <strong>ipex.quantization.default_dynamic_qconfig</strong>.</li>
  <li>Prepare the FP32 model by using the** ipex.quantization.prepare **method (provide the input parameters such as FP32 model to quantize, the prepared configuration, example inputs and information if the quantization should be in place).</li>
  <li>Convert the model from FP32 to INT8 - Use <strong>ipex.quantization.convert</strong> method for conversion. The input model will be the model prepared in step 2.</li>
</ol>

<p>We also encourage you to check out the <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/neural-compressor.html">Intel® Neural Compressor</a> tool that automates popular model-compression technologies such as quantization, pruning, and knowledge distillation across multiple <a href="https://www.intel.com/content/www/us/en/developer/tools/frameworks/overview.html">deep learning frameworks</a>.</p>

<h2 id="code-sample">Code Sample</h2>

<p>The following steps are implemented in the <a href="http://github.com/oneapi-src/oneAPI-samples/blob/master/AI-and-Analytics/Features-and-Functionality/IntelPytorch_Interactive_Chat_Quantization/IntelPytorch_Interactive_Chat_Quantization.ipynb">code sample</a>:</p>

<ol>
  <li><strong>Load model and tokenizer:</strong> <a href="http://huggingface.co/docs/transformers/index">Transformers library</a> (check out <a href="http://github.com/intel/intel-extension-for-transformers">Intel® Extension for Transformers</a>) and <a href="http://huggingface.co/docs/transformers/model_doc/auto">Auto Classes available in the Hugging Face Main Classes</a> are used in this step. These allow us to automatically find the relevant model by the given name. It also allows to easily change the model without major changes in the code on the developer’s side as shown below:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tokenizer = AutoTokenizer.from_pretrained(model)
model = AutoModelForCausalLM.from_pretrained(model)
</code></pre></div>    </div>
    <p>The model parameter is specified as an input for the tokenizer, and model initialization is just the path to the pre-trained DialoGPT model. In this sample, we are using ‘microsoft/DialoGPT-large.’ If you have limited resources, you can use ‘microsoft/DialoGPT-medium’ or ‘microsoft/DialoGPT-small’ models and receive comparable results.</p>
  </li>
  <li><strong>Perform dynamic quantization of the model:</strong>
    <ol>
      <li>Create the configuration using the default dynamic quantization configuration from Intel Extension for PyTorch library.</li>
      <li>Prepare the model.</li>
      <li>Convert the model from FP32 to INT8. <br />
The steps are explained in detail in the above section.</li>
    </ol>
  </li>
  <li><strong>Response generation:</strong> The first step in response generation is to encode the input sentence as shown in the code below:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>new_input_ids = tokenizer.encode(input("&gt;&gt; You:") + tokenizer.eos_token, return_tensors='pt')
</code></pre></div>    </div>
    <p>In this sample, we want our model to save history, so we are adding input sentences in the form of tokens to the chat history:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bot_input_ids = torch.cat([chat_history_ids, new_input_ids], dim=-1) if chat_round &gt; 0 else new_input_ids
</code></pre></div>    </div>
    <p>The text generation can be done by the model.generate function, where we can specify all important parameters like saved chat history, length of the response in tokens, and usage of both Top-K and Top-p sampling.</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>chat_history_ids = model.generate(bot_input_ids, do_sample=True, max_length=2000, top_k=50, top_p=0.95, pad_token_id=tokenizer.eos_token_id) 
</code></pre></div>    </div>
    <p>The last step is to decode and print the response:</p>
  </li>
  <li><strong>Preparation for interactive conversation:</strong> After response generation, the last step is to add interaction. This can be done by using a simple for loop. Based on the initialized tokenizer, model, and empty chat history, responses are generated for a number of rounds:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for chat_round in range(n):
chat_history_ids = generate_response(
tokenizer,
model,
chat_round,
chat_history_ids
)
</code></pre></div>    </div>
    <p>An example of interactive chat generation will look like the one shown in the picture below.</p>
  </li>
</ol>

<p><img src="/assets/images/f3-dialogpt-interaction.png" alt="An example of interactive chat generation" style="width:100%; max-width: 981px; display: block; margin-left: auto; margin-right: auto" /></p>

<h2 id="whats-next">What’s Next?</h2>

<p>Get started with interactive chat-generation models using Intel Extension for PyTorch and DialoGPT. Download and try the <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/ai-analytics-toolkit.html">Intel AI Analytics Toolkit</a> and <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/optimization-for-pytorch.html">Intel Extension for PyTorch</a> for yourself to build various end-to-end AI applications.</p>

<p>We encourage you to also check out and incorporate Intel’s other <a href="https://www.intel.com/content/www/us/en/developer/tools/frameworks/overview.html">AI/ML Framework optimizations</a> and <a href="https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/tools.html">end-to-end portfolio of tools</a> into your AI workflow and learn about the unified, open, standards-based <a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/overview.html">oneAPI</a> programming model that forms the foundation of Intel’s <a href="https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/overview.html">AI Software Portfolio</a> to help you prepare, build, deploy, and scale your AI solutions.</p>

<p>For more details about the new 4th Gen Intel® Xeon® Scalable processors, visit <a href="https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/platform.html">Intel’s AI Solution Platform portal</a> where you can learn how Intel is empowering developers to run end-to-end AI pipelines on these powerful CPUs.</p>

<h3 id="useful-resources">Useful resources</h3>

<ul>
  <li><a href="https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/overview.html">Intel AI Developer Tools and resources</a></li>
  <li><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/overview.html">oneAPI unified programming model</a></li>
  <li><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/optimization-for-pytorch.html">Official documentation - PyTorch Optimizations from Intel</a></li>
  <li><a href="http://intel.github.io/intel-extension-for-pytorch/">Intel® Extension for PyTorch - Documentation</a></li>
</ul>

<h3 id="explore-more-ai-code-samples">Explore more AI code samples</h3>

<ul>
  <li><a href="http://github.com/oneapi-src/oneAPI-samples/tree/master/AI-and-Analytics/End-to-end-Workloads/LanguageIdentification">Language Identification: Building an End-to-End AI Solution using PyTorch</a></li>
  <li><a href="http://github.com/oneapi-src/oneAPI-samples/tree/master/AI-and-Analytics/Features-and-Functionality/IntelPytorch_Quantization">Optimize PyTorch Models using Intel® Extension for PyTorch (IPEX) Quantization</a></li>
  <li><a href="http://github.com/oneapi-src/oneAPI-samples/tree/master/AI-and-Analytics/Features-and-Functionality/IntelPyTorch_TrainingOptimizations_AMX_BF16">PyTorch Training Optimizations with Advanced Matrix Extensions Bfloat16</a></li>
</ul>

<p><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/code-samples.html">See all code samples</a></p>

                </article>
            </div>
        </div>
    </div>

<!--    


 -->
    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="/docs">View Docs</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.org" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="https://pytorch.org">PyTorch</a></li>
          <li><a href="/get-started">Get Started</a></li>
          <li><a href="/features">Features</a></li>
          <li><a href="/ecosystem">Ecosystem</a></li>
          <li><a href="/blog">Blog</a></li>
          <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          <li><a href="https://github.com/pytorch/pytorch/security/policy" target="_blank">Security</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="/resources">Resources</a></li>
          <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
          <li><a href="/docs">Docs</a></li>
          <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
          <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">GitHub Issues</a></li>
          <li><a href="/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><p>Stay up to date</p></li>
          <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
          <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
          <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
          <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          <li><a href="https://social.lfx.dev/@pytorch" rel="me" target="_blank">Mastodon</a></li>
        </ul>
      </div>

      <div class="footer-links-col">
        <ul>
          <li class="list-title"><p>PyTorch Podcasts</p></li>
          <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
          <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
          <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
          <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
        </ul>
      </div>
    </div>

    <div class="privacy-policy">
      <ul>
        <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
        <li class="privacy-policy-links">|</li>
        <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
      </ul>
      <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation. 
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see 
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source 
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC, 
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
    </div>
  </div>
  <img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>
        <li class="navSearchWrapper reactNavSearchWrapper tabletSearchWrapper" key="search">
          <div class="mobile-search-border">
            <input
              id="mobile-search-input"
              type="text"
              title="Search"
            />
            <div id="mobile-search-icon"></div>
          </div>
        </li>

        <li class="">
          <a href="/get-started">Get Started</a>
        </li>

        <li class="resources-mobile-menu-title">
          <a href="/ecosystem">Ecosystem</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/ecosystem">Tools</a>
          </li>
          <li>
            <a href="/ecosystem/pted/2021">Ecosystem Day 2021</a>
          </li>
          <li>
            <a href="/ecosystem/ptdd/2021">Developer Day 2021</a>
          </li>
        </ul>

        <li class="">
          <a href="/mobile">Mobile</a>
        </li>

        <li class="active">
          <a href="/blog">Blog</a>
        </li>

        <li>
          <a href="https://pytorch.org/tutorials">Tutorials</a>
        </li>

        <li class="resources-mobile-menu-title">
          <a href="/docs">Docs</a>
        </li>

        <ul class="resources-mobile-menu-items">
          <li class="">
            <a href="/docs">PyTorch</a>
          </li>

          <li class="">
            <a href="/audio">torchaudio</a>
          </li>

          <li class="">
            <a href="/text">torchtext</a>
          </li>

          <li class="">
            <a href="/vision">torchvision</a>
          </li>

          <li class="">
            <a href="/torcharrow">torcharrow</a>
          </li>

          <li class="">
            <a href="/data">TorchData</a>
          </li> 

          <li class="">
            <a href="/torchrec">TorchRec</a>
          </li>

          <li class="">
            <a href="/serve">TorchServe</a>
          </li>

          <li class="">
            <a href="/xla/release/1.6/index.html">PyTorch on XLA Devices</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          Resources
        </li>

        <ul class="resources-mobile-menu-items">
          <li class="">
            <a href="/features">About</a>
          </li>

          <li>
            <a href="/foundation">PyTorch Foundation</a>
          </li>
          
          <li>
            <a href="/#community-module">Community</a>
          </li>
          
          <li class="">
            <a href="/community-stories">Community stories</a>
          </li>

          <li class="">
            <a href="/resources">Developer Resources</a>
          </li>

          <li>
            <a href="/events">Events</a>
          </li>

          <li>
            <a href="https://discuss.pytorch.org">Forum</a>
          </li>

          <li class="">
            <a href="/hub">Models (Beta)</a>
          </li>

        </ul>

        <li id="github-mobile-menu-link">
          <a href="https://github.com/pytorch/pytorch">GitHub</a>
        </li>
      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>

  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script>

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>


  <script src="/assets/track-events.js"></script>
  <script>trackEvents.bind();</script>



<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="/assets/images/pytorch-x.svg">
  </div>
</div>


</body>

</html>
