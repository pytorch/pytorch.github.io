<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
  <!-- End Google Tag Manager -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond | PyTorch
    
  </title>
  <meta name="robots" content="index, follow" />

<meta name="description" content="Use 3D to visualize matrix multiplication expressions, attention heads with real weights, and more.

" />

  <meta property="og:image" content="https://pytorch.org/assets/images/social-share.jpg" />
  <meta name="twitter:image" content="https://pytorch.org/assets/images/social-share.jpg" />

<meta property="og:locale" content="en_US" />
<meta property="og:type" content="website" />
<meta property="og:title" content="Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond" />
<meta property="og:description" content="Use 3D to visualize matrix multiplication expressions, attention heads with real weights, and more.

" />
<meta property="og:site_name" content="PyTorch" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond" />
<meta name="twitter:description" content="Use 3D to visualize matrix multiplication expressions, attention heads with real weights, and more.

" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
  
    <script
  async
  src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"
></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());
  gtag("config", "UA-117752657-2");
</script>

    <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window,document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '243028289693773');
    fbq('track', 'PageView');
</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

    <!-- Twitter universal website tag code -->
<img height="1" width="1" style="display:none;" alt="" src="https://analytics.twitter.com/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__analytics.twitter.com_i_adsct-3Fp-5Fid-3DTwitter-26p-5Fuser-5Fid-3D0-26txn-5Fid-3Do2gi1-26events-3D-255B-255B-2522pageview-2522-252Cnull-255D-255D-26tw-5Fsale-5Famount-3D0-26tw-5Forder-5Fquantity-3D0&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=o6i4D0V0088WH2RnzIoqiF-vj45PL-2sTrsxQ0SNO3A&e=)" />
<img height="1" width="1" style="display:none;" alt="" src="//t.co/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__linkprotect.cudasvc.com_url-3Fa-3Dhttp-253a-252f-252ft.co-252fi-252fadsct-253fp-5Fid-253dTwitter-2526p-5Fuser-5Fid-253d0-2526txn-5Fid-253do2gi1-2526events-253d-25255B-25255B-252522pageview-252522-25252Cnull-25255D-25255D-2526tw-5Fsale-5Famount-253d0-2526tw-5Forder-5Fquantity-253d0-26c-3DE-2C1-2CC33dLwIhtuEcl5FhdztSnUwsioeej5k-2DWy0RYREBAq51kGji32A2Cw94YU9vQBpY5tPN3AukEw3C-5F-2DlbtndnLoR7-5FA-5FLoH0Rr7zLtP1ykptN-26typo-3D1&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=Abgc3XBkhESv8XBYtLchdDZyISGsK6v_BB6cLMJGyCw&e=)" />
<!-- End Twitter universal website tag code -->

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Pythorch Blog Posts" />
</head>


<body class="blog">
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <div class="main-background blog-background blog-detail-background"></div>
    <div class="hello-bar">
        <div class="container">
          Join us in Silicon Valley September 18-19 at the 2024 PyTorch Conference. <a target="_blank" href="https://events.linuxfoundation.org/pytorch-conference/">Learn more</a>.
        </div>
      </div>
      
    <div class="container-fluid header-holder blog-detail-header">
        <div class="container">
            

<div class="header-container">
  <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Learn
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/get-started">
            <span class=dropdown-title>Get Started</span>
            <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/">
            <span class="dropdown-title">Tutorials</span>
            <p>Whats new in PyTorch tutorials</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
            <span class="dropdown-title">Learn the Basics</span>
            <p>Familiarize yourself with PyTorch concepts and modules</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
            <span class="dropdown-title">PyTorch Recipes</span>
            <p>Bite-size, ready-to-deploy PyTorch code examples</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
            <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
            <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Ecosystem 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/ecosystem">
            <span class="dropdown-title">Tools</span>
            <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="/#community-module">
            <span class=dropdown-title>Community</span>
            <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
          </a>
          <a class="nav-dropdown-item" href="https://discuss.pytorch.org" target="_blank">
            <span class=dropdown-title>Forums</span>
            <p>A place to discuss PyTorch code, issues, install, research</p>
          </a>
          <a class="nav-dropdown-item" href="/resources">
            <span class=dropdown-title>Developer Resources</span>
            <p>Find resources and get questions answered</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/contributor-awards-2023">
            <span class="dropdown-title">Contributor Awards - 2023</span>
            <p>Award winners announced at this year's PyTorch Conference</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Edge 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/edge">
            <span class="dropdown-title">About PyTorch Edge</span>
            <p>Build innovative and privacy-aware AI experiences for edge devices</p>
          </a>
          <a class="nav-dropdown-item" href="/executorch-overview">
            <span class="dropdown-title">ExecuTorch</span>
            <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="docsDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Docs
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="https://pytorch.org/docs">
            <span class="dropdown-title">PyTorch</span>
            <p>Explore the documentation for comprehensive guidance on how to use PyTorch.</p>
          </a>
          <a class="nav-dropdown-item" href="/pytorch-domains">
            <span class="dropdown-title">PyTorch Domains</span>
            <p> Read the PyTorch Domains documentation to learn more about domain-specific libraries.</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Blog & News
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/blog">
            <span class="dropdown-title">PyTorch Blog</span>
            <p>Catch up on the latest technical news and happenings</p>
          </a>
          <a class="nav-dropdown-item" href="/community-blog">
            <span class="dropdown-title">Community Blog</span>
            <p>Stories from the PyTorch ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="/videos">
            <span class="dropdown-title">Videos</span>
            <p>Learn about the latest PyTorch tutorials, new, and more </p>
          </a>
          <a class="nav-dropdown-item" href="/community-stories">
            <span class="dropdown-title">Community Stories</span>
            <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
          </a>
          <a class="nav-dropdown-item" href="/events">
            <span class=dropdown-title>Events</span>
            <p>Find events, webinars, and podcasts</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          About
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/foundation">
            <span class=dropdown-title>PyTorch Foundation</span>
            <p>Learn more about the PyTorch Foundation.</p>
          </a>
          <a class="nav-dropdown-item" href="/governing-board">
            <span class=dropdown-title>Governing Board</span>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <a href="/join" data-cta="join">
        Become a Member
      </a>
    </li>

    <li class="main-menu-item" id="github-main-menu-link">
      <a href="https://github.com/pytorch/pytorch" title="Go to PyTorch GitHub">
        <div id="topnav-gh-icon"></div>
      </a>
    </li>

    <li class="navSearchWrapper reactNavSearchWrapper" key="search">
      <div class="search-border">
        <div id="search-icon"></div>
        <input
          id="search-input"
          type="text"
          title="Search"
        />
        <div id="close-search">X</div>
      </div>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

        </div>
    </div>

    <div class="jumbotron jumbotron-fluid blog-detail-jumbotron">
        <div class="container blog-detail-container">
            <p class="featured-post">September 25, 2023</p>
            <h1>
                <a class="blog-title">Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond</a>
            </h1>
        </div>
    </div>

    <div class="main-content-wrapper blog-detail-wrapper">
        <div class="main-content blog-detail-content">
            <div class="container">
                <img src="/assets/images/logo-icon.svg" class="img-fluid author-icon">
                <article class="pytorch-article">
                    <p class="author">
                      by
                      
                        Basil Hosmer
                      
                    </p>
                    <p><em>Use 3D to visualize matrix multiplication expressions, attention heads with real weights, and more.</em></p>

<p>Matrix multiplications (matmuls) are the building blocks of today’s ML models. This note presents <a href="https://bhosmer.github.io/mm/ref.html">mm</a>, a visualization tool for matmuls and compositions of matmuls.</p>

<p>Matrix multiplication is inherently a three-dimensional operation. Because mm uses all three spatial dimensions, it can convey meaning more clearly and intuitively than the usual squares-on-paper idioms, especially (though not only) for visual/spatial thinkers.</p>

<p>We also have room to <em>compose</em> matmuls in geometrically consistent ways - so we can visualize big, compound structures like attention heads and MLP layers using the same rules as simple expressions. And more advanced features, like animating different matmul algorithms, partitioning for parallelism, and loading external data to explore the behavior of actual models, all build naturally on this foundation.</p>

<p>mm is fully interactive, runs <a href="https://bhosmer.github.io/mm/">in the browser</a> and keeps its complete state in the URL, so links are shareable sessions (the screenshots and videos in this note all have links that open the corresponding visualization in the tool). This <a href="https://bhosmer.github.io/mm/ref.html">reference guide</a> describes all of the available functionality.</p>

<p>We’ll first introduce the visualization approach, build intuition by visualizing some simple matmuls and expressions, then dive into some more extended examples:</p>

<ol>
  <li><strong>Pitch</strong> - why is this way of visualizing better?</li>
  <li><strong>Warmup - animations</strong> - watching the canonical matmul decompositions in action</li>
  <li><strong>Warmup - expressions</strong> - a quick tour of some fundamental expression building blocks</li>
  <li><strong>Inside an attention head</strong> - an in-depth look at the structure, values and computation behavior of a couple of attention heads from GPT2 via <a href="https://github.com/karpathy/nanoGPT">NanoGPT</a></li>
  <li><strong>Parallelizing attention</strong> - visualizing attention head parallelization with examples from the recent <a href="https://arxiv.org/pdf/2305.19370.pdf">Blockwise Parallel Transformer</a> paper</li>
  <li><strong>Sizes in an attention layer</strong> - what do the MHA and FFA halves of an attention layer look like together, when we visualize a whole layer as a single structure? How does the picture change during autoregressive decoding?</li>
  <li><strong>LoRA</strong> - a visual explanation of this elaboration of the attention head architecture</li>
  <li><strong>Wrapup</strong> - next steps and call for feedback</li>
</ol>

<h2 id="1-pitch">1 Pitch</h2>

<p><a href="https://bhosmer.github.io/mm/ref.html">mm</a>’s visualization approach is based on the premise that <em>matrix multiplication is fundamentally a three-dimensional operation</em>.</p>

<p>In other words this:</p>

<p><img src="/assets/images/inside-the-matrix/matmul3.jpg" alt="matrix multiplication is fundamentally a three-dimensional operation" style="width:100%; max-width: 478px; display: block; margin-left: auto; margin-right: auto" /></p>

<p>is a sheet of paper trying to be this (<a href="https://bhosmer.github.io/mm/index.html?params=%7B%22expr%22%3A%22L%20%40%20R%22%2C%22name%22%3A%22L%20%40%20R%22%2C%22epilog%22%3A%22none%22%2C%22left%22%3A%7B%22name%22%3A%22L%22%2C%22matmul%22%3Afalse%2C%22h%22%3A32%2C%22w%22%3A24%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22open%22%7D%2C%22right%22%3A%7B%22name%22%3A%22R%22%2C%22matmul%22%3Afalse%2C%22h%22%3A24%2C%22w%22%3A32%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22open%22%7D%2C%22anim%22%3A%7B%22fuse%22%3A%22none%22%2C%22speed%22%3A20%2C%22hide%20inputs%22%3Afalse%2C%22alg%22%3A%22none%22%2C%22spin%22%3A0%2C%22folder%22%3A%22open%22%7D%2C%22block%22%3A%7B%22i%20blocks%22%3A1%2C%22j%20blocks%22%3A1%2C%22k%20blocks%22%3A1%7D%2C%22layout%22%3A%7B%22scheme%22%3A%22blocks%22%2C%22gap%22%3A3%2C%22scatter%22%3A0%2C%22molecule%22%3A1%2C%22blast%22%3A0%2C%22polarity%22%3A%22negative%22%2C%22left%20placement%22%3A%22left%22%2C%22right%20placement%22%3A%22top%22%2C%22result%20placement%22%3A%22front%22%2C%22folder%22%3A%22closed%22%7D%2C%22deco%22%3A%7B%22legends%22%3A6%2C%22shape%22%3Atrue%2C%22spotlight%22%3A2%2C%22row%20guides%22%3A1%2C%22flow%20guides%22%3A0.5%2C%22lens%20size%22%3A0.5%2C%22magnification%22%3A10%2C%22interior%20spotlight%22%3Afalse%2C%22axes%22%3Afalse%2C%22folder%22%3A%22closed%22%7D%2C%22viz%22%3A%7B%22sensitivity%22%3A%22semilocal%22%2C%22min%20size%22%3A0.196%2C%22min%20light%22%3A0.4%2C%22max%20light%22%3A0.6%2C%22elem%20scale%22%3A0.8227%2C%22zero%20hue%22%3A0.77%2C%22hue%20gap%22%3A0.74%2C%22hue%20spread%22%3A0.04%2C%22folder%22%3A%22open%22%7D%2C%22diag%22%3A%7B%22url%22%3A%22%22%7D%2C%22cam%22%3A%7B%22x%22%3A-48.763575165818956%2C%22y%22%3A43.72517618222101%2C%22z%22%3A33.70077275818966%2C%22target%22%3A%7B%22x%22%3A0%2C%22y%22%3A0%2C%22z%22%3A0%7D%7D%2C%22folder%22%3A%22closed%22%2C%22compress%22%3Afalse%7D">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/initial.jpg" alt="wrap the matmul around a cube" style="width:100%" /></p>

<p>When we wrap the matmul around a cube this way, the correct relationships between argument shapes, result shape and shared dimensions all fall into place.</p>

<p>Now the computation makes <em>geometric sense</em>: each location <code class="language-plaintext highlighter-rouge">i, j</code> in the result matrix anchors a vector running along the depth dimension <code class="language-plaintext highlighter-rouge">k</code> in the cube’s interior, where the horizontal plane extending from row <code class="language-plaintext highlighter-rouge">i</code> in <code class="language-plaintext highlighter-rouge">L</code> and a vertical plane extending from column <code class="language-plaintext highlighter-rouge">j</code> in <code class="language-plaintext highlighter-rouge">R</code> intersect. Along this vector, pairs of <code class="language-plaintext highlighter-rouge">(i, k)</code> <code class="language-plaintext highlighter-rouge">(k, j)</code> elements from the left and right arguments meet and are multiplied, and the resulting products are summed along <code class="language-plaintext highlighter-rouge">k</code> and the result is deposited in location <code class="language-plaintext highlighter-rouge">i, j</code> of the result.</p>

<p>(Jumping ahead momentarily, <a href="https://bhosmer.github.io/mm/index.html?params=%7B%22expr%22%3A%22L%20%40%20R%22%2C%22name%22%3A%22L%20%40%20R%22%2C%22epilog%22%3A%22none%22%2C%22left%22%3A%7B%22name%22%3A%22L%22%2C%22matmul%22%3Afalse%2C%22h%22%3A32%2C%22w%22%3A24%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22open%22%7D%2C%22right%22%3A%7B%22name%22%3A%22R%22%2C%22matmul%22%3Afalse%2C%22h%22%3A24%2C%22w%22%3A32%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22open%22%7D%2C%22anim%22%3A%7B%22fuse%22%3A%22none%22%2C%22speed%22%3A48%2C%22hide%20inputs%22%3Afalse%2C%22alg%22%3A%22dotprod%20(row%20major)%22%2C%22spin%22%3A0%2C%22folder%22%3A%22open%22%7D%2C%22block%22%3A%7B%22i%20blocks%22%3A1%2C%22j%20blocks%22%3A1%2C%22k%20blocks%22%3A1%7D%2C%22layout%22%3A%7B%22scheme%22%3A%22blocks%22%2C%22gap%22%3A5%2C%22scatter%22%3A0%2C%22molecule%22%3A1%2C%22blast%22%3A0%2C%22polarity%22%3A%22negative%22%2C%22left%20placement%22%3A%22left%22%2C%22right%20placement%22%3A%22top%22%2C%22result%20placement%22%3A%22front%22%2C%22folder%22%3A%22open%22%7D%2C%22deco%22%3A%7B%22legends%22%3A6%2C%22shape%22%3Atrue%2C%22spotlight%22%3A2%2C%22row%20guides%22%3A1%2C%22flow%20guides%22%3A0.5%2C%22lens%20size%22%3A0.5%2C%22magnification%22%3A10%2C%22interior%20spotlight%22%3Afalse%2C%22axes%22%3Afalse%2C%22folder%22%3A%22closed%22%7D%2C%22viz%22%3A%7B%22sensitivity%22%3A%22semilocal%22%2C%22min%20size%22%3A0.196%2C%22min%20light%22%3A0.4%2C%22max%20light%22%3A0.6%2C%22elem%20scale%22%3A1%2C%22zero%20hue%22%3A0.77%2C%22hue%20gap%22%3A0.74%2C%22hue%20spread%22%3A0.04%2C%22folder%22%3A%22open%22%7D%2C%22diag%22%3A%7B%22url%22%3A%22%22%7D%2C%22cam%22%3A%7B%22x%22%3A-54.145594172414235%2C%22y%22%3A48.55110882721702%2C%22z%22%3A37.42031544768185%2C%22target%22%3A%7B%22x%22%3A0%2C%22y%22%3A0%2C%22z%22%3A0%7D%7D%2C%22folder%22%3A%22closed%22%2C%22compress%22%3Afalse%7D">here’s an animation</a>.)</p>

<p>This is the <em>intuitive</em> meaning of matrix multiplication:</p>

<ol>
  <li><strong>project</strong> two orthogonal matrices into the interior of a cube</li>
  <li><strong>multiply</strong> the pair of values at each intersection, forming a grid of products</li>
  <li><strong>sum</strong> along the third orthogonal dimension to produce a result matrix.</li>
</ol>

<p>For orientation, the tool displays an arrow in the cube’s interior that points towards the result matrix, with a blue vane coming from the left argument and a <strong>r</strong>ed vane coming from the <strong>r</strong>ight argument. The tool also displays white guidelines to indicate the row axis of each matrix, though they’re faint in this screenshot.</p>

<p>The layout constraints are straightforward:</p>

<ul>
  <li>left argument and result must be adjoined along their shared <strong>height</strong> (i) dimension</li>
  <li>right argument and result must be adjoined along their shared <strong>width</strong> (j) dimension</li>
  <li>left and right arguments must be adjoined along their shared (left width/right height) dimension, which becomes the matmul’s <strong>depth</strong> (k) dimension</li>
</ul>

<p>This geometry gives us a solid foundation for visualizing all the standard matmul decompositions, and an intuitive basis for exploring nontrivially complex <em>compositions</em> of matmuls, as we’ll see below.</p>

<h2 id="2-warmup---animations">2 Warmup - animations</h2>

<p>Before diving into some more complex examples, we’ll run through a few intuition builders to get a feel for how things look and feel in this style of visualization.</p>

<h3 id="2a-dot-product">2a Dot product</h3>

<p>First, the canonical algorithm - computing each result element by taking the dot product of the corresponding left row and right column. What we see in the animation is the sweep of multiplied value vectors through the cube’s interior, each delivering a summed result at the corresponding position.</p>

<p>Here, <code class="language-plaintext highlighter-rouge">L</code> has blocks of rows filled with 1 (blue) or -1 (red); <code class="language-plaintext highlighter-rouge">R</code> has column blocks filled similarly. <code class="language-plaintext highlighter-rouge">k</code> is 24 here, so the result matrix (<code class="language-plaintext highlighter-rouge">L @ R</code>) has blue values of 24 and red values of -24 (<a href="https://bhosmer.github.io/mm/index.html?params=%7B%22expr%22%3A%22L%20%40%20R%22%2C%22name%22%3A%22L%20%40%20R%22%2C%22epilog%22%3A%22none%22%2C%22left%22%3A%7B%22name%22%3A%22L%22%2C%22matmul%22%3Afalse%2C%22h%22%3A32%2C%22w%22%3A24%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22open%22%7D%2C%22right%22%3A%7B%22name%22%3A%22R%22%2C%22matmul%22%3Afalse%2C%22h%22%3A24%2C%22w%22%3A32%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22open%22%7D%2C%22anim%22%3A%7B%22fuse%22%3A%22none%22%2C%22speed%22%3A48%2C%22hide%20inputs%22%3Afalse%2C%22alg%22%3A%22dotprod%20(row%20major)%22%2C%22spin%22%3A0%2C%22folder%22%3A%22open%22%7D%2C%22block%22%3A%7B%22i%20blocks%22%3A1%2C%22j%20blocks%22%3A1%2C%22k%20blocks%22%3A1%7D%2C%22layout%22%3A%7B%22scheme%22%3A%22blocks%22%2C%22gap%22%3A5%2C%22scatter%22%3A0%2C%22molecule%22%3A1%2C%22blast%22%3A0%2C%22polarity%22%3A%22negative%22%2C%22left%20placement%22%3A%22left%22%2C%22right%20placement%22%3A%22top%22%2C%22result%20placement%22%3A%22front%22%2C%22folder%22%3A%22open%22%7D%2C%22deco%22%3A%7B%22legends%22%3A6%2C%22shape%22%3Atrue%2C%22spotlight%22%3A2%2C%22row%20guides%22%3A1%2C%22flow%20guides%22%3A0.5%2C%22lens%20size%22%3A0.5%2C%22magnification%22%3A10%2C%22interior%20spotlight%22%3Afalse%2C%22axes%22%3Afalse%2C%22folder%22%3A%22closed%22%7D%2C%22viz%22%3A%7B%22sensitivity%22%3A%22semilocal%22%2C%22min%20size%22%3A0.196%2C%22min%20light%22%3A0.4%2C%22max%20light%22%3A0.6%2C%22elem%20scale%22%3A1%2C%22zero%20hue%22%3A0.77%2C%22hue%20gap%22%3A0.74%2C%22hue%20spread%22%3A0.04%2C%22folder%22%3A%22open%22%7D%2C%22diag%22%3A%7B%22url%22%3A%22%22%7D%2C%22cam%22%3A%7B%22x%22%3A-54.145594172414235%2C%22y%22%3A48.55110882721702%2C%22z%22%3A37.42031544768185%2C%22target%22%3A%7B%22x%22%3A0%2C%22y%22%3A0%2C%22z%22%3A0%7D%7D%2C%22folder%22%3A%22closed%22%2C%22compress%22%3Afalse%7D">open in mm</a> - long click or control-click to inspect values):</p>

<p align="center">
  <video width="100%" controls="">
    <source src="/assets/videos/inside-the-matrix/dotprod1.mp4" type="video/mp4" />
  </video>
</p>

<h3 id="2b-matrix-vector-products">2b Matrix-vector products</h3>

<p>A matmul decomposed into matrix-vector products looks like a vertical plane (a product of the left argument with each column of the right argument) painting columns onto the result as it sweeps horizontally through the cube’s interior (<a href="https://bhosmer.github.io/mm/index.html?params=%7B%22expr%22%3A%22L%20%40%20R%22%2C%22name%22%3A%22L%20%40%20R%22%2C%22epilog%22%3A%22none%22%2C%22left%22%3A%7B%22name%22%3A%22L%22%2C%22matmul%22%3Afalse%2C%22h%22%3A32%2C%22w%22%3A24%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22closed%22%7D%2C%22right%22%3A%7B%22name%22%3A%22R%22%2C%22matmul%22%3Afalse%2C%22h%22%3A24%2C%22w%22%3A32%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22closed%22%7D%2C%22anim%22%3A%7B%22fuse%22%3A%22none%22%2C%22speed%22%3A12%2C%22hide%20inputs%22%3Afalse%2C%22alg%22%3A%22mvprod%22%2C%22spin%22%3A0%2C%22folder%22%3A%22open%22%7D%2C%22block%22%3A%7B%22i%20blocks%22%3A1%2C%22j%20blocks%22%3A1%2C%22k%20blocks%22%3A1%7D%2C%22layout%22%3A%7B%22scheme%22%3A%22blocks%22%2C%22gap%22%3A5%2C%22scatter%22%3A0%2C%22molecule%22%3A1%2C%22blast%22%3A0%2C%22polarity%22%3A%22negative%22%2C%22left%20placement%22%3A%22left%22%2C%22right%20placement%22%3A%22top%22%2C%22result%20placement%22%3A%22front%22%2C%22folder%22%3A%22open%22%7D%2C%22deco%22%3A%7B%22legends%22%3A6%2C%22shape%22%3Atrue%2C%22spotlight%22%3A2%2C%22row%20guides%22%3A1%2C%22flow%20guides%22%3A0.5%2C%22lens%20size%22%3A0.5%2C%22magnification%22%3A10%2C%22interior%20spotlight%22%3Afalse%2C%22axes%22%3Afalse%2C%22folder%22%3A%22closed%22%7D%2C%22viz%22%3A%7B%22sensitivity%22%3A%22semilocal%22%2C%22min%20size%22%3A0.196%2C%22min%20light%22%3A0.4%2C%22max%20light%22%3A0.6%2C%22elem%20scale%22%3A1%2C%22zero%20hue%22%3A0.77%2C%22hue%20gap%22%3A0.74%2C%22hue%20spread%22%3A0.04%2C%22folder%22%3A%22open%22%7D%2C%22diag%22%3A%7B%22url%22%3A%22%22%7D%2C%22cam%22%3A%7B%22x%22%3A-54.145594172414235%2C%22y%22%3A48.55110882721702%2C%22z%22%3A37.42031544768185%2C%22target%22%3A%7B%22x%22%3A0%2C%22y%22%3A0%2C%22z%22%3A0%7D%7D%2C%22folder%22%3A%22closed%22%2C%22compress%22%3Afalse%7D">open in mm</a>):</p>

<p align="center">
  <video width="100%" controls="">
    <source src="/assets/videos/inside-the-matrix/mvprod1.mp4" type="video/mp4" />
  </video>
</p>

<p>Observing the intermediate values of a decomposition can be quite interesting, even in simple examples.</p>

<p>For instance, note the prominent vertical patterns in the intermediate matrix-vector products when we use randomly initialized arguments- reflecting the fact that each intermediate is a column-scaled replica of the left argument (<a href="https://bhosmer.github.io/mm/index.html?params=%7B%22expr%22%3A%22L%20%40%20R%22%2C%22name%22%3A%22L%20%40%20R%22%2C%22epilog%22%3A%22none%22%2C%22left%22%3A%7B%22name%22%3A%22L%22%2C%22matmul%22%3Afalse%2C%22h%22%3A32%2C%22w%22%3A24%2C%22init%22%3A%22gaussian%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22(-Math.trunc(i%20%2F%208)%20%25%202)%20%2B%20.5%22%2C%22folder%22%3A%22open%22%7D%2C%22right%22%3A%7B%22name%22%3A%22R%22%2C%22matmul%22%3Afalse%2C%22h%22%3A24%2C%22w%22%3A32%2C%22init%22%3A%22gaussian%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22(-Math.trunc(j%20%2F%208)%20%25%202)%20%2B%20.5%22%2C%22folder%22%3A%22open%22%7D%2C%22anim%22%3A%7B%22fuse%22%3A%22none%22%2C%22speed%22%3A6%2C%22hide%20inputs%22%3Afalse%2C%22alg%22%3A%22mvprod%22%2C%22spin%22%3A0%2C%22folder%22%3A%22open%22%7D%2C%22block%22%3A%7B%22i%20blocks%22%3A1%2C%22j%20blocks%22%3A1%2C%22k%20blocks%22%3A1%7D%2C%22layout%22%3A%7B%22scheme%22%3A%22blocks%22%2C%22gap%22%3A5%2C%22scatter%22%3A0%2C%22molecule%22%3A1%2C%22blast%22%3A0%2C%22polarity%22%3A%22negative%22%2C%22left%20placement%22%3A%22left%22%2C%22right%20placement%22%3A%22top%22%2C%22result%20placement%22%3A%22front%22%2C%22folder%22%3A%22open%22%7D%2C%22deco%22%3A%7B%22legends%22%3A6%2C%22shape%22%3Atrue%2C%22spotlight%22%3A2%2C%22row%20guides%22%3A1%2C%22flow%20guides%22%3A0%2C%22lens%20size%22%3A0.5%2C%22magnification%22%3A10%2C%22interior%20spotlight%22%3Afalse%2C%22axes%22%3Afalse%2C%22folder%22%3A%22open%22%7D%2C%22viz%22%3A%7B%22sensitivity%22%3A%22local%22%2C%22min%20size%22%3A0.196%2C%22min%20light%22%3A0.4%2C%22max%20light%22%3A0.6%2C%22elem%20scale%22%3A1%2C%22zero%20hue%22%3A0.77%2C%22hue%20gap%22%3A0.74%2C%22hue%20spread%22%3A0.04%2C%22folder%22%3A%22open%22%7D%2C%22diag%22%3A%7B%22url%22%3A%22%22%7D%2C%22cam%22%3A%7B%22x%22%3A-54.14559417241423%2C%22y%22%3A48.55110882721702%2C%22z%22%3A37.42031544768186%2C%22target%22%3A%7B%22x%22%3A0%2C%22y%22%3A0%2C%22z%22%3A0%7D%7D%2C%22folder%22%3A%22closed%22%2C%22compress%22%3Afalse%7D">open in mm</a>):</p>

<p align="center">
  <video width="100%" controls="">
    <source src="/assets/videos/inside-the-matrix/mvprod2.mp4" type="video/mp4" />
  </video>
</p>

<h3 id="2c-vector-matrix-products">2c Vector-matrix products</h3>

<p>A matmul decomposed into vector-matrix products looks like a horizontal plane painting rows onto the result as it descends through the cube’s interior (<a href="https://bhosmer.github.io/mm/index.html?params=%7B%22expr%22%3A%22L%20%40%20R%22%2C%22name%22%3A%22L%20%40%20R%22%2C%22epilog%22%3A%22none%22%2C%22left%22%3A%7B%22name%22%3A%22L%22%2C%22matmul%22%3Afalse%2C%22h%22%3A32%2C%22w%22%3A24%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22closed%22%7D%2C%22right%22%3A%7B%22name%22%3A%22R%22%2C%22matmul%22%3Afalse%2C%22h%22%3A24%2C%22w%22%3A32%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22closed%22%7D%2C%22anim%22%3A%7B%22fuse%22%3A%22none%22%2C%22speed%22%3A12%2C%22hide%20inputs%22%3Afalse%2C%22alg%22%3A%22vmprod%22%2C%22spin%22%3A0%2C%22folder%22%3A%22open%22%7D%2C%22block%22%3A%7B%22i%20blocks%22%3A1%2C%22j%20blocks%22%3A1%2C%22k%20blocks%22%3A1%7D%2C%22layout%22%3A%7B%22scheme%22%3A%22blocks%22%2C%22gap%22%3A5%2C%22scatter%22%3A0%2C%22molecule%22%3A1%2C%22blast%22%3A0%2C%22polarity%22%3A%22negative%22%2C%22left%20placement%22%3A%22left%22%2C%22right%20placement%22%3A%22top%22%2C%22result%20placement%22%3A%22front%22%2C%22folder%22%3A%22open%22%7D%2C%22deco%22%3A%7B%22legends%22%3A6%2C%22shape%22%3Atrue%2C%22spotlight%22%3A2%2C%22row%20guides%22%3A1%2C%22flow%20guides%22%3A0.5%2C%22lens%20size%22%3A0.5%2C%22magnification%22%3A10%2C%22interior%20spotlight%22%3Afalse%2C%22axes%22%3Afalse%2C%22folder%22%3A%22closed%22%7D%2C%22viz%22%3A%7B%22sensitivity%22%3A%22semilocal%22%2C%22min%20size%22%3A0.196%2C%22min%20light%22%3A0.4%2C%22max%20light%22%3A0.6%2C%22elem%20scale%22%3A1%2C%22zero%20hue%22%3A0.77%2C%22hue%20gap%22%3A0.74%2C%22hue%20spread%22%3A0.04%2C%22folder%22%3A%22open%22%7D%2C%22diag%22%3A%7B%22url%22%3A%22%22%7D%2C%22cam%22%3A%7B%22x%22%3A-54.145594172414235%2C%22y%22%3A48.55110882721702%2C%22z%22%3A37.42031544768185%2C%22target%22%3A%7B%22x%22%3A0%2C%22y%22%3A0%2C%22z%22%3A0%7D%7D%2C%22folder%22%3A%22closed%22%2C%22compress%22%3Afalse%7D">open in mm</a>):</p>

<p align="center">
  <video width="100%" controls="">
    <source src="/assets/videos/inside-the-matrix/vmprod_check.mp4" type="video/mp4" />
  </video>
</p>

<p>Switching to randomly initialized arguments, we see patterns analogous to those we saw with matrix-vector products - only this time the patterns are horizontal, corresponding to the fact that each intermediate vector-matrix product is a row-scaled replica of the right argument.</p>

<p>When thinking about how matmuls express the rank and structure of their arguments, it’s useful to envision both of these patterns happening simultaneously in the computation (<a href="https://bhosmer.github.io/mm/index.html?params=%7B%22expr%22%3A%22L%20%40%20R%22%2C%22name%22%3A%22L%20%40%20R%22%2C%22epilog%22%3A%22none%22%2C%22left%22%3A%7B%22name%22%3A%22L%22%2C%22matmul%22%3Afalse%2C%22h%22%3A32%2C%22w%22%3A24%2C%22init%22%3A%22gaussian%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22(-Math.trunc(i%20%2F%208)%20%25%202)%20%2B%20.5%22%2C%22folder%22%3A%22open%22%7D%2C%22right%22%3A%7B%22name%22%3A%22R%22%2C%22matmul%22%3Afalse%2C%22h%22%3A24%2C%22w%22%3A32%2C%22init%22%3A%22gaussian%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22(-Math.trunc(j%20%2F%208)%20%25%202)%20%2B%20.5%22%2C%22folder%22%3A%22open%22%7D%2C%22anim%22%3A%7B%22fuse%22%3A%22none%22%2C%22speed%22%3A6%2C%22hide%20inputs%22%3Afalse%2C%22alg%22%3A%22vmprod%22%2C%22spin%22%3A0%2C%22folder%22%3A%22open%22%7D%2C%22block%22%3A%7B%22i%20blocks%22%3A1%2C%22j%20blocks%22%3A1%2C%22k%20blocks%22%3A1%7D%2C%22layout%22%3A%7B%22scheme%22%3A%22blocks%22%2C%22gap%22%3A5%2C%22scatter%22%3A0%2C%22molecule%22%3A1%2C%22blast%22%3A0%2C%22polarity%22%3A%22negative%22%2C%22left%20placement%22%3A%22left%22%2C%22right%20placement%22%3A%22top%22%2C%22result%20placement%22%3A%22front%22%2C%22folder%22%3A%22open%22%7D%2C%22deco%22%3A%7B%22legends%22%3A6%2C%22shape%22%3Atrue%2C%22spotlight%22%3A2%2C%22row%20guides%22%3A1%2C%22flow%20guides%22%3A0%2C%22lens%20size%22%3A0.5%2C%22magnification%22%3A10%2C%22interior%20spotlight%22%3Afalse%2C%22axes%22%3Afalse%2C%22folder%22%3A%22open%22%7D%2C%22viz%22%3A%7B%22sensitivity%22%3A%22local%22%2C%22min%20size%22%3A0.196%2C%22min%20light%22%3A0.4%2C%22max%20light%22%3A0.6%2C%22elem%20scale%22%3A1%2C%22zero%20hue%22%3A0.77%2C%22hue%20gap%22%3A0.74%2C%22hue%20spread%22%3A0.04%2C%22folder%22%3A%22open%22%7D%2C%22diag%22%3A%7B%22url%22%3A%22%22%7D%2C%22cam%22%3A%7B%22x%22%3A-54.14559417241423%2C%22y%22%3A48.55110882721702%2C%22z%22%3A37.42031544768186%2C%22target%22%3A%7B%22x%22%3A0%2C%22y%22%3A0%2C%22z%22%3A0%7D%7D%2C%22folder%22%3A%22closed%22%2C%22compress%22%3Afalse%7D">open in mm</a>):</p>

<p align="center">
  <video width="100%" controls="">
    <source src="/assets/videos/inside-the-matrix/vmprod3.mp4" type="video/mp4" />
  </video>
</p>

<p>Here’s one more intuition builder using vector-matrix products, showing how the identity matrix functions exactly like a mirror set at a 45deg angle to both its counterargument and the result (<a href="https://bhosmer.github.io/mm/index.html?params=%7B%22expr%22%3A%22L%20%40%20R%22%2C%22name%22%3A%22L%20%40%20R%22%2C%22epilog%22%3A%22none%22%2C%22left%22%3A%7B%22name%22%3A%22L%22%2C%22matmul%22%3Afalse%2C%22h%22%3A24%2C%22w%22%3A24%2C%22init%22%3A%22eye%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22(-Math.trunc(i%20%2F%208)%20%25%202)%20%2B%20.5%22%2C%22folder%22%3A%22open%22%7D%2C%22right%22%3A%7B%22name%22%3A%22R%22%2C%22matmul%22%3Afalse%2C%22h%22%3A24%2C%22w%22%3A32%2C%22init%22%3A%22row%20major%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22(-Math.trunc(j%20%2F%208)%20%25%202)%20%2B%20.5%22%2C%22folder%22%3A%22open%22%7D%2C%22anim%22%3A%7B%22fuse%22%3A%22none%22%2C%22speed%22%3A12%2C%22hide%20inputs%22%3Afalse%2C%22alg%22%3A%22vmprod%22%2C%22spin%22%3A0%2C%22folder%22%3A%22open%22%7D%2C%22block%22%3A%7B%22i%20blocks%22%3A1%2C%22j%20blocks%22%3A1%2C%22k%20blocks%22%3A1%7D%2C%22layout%22%3A%7B%22scheme%22%3A%22blocks%22%2C%22gap%22%3A5%2C%22scatter%22%3A0%2C%22molecule%22%3A1%2C%22blast%22%3A0%2C%22polarity%22%3A%22negative%22%2C%22left%20placement%22%3A%22left%22%2C%22right%20placement%22%3A%22top%22%2C%22result%20placement%22%3A%22front%22%2C%22folder%22%3A%22open%22%7D%2C%22deco%22%3A%7B%22legends%22%3A6%2C%22shape%22%3Atrue%2C%22spotlight%22%3A2%2C%22row%20guides%22%3A1%2C%22flow%20guides%22%3A0%2C%22lens%20size%22%3A0.5%2C%22magnification%22%3A10%2C%22interior%20spotlight%22%3Afalse%2C%22axes%22%3Afalse%2C%22folder%22%3A%22open%22%7D%2C%22viz%22%3A%7B%22sensitivity%22%3A%22local%22%2C%22min%20size%22%3A0.196%2C%22min%20light%22%3A0.4%2C%22max%20light%22%3A0.6%2C%22elem%20scale%22%3A1%2C%22zero%20hue%22%3A0.77%2C%22hue%20gap%22%3A0.74%2C%22hue%20spread%22%3A0.04%2C%22folder%22%3A%22open%22%7D%2C%22diag%22%3A%7B%22url%22%3A%22%22%7D%2C%22cam%22%3A%7B%22x%22%3A-50.560896320538845%2C%22y%22%3A45.336792719337595%2C%22z%22%3A34.94291121097398%7D%2C%22folder%22%3A%22closed%22%2C%22compress%22%3Afalse%7D">open in mm</a>):</p>

<p align="center">
  <video width="100%" controls="">
    <source src="/assets/videos/inside-the-matrix/vmprod_id.mp4" type="video/mp4" />
  </video>
</p>

<h3 id="2d-summed-outer-products">2d Summed outer products</h3>

<p>The third planar decomposition is along the <code class="language-plaintext highlighter-rouge">k</code> axis, computing the matmul result by a pointwise summation of vector outer products. Here we see the plane of outer products sweeping the cube “from back to front”, accumulating into the result (<a href="https://bhosmer.github.io/mm/index.html?params=%7B%22expr%22%3A%22L%20%40%20R%22%2C%22name%22%3A%22L%20%40%20R%22%2C%22epilog%22%3A%22none%22%2C%22left%22%3A%7B%22name%22%3A%22L%22%2C%22matmul%22%3Afalse%2C%22h%22%3A32%2C%22w%22%3A24%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22closed%22%7D%2C%22right%22%3A%7B%22name%22%3A%22R%22%2C%22matmul%22%3Afalse%2C%22h%22%3A24%2C%22w%22%3A32%2C%22init%22%3A%22expr%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201%22%2C%22folder%22%3A%22closed%22%7D%2C%22anim%22%3A%7B%22fuse%22%3A%22none%22%2C%22speed%22%3A12%2C%22hide%20inputs%22%3Afalse%2C%22alg%22%3A%22vvprod%22%2C%22spin%22%3A0%2C%22folder%22%3A%22open%22%7D%2C%22block%22%3A%7B%22i%20blocks%22%3A1%2C%22j%20blocks%22%3A1%2C%22k%20blocks%22%3A1%7D%2C%22layout%22%3A%7B%22scheme%22%3A%22blocks%22%2C%22gap%22%3A5%2C%22scatter%22%3A0%2C%22molecule%22%3A1%2C%22blast%22%3A0%2C%22polarity%22%3A%22negative%22%2C%22left%20placement%22%3A%22left%22%2C%22right%20placement%22%3A%22top%22%2C%22result%20placement%22%3A%22front%22%2C%22folder%22%3A%22open%22%7D%2C%22deco%22%3A%7B%22legends%22%3A6%2C%22shape%22%3Atrue%2C%22spotlight%22%3A2%2C%22row%20guides%22%3A1%2C%22flow%20guides%22%3A0.5%2C%22lens%20size%22%3A0.5%2C%22magnification%22%3A10%2C%22interior%20spotlight%22%3Afalse%2C%22axes%22%3Afalse%2C%22folder%22%3A%22closed%22%7D%2C%22viz%22%3A%7B%22sensitivity%22%3A%22semilocal%22%2C%22min%20size%22%3A0.196%2C%22min%20light%22%3A0.4%2C%22max%20light%22%3A0.6%2C%22elem%20scale%22%3A1%2C%22zero%20hue%22%3A0.77%2C%22hue%20gap%22%3A0.74%2C%22hue%20spread%22%3A0.04%2C%22folder%22%3A%22open%22%7D%2C%22diag%22%3A%7B%22url%22%3A%22%22%7D%2C%22cam%22%3A%7B%22x%22%3A-54.145594172414235%2C%22y%22%3A48.55110882721702%2C%22z%22%3A37.42031544768185%2C%22target%22%3A%7B%22x%22%3A0%2C%22y%22%3A0%2C%22z%22%3A0%7D%7D%2C%22folder%22%3A%22closed%22%2C%22compress%22%3Afalse%7D">open in mm</a>):</p>

<p align="center">
  <video width="100%" controls="">
    <source src="/assets/videos/inside-the-matrix/vvprod_check.mp4" type="video/mp4" />
  </video>
</p>

<p>Using randomly initialized matrices with this decomposition, we can see not just values but <em>rank</em> accumulate in the result, as each rank-1 outer product is added to it.</p>

<p>Among other things this builds intuition for why “low-rank factorization” - i.e. approximating a matrix by constructing a matmul whose arguments are small in the depth dimension - works best when the matrix being approximated is low rank. <a href="https://arxiv.org/pdf/2106.09685.pdf">LoRA</a> in a later section (<a href="https://bhosmer.github.io/mm/index.html?params=%7B%22expr%22%3A%22L%20%40%20R%22%2C%22name%22%3A%22L%20%40%20R%22%2C%22epilog%22%3A%22none%22%2C%22left%22%3A%7B%22name%22%3A%22L%22%2C%22matmul%22%3Afalse%2C%22h%22%3A32%2C%22w%22%3A24%2C%22init%22%3A%22gaussian%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22(-Math.trunc(i%20%2F%208)%20%25%202)%20%2B%20.5%22%2C%22folder%22%3A%22closed%22%7D%2C%22right%22%3A%7B%22name%22%3A%22R%22%2C%22matmul%22%3Afalse%2C%22h%22%3A24%2C%22w%22%3A32%2C%22init%22%3A%22gaussian%22%2C%22url%22%3A%22%22%2C%22min%22%3A-1%2C%22max%22%3A1%2C%22dropout%22%3A0%2C%22expr%22%3A%22(-Math.trunc(j%20%2F%208)%20%25%202)%20%2B%20.5%22%2C%22folder%22%3A%22closed%22%7D%2C%22anim%22%3A%7B%22fuse%22%3A%22none%22%2C%22speed%22%3A6%2C%22hide%20inputs%22%3Afalse%2C%22alg%22%3A%22vvprod%22%2C%22spin%22%3A0%2C%22folder%22%3A%22open%22%7D%2C%22block%22%3A%7B%22i%20blocks%22%3A1%2C%22j%20blocks%22%3A1%2C%22k%20blocks%22%3A1%7D%2C%22layout%22%3A%7B%22scheme%22%3A%22blocks%22%2C%22gap%22%3A5%2C%22scatter%22%3A0%2C%22molecule%22%3A1%2C%22blast%22%3A0%2C%22polarity%22%3A%22negative%22%2C%22left%20placement%22%3A%22left%22%2C%22right%20placement%22%3A%22top%22%2C%22result%20placement%22%3A%22front%22%2C%22folder%22%3A%22open%22%7D%2C%22deco%22%3A%7B%22legends%22%3A6%2C%22shape%22%3Atrue%2C%22spotlight%22%3A2%2C%22row%20guides%22%3A1%2C%22flow%20guides%22%3A0%2C%22lens%20size%22%3A0.5%2C%22magnification%22%3A10%2C%22interior%20spotlight%22%3Afalse%2C%22axes%22%3Afalse%2C%22folder%22%3A%22open%22%7D%2C%22viz%22%3A%7B%22sensitivity%22%3A%22local%22%2C%22min%20size%22%3A0.196%2C%22min%20light%22%3A0.4%2C%22max%20light%22%3A0.6%2C%22elem%20scale%22%3A1%2C%22zero%20hue%22%3A0.77%2C%22hue%20gap%22%3A0.74%2C%22hue%20spread%22%3A0.04%2C%22folder%22%3A%22open%22%7D%2C%22diag%22%3A%7B%22url%22%3A%22%22%7D%2C%22cam%22%3A%7B%22x%22%3A-54.14559417241423%2C%22y%22%3A48.55110882721702%2C%22z%22%3A37.42031544768186%2C%22target%22%3A%7B%22x%22%3A0%2C%22y%22%3A0%2C%22z%22%3A0%7D%7D%2C%22folder%22%3A%22closed%22%2C%22compress%22%3Afalse%7D">open in mm</a>):</p>

<p align="center">
  <video width="100%" controls="">
    <source src="/assets/videos/inside-the-matrix/vvprod_random_fast.mp4" type="video/mp4" />
  </video>
</p>

<h2 id="3-warmup---expressions">3 Warmup - expressions</h2>

<p>How can we extend this visualization approach to <em>compositions</em> of matmuls? Our examples so far have all visualized a single matmul <code class="language-plaintext highlighter-rouge">L @ R</code> of some matrices <code class="language-plaintext highlighter-rouge">L</code> and <code class="language-plaintext highlighter-rouge">R</code> - what about when <code class="language-plaintext highlighter-rouge">L</code> and/or <code class="language-plaintext highlighter-rouge">R</code> are themselves matmuls, and so on transitively?</p>

<p>It turns out we can extend the approach nicely to compound expressions. The key rules are simple: the subexpression (child) matmul is another cube, subject to the same layout constraints as the parent, and the result face of the child is <em>simultaneously</em> the corresponding argument face of the parent, like a covalently shared electron.</p>

<p>Within these constraints, we’re free to arrange the faces of a child matmul however we like. Here we use the tool’s default scheme, which generates alternating convex and concave cubes - this layout works well in practice to maximize use of space and minimize occlusion. (Layouts are completely customizable, however - see the <a href="https://bhosmer.github.io/mm/ref.html">reference</a> for details.)</p>

<p>In this section we’ll visualize some of the key building blocks we find in ML models, to gain fluency in the visual idiom and to see what intuitions even simple examples can give us.</p>

<h3 id="3a-left-associative-expressions">3a Left-associative expressions</h3>

<p>We’ll look at two expressions of the form <code class="language-plaintext highlighter-rouge">(A @ B) @ C</code>, each with its own distinctive shape and character. (Note: mm adheres to the convention that matrix multiplication is left-associative and writes this simply as <code class="language-plaintext highlighter-rouge">A @ B @ C</code>.)</p>

<p>First we’ll give <code class="language-plaintext highlighter-rouge">A @ B @ C</code> the characteristic FFN shape, in which the “hidden dimension” is wider than the “input” or “output” dimensions. (Concretely in the context of this example, this means that the width of <code class="language-plaintext highlighter-rouge">B</code> is greater than the widths of <code class="language-plaintext highlighter-rouge">A</code> or <code class="language-plaintext highlighter-rouge">C</code>.)</p>

<p>As in the single matmul examples, the floating arrows point towards the result matrix, blue vane coming from the left argument and red vane from right argument (<a href="https://bhosmer.github.io/mm/index.html?0=A%20%40%20B%20%40%20C&amp;1=A%20%40%20B%20%40%20C&amp;2=none&amp;12=closed&amp;64=true&amp;3.1=A%20%40%20B&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.12=open&amp;3.2=none&amp;13.1=A&amp;13.4=false&amp;13.5=64&amp;13.6=32&amp;13.7=expr&amp;13.8=&amp;13.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;13.9=-1&amp;13.10=1&amp;13.11=0&amp;13.12=open&amp;14.1=B&amp;14.4=false&amp;14.5=32&amp;14.6=96&amp;14.7=row%20major&amp;14.8=&amp;14.0=-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201&amp;14.9=-1&amp;14.10=1&amp;14.11=0&amp;14.12=open&amp;15.16=inherit&amp;17.18=positive&amp;17.19=left&amp;17.20=bottom&amp;17.21=back&amp;22.23=1&amp;24.1=C&amp;24.4=false&amp;24.5=96&amp;24.6=32&amp;24.7=col%20major&amp;24.8=&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;24.12=open&amp;25.26=none&amp;25.27=12&amp;25.28=false&amp;25.16=none&amp;25.29=0&amp;25.12=closed&amp;30.31=1&amp;30.32=1&amp;30.23=1&amp;33.34=blocks&amp;33.35=5&amp;33.36=0&amp;33.37=1&amp;33.38=0&amp;33.18=negative&amp;33.19=left&amp;33.20=top&amp;33.21=front&amp;33.12=closed&amp;39.40=6&amp;39.41=true&amp;39.42=2&amp;39.43=1&amp;39.44=0.5&amp;39.45=0.5&amp;39.46=10&amp;39.47=false&amp;39.48=false&amp;39.12=open&amp;49.50=semilocal&amp;49.51=0.2&amp;49.52=0.4&amp;49.53=0.6&amp;49.54=1.25&amp;49.55=0.77&amp;49.56=0.74&amp;49.57=0.04&amp;49.12=open&amp;58.8=&amp;59.60=-102.42301073851515&amp;59.61=96.27580041479706&amp;59.62=112.34410815468306&amp;63.60=-4.617417891034972&amp;63.61=-3.695553245058398&amp;63.62=-1.8863985145585351&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;folder=12&amp;left.left=13&amp;left.right=14&amp;left.anim=15&amp;alg=16&amp;left.layout=17&amp;polarity=18&amp;left%20placement=19&amp;right%20placement=20&amp;result%20placement=21&amp;left.block=22&amp;k%20blocks=23&amp;right=24&amp;anim=25&amp;fuse=26&amp;speed=27&amp;hide%20inputs=28&amp;spin=29&amp;block=30&amp;i%20blocks=31&amp;j%20blocks=32&amp;layout=33&amp;scheme=34&amp;gap=35&amp;scatter=36&amp;molecule=37&amp;blast=38&amp;deco=39&amp;legends=40&amp;shape=41&amp;spotlight=42&amp;row%20guides=43&amp;flow%20guides=44&amp;lens%20size=45&amp;magnification=46&amp;interior%20spotlight=47&amp;axes=48&amp;viz=49&amp;sensitivity=50&amp;min%20size=51&amp;min%20light=52&amp;max%20light=53&amp;elem%20scale=54&amp;zero%20hue=55&amp;hue%20gap=56&amp;hue%20spread=57&amp;diag=58&amp;cam=59&amp;x=60&amp;y=61&amp;z=62&amp;cam.target=63&amp;compress=64">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/la2still.jpg" alt="As in the single matmul examples, the floating arrows point towards the result matrix, blue vane coming from the left argument and red vane from right argument" style="width:100%" /></p>

<p>Next we’ll visualize <code class="language-plaintext highlighter-rouge">A @ B @ C</code> with the width of <code class="language-plaintext highlighter-rouge">B</code> <em>narrower</em> than that of <code class="language-plaintext highlighter-rouge">A</code> or <code class="language-plaintext highlighter-rouge">C</code>, giving it a bottleneck or “autoencoder” shape (<a href="https://bhosmer.github.io/mm/index.html?0=A%20%40%20B%20%40%20C&amp;1=A%20%40%20B%20%40%20C&amp;2=none&amp;12=closed&amp;64=true&amp;3.1=A%20%40%20B&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.12=open&amp;3.2=none&amp;13.1=A&amp;13.4=false&amp;13.5=64&amp;13.6=96&amp;13.7=expr&amp;13.8=&amp;13.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;13.9=-1&amp;13.10=1&amp;13.11=0&amp;13.12=open&amp;14.1=B&amp;14.4=false&amp;14.5=96&amp;14.6=32&amp;14.7=row%20major&amp;14.8=&amp;14.0=-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201&amp;14.9=-1&amp;14.10=1&amp;14.11=0&amp;14.12=open&amp;15.16=inherit&amp;17.18=positive&amp;17.19=left&amp;17.20=bottom&amp;17.21=back&amp;22.23=1&amp;24.1=C&amp;24.4=false&amp;24.5=32&amp;24.6=96&amp;24.7=col%20major&amp;24.8=&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;24.12=open&amp;25.26=none&amp;25.27=12&amp;25.28=false&amp;25.16=none&amp;25.29=0&amp;25.12=closed&amp;30.31=1&amp;30.32=1&amp;30.23=1&amp;33.34=blocks&amp;33.35=5&amp;33.36=0&amp;33.37=1&amp;33.38=0&amp;33.18=negative&amp;33.19=left&amp;33.20=top&amp;33.21=front&amp;33.12=closed&amp;39.40=6&amp;39.41=true&amp;39.42=2&amp;39.43=1&amp;39.44=0.5&amp;39.45=0.5&amp;39.46=10&amp;39.47=false&amp;39.48=false&amp;39.12=open&amp;49.50=semilocal&amp;49.51=0.2&amp;49.52=0.4&amp;49.53=0.6&amp;49.54=1.25&amp;49.55=0.77&amp;49.56=0.74&amp;49.57=0.04&amp;49.12=open&amp;58.8=&amp;59.60=-125.71162036288077&amp;59.61=101.84279252909485&amp;59.62=122.50425255743914&amp;63.60=-14.817097084822203&amp;63.61=-9.723209466639396&amp;63.62=-5.4699873376955646&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;folder=12&amp;left.left=13&amp;left.right=14&amp;left.anim=15&amp;alg=16&amp;left.layout=17&amp;polarity=18&amp;left%20placement=19&amp;right%20placement=20&amp;result%20placement=21&amp;left.block=22&amp;k%20blocks=23&amp;right=24&amp;anim=25&amp;fuse=26&amp;speed=27&amp;hide%20inputs=28&amp;spin=29&amp;block=30&amp;i%20blocks=31&amp;j%20blocks=32&amp;layout=33&amp;scheme=34&amp;gap=35&amp;scatter=36&amp;molecule=37&amp;blast=38&amp;deco=39&amp;legends=40&amp;shape=41&amp;spotlight=42&amp;row%20guides=43&amp;flow%20guides=44&amp;lens%20size=45&amp;magnification=46&amp;interior%20spotlight=47&amp;axes=48&amp;viz=49&amp;sensitivity=50&amp;min%20size=51&amp;min%20light=52&amp;max%20light=53&amp;elem%20scale=54&amp;zero%20hue=55&amp;hue%20gap=56&amp;hue%20spread=57&amp;diag=58&amp;cam=59&amp;x=60&amp;y=61&amp;z=62&amp;cam.target=63&amp;compress=64">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/lacontract.jpg" alt="visualize A @ B @ C with the width of B narrower than that of A or C" style="width:100%" /></p>

<p>This pattern of alternating convex and concave blocks extends to chains of arbitrary length: for example this multilayer bottleneck (<a href="https://bhosmer.github.io/mm/index.html?0=A%20%40%20B%20%40%20C%20%40%20D%20%40%20E&amp;1=A%20%40%20B%20%40%20C%20%40%20D%20%40%20E&amp;2=none&amp;23=closed&amp;63=true&amp;3.2=none&amp;4.5=inherit&amp;6.7=1&amp;8.9=positive&amp;8.10=left&amp;8.11=bottom&amp;8.12=back&amp;13.0=A%20%40%20B%20%40%20C%20%40%20D%20%40%20E&amp;13.1=A%20%40%20B%20%40%20C&amp;13.2=none&amp;14.1=A%20%40%20B&amp;14.15=true&amp;14.16=32&amp;14.17=32&amp;14.18=row%20major&amp;14.19=&amp;14.20=-1&amp;14.21=1&amp;14.22=0&amp;14.23=open&amp;14.2=none&amp;24.1=A&amp;24.15=false&amp;24.16=64&amp;24.17=96&amp;24.18=expr&amp;24.19=&amp;24.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;24.20=-1&amp;24.21=1&amp;24.22=0&amp;24.23=open&amp;25.1=B&amp;25.15=false&amp;25.16=96&amp;25.17=64&amp;25.18=row%20major&amp;25.19=&amp;25.0=-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201&amp;25.20=-1&amp;25.21=1&amp;25.22=0&amp;25.23=open&amp;26.5=inherit&amp;27.9=positive&amp;27.10=left&amp;27.11=bottom&amp;27.12=back&amp;28.7=1&amp;29.1=C&amp;29.15=false&amp;29.16=64&amp;29.17=32&amp;29.18=col%20major&amp;29.19=&amp;29.20=-1&amp;29.21=1&amp;29.22=0&amp;29.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;29.23=open&amp;30.31=none&amp;30.32=12&amp;30.33=false&amp;30.5=none&amp;30.34=0&amp;30.23=closed&amp;35.36=1&amp;35.7=1&amp;37.9=negative&amp;37.10=left&amp;37.11=top&amp;37.12=front&amp;38.39=6&amp;38.40=true&amp;38.41=2&amp;38.42=1&amp;38.43=0.5&amp;38.44=0.5&amp;38.45=10&amp;38.46=false&amp;38.47=false&amp;38.23=open&amp;48.49=semilocal&amp;48.50=0.2&amp;48.51=0.4&amp;48.52=0.6&amp;48.53=1.25&amp;48.54=0.77&amp;48.55=0.74&amp;48.56=0.04&amp;48.23=open&amp;57.19=&amp;58.59=-125.71162036288077&amp;58.60=101.84279252909485&amp;58.61=122.50425255743914&amp;62.59=-14.817097084822203&amp;62.60=-9.723209466639396&amp;62.61=-5.4699873376955646&amp;13.23=open&amp;13.63=true&amp;13.15=true&amp;64.1=D&amp;64.15=false&amp;64.16=32&amp;64.17=64&amp;64.18=col%20major&amp;64.19=&amp;64.20=-1&amp;64.21=1&amp;64.22=0&amp;64.0=&amp;64.23=open&amp;3.1=A%20%40%20B%20%40%20C%20%40%20D&amp;3.15=true&amp;65.1=E&amp;65.15=false&amp;65.16=64&amp;65.17=96&amp;65.18=col%20major&amp;65.19=&amp;65.20=-1&amp;65.21=1&amp;65.22=0&amp;65.0=&amp;66.31=none&amp;66.32=12&amp;66.33=false&amp;66.5=none&amp;66.34=0&amp;66.23=closed&amp;67.36=1&amp;67.68=1&amp;67.7=1&amp;69.70=blocks&amp;69.71=5&amp;69.72=0&amp;69.73=1&amp;69.74=0&amp;69.9=negative&amp;69.10=left&amp;69.11=top&amp;69.12=front&amp;69.23=closed&amp;75.39=5.28&amp;75.40=true&amp;75.41=2&amp;75.42=1&amp;75.43=0.5&amp;75.44=0.5&amp;75.45=10&amp;75.46=false&amp;75.47=false&amp;75.23=open&amp;76.49=semilocal&amp;76.50=0.2&amp;76.51=0.4&amp;76.52=0.6&amp;76.53=1.25&amp;76.54=0.77&amp;76.55=0.74&amp;76.56=0.04&amp;76.23=open&amp;77.19=&amp;78.59=-163.23429720087873&amp;78.60=132.20892347209139&amp;78.61=159.04014894666057&amp;79.59=-14.817097084822203&amp;79.60=-9.723209466639396&amp;79.61=-5.4699873376955646&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;left.anim=4&amp;alg=5&amp;left.block=6&amp;k%20blocks=7&amp;left.layout=8&amp;polarity=9&amp;left%20placement=10&amp;right%20placement=11&amp;result%20placement=12&amp;left.left=13&amp;left.left.left=14&amp;matmul=15&amp;h=16&amp;w=17&amp;init=18&amp;url=19&amp;min=20&amp;max=21&amp;dropout=22&amp;folder=23&amp;left.left.left.left=24&amp;left.left.left.right=25&amp;left.left.left.anim=26&amp;left.left.left.layout=27&amp;left.left.left.block=28&amp;left.left.right=29&amp;left.left.anim=30&amp;fuse=31&amp;speed=32&amp;hide%20inputs=33&amp;spin=34&amp;left.left.block=35&amp;i%20blocks=36&amp;left.left.layout=37&amp;left.left.deco=38&amp;legends=39&amp;shape=40&amp;spotlight=41&amp;row%20guides=42&amp;flow%20guides=43&amp;lens%20size=44&amp;magnification=45&amp;interior%20spotlight=46&amp;axes=47&amp;left.left.viz=48&amp;sensitivity=49&amp;min%20size=50&amp;min%20light=51&amp;max%20light=52&amp;elem%20scale=53&amp;zero%20hue=54&amp;hue%20gap=55&amp;hue%20spread=56&amp;left.left.diag=57&amp;left.left.cam=58&amp;x=59&amp;y=60&amp;z=61&amp;left.left.cam.target=62&amp;compress=63&amp;left.right=64&amp;right=65&amp;anim=66&amp;block=67&amp;j%20blocks=68&amp;layout=69&amp;scheme=70&amp;gap=71&amp;scatter=72&amp;molecule=73&amp;blast=74&amp;deco=75&amp;viz=76&amp;diag=77&amp;cam=78&amp;cam.target=79">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/nlayerbottleneck.jpg" alt="pattern of alternating convex and concave blocks extends to chains of arbitrary length" style="width:100%" /></p>

<h3 id="3b-right-associative-expressions">3b Right associative expressions</h3>

<p>Next we’ll visualize a right-associative expression <code class="language-plaintext highlighter-rouge">A @ (B @ C)</code>.</p>

<p>In the same way left-associative expressions extend horizontally - sprouting from the left argument of the root expression, so to speak - right-associative chains extend vertically, sprouting from the root’s right argument.</p>

<p>One sometimes sees an MLP formulated right-associatively, i.e. with columnar input on the right and weight layers running right to left. Using the matrices from the 2-layer FFN example pictured above - suitably transposed - here’s what that looks like, with <code class="language-plaintext highlighter-rouge">C</code> now playing the role of the input, <code class="language-plaintext highlighter-rouge">B</code> the first layer and <code class="language-plaintext highlighter-rouge">A</code> the second layer (<a href="https://bhosmer.github.io/mm/index.html?0=A%20%40%20(B%20%40%20C)&amp;1=A%20%40%20(B%20%40%20C)&amp;2=none&amp;12=closed&amp;64=true&amp;3.1=A&amp;3.4=false&amp;3.5=32&amp;3.6=96&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.0=-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201&amp;3.12=open&amp;13.1=B%20%40%20C&amp;13.4=true&amp;13.5=32&amp;13.6=32&amp;13.7=col%20major&amp;13.8=&amp;13.9=-1&amp;13.10=1&amp;13.11=0&amp;13.2=none&amp;14.15=inherit&amp;16.17=1&amp;18.19=positive&amp;18.20=right&amp;18.21=top&amp;18.22=back&amp;23.1=B&amp;23.4=false&amp;23.5=96&amp;23.6=32&amp;23.7=col%20major&amp;23.8=&amp;23.0=-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.12=open&amp;24.1=C&amp;24.4=false&amp;24.5=32&amp;24.6=64&amp;24.7=expr&amp;24.8=&amp;24.0=-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.12=open&amp;13.12=open&amp;25.26=none&amp;25.27=12&amp;25.28=false&amp;25.15=none&amp;25.29=0&amp;25.12=closed&amp;30.31=1&amp;30.32=1&amp;30.17=1&amp;33.34=blocks&amp;33.35=5&amp;33.36=0&amp;33.37=1&amp;33.38=0&amp;33.19=negative&amp;33.20=left&amp;33.21=top&amp;33.22=front&amp;33.12=closed&amp;39.40=6&amp;39.41=true&amp;39.42=2&amp;39.43=1&amp;39.44=0.5&amp;39.45=0.5&amp;39.46=10&amp;39.47=false&amp;39.48=false&amp;39.12=closed&amp;49.50=semilocal&amp;49.51=0.2&amp;49.52=0.4&amp;49.53=0.6&amp;49.54=1.25&amp;49.55=0.77&amp;49.56=0.74&amp;49.57=0.04&amp;49.12=closed&amp;58.8=&amp;58.12=open&amp;59.60=-105.78213185291946&amp;59.61=96.67420268229331&amp;59.62=113.6419504179439&amp;63.60=-4.617417891034972&amp;63.61=-3.695553245058398&amp;63.62=-1.8863985145585351&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;folder=12&amp;right=13&amp;right.anim=14&amp;alg=15&amp;right.block=16&amp;k%20blocks=17&amp;right.layout=18&amp;polarity=19&amp;left%20placement=20&amp;right%20placement=21&amp;result%20placement=22&amp;right.left=23&amp;right.right=24&amp;anim=25&amp;fuse=26&amp;speed=27&amp;hide%20inputs=28&amp;spin=29&amp;block=30&amp;i%20blocks=31&amp;j%20blocks=32&amp;layout=33&amp;scheme=34&amp;gap=35&amp;scatter=36&amp;molecule=37&amp;blast=38&amp;deco=39&amp;legends=40&amp;shape=41&amp;spotlight=42&amp;row%20guides=43&amp;flow%20guides=44&amp;lens%20size=45&amp;magnification=46&amp;interior%20spotlight=47&amp;axes=48&amp;viz=49&amp;sensitivity=50&amp;min%20size=51&amp;min%20light=52&amp;max%20light=53&amp;elem%20scale=54&amp;zero%20hue=55&amp;hue%20gap=56&amp;hue%20spread=57&amp;diag=58&amp;cam=59&amp;x=60&amp;y=61&amp;z=62&amp;cam.target=63&amp;compress=64">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/raffn.jpg" alt="an MLP formulated right-associatively" style="width:100%" /></p>

<p>Aside: in addition to the color of the arrow vanes (blue for left, red for right), a second visual cue for distinguishing left and right arguments is their <em>orientation</em>: the rows of the left argument are coplanar with those of the result - they stack along the same axis (<code class="language-plaintext highlighter-rouge">i</code>). Both cues tell us for example that <code class="language-plaintext highlighter-rouge">B</code> is the left argument to <code class="language-plaintext highlighter-rouge">(B @ C)</code> above.</p>

<h3 id="3c-binary-expressions">3c Binary expressions</h3>

<p>For a visualization tool to be useful beyond simple didactic examples, visualizations need to remain legible as expressions get more complicated. A key structural component in real-world use cases is binary expressions - matmuls with subexpressions on both the left and right.</p>

<p>Here we’ll visualize the simplest such expression shape, <code class="language-plaintext highlighter-rouge">(A @ B) @ (C @ D)</code> (<a href="https://bhosmer.github.io/mm/index.html?0=A%20%40%20B%20%40%20(C%20%40%20D)&amp;1=A%20%40%20B%20%40%20(C%20%40%20D)&amp;2=none&amp;12=closed&amp;69=true&amp;3.1=A%20%40%20B&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.12=open&amp;3.2=none&amp;13.1=A&amp;13.4=false&amp;13.5=64&amp;13.6=64&amp;13.7=expr&amp;13.8=&amp;13.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;13.9=-1&amp;13.10=1&amp;13.11=0&amp;13.12=closed&amp;14.1=B&amp;14.4=false&amp;14.5=64&amp;14.6=64&amp;14.7=row%20major&amp;14.8=&amp;14.0=-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201&amp;14.9=-1&amp;14.10=1&amp;14.11=0&amp;14.12=closed&amp;15.16=inherit&amp;17.18=positive&amp;17.19=left&amp;17.20=bottom&amp;17.21=back&amp;22.23=1&amp;24.1=C%20%40%20D&amp;24.4=true&amp;24.5=32&amp;24.6=32&amp;24.7=col%20major&amp;24.8=&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.2=none&amp;25.16=inherit&amp;26.23=1&amp;27.18=positive&amp;27.19=right&amp;27.20=top&amp;27.21=back&amp;28.1=C&amp;28.4=false&amp;28.5=64&amp;28.6=64&amp;28.7=col%20major&amp;28.8=&amp;28.9=-1&amp;28.10=1&amp;28.11=0&amp;28.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;28.12=open&amp;29.1=D&amp;29.4=false&amp;29.5=64&amp;29.6=64&amp;29.7=expr&amp;29.8=&amp;29.9=-1&amp;29.10=1&amp;29.11=0&amp;29.0=-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201&amp;29.12=open&amp;30.31=none&amp;30.32=12&amp;30.33=false&amp;30.16=none&amp;30.34=0&amp;30.12=closed&amp;35.36=1&amp;35.37=1&amp;35.23=1&amp;38.39=blocks&amp;38.40=5&amp;38.41=0&amp;38.42=1&amp;38.43=0&amp;38.18=negative&amp;38.19=left&amp;38.20=top&amp;38.21=front&amp;38.12=closed&amp;44.45=6&amp;44.46=true&amp;44.47=2&amp;44.48=1&amp;44.49=0.5&amp;44.50=0.5&amp;44.51=10&amp;44.52=false&amp;44.53=false&amp;44.12=closed&amp;54.55=semilocal&amp;54.56=0.4&amp;54.57=0.4&amp;54.58=0.6&amp;54.59=1.5&amp;54.60=0.77&amp;54.61=0.74&amp;54.62=0.04&amp;54.12=open&amp;63.8=&amp;64.65=-149.45958189074523&amp;64.66=140.76437147298853&amp;64.67=162.13832534246401&amp;68.65=-4.044017278625395&amp;68.66=-2.123834827920271&amp;68.67=-2.551083969824457&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;folder=12&amp;left.left=13&amp;left.right=14&amp;left.anim=15&amp;alg=16&amp;left.layout=17&amp;polarity=18&amp;left%20placement=19&amp;right%20placement=20&amp;result%20placement=21&amp;left.block=22&amp;k%20blocks=23&amp;right=24&amp;right.anim=25&amp;right.block=26&amp;right.layout=27&amp;right.left=28&amp;right.right=29&amp;anim=30&amp;fuse=31&amp;speed=32&amp;hide%20inputs=33&amp;spin=34&amp;block=35&amp;i%20blocks=36&amp;j%20blocks=37&amp;layout=38&amp;scheme=39&amp;gap=40&amp;scatter=41&amp;molecule=42&amp;blast=43&amp;deco=44&amp;legends=45&amp;shape=46&amp;spotlight=47&amp;row%20guides=48&amp;flow%20guides=49&amp;lens%20size=50&amp;magnification=51&amp;interior%20spotlight=52&amp;axes=53&amp;viz=54&amp;sensitivity=55&amp;min%20size=56&amp;min%20light=57&amp;max%20light=58&amp;elem%20scale=59&amp;zero%20hue=60&amp;hue%20gap=61&amp;hue%20spread=62&amp;diag=63&amp;cam=64&amp;x=65&amp;y=66&amp;z=67&amp;cam.target=68&amp;compress=69">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/binary4.jpg" alt="binary expressions - matmuls with subexpressions on both the left and right" style="width:100%" /></p>

<h3 id="3d-quick-aside-partitioning-and-parallelism">3d Quick aside: partitioning and parallelism</h3>

<p>A full presentation of this topic is out of scope for this note, though we’ll see it in action later in the context of attention heads. But as a warmup, two quick examples should give a sense of how this style of visualization makes reasoning about parallelizing compound expressions very intuitive, via the simple geometry of partitioning.</p>

<p>In the first example we’ll apply the canonical “data parallel” partitioning to the left-associative multilayer bottleneck example above. We partition along <code class="language-plaintext highlighter-rouge">i</code>, segmenting the initial left argument (“batch”) and all intermediate results (“activations”), but none of the subsequent arguments (“weights”) - the geometry making it obvious which participants in the expression are segmented and which remain whole (<a href="https://bhosmer.github.io/mm/index.html?0=A%20%40%20B%20%40%20C%20%40%20D%20%40%20E&amp;1=A%20%40%20B%20%40%20C%20%40%20D%20%40%20E&amp;2=none&amp;23=closed&amp;63=true&amp;3.1=A%20%40%20B%20%40%20C%20%40%20D&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=inherit&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.0=A%20%40%20B%20%40%20C%20%40%20D%20%40%20E&amp;21.1=A%20%40%20B%20%40%20C&amp;21.2=none&amp;22.1=A%20%40%20B&amp;22.4=true&amp;22.5=32&amp;22.6=32&amp;22.7=row%20major&amp;22.8=&amp;22.9=-1&amp;22.10=1&amp;22.11=0&amp;22.23=open&amp;22.2=none&amp;24.1=A&amp;24.4=false&amp;24.5=64&amp;24.6=96&amp;24.7=expr&amp;24.8=&amp;24.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.23=open&amp;25.1=B&amp;25.4=false&amp;25.5=96&amp;25.6=64&amp;25.7=row%20major&amp;25.8=&amp;25.0=-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201&amp;25.9=-1&amp;25.10=1&amp;25.11=0&amp;25.23=open&amp;26.13=inherit&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.15=1&amp;29.1=C&amp;29.4=false&amp;29.5=64&amp;29.6=32&amp;29.7=col%20major&amp;29.8=&amp;29.9=-1&amp;29.10=1&amp;29.11=0&amp;29.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;29.23=open&amp;30.31=none&amp;30.32=12&amp;30.33=false&amp;30.13=none&amp;30.34=0&amp;30.23=closed&amp;35.36=1&amp;35.15=1&amp;37.17=negative&amp;37.18=left&amp;37.19=top&amp;37.20=front&amp;38.39=6&amp;38.40=true&amp;38.41=2&amp;38.42=1&amp;38.43=0.5&amp;38.44=0.5&amp;38.45=10&amp;38.46=false&amp;38.47=false&amp;38.23=open&amp;48.49=semilocal&amp;48.50=0.2&amp;48.51=0.4&amp;48.52=0.6&amp;48.53=1.25&amp;48.54=0.77&amp;48.55=0.74&amp;48.56=0.04&amp;48.23=open&amp;57.8=&amp;58.59=-125.71162036288077&amp;58.60=101.84279252909485&amp;58.61=122.50425255743914&amp;62.59=-14.817097084822203&amp;62.60=-9.723209466639396&amp;62.61=-5.4699873376955646&amp;21.23=open&amp;21.63=true&amp;21.4=true&amp;64.1=D&amp;64.4=false&amp;64.5=32&amp;64.6=64&amp;64.7=col%20major&amp;64.8=&amp;64.9=-1&amp;64.10=1&amp;64.11=0&amp;64.0=&amp;64.23=open&amp;65.1=E&amp;65.4=false&amp;65.5=64&amp;65.6=96&amp;65.7=col%20major&amp;65.8=&amp;65.9=-1&amp;65.10=1&amp;65.11=0&amp;65.0=&amp;66.31=none&amp;66.32=12&amp;66.33=false&amp;66.13=none&amp;66.34=0&amp;66.23=closed&amp;67.36=8&amp;67.68=1&amp;67.15=1&amp;67.23=open&amp;69.70=blocks&amp;69.71=5&amp;69.72=0&amp;69.73=1&amp;69.74=0&amp;69.17=negative&amp;69.18=left&amp;69.19=top&amp;69.20=front&amp;69.23=closed&amp;75.39=5.28&amp;75.40=true&amp;75.41=2&amp;75.42=1&amp;75.43=0.5&amp;75.44=0.5&amp;75.45=10&amp;75.46=false&amp;75.47=false&amp;75.23=closed&amp;76.49=semilocal&amp;76.50=0.3&amp;76.51=0.4&amp;76.52=0.6&amp;76.53=1.5&amp;76.54=0.77&amp;76.55=0.74&amp;76.56=0.04&amp;76.23=closed&amp;77.8=&amp;78.59=-174.76129648411032&amp;78.60=141.54502619212317&amp;78.61=170.2709730709386&amp;79.59=-14.817097084822203&amp;79.60=-9.723209466639396&amp;79.61=-5.4699873376955646&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;folder=23&amp;left.left.left.left=24&amp;left.left.left.right=25&amp;left.left.left.anim=26&amp;left.left.left.layout=27&amp;left.left.left.block=28&amp;left.left.right=29&amp;left.left.anim=30&amp;fuse=31&amp;speed=32&amp;hide%20inputs=33&amp;spin=34&amp;left.left.block=35&amp;i%20blocks=36&amp;left.left.layout=37&amp;left.left.deco=38&amp;legends=39&amp;shape=40&amp;spotlight=41&amp;row%20guides=42&amp;flow%20guides=43&amp;lens%20size=44&amp;magnification=45&amp;interior%20spotlight=46&amp;axes=47&amp;left.left.viz=48&amp;sensitivity=49&amp;min%20size=50&amp;min%20light=51&amp;max%20light=52&amp;elem%20scale=53&amp;zero%20hue=54&amp;hue%20gap=55&amp;hue%20spread=56&amp;left.left.diag=57&amp;left.left.cam=58&amp;x=59&amp;y=60&amp;z=61&amp;left.left.cam.target=62&amp;compress=63&amp;left.right=64&amp;right=65&amp;anim=66&amp;block=67&amp;j%20blocks=68&amp;layout=69&amp;scheme=70&amp;gap=71&amp;scatter=72&amp;molecule=73&amp;blast=74&amp;deco=75&amp;viz=76&amp;diag=77&amp;cam=78&amp;cam.target=79">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/bottleneck_part.jpg" alt="the canonical &quot;data parallel&quot; partitioning to the left-associative multilayer bottleneck example" style="width:100%" /></p>

<p>The second example would (for me, anyway) be much harder to build intuition about without clear geometry to support it: it shows how a binary expression can be parallelized by partitioning the left subexpression along its <code class="language-plaintext highlighter-rouge">j</code> axis, the right subexpression along its <code class="language-plaintext highlighter-rouge">i</code> axis, and the parent expression along its <code class="language-plaintext highlighter-rouge">k</code> axis (<a href="https://bhosmer.github.io/mm/index.html?0=A%20%40%20B%20%40%20(C%20%40%20D)&amp;1=A%20%40%20B%20%40%20(C%20%40%20D)&amp;2=none&amp;12=closed&amp;69=true&amp;3.1=A%20%40%20B&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.12=open&amp;3.2=none&amp;13.1=A&amp;13.4=false&amp;13.5=64&amp;13.6=64&amp;13.7=expr&amp;13.8=&amp;13.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;13.9=-1&amp;13.10=1&amp;13.11=0&amp;13.12=closed&amp;14.1=B&amp;14.4=false&amp;14.5=64&amp;14.6=64&amp;14.7=row%20major&amp;14.8=&amp;14.0=-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201&amp;14.9=-1&amp;14.10=1&amp;14.11=0&amp;14.12=closed&amp;15.16=inherit&amp;17.18=positive&amp;17.19=left&amp;17.20=bottom&amp;17.21=back&amp;22.23=1&amp;24.1=C%20%40%20D&amp;24.4=true&amp;24.5=32&amp;24.6=32&amp;24.7=col%20major&amp;24.8=&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.2=none&amp;25.16=inherit&amp;26.23=1&amp;27.18=positive&amp;27.19=right&amp;27.20=top&amp;27.21=back&amp;28.1=C&amp;28.4=false&amp;28.5=64&amp;28.6=64&amp;28.7=col%20major&amp;28.8=&amp;28.9=-1&amp;28.10=1&amp;28.11=0&amp;28.0=-2%20*%20(Math.trunc(i%20%2F%208)%20%25%202)%20%2B%201&amp;28.12=open&amp;29.1=D&amp;29.4=false&amp;29.5=64&amp;29.6=64&amp;29.7=expr&amp;29.8=&amp;29.9=-1&amp;29.10=1&amp;29.11=0&amp;29.0=-2%20*%20(Math.trunc(j%20%2F%208)%20%25%202)%20%2B%201&amp;29.12=open&amp;30.31=none&amp;30.32=12&amp;30.33=false&amp;30.16=none&amp;30.34=0&amp;30.12=closed&amp;35.36=1&amp;35.37=1&amp;35.23=8&amp;35.12=open&amp;38.39=blocks&amp;38.40=5&amp;38.41=0&amp;38.42=1&amp;38.43=0&amp;38.18=negative&amp;38.19=left&amp;38.20=top&amp;38.21=front&amp;38.12=closed&amp;44.45=6&amp;44.46=true&amp;44.47=2&amp;44.48=1&amp;44.49=0.5&amp;44.50=0.5&amp;44.51=10&amp;44.52=false&amp;44.53=false&amp;44.12=closed&amp;54.55=semilocal&amp;54.56=0.4&amp;54.57=0.4&amp;54.58=0.6&amp;54.59=1.5&amp;54.60=0.77&amp;54.61=0.74&amp;54.62=0.04&amp;54.12=open&amp;63.8=&amp;64.65=-163.0431410622342&amp;64.66=153.55767080483412&amp;64.67=176.87418575632128&amp;68.65=-4.044017278625395&amp;68.66=-2.123834827920271&amp;68.67=-2.551083969824457&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;folder=12&amp;left.left=13&amp;left.right=14&amp;left.anim=15&amp;alg=16&amp;left.layout=17&amp;polarity=18&amp;left%20placement=19&amp;right%20placement=20&amp;result%20placement=21&amp;left.block=22&amp;k%20blocks=23&amp;right=24&amp;right.anim=25&amp;right.block=26&amp;right.layout=27&amp;right.left=28&amp;right.right=29&amp;anim=30&amp;fuse=31&amp;speed=32&amp;hide%20inputs=33&amp;spin=34&amp;block=35&amp;i%20blocks=36&amp;j%20blocks=37&amp;layout=38&amp;scheme=39&amp;gap=40&amp;scatter=41&amp;molecule=42&amp;blast=43&amp;deco=44&amp;legends=45&amp;shape=46&amp;spotlight=47&amp;row%20guides=48&amp;flow%20guides=49&amp;lens%20size=50&amp;magnification=51&amp;interior%20spotlight=52&amp;axes=53&amp;viz=54&amp;sensitivity=55&amp;min%20size=56&amp;min%20light=57&amp;max%20light=58&amp;elem%20scale=59&amp;zero%20hue=60&amp;hue%20gap=61&amp;hue%20spread=62&amp;diag=63&amp;cam=64&amp;x=65&amp;y=66&amp;z=67&amp;cam.target=68&amp;compress=69">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/binary_part.jpg" alt="a binary expression can be parallelized by partitioning the left subexpression along its j axis, the right subexpression along its i axis, and the parent expression along its k axis" style="width:100%" /></p>

<h2 id="4-inside-an-attention-head">4 Inside an Attention Head</h2>

<p>Let’s look at a GPT2 attention head - specifically layer 5, head 4 of the “gpt2” (small) configuration (layers=12, heads=12, embed=768) from <a href="https://github.com/karpathy/nanoGPT">NanoGPT</a>, using OpenAI weights via HuggingFace. Input activations are taken from a forward pass on an OpenWebText training sample of 256 tokens.</p>

<p>There’s nothing particularly unusual about this particular head; I chose it mainly because it computes a fairly common attention pattern and lives in the middle of the model, where activations have become structured and show some interesting texture. (Aside: in a subsequent note I’ll present an attention head explorer that lets you visualize all layers and heads of this model, along with some travel notes.)</p>

<p><a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input%20%40%20wQ)%20%40%20(K_t%20%3D%20wK_t%20%40%20input_t))%20%40%20(V%20%3D%20input%20%40%20wV)%20%40%20wO&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;23.0=&amp;24.1=wQ&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;24.0=&amp;25.13=vmprod&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=vmprod&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;38.0=&amp;39.1=wV&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=none&amp;44.48=0&amp;44.49=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=10&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;53.49=open&amp;59.60=10&amp;59.61=true&amp;59.62=4&amp;59.63=0.394&amp;59.64=0.655&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=open&amp;69.70=local&amp;69.71=0.2&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.49=closed&amp;78.8=&amp;78.49=closed&amp;79.80=-1149.3128801149742&amp;79.81=1143.004532598807&amp;79.82=1754.3660479535383&amp;83.80=-6.708919569777563&amp;83.81=75.05036284609801&amp;83.82=-216.66743330111652&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">Open in mm</a> (may take a few seconds to fetch model weights)</p>

<p><img src="/assets/images/inside-the-matrix/mha1.jpg" alt="There's nothing particularly unusual about this particular head" style="width:100%" /></p>

<h3 id="4a-structure">4a Structure</h3>

<p>The entire attention head is visualized as a single compound expression, starting with input and ending with projected output. (Note: to keep things self-contained we do per-head output projection as described in <a href="https://arxiv.org/pdf/1909.08053.pdf">Megatron-LM</a>.)</p>

<p>The computation contains six matmuls:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Q = input @ wQ        // 1
K_t = wK_t @ input_t  // 2
V = input @ wV        // 3
attn = sdpa(Q @ K_t)  // 4
head_out = attn @ V   // 5
out = head_out @ wO   // 6
</code></pre></div></div>

<p>A thumbnail description of what we’re looking at:</p>

<ul>
  <li>the blades of the windmill are matmuls 1, 2, 3 and 6: the former group are the in-projections from input to Q, K and V; the latter is the out-projection from attn @ V back to the embedding dimension.</li>
  <li>at the hub is the double matmul that first calculates attention scores (convex cube in back), then uses them to produce output tokens from the values vector (concave cube in front). Causality means that the attention scores form a lower triangle.</li>
</ul>

<p>But I’d encourage <a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input%20%40%20wQ)%20%40%20(K_t%20%3D%20wK_t%20%40%20input_t))%20%40%20(V%20%3D%20input%20%40%20wV)%20%40%20wO&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;23.0=&amp;24.1=wQ&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;24.0=&amp;25.13=vmprod&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=vmprod&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;38.0=&amp;39.1=wV&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=none&amp;44.48=0&amp;44.49=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=10&amp;59.61=true&amp;59.62=4&amp;59.63=0.394&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=closed&amp;69.70=local&amp;69.71=0&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.49=open&amp;78.8=&amp;78.49=open&amp;79.80=-1212.5184472916683&amp;79.81=1205.8631771144878&amp;79.82=1850.8460431010271&amp;83.80=-6.708919569777563&amp;83.81=75.05036284609801&amp;83.82=-216.66743330111652&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">exploring this example in the tool itself</a>, rather than relying on the screenshot or the video below to convey just how much signal can be absorbed from it - both about its structure and the actual values flowing through the computation.</p>

<h3 id="4b-computation-and-values">4b Computation and Values</h3>

<p>Here’s an animation of the attention head computation. Specifically, we’re watching</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sdpa(input @ wQ @ K_t) @ V @ wO
</code></pre></div></div>

<p>(i.e., matmuls 1, 4 , 5 and 6 above, with <code class="language-plaintext highlighter-rouge">K_t</code> and <code class="language-plaintext highlighter-rouge">V</code> precomputed) being computed as a fused chain of vector-matrix products: each item in the sequence goes all the way from input through attention to output in one step. More on this animation choice in the later section on parallelization, but first let’s look at what the values being computed tell us.</p>

<p><a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_5%20%40%20wQ_5_4)%20%40%20(K_t%20%3D%20wK_t_5_4%20%40%20input_t_0_5))%20%40%20(V%20%3D%20input_0_5%20%40%20wV_5_4)%20%40%20wO_5_4&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_5&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;23.0=&amp;24.1=wQ_5_4&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;24.0=&amp;25.13=vmprod&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t_5_4&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t_0_5&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=vmprod&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input_0_5&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;38.0=&amp;39.1=wV_5_4&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO_5_4&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=vmprod&amp;44.48=0&amp;44.49=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=8.38&amp;59.61=true&amp;59.62=4&amp;59.63=0.394&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=open&amp;69.70=local&amp;69.71=0.05&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;78.8=&amp;79.80=-382.8684269325278&amp;79.81=293.7591554956184&amp;79.82=395.95878922315694&amp;83.80=-14.023727291338966&amp;83.81=-38.22974037070054&amp;83.82=-84.10726407282482&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">Open in mm</a></p>

<p align="center">
  <video width="100%" controls="">
    <source src="/assets/videos/inside-the-matrix/gpt2_big2b.mp4" type="video/mp4" />
  </video>
</p>

<p>There’s a lot of interesting stuff going on here.</p>

<ul>
  <li>Before we even get to the attention calculation, it’s quite striking how low-rank <code class="language-plaintext highlighter-rouge">Q</code> and <code class="language-plaintext highlighter-rouge">K_t</code> are. <a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_5%20%40%20wQ_5_4)%20%40%20(K_t%20%3D%20wK_t_5_4%20%40%20input_t_0_5))%20%40%20(V%20%3D%20input_0_5%20%40%20wV_5_4)%20%40%20wO_5_4&amp;1=out&amp;2=none&amp;24=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_5&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;23.0=&amp;23.24=closed&amp;25.1=wQ_5_4&amp;25.4=false&amp;25.5=768&amp;25.6=64&amp;25.7=url&amp;25.9=-1&amp;25.10=1&amp;25.11=0&amp;25.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;25.0=&amp;26.13=none&amp;26.24=open&amp;27.15=1&amp;28.17=positive&amp;28.18=left&amp;28.19=bottom&amp;28.20=back&amp;22.24=open&amp;29.2=none&amp;30.13=none&amp;31.15=1&amp;32.17=positive&amp;32.18=right&amp;32.19=top&amp;32.20=back&amp;33.1=wK_t_5_4&amp;33.4=false&amp;33.5=64&amp;33.6=768&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;34.1=input_t_0_5&amp;34.4=false&amp;34.5=768&amp;34.6=256&amp;34.7=url&amp;34.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;34.9=-1&amp;34.10=1&amp;34.11=0&amp;34.0=&amp;29.1=K_t&amp;29.4=true&amp;35.13=vmprod&amp;36.15=1&amp;37.17=negative&amp;37.18=left&amp;37.19=top&amp;37.20=front&amp;21.24=closed&amp;38.1=V&amp;38.4=true&amp;38.2=none&amp;39.1=input_0_5&amp;39.4=false&amp;39.5=256&amp;39.6=768&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;39.0=&amp;40.1=wV_5_4&amp;40.4=false&amp;40.5=768&amp;40.6=64&amp;40.7=url&amp;40.9=-1&amp;40.10=1&amp;40.11=0&amp;40.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;40.0=&amp;41.13=none&amp;42.15=1&amp;43.17=negative&amp;43.18=right&amp;43.19=top&amp;43.20=back&amp;3.24=closed&amp;44.1=wO_5_4&amp;44.4=false&amp;44.5=64&amp;44.6=768&amp;44.7=url&amp;44.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;44.9=-1&amp;44.10=1&amp;44.11=0&amp;44.0=&amp;45.46=sync&amp;45.47=4&amp;45.48=false&amp;45.13=vmprod&amp;45.49=0&amp;45.24=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=8.38&amp;59.61=true&amp;59.62=4&amp;59.63=0.394&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.24=open&amp;69.70=local&amp;69.71=0.05&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;78.8=&amp;79.80=-0.30816774330149777&amp;79.81=333.6054152134701&amp;79.82=155.72856559616935&amp;83.80=-0.11764216999897817&amp;83.81=-38.43510027180947&amp;83.82=-78.52287109278605&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;folder=24&amp;left.left.left.right=25&amp;left.left.left.anim=26&amp;left.left.left.block=27&amp;left.left.left.layout=28&amp;left.left.right=29&amp;left.left.right.anim=30&amp;left.left.right.block=31&amp;left.left.right.layout=32&amp;left.left.right.left=33&amp;left.left.right.right=34&amp;left.left.anim=35&amp;left.left.block=36&amp;left.left.layout=37&amp;left.right=38&amp;left.right.left=39&amp;left.right.right=40&amp;left.right.anim=41&amp;left.right.block=42&amp;left.right.layout=43&amp;right=44&amp;anim=45&amp;fuse=46&amp;speed=47&amp;hide%20inputs=48&amp;spin=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">Zooming in on the Q @ K_t vector-matrix product animation</a>, the situation is even more vivid: a significant number of channels (embedding positions) in <em>both</em> <code class="language-plaintext highlighter-rouge">Q</code> and <code class="language-plaintext highlighter-rouge">K</code> look more or less constant across the sequence, implying that the useful attention signal is potentially driven by a only smallish subset of the embedding. Understanding and exploiting this phenomenon is one of the threads we’re pulling on as part of the SysML ATOM transformer efficiency project.</li>
  <li>Perhaps most familiar is the strong-but-not-perfect diagonal that emerges in the attention matrix. This is a common pattern, showing up in many of the attention heads of this model (and those of many transformers). It produces <em>localized</em> attention: the value tokens in the small neighborhood immediately preceding an output token’s position largely determine that output token’s content pattern.</li>
  <li>However, the size of this neighborhood and the influence of individual tokens within it vary nontrivially - this can be seen both in the off-diagonal frost in the attention grid, and in the <a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_5%20%40%20wQ_5_4)%20%40%20(K_t%20%3D%20wK_t_5_4%20%40%20input_t_0_5))%20%40%20(V%20%3D%20input_0_5%20%40%20wV_5_4)%20%40%20wO_5_4&amp;1=out&amp;2=none&amp;26=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_5&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;23.0=&amp;24.1=wQ_5_4&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;24.0=&amp;25.13=none&amp;25.26=open&amp;27.15=1&amp;28.17=positive&amp;28.18=left&amp;28.19=bottom&amp;28.20=back&amp;22.26=closed&amp;29.2=none&amp;30.13=none&amp;31.15=1&amp;32.17=positive&amp;32.18=right&amp;32.19=top&amp;32.20=back&amp;33.1=wK_t_5_4&amp;33.4=false&amp;33.5=64&amp;33.6=768&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;34.1=input_t_0_5&amp;34.4=false&amp;34.5=768&amp;34.6=256&amp;34.7=url&amp;34.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;34.9=-1&amp;34.10=1&amp;34.11=0&amp;34.0=&amp;29.1=K_t&amp;29.4=true&amp;35.13=none&amp;35.26=open&amp;36.15=1&amp;37.17=negative&amp;37.18=left&amp;37.19=top&amp;37.20=front&amp;21.26=open&amp;38.1=V&amp;38.4=true&amp;38.2=none&amp;39.1=input_0_5&amp;39.4=false&amp;39.5=256&amp;39.6=768&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;39.0=&amp;40.1=wV_5_4&amp;40.4=false&amp;40.5=768&amp;40.6=64&amp;40.7=url&amp;40.9=-1&amp;40.10=1&amp;40.11=0&amp;40.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;40.0=&amp;41.13=none&amp;42.15=1&amp;43.17=negative&amp;43.18=right&amp;43.19=top&amp;43.20=back&amp;3.26=open&amp;44.1=wO_5_4&amp;44.4=false&amp;44.5=64&amp;44.6=768&amp;44.7=url&amp;44.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;44.9=-1&amp;44.10=1&amp;44.11=0&amp;44.0=&amp;45.46=sync&amp;45.47=16&amp;45.48=false&amp;45.13=vmprod&amp;45.49=0&amp;45.26=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=8.38&amp;59.61=true&amp;59.62=4&amp;59.63=0.394&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.26=open&amp;69.70=local&amp;69.71=0.05&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;78.8=&amp;79.80=-12.838747258760423&amp;79.81=224.62765397316576&amp;79.82=274.71626756027933&amp;83.80=-13.049253781233714&amp;83.81=-55.16215322834755&amp;83.82=-70.26525235295296&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;folder=26&amp;left.left.left.block=27&amp;left.left.left.layout=28&amp;left.left.right=29&amp;left.left.right.anim=30&amp;left.left.right.block=31&amp;left.left.right.layout=32&amp;left.left.right.left=33&amp;left.left.right.right=34&amp;left.left.anim=35&amp;left.left.block=36&amp;left.left.layout=37&amp;left.right=38&amp;left.right.left=39&amp;left.right.right=40&amp;left.right.anim=41&amp;left.right.block=42&amp;left.right.layout=43&amp;right=44&amp;anim=45&amp;fuse=46&amp;speed=47&amp;hide%20inputs=48&amp;spin=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">fluctuating patterns of the attn[i] @ V vector-matrix product plane</a> as it descends the attention matrix on its way through the sequence.</li>
  <li>But note that the local neighborhood isn’t the only thing that’s attracting attention: the leftmost column of the attention grid, corresponding to the first token of the sequence, is entirely filled with nonzero (but fluctuating) values, meaning every output token will be influenced to some degree by the first value token.</li>
  <li>Moreover there’s an <a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_5%20%40%20wQ_5_4)%20%40%20(K_t%20%3D%20wK_t_5_4%20%40%20input_t_0_5))%20%40%20(V%20%3D%20input_0_5%20%40%20wV_5_4)%20%40%20wO_5_4&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_5&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;23.0=&amp;24.1=wQ_5_4&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;24.0=&amp;25.13=vmprod&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t_5_4&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t_0_5&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=vmprod&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input_0_5&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;38.0=&amp;39.1=wV_5_4&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO_5_4&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=none&amp;44.48=0&amp;44.49=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=8.38&amp;59.61=true&amp;59.62=4&amp;59.63=0.394&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=open&amp;69.70=local&amp;69.71=0.05&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;78.8=&amp;79.80=-328.8286059935543&amp;79.81=-64.64788859858083&amp;79.82=156.66189435044396&amp;83.80=-6.5479856531724625&amp;83.81=-27.630477427688977&amp;83.82=-64.70186279804427&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">inexact but discernible oscillation in attention score dominance</a> between the current token neighborhood and the initial token. The period of the oscillation varies, but broadly speaking starts short and then lengthens as one travels down the sequence (evocatively correlated with the quantity of candidate attention tokens for each row, given causality).</li>
  <li>To get a feel for how (<code class="language-plaintext highlighter-rouge">attn @ V)</code> is formed, it’s important not to focus on attention in isolation - <code class="language-plaintext highlighter-rouge">V</code> is an equal player. Each output item is a weighted average of the entire <code class="language-plaintext highlighter-rouge">V</code> vector: at the limit when attention is a perfect diagonal, <code class="language-plaintext highlighter-rouge">attn @ V</code> is simply an exact copy of <code class="language-plaintext highlighter-rouge">V</code>. Here we see <a href="https://bhosmer.github.io/mm/index.html?0=out+%3D+%28attn+%3D+%28Q+%3D+input_0_5+%40+wQ_5_4%29+%40+%28K_t+%3D+wK_t_5_4+%40+input_t_0_5%29%29+%40+%28V+%3D+input_0_5+%40+wV_5_4%29+%40+wO_5_4&amp;1=out&amp;2=none&amp;51=closed&amp;84=true&amp;3.1=attn+%40+V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row+major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;14.16=1&amp;14.17=1&amp;18.19=positive&amp;18.20=left&amp;18.21=bottom&amp;18.22=back&amp;23.1=attn&amp;23.4=true&amp;23.2=softmax%28tril%28x%2Fsqrt%28k%29%29%29&amp;24.1=Q&amp;24.4=true&amp;24.2=none&amp;25.1=input_0_5&amp;25.4=false&amp;25.5=256&amp;25.6=768&amp;25.7=url&amp;25.9=-1&amp;25.10=1&amp;25.11=0&amp;25.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;25.0=&amp;26.1=wQ_5_4&amp;26.4=false&amp;26.5=768&amp;26.6=64&amp;26.7=url&amp;26.9=-1&amp;26.10=1&amp;26.11=0&amp;26.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;26.0=&amp;27.13=vmprod&amp;28.15=1&amp;28.16=1&amp;28.17=1&amp;29.19=positive&amp;29.20=left&amp;29.21=bottom&amp;29.22=back&amp;30.2=none&amp;31.13=none&amp;32.15=1&amp;32.16=1&amp;32.17=1&amp;33.19=positive&amp;33.20=right&amp;33.21=top&amp;33.22=back&amp;34.1=wK_t_5_4&amp;34.4=false&amp;34.5=64&amp;34.6=768&amp;34.7=url&amp;34.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;34.9=-1&amp;34.10=1&amp;34.11=0&amp;34.0=&amp;35.1=input_t_0_5&amp;35.4=false&amp;35.5=768&amp;35.6=256&amp;35.7=url&amp;35.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;35.9=-1&amp;35.10=1&amp;35.11=0&amp;35.0=&amp;30.1=K_t&amp;30.4=true&amp;36.13=vmprod&amp;37.15=1&amp;37.16=1&amp;37.17=1&amp;38.19=negative&amp;38.20=left&amp;38.21=top&amp;38.22=front&amp;39.1=V&amp;39.4=true&amp;39.2=none&amp;40.1=input_0_5&amp;40.4=false&amp;40.5=256&amp;40.6=768&amp;40.7=url&amp;40.9=-1&amp;40.10=1&amp;40.11=0&amp;40.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;40.0=&amp;41.1=wV_5_4&amp;41.4=false&amp;41.5=768&amp;41.6=64&amp;41.7=url&amp;41.9=-1&amp;41.10=1&amp;41.11=0&amp;41.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;41.0=&amp;42.13=none&amp;43.15=1&amp;43.16=1&amp;43.17=1&amp;44.19=negative&amp;44.20=right&amp;44.21=top&amp;44.22=back&amp;45.1=wO_5_4&amp;45.4=false&amp;45.5=64&amp;45.6=768&amp;45.7=url&amp;45.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;45.9=-1&amp;45.10=1&amp;45.11=0&amp;45.0=&amp;46.47=sync&amp;46.48=16&amp;46.49=false&amp;46.13=none&amp;46.50=0&amp;46.51=open&amp;52.16=1&amp;52.15=1&amp;52.17=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.19=negative&amp;53.20=left&amp;53.21=top&amp;53.22=front&amp;59.60=8.38&amp;59.61=true&amp;59.62=4&amp;59.63=0.394&amp;59.64=0&amp;59.65=0.5&amp;59.66=20&amp;59.67=false&amp;59.68=false&amp;59.51=open&amp;69.70=local&amp;69.71=0.05&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;78.8=&amp;79.80=-164.2339403949366&amp;79.81=18.940074323234473&amp;79.82=173.55325640245638&amp;83.80=117.76774477612946&amp;83.81=2.623526996843087&amp;83.82=53.25986191913323&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k+blocks=15&amp;i+blocks=16&amp;j+blocks=17&amp;left.layout=18&amp;polarity=19&amp;left+placement=20&amp;right+placement=21&amp;result+placement=22&amp;left.left=23&amp;left.left.left=24&amp;left.left.left.left=25&amp;left.left.left.right=26&amp;left.left.left.anim=27&amp;left.left.left.block=28&amp;left.left.left.layout=29&amp;left.left.right=30&amp;left.left.right.anim=31&amp;left.left.right.block=32&amp;left.left.right.layout=33&amp;left.left.right.left=34&amp;left.left.right.right=35&amp;left.left.anim=36&amp;left.left.block=37&amp;left.left.layout=38&amp;left.right=39&amp;left.right.left=40&amp;left.right.right=41&amp;left.right.anim=42&amp;left.right.block=43&amp;left.right.layout=44&amp;right=45&amp;anim=46&amp;fuse=47&amp;speed=48&amp;hide+inputs=49&amp;spin=50&amp;folder=51&amp;block=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row+guides=63&amp;flow+guides=64&amp;lens+size=65&amp;magnification=66&amp;interior+spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min+size=71&amp;min+light=72&amp;max+light=73&amp;elem+scale=74&amp;zero+hue=75&amp;hue+gap=76&amp;hue+spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">something more textured</a>: visible banding where particular tokens have scored high over a contiguous subsequence of attention rows, superimposed on a matrix visibly similar to to <code class="language-plaintext highlighter-rouge">V</code> but with some vertical smearing due to the fat diagonal. (Aside: per the <a href="https://bhosmer.github.io/mm/ref.html">mm reference guide</a>, long-clicking or control-clicking will reveal the actual numeric values of visualized elements.)</li>
  <li>Bear in mind that since we’re in a middle layer (5), the input to this attention head is an intermediate representation, not the original tokenized text. So the <a href="https://bhosmer.github.io/mm/index.html?0=out+%3D+%28attn+%3D+%28Q+%3D+input+%40+wQ%29+%40+%28K_t+%3D+wK_t+%40+input_t%29%29+%40+%28V+%3D+input+%40+wV%29+%40+wO&amp;1=out&amp;2=none&amp;26=closed&amp;84=true&amp;3.1=attn+%40+V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row+major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;14.16=1&amp;14.17=1&amp;18.19=positive&amp;18.20=left&amp;18.21=bottom&amp;18.22=back&amp;23.1=attn&amp;23.4=true&amp;23.2=softmax%28tril%28x%2Fsqrt%28k%29%29%29&amp;24.1=Q&amp;24.4=true&amp;24.2=none&amp;25.1=input&amp;25.4=false&amp;25.5=256&amp;25.6=768&amp;25.7=url&amp;25.9=-1&amp;25.10=1&amp;25.11=0&amp;25.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;25.0=&amp;25.26=open&amp;27.1=wQ&amp;27.4=false&amp;27.5=768&amp;27.6=64&amp;27.7=url&amp;27.9=-1&amp;27.10=1&amp;27.11=0&amp;27.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;27.0=&amp;28.13=vmprod&amp;29.15=1&amp;29.16=1&amp;29.17=1&amp;30.19=positive&amp;30.20=left&amp;30.21=bottom&amp;30.22=back&amp;24.26=open&amp;31.2=none&amp;32.13=none&amp;33.15=1&amp;33.16=1&amp;33.17=1&amp;34.19=positive&amp;34.20=right&amp;34.21=top&amp;34.22=back&amp;35.1=wK_t&amp;35.4=false&amp;35.5=64&amp;35.6=768&amp;35.7=url&amp;35.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;35.9=-1&amp;35.10=1&amp;35.11=0&amp;35.0=&amp;36.1=input_t&amp;36.4=false&amp;36.5=768&amp;36.6=256&amp;36.7=url&amp;36.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;36.9=-1&amp;36.10=1&amp;36.11=0&amp;36.0=&amp;31.1=K_t&amp;31.4=true&amp;37.13=vmprod&amp;38.15=1&amp;38.16=1&amp;38.17=1&amp;39.19=negative&amp;39.20=left&amp;39.21=top&amp;39.22=front&amp;23.26=open&amp;40.1=V&amp;40.4=true&amp;40.2=none&amp;41.1=input&amp;41.4=false&amp;41.5=256&amp;41.6=768&amp;41.7=url&amp;41.9=-1&amp;41.10=1&amp;41.11=0&amp;41.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;41.0=&amp;42.1=wV&amp;42.4=false&amp;42.5=768&amp;42.6=64&amp;42.7=url&amp;42.9=-1&amp;42.10=1&amp;42.11=0&amp;42.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;42.0=&amp;43.13=none&amp;44.15=1&amp;44.16=1&amp;44.17=1&amp;45.19=negative&amp;45.20=right&amp;45.21=top&amp;45.22=back&amp;3.26=open&amp;46.1=wO&amp;46.4=false&amp;46.5=64&amp;46.6=768&amp;46.7=url&amp;46.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;46.9=-1&amp;46.10=1&amp;46.11=0&amp;46.0=&amp;47.48=sync&amp;47.49=16&amp;47.50=false&amp;47.13=none&amp;47.51=0&amp;47.26=open&amp;52.16=1&amp;52.15=1&amp;52.17=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.19=negative&amp;53.20=left&amp;53.21=top&amp;53.22=front&amp;59.60=10&amp;59.61=true&amp;59.62=5&amp;59.63=0.394&amp;59.64=0&amp;59.65=0.25&amp;59.66=4.632&amp;59.67=false&amp;59.68=false&amp;59.26=open&amp;69.70=local&amp;69.71=0.2&amp;69.72=0.4&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.26=open&amp;78.8=&amp;78.26=open&amp;79.80=-1126.8641673236093&amp;79.81=-4.707283693510895&amp;79.82=168.0669807860928&amp;83.80=-692.9006907132649&amp;83.81=4.068470706235418&amp;83.82=-171.27561837707958&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k+blocks=15&amp;i+blocks=16&amp;j+blocks=17&amp;left.layout=18&amp;polarity=19&amp;left+placement=20&amp;right+placement=21&amp;result+placement=22&amp;left.left=23&amp;left.left.left=24&amp;left.left.left.left=25&amp;folder=26&amp;left.left.left.right=27&amp;left.left.left.anim=28&amp;left.left.left.block=29&amp;left.left.left.layout=30&amp;left.left.right=31&amp;left.left.right.anim=32&amp;left.left.right.block=33&amp;left.left.right.layout=34&amp;left.left.right.left=35&amp;left.left.right.right=36&amp;left.left.anim=37&amp;left.left.block=38&amp;left.left.layout=39&amp;left.right=40&amp;left.right.left=41&amp;left.right.right=42&amp;left.right.anim=43&amp;left.right.block=44&amp;left.right.layout=45&amp;right=46&amp;anim=47&amp;fuse=48&amp;speed=49&amp;hide+inputs=50&amp;spin=51&amp;block=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row+guides=63&amp;flow+guides=64&amp;lens+size=65&amp;magnification=66&amp;interior+spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min+size=71&amp;min+light=72&amp;max+light=73&amp;elem+scale=74&amp;zero+hue=75&amp;hue+gap=76&amp;hue+spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">patterns seen in the input</a> are themselves thought-provoking - in particular, the strong vertical threads are particular embedding positions whose values are uniformly high magnitude across long stretches of the sequence - sometimes almost the entire thing.</li>
  <li>Interestingly, though, the <a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input%20%40%20wQ)%20%40%20(K_t%20%3D%20wK_t%20%40%20input_t))%20%40%20(V%20%3D%20input%20%40%20wV)%20%40%20wO&amp;1=out&amp;2=none&amp;24=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;23.0=&amp;23.24=open&amp;25.1=wQ&amp;25.4=false&amp;25.5=768&amp;25.6=64&amp;25.7=url&amp;25.9=-1&amp;25.10=1&amp;25.11=0&amp;25.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;25.0=&amp;26.13=vmprod&amp;27.15=1&amp;28.17=positive&amp;28.18=left&amp;28.19=bottom&amp;28.20=back&amp;22.24=open&amp;29.2=none&amp;30.13=none&amp;31.15=1&amp;32.17=positive&amp;32.18=right&amp;32.19=top&amp;32.20=back&amp;33.1=wK_t&amp;33.4=false&amp;33.5=64&amp;33.6=768&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;34.1=input_t&amp;34.4=false&amp;34.5=768&amp;34.6=256&amp;34.7=url&amp;34.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;34.9=-1&amp;34.10=1&amp;34.11=0&amp;34.0=&amp;29.1=K_t&amp;29.4=true&amp;35.13=vmprod&amp;36.15=1&amp;37.17=negative&amp;37.18=left&amp;37.19=top&amp;37.20=front&amp;21.24=open&amp;38.1=V&amp;38.4=true&amp;38.2=none&amp;39.1=input&amp;39.4=false&amp;39.5=256&amp;39.6=768&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;39.0=&amp;40.1=wV&amp;40.4=false&amp;40.5=768&amp;40.6=64&amp;40.7=url&amp;40.9=-1&amp;40.10=1&amp;40.11=0&amp;40.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;40.0=&amp;41.13=none&amp;42.15=1&amp;43.17=negative&amp;43.18=right&amp;43.19=top&amp;43.20=back&amp;3.24=open&amp;44.1=wO&amp;44.4=false&amp;44.5=64&amp;44.6=768&amp;44.7=url&amp;44.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;44.9=-1&amp;44.10=1&amp;44.11=0&amp;44.0=&amp;45.46=sync&amp;45.47=16&amp;45.48=false&amp;45.13=none&amp;45.49=0&amp;45.24=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=10&amp;59.61=true&amp;59.62=5&amp;59.63=0.394&amp;59.64=0&amp;59.65=0&amp;59.66=4.632&amp;59.67=false&amp;59.68=false&amp;59.24=open&amp;69.70=local&amp;69.71=0.2&amp;69.72=0.4&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.24=open&amp;78.8=&amp;78.24=open&amp;79.80=-905.2149526505231&amp;79.81=126.10717525695773&amp;79.82=-90.1644865901155&amp;83.80=-739.2766627330938&amp;83.81=125.47333863007341&amp;83.82=-229.39828071999955&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;folder=24&amp;left.left.left.right=25&amp;left.left.left.anim=26&amp;left.left.left.block=27&amp;left.left.left.layout=28&amp;left.left.right=29&amp;left.left.right.anim=30&amp;left.left.right.block=31&amp;left.left.right.layout=32&amp;left.left.right.left=33&amp;left.left.right.right=34&amp;left.left.anim=35&amp;left.left.block=36&amp;left.left.layout=37&amp;left.right=38&amp;left.right.left=39&amp;left.right.right=40&amp;left.right.anim=41&amp;left.right.block=42&amp;left.right.layout=43&amp;right=44&amp;anim=45&amp;fuse=46&amp;speed=47&amp;hide%20inputs=48&amp;spin=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">first vector in the input sequence is distinctive</a>, not only breaking the pattern of these high-magnitude columns but carrying atypical values at almost every position (aside: not visualized here, but this pattern is repeated over multiple sample inputs).</li>
</ul>

<p>Note: apropos of the last two bullet points, it’s worth reiterating that we’re visualizing computation over a <em>single sample input</em>. In practice I’ve found that each head has a characteristic pattern it will express consistently (though not identically) over a decent collection of samples (and the upcoming attention head browser will provide a collection of samples to play with), but when looking at any visualization that includes activations, it’s important to bear in mind that a full distribution of inputs may influence the ideas and intuitions it provokes it in subtle ways.</p>

<p>Finally, one more pitch to <a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_5%20%40%20wQ_5_4)%20%40%20(K_t%20%3D%20wK_t_5_4%20%40%20input_t_0_5))%20%40%20(V%20%3D%20input_0_5%20%40%20wV_5_4)%20%40%20wO_5_4&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_5&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;23.0=&amp;24.1=wQ_5_4&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;24.0=&amp;25.13=vmprod&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t_5_4&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t_0_5&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=vmprod&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input_0_5&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;38.0=&amp;39.1=wV_5_4&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO_5_4&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=vmprod&amp;44.48=0&amp;44.49=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=8.38&amp;59.61=true&amp;59.62=4&amp;59.63=0.394&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=open&amp;69.70=local&amp;69.71=0.05&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;78.8=&amp;79.80=-382.8684269325278&amp;79.81=293.7591554956184&amp;79.82=395.95878922315694&amp;83.80=-14.023727291338966&amp;83.81=-38.22974037070054&amp;83.82=-84.10726407282482&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">explore the animation directly</a>!</p>

<h3 id="4c-heads-are-different-in-interesting-ways">4c Heads are different in interesting ways</h3>

<p>Before we move on, here’s one more demonstration of the usefulness of simply poking around a model to see how it works in detail.</p>

<p>This is another attention head from GPT2. It behaves quite differently from layer 5, head 4 above - as one might expect, given that it’s in a very different part of the model. This head is in the very first layer: layer 0, head 2 (<a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_0%20%40%20wQ_0_2)%20%40%20(K_t%20%3D%20wK_t_0_2%20%40%20input_t_0_0))%20%40%20(V%20%3D%20input_0_0%20%40%20wV_0_2)%20%40%20wO_0_2&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_0&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;23.0=&amp;24.1=wQ_0_2&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wq2_768_64.csv&amp;24.0=&amp;25.13=none&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t_0_2&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wk_t2_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t_0_0&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=none&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input_0_0&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;38.0=&amp;39.1=wV_0_2&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wv2_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO_0_2&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wo2_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=none&amp;44.48=0&amp;44.49=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=6&amp;59.61=true&amp;59.62=4&amp;59.63=0.73&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=open&amp;69.70=local&amp;69.71=0.2&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.49=open&amp;78.8=&amp;78.49=open&amp;79.80=-217.09372134188362&amp;79.81=412.82010718887307&amp;79.82=523.3596617096426&amp;83.80=127.59196458710655&amp;83.81=35.32022663933653&amp;83.82=87.43354119148215&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">open in mm</a>, may take a few seconds to load model weights):</p>

<p><img src="/assets/images/inside-the-matrix/gpt2_0_2c.jpg" alt="This is another attention head from GPT2" style="width:100%" /></p>

<p>Things to note:</p>

<ul>
  <li>This head spreads attention very evenly. This has the effect of delivering a relatively <em>unweighted</em> average of <code class="language-plaintext highlighter-rouge">V</code> (or rather, the appropriate causal prefix of <code class="language-plaintext highlighter-rouge">V</code>) to each row in <code class="language-plaintext highlighter-rouge">attn @ V</code>, as can be seen in <a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_0%20%40%20wQ_0_2)%20%40%20(K_t%20%3D%20wK_t_0_2%20%40%20input_t_0_0))%20%40%20(V%20%3D%20input_0_0%20%40%20wV_0_2)%20%40%20wO_0_2&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_0&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;23.0=&amp;24.1=wQ_0_2&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wq2_768_64.csv&amp;24.0=&amp;25.13=none&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t_0_2&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wk_t2_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t_0_0&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=none&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input_0_0&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;38.0=&amp;39.1=wV_0_2&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wv2_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO_0_2&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wo2_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=vmprod&amp;44.48=0&amp;44.49=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=6&amp;59.61=true&amp;59.62=4&amp;59.63=0.73&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=closed&amp;69.70=local&amp;69.71=0.4&amp;69.72=0.4&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.49=open&amp;78.8=&amp;78.49=closed&amp;79.80=11.34872888812131&amp;79.81=324.07536950158396&amp;79.82=239.8893041928473&amp;83.80=11.804686909150822&amp;83.81=25.33948904441141&amp;83.82=46.896270190786204&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">this animation</a>: as we move down the attention score triangle, the <code class="language-plaintext highlighter-rouge">attn[i] @ V</code> vector-matrix product is small fluctuations away from being simply a downscaled, progressively revealed copy of <code class="language-plaintext highlighter-rouge">V</code>.</li>
  <li><code class="language-plaintext highlighter-rouge">attn @ V</code> has <a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_0%20%40%20wQ_0_2)%20%40%20(K_t%20%3D%20wK_t_0_2%20%40%20input_t_0_0))%20%40%20(V%20%3D%20input_0_0%20%40%20wV_0_2)%20%40%20wO_0_2&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_0&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;23.0=&amp;24.1=wQ_0_2&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wq2_768_64.csv&amp;24.0=&amp;25.13=none&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t_0_2&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wk_t2_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t_0_0&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=none&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input_0_0&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;38.0=&amp;39.1=wV_0_2&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wv2_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO_0_2&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wo2_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=none&amp;44.48=0&amp;44.49=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=6&amp;59.61=true&amp;59.62=4&amp;59.63=0.73&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=open&amp;69.70=local&amp;69.71=0.2&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.49=open&amp;78.8=&amp;78.49=open&amp;79.80=-152.24249732960024&amp;79.81=115.78244265148294&amp;79.82=89.29496035154&amp;83.80=20.231661185991296&amp;83.81=61.75722293832386&amp;83.82=52.45120329048098&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">striking vertical uniformity</a> - in large columnar regions of the embedding, the same value patterns persist over <em>the entire sequence</em>. One can think of these as properties shared by every token.</li>
  <li>Aside: on the one hand one might expect <em>some</em> uniformity in <code class="language-plaintext highlighter-rouge">attn @ V</code> given the effect of very evenly spread attention. But each row has been constructed from only a causal subsequence of <code class="language-plaintext highlighter-rouge">V</code> rather than the whole thing - why is that not causing more variation, like a progressive morphing as one moves down the sequence? <a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_0%20%40%20wQ_0_2)%20%40%20(K_t%20%3D%20wK_t_0_2%20%40%20input_t_0_0))%20%40%20(V%20%3D%20input_0_0%20%40%20wV_0_2)%20%40%20wO_0_2&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_0&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;23.0=&amp;24.1=wQ_0_2&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wq2_768_64.csv&amp;24.0=&amp;25.13=none&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t_0_2&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wk_t2_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t_0_0&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=none&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input_0_0&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;38.0=&amp;39.1=wV_0_2&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wv2_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO_0_2&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wo2_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=none&amp;44.48=0&amp;44.49=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=6&amp;59.61=true&amp;59.62=4&amp;59.63=0.73&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=open&amp;69.70=local&amp;69.71=0.2&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.49=open&amp;78.8=&amp;78.49=open&amp;79.80=8.296178745251016&amp;79.81=-533.8678069620822&amp;79.82=35.64126972299759&amp;83.80=8.29674894856322&amp;83.81=36.25749961529174&amp;83.82=35.64126624185369&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">By visual inspection V isn’t uniform along its length</a>, so the answer must lie in some more subtle property of its distribution of values.</li>
  <li>Finally, this head’s output is <a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_0%20%40%20wQ_0_2)%20%40%20(K_t%20%3D%20wK_t_0_2%20%40%20input_t_0_0))%20%40%20(V%20%3D%20input_0_0%20%40%20wV_0_2)%20%40%20wO_0_2&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_0&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;23.0=&amp;24.1=wQ_0_2&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wq2_768_64.csv&amp;24.0=&amp;25.13=none&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t_0_2&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wk_t2_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t_0_0&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=none&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input_0_0&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;38.0=&amp;39.1=wV_0_2&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wv2_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO_0_2&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wo2_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=none&amp;44.48=0&amp;44.49=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=6&amp;59.61=true&amp;59.62=4&amp;59.63=0.73&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=open&amp;69.70=local&amp;69.71=0.2&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.49=open&amp;78.8=&amp;78.49=open&amp;79.80=41.37507219272118&amp;79.81=4.367136718959145&amp;79.82=430.5595129727994&amp;83.80=607.5332301692057&amp;83.81=-2.548000389888877&amp;83.82=-122.74351758382484&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">even more vertically uniform after out-projection</a></li>
  <li>the strong impression being that the bulk of the information being delivered by this attention head consists of properties which are shared by every token in the sequence. The composition of its <a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_0%20%40%20wQ_0_2)%20%40%20(K_t%20%3D%20wK_t_0_2%20%40%20input_t_0_0))%20%40%20(V%20%3D%20input_0_0%20%40%20wV_0_2)%20%40%20wO_0_2&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_0&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;23.0=&amp;24.1=wQ_0_2&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wq2_768_64.csv&amp;24.0=&amp;25.13=none&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t_0_2&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wk_t2_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t_0_0&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=none&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input_0_0&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;38.0=&amp;39.1=wV_0_2&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wv2_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO_0_2&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wo2_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=none&amp;44.48=0&amp;44.49=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=6&amp;59.61=true&amp;59.62=4&amp;59.63=0.73&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=open&amp;69.70=local&amp;69.71=0.2&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.49=open&amp;78.8=&amp;78.49=open&amp;79.80=136.19712021298585&amp;79.81=351.47497630691043&amp;79.82=254.9066405965837&amp;83.80=554.2569175811409&amp;83.81=-39.63963114876448&amp;83.82=-109.72659308933949&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">output projection weights</a> reinforces this intuition.</li>
</ul>

<p>Overall, it’s hard to resist the idea that the extremely regular, highly structured information this attention head produces might be obtained by computational means that are a bit… less lavish. Of course this isn’t an unexplored area, but the specificity and richness of signal of the visualized computation has been useful in generating new ideas, and reasoning about existing ones.</p>

<h3 id="4d-revisiting-the-pitch-invariants-for-free">4d Revisiting the pitch: invariants for free</h3>

<p>Stepping back, it’s worth reiterating that the reason we can visualize nontrivially compound operations like attention heads and have them remain intuitive is that important algebraic properties - like how argument shapes are constrained, or which parallelization axes intersect which operations - <em>don’t require additional thinking</em>: they arise directly from the geometry of the visualized object, rather than being additional rules to keep in mind.</p>

<p>For example, in these attention head visualizations it’s immediately obvious that</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Q</code> and <code class="language-plaintext highlighter-rouge">attn @ V</code> are the same length, <code class="language-plaintext highlighter-rouge">K</code> and <code class="language-plaintext highlighter-rouge">V</code> are the same length, and the lengths of these pairs are independent of each other</li>
  <li><code class="language-plaintext highlighter-rouge">Q</code> and <code class="language-plaintext highlighter-rouge">K</code> are the same width, <code class="language-plaintext highlighter-rouge">V</code> and <code class="language-plaintext highlighter-rouge">attn @ V</code> are the same width, and the widths of these pairs are independent of each other.</li>
</ul>

<p>These properties are true by construction, as a simple consequence of which parts of the compound structure the constituents inhabit and how they are oriented.</p>

<p>This “properties for free” benefit can be especially useful when exploring variations on a canonical structure - an obvious example being the one-row-high attention matrix in autoregressive token-at-a-time decoding (<a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_5%20%40%20wQ_5_4)%20%40%20(K_t%20%3D%20wK_t_5_4%20%40%20input_t_0_5))%20%40%20(V%20%3D%20input_0_5%20%40%20wV_5_4)%20%40%20wO_5_4&amp;1=out&amp;2=none&amp;24=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(x%2Fsqrt(k))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_5&amp;23.4=false&amp;23.5=1&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;23.0=&amp;23.24=open&amp;25.1=wQ_5_4&amp;25.4=false&amp;25.5=768&amp;25.6=64&amp;25.7=url&amp;25.9=-1&amp;25.10=1&amp;25.11=0&amp;25.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;25.0=&amp;26.13=vmprod&amp;27.15=1&amp;28.17=positive&amp;28.18=left&amp;28.19=bottom&amp;28.20=back&amp;22.24=open&amp;29.2=none&amp;30.13=none&amp;31.15=1&amp;32.17=positive&amp;32.18=right&amp;32.19=top&amp;32.20=back&amp;33.1=wK_t_5_4&amp;33.4=false&amp;33.5=64&amp;33.6=768&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;34.1=input_t_0_5&amp;34.4=false&amp;34.5=768&amp;34.6=256&amp;34.7=url&amp;34.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;34.9=-1&amp;34.10=1&amp;34.11=0&amp;34.0=&amp;29.1=K_t&amp;29.4=true&amp;35.13=vmprod&amp;36.15=1&amp;37.17=negative&amp;37.18=left&amp;37.19=top&amp;37.20=front&amp;21.24=open&amp;38.1=V&amp;38.4=true&amp;38.2=none&amp;39.1=input_0_5&amp;39.4=false&amp;39.5=256&amp;39.6=768&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;39.0=&amp;40.1=wV_5_4&amp;40.4=false&amp;40.5=768&amp;40.6=64&amp;40.7=url&amp;40.9=-1&amp;40.10=1&amp;40.11=0&amp;40.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;40.0=&amp;41.13=none&amp;42.15=1&amp;43.17=negative&amp;43.18=right&amp;43.19=top&amp;43.20=back&amp;3.24=closed&amp;44.1=wO_5_4&amp;44.4=false&amp;44.5=64&amp;44.6=768&amp;44.7=url&amp;44.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;44.9=-1&amp;44.10=1&amp;44.11=0&amp;44.0=&amp;45.46=sync&amp;45.47=16&amp;45.48=false&amp;45.13=none&amp;45.49=0&amp;45.24=open&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;53.54=blocks&amp;53.55=24&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;59.60=10&amp;59.61=true&amp;59.62=4&amp;59.63=0.394&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.24=open&amp;69.70=local&amp;69.71=0.05&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;78.8=&amp;79.80=-289.3020871171715&amp;79.81=176.55051931108687&amp;79.82=202.12550566094345&amp;83.80=6.09420901744693&amp;83.81=-60.94451681776672&amp;83.82=-55.94371166611936&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;folder=24&amp;left.left.left.right=25&amp;left.left.left.anim=26&amp;left.left.left.block=27&amp;left.left.left.layout=28&amp;left.left.right=29&amp;left.left.right.anim=30&amp;left.left.right.block=31&amp;left.left.right.layout=32&amp;left.left.right.left=33&amp;left.left.right.right=34&amp;left.left.anim=35&amp;left.left.block=36&amp;left.left.layout=37&amp;left.right=38&amp;left.right.left=39&amp;left.right.right=40&amp;left.right.anim=41&amp;left.right.block=42&amp;left.right.layout=43&amp;right=44&amp;anim=45&amp;fuse=46&amp;speed=47&amp;hide%20inputs=48&amp;spin=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/gpt2_decode2.jpg" alt="the one-row-high attention matrix in autoregressive token-at-a-time decoding" style="width:100%" /></p>

<h2 id="5-parallelizing-attention">5 Parallelizing attention</h2>

<p>In the animation of head 5, layer 4 above, we visualize 4 of the 6 matmuls in the attention head</p>

<p>as a fused chain of vector-matrix products, confirming the geometric intuition that the entire left-associative chain from input to output is <em>laminar</em> along the shared <code class="language-plaintext highlighter-rouge">i</code> axis, and can be parallelized.</p>

<h3 id="5a-example-partitioning-along-i">5a Example: partitioning along <code>i</code></h3>

<p>To parallelize the computation in practice, we would partition the input into blocks along the <code class="language-plaintext highlighter-rouge">i</code> axis. We can visualize this partition in the tool, by specifying that a given axis be partitioned into a particular number of blocks - in these examples we’ll use 8, but there’s nothing special about that number.</p>

<p>Among other things, this visualization makes clear that <code class="language-plaintext highlighter-rouge">wQ</code> (for in-projection), <code class="language-plaintext highlighter-rouge">K_t</code> and <code class="language-plaintext highlighter-rouge">V</code> (for attention) and <code class="language-plaintext highlighter-rouge">wO</code> (for out-projection) are needed in their entirety by each parallel computation, since they’re adjacent to the partitioned matrices along those matrices’ unpartitioned dimensions (<a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_5%20%40%20wQ_5_4)%20%40%20(K_t%20%3D%20wK_t_5_4%20%40%20input_t_0_5))%20%40%20(V%20%3D%20input_0_5%20%40%20wV_5_4)%20%40%20wO_5_4&amp;1=out&amp;2=none&amp;49=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=1&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input_0_5&amp;23.4=false&amp;23.5=256&amp;23.6=768&amp;23.7=url&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;23.0=&amp;24.1=wQ_5_4&amp;24.4=false&amp;24.5=768&amp;24.6=64&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;24.0=&amp;25.13=vmprod&amp;26.15=1&amp;27.17=positive&amp;27.18=left&amp;27.19=bottom&amp;27.20=back&amp;28.2=none&amp;29.13=none&amp;30.15=1&amp;31.17=positive&amp;31.18=right&amp;31.19=top&amp;31.20=back&amp;32.1=wK_t_5_4&amp;32.4=false&amp;32.5=64&amp;32.6=768&amp;32.7=url&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.0=&amp;33.1=input_t_0_5&amp;33.4=false&amp;33.5=768&amp;33.6=256&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;28.1=K_t&amp;28.4=true&amp;34.13=vmprod&amp;35.15=1&amp;36.17=negative&amp;36.18=left&amp;36.19=top&amp;36.20=front&amp;37.1=V&amp;37.4=true&amp;37.2=none&amp;38.1=input_0_5&amp;38.4=false&amp;38.5=256&amp;38.6=768&amp;38.7=url&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;38.0=&amp;39.1=wV_5_4&amp;39.4=false&amp;39.5=768&amp;39.6=64&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;39.0=&amp;40.13=none&amp;41.15=1&amp;42.17=negative&amp;42.18=right&amp;42.19=top&amp;42.20=back&amp;43.1=wO_5_4&amp;43.4=false&amp;43.5=64&amp;43.6=768&amp;43.7=url&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;44.45=sync&amp;44.46=16&amp;44.47=false&amp;44.13=none&amp;44.48=0&amp;44.49=closed&amp;50.51=8&amp;50.52=1&amp;50.15=1&amp;50.49=open&amp;53.54=blocks&amp;53.55=10&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.17=negative&amp;53.18=left&amp;53.19=top&amp;53.20=front&amp;53.49=closed&amp;59.60=10&amp;59.61=true&amp;59.62=4&amp;59.63=0.507&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.49=open&amp;69.70=local&amp;69.71=0.2&amp;69.72=0.3&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.49=closed&amp;78.8=&amp;78.49=open&amp;79.80=-452.09425433307837&amp;79.81=-10.01467989007457&amp;79.82=392.9851223674549&amp;83.80=-27.91725760321879&amp;83.81=-18.858991089590095&amp;83.82=-140.6826497984033&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.anim=25&amp;left.left.left.block=26&amp;left.left.left.layout=27&amp;left.left.right=28&amp;left.left.right.anim=29&amp;left.left.right.block=30&amp;left.left.right.layout=31&amp;left.left.right.left=32&amp;left.left.right.right=33&amp;left.left.anim=34&amp;left.left.block=35&amp;left.left.layout=36&amp;left.right=37&amp;left.right.left=38&amp;left.right.right=39&amp;left.right.anim=40&amp;left.right.block=41&amp;left.right.layout=42&amp;right=43&amp;anim=44&amp;fuse=45&amp;speed=46&amp;hide%20inputs=47&amp;spin=48&amp;folder=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/gpt2_parti.jpg" alt="wQ (for in-projection), K_t and V (for attention) and wO (for out-projection) are needed in their entirety by each parallel computation" style="width:100%" /></p>

<h3 id="5b-example-double-partitioning">5b Example: double partitioning</h3>

<p>As an example of partitioning along <em>multiple</em> axes, we can visualize some recent work which innovates in this space (<a href="https://arxiv.org/pdf/2305.19370.pdf">Block Parallel Transformer</a>, building on work done in e.g. <a href="https://arxiv.org/pdf/2205.14135.pdf">Flash Attention</a> and its antecedents).</p>

<p>First, BPT partitions along <code class="language-plaintext highlighter-rouge">i</code> as described above - and actually extends this horizontal partitioning of the sequence into chunks all the way through the second (FFN) half of the attention layer as well. (We’ll visualize this in a later section.)</p>

<p>To fully attack the context length problem, a second partitioning is then added to MHA - that of the attention calculation itself (i.e., a partition along the <code class="language-plaintext highlighter-rouge">j</code> axis of <code class="language-plaintext highlighter-rouge">Q @ K_t</code>). The two partitions together divide attention into a grid of blocks (<a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input_0_5%20%40%20wQ_5_4)%20%40%20(K_t%20%3D%20wK_t_5_4%20%40%20input_t_0_5))%20%40%20(V%20%3D%20input_0_5%20%40%20wV_5_4)%20%40%20wO_5_4&amp;1=out&amp;2=none&amp;16=closed&amp;84=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=vmprod&amp;14.15=8&amp;14.16=open&amp;17.18=positive&amp;17.19=left&amp;17.20=bottom&amp;17.21=back&amp;22.1=attn&amp;22.4=true&amp;22.2=softmax(tril(x%2Fsqrt(k)))&amp;23.1=Q&amp;23.4=true&amp;23.2=none&amp;24.1=input_0_5&amp;24.4=false&amp;24.5=256&amp;24.6=768&amp;24.7=url&amp;24.9=-1&amp;24.10=1&amp;24.11=0&amp;24.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;24.0=&amp;25.1=wQ_5_4&amp;25.4=false&amp;25.5=768&amp;25.6=64&amp;25.7=url&amp;25.9=-1&amp;25.10=1&amp;25.11=0&amp;25.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;25.0=&amp;26.13=vmprod&amp;27.15=1&amp;28.18=positive&amp;28.19=left&amp;28.20=bottom&amp;28.21=back&amp;29.2=none&amp;30.13=none&amp;31.15=1&amp;32.18=positive&amp;32.19=right&amp;32.20=top&amp;32.21=back&amp;33.1=wK_t_5_4&amp;33.4=false&amp;33.5=64&amp;33.6=768&amp;33.7=url&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.0=&amp;34.1=input_t_0_5&amp;34.4=false&amp;34.5=768&amp;34.6=256&amp;34.7=url&amp;34.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;34.9=-1&amp;34.10=1&amp;34.11=0&amp;34.0=&amp;29.1=K_t&amp;29.4=true&amp;35.13=vmprod&amp;36.15=1&amp;37.18=negative&amp;37.19=left&amp;37.20=top&amp;37.21=front&amp;38.1=V&amp;38.4=true&amp;38.2=none&amp;39.1=input_0_5&amp;39.4=false&amp;39.5=256&amp;39.6=768&amp;39.7=url&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;39.0=&amp;40.1=wV_5_4&amp;40.4=false&amp;40.5=768&amp;40.6=64&amp;40.7=url&amp;40.9=-1&amp;40.10=1&amp;40.11=0&amp;40.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;40.0=&amp;41.13=none&amp;42.15=1&amp;43.18=negative&amp;43.19=right&amp;43.20=top&amp;43.21=back&amp;3.16=open&amp;44.1=wO_5_4&amp;44.4=false&amp;44.5=64&amp;44.6=768&amp;44.7=url&amp;44.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;44.9=-1&amp;44.10=1&amp;44.11=0&amp;44.0=&amp;45.46=sync&amp;45.47=16&amp;45.48=false&amp;45.13=none&amp;45.49=0&amp;45.16=closed&amp;50.51=8&amp;50.52=1&amp;50.15=1&amp;50.16=closed&amp;53.54=blocks&amp;53.55=10&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.18=negative&amp;53.19=left&amp;53.20=top&amp;53.21=front&amp;53.16=closed&amp;59.60=10&amp;59.61=true&amp;59.62=4&amp;59.63=0.507&amp;59.64=0&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.16=open&amp;69.70=local&amp;69.71=0.2&amp;69.72=0.3&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.16=closed&amp;78.8=&amp;78.16=open&amp;79.80=-459.733038437248&amp;79.81=-10.183892342609507&amp;79.82=399.6251724834292&amp;83.80=-27.91725760321879&amp;83.81=-18.858991089590095&amp;83.82=-140.6826497984033&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;folder=16&amp;left.layout=17&amp;polarity=18&amp;left%20placement=19&amp;right%20placement=20&amp;result%20placement=21&amp;left.left=22&amp;left.left.left=23&amp;left.left.left.left=24&amp;left.left.left.right=25&amp;left.left.left.anim=26&amp;left.left.left.block=27&amp;left.left.left.layout=28&amp;left.left.right=29&amp;left.left.right.anim=30&amp;left.left.right.block=31&amp;left.left.right.layout=32&amp;left.left.right.left=33&amp;left.left.right.right=34&amp;left.left.anim=35&amp;left.left.block=36&amp;left.left.layout=37&amp;left.right=38&amp;left.right.left=39&amp;left.right.right=40&amp;left.right.anim=41&amp;left.right.block=42&amp;left.right.layout=43&amp;right=44&amp;anim=45&amp;fuse=46&amp;speed=47&amp;hide%20inputs=48&amp;spin=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/gpt2_ik.jpg" alt="The two partitions together divide attention into a grid of blocks" style="width:100%" /></p>

<p>This visualization makes clear</p>

<ul>
  <li>the effectiveness of this double partitioning as an attack on the context length problem, since we’ve now visibly partitioned every occurrence of sequence length in the attention calculation</li>
  <li>the “reach” of this second partitioning: it’s clear from the geometry that the in-projection computations of <code class="language-plaintext highlighter-rouge">K</code> and <code class="language-plaintext highlighter-rouge">V</code> can be partitioned along with the core double matmul</li>
</ul>

<p>Note one subtlety: the visual implication here is that we can also parallelize the subsequent matmul <code class="language-plaintext highlighter-rouge">attn @ V</code> along <code class="language-plaintext highlighter-rouge">k</code> and sum the partial results <a href="https://github.com/NVIDIA/cutlass/blob/main/media/docs/efficient_gemm.md#parallelized-reductions">split-k style</a>, thus parallelizing the entire double matmul. But the row-wise softmax in <code class="language-plaintext highlighter-rouge">sdpa()</code> adds the requirement that each row have all its segments normalized before the corresponding row of <code class="language-plaintext highlighter-rouge">attn @ V</code> can be computed, adding an extra row-wise step between the attention calculation and the final matmul.</p>

<h2 id="6-sizes-in-an-attention-layer">6 Sizes in an Attention Layer</h2>

<p>The first (MHA) half of an attention layer is famously computationally demanding because of its quadratic complexity, but the second (FFN) half is demanding in its own right due to the width of its hidden dimension, typically 4 times that of the model’s embedding dimension. Visualizing the biomass of a full attention layer can be useful in building intuition about how the two halves of the layer compare to each other.</p>

<h3 id="6a-visualizing-the-full-layer">6a Visualizing the full layer</h3>

<p>Below is a full attention layer with the first half (MHA) in the background and the second (FFN) in the foreground. As usual, arrows point in the direction of computation.</p>

<p>Notes:</p>

<ul>
  <li>This visualization doesn’t depict individual attention heads, but instead shows the unsliced Q/K/V weights and projections surrounding a central double matmul. Of course this isn’t a faithful visualization of the full MHA operation - but the goal here is to give a clearer sense of the relative matrix <em>sizes</em> in the two halves of the layer, rather than the relative amounts of computation each half performs. (Also, randomized values are used rather than real weights.)</li>
  <li>The dimensions used here are downsized to keep the browser (relatively) happy, but the proportions are preserved (from <a href="https://github.com/karpathy/nanoGPT/blob/master/model.py#L217">NanoGPT’s small config</a>): model embedding dimension = 192 (from 768), FFN embedding dimension = 768 (from 3072), sequence length = 256 (from 1024), although sequence length is not fundamental to the model. (Visually, changes in sequence length would appear as changes in the width of the input blades, and consequently in the size of the attention hub and the height of the downstream vertical planes.)</li>
</ul>

<p><a href="https://bhosmer.github.io/mm/index.html?0=layer_out%20%3D%20(attn_out%20%3D%20(attn%20%3D%20(Q%20%3D%20input%20%40%20wQ)%20%40%20(K_t%20%3D%20wK_t%20%40%20input_t))%20%40%20(V%20%3D%20input%20%40%20wV)%20%40%20wO)%20%40%20FFN_1%20%40%20FFN_2&amp;1=layer_out&amp;2=layernorm&amp;16=closed&amp;94=true&amp;3.1=attn_out%20%40%20FFN_1&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=gelu&amp;12.13=inherit&amp;14.15=1&amp;14.16=open&amp;17.18=positive&amp;17.19=left&amp;17.20=bottom&amp;17.21=back&amp;22.2=layernorm&amp;23.13=inherit&amp;24.15=1&amp;24.16=open&amp;25.18=negative&amp;25.19=left&amp;25.20=top&amp;25.21=front&amp;26.1=attn%20%40%20V&amp;26.4=true&amp;26.5=32&amp;26.6=32&amp;26.7=row%20major&amp;26.8=&amp;26.9=-1&amp;26.10=1&amp;26.11=0&amp;26.2=none&amp;27.13=vmprod&amp;28.15=1&amp;28.16=open&amp;29.18=positive&amp;29.19=left&amp;29.20=bottom&amp;29.21=back&amp;30.1=attn&amp;30.4=true&amp;30.2=softmax(tril(x%2Fsqrt(k)))&amp;31.1=Q&amp;31.4=true&amp;31.2=none&amp;32.1=input&amp;32.4=false&amp;32.5=256&amp;32.6=192&amp;32.7=gaussian&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;32.0=&amp;32.16=open&amp;33.1=wQ&amp;33.4=false&amp;33.5=192&amp;33.6=192&amp;33.7=gaussian&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;33.0=&amp;33.16=open&amp;34.13=vmprod&amp;35.15=1&amp;36.18=positive&amp;36.19=left&amp;36.20=bottom&amp;36.21=back&amp;31.16=closed&amp;37.2=none&amp;38.13=none&amp;39.15=1&amp;40.18=positive&amp;40.19=right&amp;40.20=top&amp;40.21=back&amp;41.1=wK_t&amp;41.4=false&amp;41.5=192&amp;41.6=192&amp;41.7=gaussian&amp;41.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;41.9=-1&amp;41.10=1&amp;41.11=0&amp;41.0=&amp;41.16=open&amp;42.1=input_t&amp;42.4=false&amp;42.5=192&amp;42.6=256&amp;42.7=gaussian&amp;42.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;42.9=-1&amp;42.10=1&amp;42.11=0&amp;42.0=&amp;42.16=open&amp;37.1=K_t&amp;37.4=true&amp;37.16=closed&amp;43.13=vmprod&amp;44.15=1&amp;44.16=open&amp;45.18=negative&amp;45.19=left&amp;45.20=top&amp;45.21=front&amp;30.16=open&amp;46.1=V&amp;46.4=true&amp;46.2=none&amp;47.1=input&amp;47.4=false&amp;47.5=256&amp;47.6=192&amp;47.7=gaussian&amp;47.9=-1&amp;47.10=1&amp;47.11=0&amp;47.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;47.0=&amp;47.16=open&amp;48.1=wV&amp;48.4=false&amp;48.5=192&amp;48.6=192&amp;48.7=gaussian&amp;48.9=-1&amp;48.10=1&amp;48.11=0&amp;48.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;48.0=&amp;48.16=open&amp;49.13=none&amp;50.15=1&amp;51.18=negative&amp;51.19=right&amp;51.20=top&amp;51.21=back&amp;46.16=open&amp;26.16=open&amp;52.1=wO&amp;52.4=false&amp;52.5=192&amp;52.6=192&amp;52.7=gaussian&amp;52.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;52.9=-1&amp;52.10=0.996&amp;52.11=0&amp;52.0=&amp;52.16=closed&amp;22.1=attn_out&amp;22.4=true&amp;22.16=open&amp;53.1=FFN_1&amp;53.4=false&amp;53.5=192&amp;53.6=768&amp;53.7=gaussian&amp;53.8=&amp;53.9=-1&amp;53.10=1&amp;53.11=0&amp;53.0=&amp;53.16=closed&amp;3.16=open&amp;54.1=FFN_2&amp;54.4=false&amp;54.5=768&amp;54.6=192&amp;54.7=gaussian&amp;54.8=&amp;54.9=-1&amp;54.10=1&amp;54.11=0&amp;54.0=&amp;54.16=closed&amp;55.56=sync&amp;55.57=16&amp;55.58=false&amp;55.13=none&amp;55.59=0&amp;55.16=closed&amp;60.61=1&amp;60.62=1&amp;60.15=1&amp;60.16=closed&amp;63.64=blocks&amp;63.65=8&amp;63.66=0&amp;63.67=1&amp;63.68=0&amp;63.18=negative&amp;63.19=left&amp;63.20=top&amp;63.21=front&amp;63.16=closed&amp;69.70=10&amp;69.71=true&amp;69.72=4&amp;69.73=0.507&amp;69.74=0.524&amp;69.75=0.5&amp;69.76=12&amp;69.77=false&amp;69.78=false&amp;69.16=closed&amp;79.80=local&amp;79.81=0.1&amp;79.82=0.2&amp;79.83=0.9&amp;79.84=2&amp;79.85=0.75&amp;79.86=0.75&amp;79.87=0.03&amp;79.16=closed&amp;88.8=&amp;88.16=open&amp;89.90=-738.1526976199144&amp;89.91=919.9001193338946&amp;89.92=957.7418906526483&amp;93.90=0&amp;93.91=0&amp;93.92=0&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;folder=16&amp;left.layout=17&amp;polarity=18&amp;left%20placement=19&amp;right%20placement=20&amp;result%20placement=21&amp;left.left=22&amp;left.left.anim=23&amp;left.left.block=24&amp;left.left.layout=25&amp;left.left.left=26&amp;left.left.left.anim=27&amp;left.left.left.block=28&amp;left.left.left.layout=29&amp;left.left.left.left=30&amp;left.left.left.left.left=31&amp;left.left.left.left.left.left=32&amp;left.left.left.left.left.right=33&amp;left.left.left.left.left.anim=34&amp;left.left.left.left.left.block=35&amp;left.left.left.left.left.layout=36&amp;left.left.left.left.right=37&amp;left.left.left.left.right.anim=38&amp;left.left.left.left.right.block=39&amp;left.left.left.left.right.layout=40&amp;left.left.left.left.right.left=41&amp;left.left.left.left.right.right=42&amp;left.left.left.left.anim=43&amp;left.left.left.left.block=44&amp;left.left.left.left.layout=45&amp;left.left.left.right=46&amp;left.left.left.right.left=47&amp;left.left.left.right.right=48&amp;left.left.left.right.anim=49&amp;left.left.left.right.block=50&amp;left.left.left.right.layout=51&amp;left.left.right=52&amp;left.right=53&amp;right=54&amp;anim=55&amp;fuse=56&amp;speed=57&amp;hide%20inputs=58&amp;spin=59&amp;block=60&amp;i%20blocks=61&amp;j%20blocks=62&amp;layout=63&amp;scheme=64&amp;gap=65&amp;scatter=66&amp;molecule=67&amp;blast=68&amp;deco=69&amp;legends=70&amp;shape=71&amp;spotlight=72&amp;row%20guides=73&amp;flow%20guides=74&amp;lens%20size=75&amp;magnification=76&amp;interior%20spotlight=77&amp;axes=78&amp;viz=79&amp;sensitivity=80&amp;min%20size=81&amp;min%20light=82&amp;max%20light=83&amp;elem%20scale=84&amp;zero%20hue=85&amp;hue%20gap=86&amp;hue%20spread=87&amp;diag=88&amp;cam=89&amp;x=90&amp;y=91&amp;z=92&amp;cam.target=93&amp;compress=94">Open in mm</a>:</p>

<p><img src="/assets/images/inside-the-matrix/attnlayer2.jpg" alt="a full attention layer with the first half (MHA) in the background and the second (FFN) in the foreground" style="width:100%" /></p>

<h3 id="6b-visualizing-the-bpt-partitioned-layer">6b Visualizing the BPT partitioned layer</h3>

<p>Revisiting <a href="https://arxiv.org/pdf/2305.19370.pdf">Blockwise Parallel Transformer</a> briefly, here we visualize BPT’s parallelization scheme in the context of an entire attention layer (with individual heads elided per above). In particular, note how the partitioning along <code class="language-plaintext highlighter-rouge">i</code> (of sequence blocks) extends through both MHA and FFN halves (<a href="https://bhosmer.github.io/mm/index.html?0=layer_out%20%3D%20(attn_out%20%3D%20(attn%20%3D%20(Q%20%3D%20input%20%40%20wQ)%20%40%20(K_t%20%3D%20wK_t%20%40%20input_t))%20%40%20(V%20%3D%20input%20%40%20wV)%20%40%20wO)%20%40%20FFN_1%20%40%20FFN_2&amp;1=layer_out&amp;2=layernorm&amp;16=closed&amp;94=true&amp;3.1=attn_out%20%40%20FFN_1&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=gelu&amp;12.13=inherit&amp;14.15=1&amp;14.16=closed&amp;17.18=positive&amp;17.19=left&amp;17.20=bottom&amp;17.21=back&amp;22.2=layernorm&amp;23.13=inherit&amp;24.15=1&amp;24.16=closed&amp;25.18=negative&amp;25.19=left&amp;25.20=top&amp;25.21=front&amp;26.1=attn%20%40%20V&amp;26.4=true&amp;26.5=32&amp;26.6=32&amp;26.7=row%20major&amp;26.8=&amp;26.9=-1&amp;26.10=1&amp;26.11=0&amp;26.2=none&amp;27.13=vmprod&amp;28.15=8&amp;28.16=open&amp;29.18=positive&amp;29.19=left&amp;29.20=bottom&amp;29.21=back&amp;30.1=attn&amp;30.4=true&amp;30.2=softmax(tril(x%2Fsqrt(k)))&amp;31.1=Q&amp;31.4=true&amp;31.2=none&amp;32.1=input&amp;32.4=false&amp;32.5=256&amp;32.6=192&amp;32.7=gaussian&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;32.0=&amp;32.16=open&amp;33.1=wQ&amp;33.4=false&amp;33.5=192&amp;33.6=192&amp;33.7=gaussian&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;33.0=&amp;33.16=open&amp;34.13=vmprod&amp;35.15=1&amp;36.18=positive&amp;36.19=left&amp;36.20=bottom&amp;36.21=back&amp;31.16=closed&amp;37.2=none&amp;38.13=none&amp;39.15=1&amp;40.18=positive&amp;40.19=right&amp;40.20=top&amp;40.21=back&amp;41.1=wK_t&amp;41.4=false&amp;41.5=192&amp;41.6=192&amp;41.7=gaussian&amp;41.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;41.9=-1&amp;41.10=1&amp;41.11=0&amp;41.0=&amp;41.16=open&amp;42.1=input_t&amp;42.4=false&amp;42.5=192&amp;42.6=256&amp;42.7=gaussian&amp;42.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;42.9=-1&amp;42.10=1&amp;42.11=0&amp;42.0=&amp;42.16=open&amp;37.1=K_t&amp;37.4=true&amp;37.16=closed&amp;43.13=vmprod&amp;44.15=1&amp;44.16=open&amp;45.18=negative&amp;45.19=left&amp;45.20=top&amp;45.21=front&amp;30.16=closed&amp;46.1=V&amp;46.4=true&amp;46.2=none&amp;47.1=input&amp;47.4=false&amp;47.5=256&amp;47.6=192&amp;47.7=gaussian&amp;47.9=-1&amp;47.10=1&amp;47.11=0&amp;47.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;47.0=&amp;47.16=open&amp;48.1=wV&amp;48.4=false&amp;48.5=192&amp;48.6=192&amp;48.7=gaussian&amp;48.9=-1&amp;48.10=1&amp;48.11=0&amp;48.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;48.0=&amp;48.16=open&amp;49.13=none&amp;50.15=1&amp;51.18=negative&amp;51.19=right&amp;51.20=top&amp;51.21=back&amp;46.16=closed&amp;26.16=open&amp;52.1=wO&amp;52.4=false&amp;52.5=192&amp;52.6=192&amp;52.7=gaussian&amp;52.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;52.9=-1&amp;52.10=0.996&amp;52.11=0&amp;52.0=&amp;52.16=closed&amp;22.1=attn_out&amp;22.4=true&amp;22.16=open&amp;53.1=FFN_1&amp;53.4=false&amp;53.5=192&amp;53.6=768&amp;53.7=gaussian&amp;53.8=&amp;53.9=-1&amp;53.10=1&amp;53.11=0&amp;53.0=&amp;53.16=closed&amp;3.16=open&amp;54.1=FFN_2&amp;54.4=false&amp;54.5=768&amp;54.6=192&amp;54.7=gaussian&amp;54.8=&amp;54.9=-1&amp;54.10=1&amp;54.11=0&amp;54.0=&amp;54.16=closed&amp;55.56=sync&amp;55.57=16&amp;55.58=false&amp;55.13=none&amp;55.59=0&amp;55.16=closed&amp;60.61=8&amp;60.62=1&amp;60.15=1&amp;60.16=open&amp;63.64=blocks&amp;63.65=8&amp;63.66=0&amp;63.67=1&amp;63.68=0&amp;63.18=negative&amp;63.19=left&amp;63.20=top&amp;63.21=front&amp;63.16=closed&amp;69.70=10&amp;69.71=true&amp;69.72=4&amp;69.73=0.507&amp;69.74=0.524&amp;69.75=0.5&amp;69.76=12&amp;69.77=false&amp;69.78=false&amp;69.16=closed&amp;79.80=local&amp;79.81=0.1&amp;79.82=0.2&amp;79.83=0.9&amp;79.84=2&amp;79.85=0.75&amp;79.86=0.75&amp;79.87=0.03&amp;79.16=closed&amp;88.8=&amp;88.16=open&amp;89.90=-766.4372214429399&amp;89.91=955.1488380935747&amp;89.92=994.4406298292719&amp;93.90=0&amp;93.91=0&amp;93.92=0&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;folder=16&amp;left.layout=17&amp;polarity=18&amp;left%20placement=19&amp;right%20placement=20&amp;result%20placement=21&amp;left.left=22&amp;left.left.anim=23&amp;left.left.block=24&amp;left.left.layout=25&amp;left.left.left=26&amp;left.left.left.anim=27&amp;left.left.left.block=28&amp;left.left.left.layout=29&amp;left.left.left.left=30&amp;left.left.left.left.left=31&amp;left.left.left.left.left.left=32&amp;left.left.left.left.left.right=33&amp;left.left.left.left.left.anim=34&amp;left.left.left.left.left.block=35&amp;left.left.left.left.left.layout=36&amp;left.left.left.left.right=37&amp;left.left.left.left.right.anim=38&amp;left.left.left.left.right.block=39&amp;left.left.left.left.right.layout=40&amp;left.left.left.left.right.left=41&amp;left.left.left.left.right.right=42&amp;left.left.left.left.anim=43&amp;left.left.left.left.block=44&amp;left.left.left.left.layout=45&amp;left.left.left.right=46&amp;left.left.left.right.left=47&amp;left.left.left.right.right=48&amp;left.left.left.right.anim=49&amp;left.left.left.right.block=50&amp;left.left.left.right.layout=51&amp;left.left.right=52&amp;left.right=53&amp;right=54&amp;anim=55&amp;fuse=56&amp;speed=57&amp;hide%20inputs=58&amp;spin=59&amp;block=60&amp;i%20blocks=61&amp;j%20blocks=62&amp;layout=63&amp;scheme=64&amp;gap=65&amp;scatter=66&amp;molecule=67&amp;blast=68&amp;deco=69&amp;legends=70&amp;shape=71&amp;spotlight=72&amp;row%20guides=73&amp;flow%20guides=74&amp;lens%20size=75&amp;magnification=76&amp;interior%20spotlight=77&amp;axes=78&amp;viz=79&amp;sensitivity=80&amp;min%20size=81&amp;min%20light=82&amp;max%20light=83&amp;elem%20scale=84&amp;zero%20hue=85&amp;hue%20gap=86&amp;hue%20spread=87&amp;diag=88&amp;cam=89&amp;x=90&amp;y=91&amp;z=92&amp;cam.target=93&amp;compress=94">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/bptlayer.jpg" alt="visualize BPT's parallelization scheme in the context of an entire attention layer" style="width:100%" /></p>

<h3 id="6c-partitioning-the-ffn">6c Partitioning the FFN</h3>

<p>The visualization suggests an additional partitioning, orthogonal to the ones described above - in the FFN half of the attention layer, splitting the double matmul <code class="language-plaintext highlighter-rouge">(attn_out @ FFN_1) @ FFN_2</code>, first along <code class="language-plaintext highlighter-rouge">j</code> for <code class="language-plaintext highlighter-rouge">attn_out @ FFN_1</code>, then along <code class="language-plaintext highlighter-rouge">k</code> in the subsequent matmul with <code class="language-plaintext highlighter-rouge">FFN_2</code>. This partition slices both layers of <code class="language-plaintext highlighter-rouge">FFN</code> weights, reducing the capacity requirements of each participant in the computation at the cost of a final summation of the partial results.</p>

<p>Here’s what this partition looks like applied to an otherwise unpartitioned attention layer (<a href="https://bhosmer.github.io/mm/index.html?0=layer_out+%3D+%28attn_out+%3D+%28attn+%3D+%28Q+%3D+input+%40+wQ%29+%40+%28K_t+%3D+wK_t+%40+input_t%29%29+%40+%28V+%3D+input+%40+wV%29+%40+wO%29+%40+FFN_1+%40+FFN_2&amp;1=layer_out&amp;2=layernorm&amp;16=closed&amp;94=true&amp;3.1=attn_out+%40+FFN_1&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row+major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=gelu&amp;12.13=inherit&amp;14.15=1&amp;14.16=open&amp;14.17=1&amp;14.18=8&amp;19.20=positive&amp;19.21=left&amp;19.22=bottom&amp;19.23=back&amp;24.2=layernorm&amp;25.13=inherit&amp;26.15=1&amp;26.16=closed&amp;26.17=1&amp;26.18=1&amp;27.20=negative&amp;27.21=left&amp;27.22=top&amp;27.23=front&amp;28.1=attn+%40+V&amp;28.4=true&amp;28.5=32&amp;28.6=32&amp;28.7=row+major&amp;28.8=&amp;28.9=-1&amp;28.10=1&amp;28.11=0&amp;28.2=none&amp;29.13=vmprod&amp;30.15=1&amp;30.16=open&amp;30.17=1&amp;30.18=1&amp;31.20=positive&amp;31.21=left&amp;31.22=bottom&amp;31.23=back&amp;32.1=attn&amp;32.4=true&amp;32.2=softmax%28tril%28x%2Fsqrt%28k%29%29%29&amp;33.1=Q&amp;33.4=true&amp;33.2=none&amp;34.1=input&amp;34.4=false&amp;34.5=256&amp;34.6=192&amp;34.7=gaussian&amp;34.9=-1&amp;34.10=1&amp;34.11=0&amp;34.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;34.0=&amp;34.16=open&amp;35.1=wQ&amp;35.4=false&amp;35.5=192&amp;35.6=192&amp;35.7=gaussian&amp;35.9=-1&amp;35.10=1&amp;35.11=0&amp;35.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;35.0=&amp;35.16=open&amp;36.13=vmprod&amp;37.15=1&amp;37.17=1&amp;37.18=1&amp;38.20=positive&amp;38.21=left&amp;38.22=bottom&amp;38.23=back&amp;33.16=closed&amp;39.2=none&amp;40.13=none&amp;41.15=1&amp;41.17=1&amp;41.18=1&amp;42.20=positive&amp;42.21=right&amp;42.22=top&amp;42.23=back&amp;43.1=wK_t&amp;43.4=false&amp;43.5=192&amp;43.6=192&amp;43.7=gaussian&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;43.16=open&amp;44.1=input_t&amp;44.4=false&amp;44.5=192&amp;44.6=256&amp;44.7=gaussian&amp;44.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;44.9=-1&amp;44.10=1&amp;44.11=0&amp;44.0=&amp;44.16=open&amp;39.1=K_t&amp;39.4=true&amp;39.16=closed&amp;45.13=vmprod&amp;46.15=1&amp;46.16=open&amp;46.17=1&amp;46.18=1&amp;47.20=negative&amp;47.21=left&amp;47.22=top&amp;47.23=front&amp;32.16=closed&amp;48.1=V&amp;48.4=true&amp;48.2=none&amp;49.1=input&amp;49.4=false&amp;49.5=256&amp;49.6=192&amp;49.7=gaussian&amp;49.9=-1&amp;49.10=1&amp;49.11=0&amp;49.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;49.0=&amp;49.16=open&amp;50.1=wV&amp;50.4=false&amp;50.5=192&amp;50.6=192&amp;50.7=gaussian&amp;50.9=-1&amp;50.10=1&amp;50.11=0&amp;50.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;50.0=&amp;50.16=open&amp;51.13=none&amp;52.15=1&amp;52.17=1&amp;52.18=1&amp;53.20=negative&amp;53.21=right&amp;53.22=top&amp;53.23=back&amp;48.16=closed&amp;28.16=open&amp;54.1=wO&amp;54.4=false&amp;54.5=192&amp;54.6=192&amp;54.7=gaussian&amp;54.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;54.9=-1&amp;54.10=0.996&amp;54.11=0&amp;54.0=&amp;54.16=closed&amp;24.1=attn_out&amp;24.4=true&amp;24.16=closed&amp;55.1=FFN_1&amp;55.4=false&amp;55.5=192&amp;55.6=768&amp;55.7=gaussian&amp;55.8=&amp;55.9=-1&amp;55.10=1&amp;55.11=0&amp;55.0=&amp;55.16=closed&amp;3.16=open&amp;56.1=FFN_2&amp;56.4=false&amp;56.5=768&amp;56.6=192&amp;56.7=gaussian&amp;56.8=&amp;56.9=-1&amp;56.10=1&amp;56.11=0&amp;56.0=&amp;56.16=closed&amp;57.58=sync&amp;57.59=16&amp;57.60=false&amp;57.13=none&amp;57.61=0&amp;57.16=closed&amp;62.17=1&amp;62.15=8&amp;62.18=1&amp;62.16=closed&amp;63.64=blocks&amp;63.65=8&amp;63.66=0&amp;63.67=1&amp;63.68=0&amp;63.20=negative&amp;63.21=left&amp;63.22=top&amp;63.23=front&amp;63.16=closed&amp;69.70=10&amp;69.71=true&amp;69.72=4&amp;69.73=0.507&amp;69.74=0.524&amp;69.75=0.5&amp;69.76=12&amp;69.77=false&amp;69.78=false&amp;69.16=closed&amp;79.80=local&amp;79.81=0.1&amp;79.82=0.2&amp;79.83=0.9&amp;79.84=2&amp;79.85=0.75&amp;79.86=0.75&amp;79.87=0.03&amp;79.16=closed&amp;88.8=&amp;88.16=open&amp;89.90=-725.0392607527422&amp;89.91=909.2543497392985&amp;89.92=1420.9035091451585&amp;93.90=84.4062135237143&amp;93.91=2.295441349889614&amp;93.92=60.16668289640925&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k+blocks=15&amp;folder=16&amp;i+blocks=17&amp;j+blocks=18&amp;left.layout=19&amp;polarity=20&amp;left+placement=21&amp;right+placement=22&amp;result+placement=23&amp;left.left=24&amp;left.left.anim=25&amp;left.left.block=26&amp;left.left.layout=27&amp;left.left.left=28&amp;left.left.left.anim=29&amp;left.left.left.block=30&amp;left.left.left.layout=31&amp;left.left.left.left=32&amp;left.left.left.left.left=33&amp;left.left.left.left.left.left=34&amp;left.left.left.left.left.right=35&amp;left.left.left.left.left.anim=36&amp;left.left.left.left.left.block=37&amp;left.left.left.left.left.layout=38&amp;left.left.left.left.right=39&amp;left.left.left.left.right.anim=40&amp;left.left.left.left.right.block=41&amp;left.left.left.left.right.layout=42&amp;left.left.left.left.right.left=43&amp;left.left.left.left.right.right=44&amp;left.left.left.left.anim=45&amp;left.left.left.left.block=46&amp;left.left.left.left.layout=47&amp;left.left.left.right=48&amp;left.left.left.right.left=49&amp;left.left.left.right.right=50&amp;left.left.left.right.anim=51&amp;left.left.left.right.block=52&amp;left.left.left.right.layout=53&amp;left.left.right=54&amp;left.right=55&amp;right=56&amp;anim=57&amp;fuse=58&amp;speed=59&amp;hide+inputs=60&amp;spin=61&amp;block=62&amp;layout=63&amp;scheme=64&amp;gap=65&amp;scatter=66&amp;molecule=67&amp;blast=68&amp;deco=69&amp;legends=70&amp;shape=71&amp;spotlight=72&amp;row+guides=73&amp;flow+guides=74&amp;lens+size=75&amp;magnification=76&amp;interior+spotlight=77&amp;axes=78&amp;viz=79&amp;sensitivity=80&amp;min+size=81&amp;min+light=82&amp;max+light=83&amp;elem+scale=84&amp;zero+hue=85&amp;hue+gap=86&amp;hue+spread=87&amp;diag=88&amp;cam=89&amp;x=90&amp;y=91&amp;z=92&amp;cam.target=93&amp;compress=94">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/attnlayer_ffnsplitk.jpg" alt="what this partition looks like applied to an otherwise unpartitioned attention layer" style="width:100%" /></p>

<p>And here it is applied to a layer partitioned a la BPT (<a href="https://bhosmer.github.io/mm/index.html?0=layer_out+%3D+%28attn_out+%3D+%28attn+%3D+%28Q+%3D+input+%40+wQ%29+%40+%28K_t+%3D+wK_t+%40+input_t%29%29+%40+%28V+%3D+input+%40+wV%29+%40+wO%29+%40+FFN_1+%40+FFN_2&amp;1=layer_out&amp;2=layernorm&amp;16=closed&amp;94=true&amp;3.1=attn_out+%40+FFN_1&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row+major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=gelu&amp;12.13=inherit&amp;14.15=1&amp;14.16=open&amp;14.17=8&amp;14.18=8&amp;19.20=positive&amp;19.21=left&amp;19.22=bottom&amp;19.23=back&amp;24.2=layernorm&amp;25.13=inherit&amp;26.15=1&amp;26.16=closed&amp;26.17=8&amp;26.18=1&amp;27.20=negative&amp;27.21=left&amp;27.22=top&amp;27.23=front&amp;28.1=attn+%40+V&amp;28.4=true&amp;28.5=32&amp;28.6=32&amp;28.7=row+major&amp;28.8=&amp;28.9=-1&amp;28.10=1&amp;28.11=0&amp;28.2=none&amp;29.13=vmprod&amp;30.15=8&amp;30.16=open&amp;30.17=8&amp;30.18=1&amp;31.20=positive&amp;31.21=left&amp;31.22=bottom&amp;31.23=back&amp;32.1=attn&amp;32.4=true&amp;32.2=softmax%28tril%28x%2Fsqrt%28k%29%29%29&amp;33.1=Q&amp;33.4=true&amp;33.2=none&amp;34.1=input&amp;34.4=false&amp;34.5=256&amp;34.6=192&amp;34.7=gaussian&amp;34.9=-1&amp;34.10=1&amp;34.11=0&amp;34.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;34.0=&amp;34.16=open&amp;35.1=wQ&amp;35.4=false&amp;35.5=192&amp;35.6=192&amp;35.7=gaussian&amp;35.9=-1&amp;35.10=1&amp;35.11=0&amp;35.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;35.0=&amp;35.16=open&amp;36.13=vmprod&amp;37.15=1&amp;37.17=8&amp;37.18=1&amp;38.20=positive&amp;38.21=left&amp;38.22=bottom&amp;38.23=back&amp;33.16=closed&amp;39.2=none&amp;40.13=none&amp;41.15=1&amp;41.17=1&amp;41.18=1&amp;42.20=positive&amp;42.21=right&amp;42.22=top&amp;42.23=back&amp;43.1=wK_t&amp;43.4=false&amp;43.5=192&amp;43.6=192&amp;43.7=gaussian&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wk_t4_64_768.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;43.16=open&amp;44.1=input_t&amp;44.4=false&amp;44.5=192&amp;44.6=256&amp;44.7=gaussian&amp;44.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;44.9=-1&amp;44.10=1&amp;44.11=0&amp;44.0=&amp;44.16=open&amp;39.1=K_t&amp;39.4=true&amp;39.16=closed&amp;45.13=vmprod&amp;46.15=1&amp;46.16=open&amp;46.17=8&amp;46.18=1&amp;47.20=negative&amp;47.21=left&amp;47.22=top&amp;47.23=front&amp;32.16=closed&amp;48.1=V&amp;48.4=true&amp;48.2=none&amp;49.1=input&amp;49.4=false&amp;49.5=256&amp;49.6=192&amp;49.7=gaussian&amp;49.9=-1&amp;49.10=1&amp;49.11=0&amp;49.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;49.0=&amp;49.16=open&amp;50.1=wV&amp;50.4=false&amp;50.5=192&amp;50.6=192&amp;50.7=gaussian&amp;50.9=-1&amp;50.10=1&amp;50.11=0&amp;50.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;50.0=&amp;50.16=open&amp;51.13=none&amp;52.15=1&amp;52.17=1&amp;52.18=1&amp;53.20=negative&amp;53.21=right&amp;53.22=top&amp;53.23=back&amp;48.16=closed&amp;28.16=open&amp;54.1=wO&amp;54.4=false&amp;54.5=192&amp;54.6=192&amp;54.7=gaussian&amp;54.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;54.9=-1&amp;54.10=0.996&amp;54.11=0&amp;54.0=&amp;54.16=closed&amp;24.1=attn_out&amp;24.4=true&amp;24.16=closed&amp;55.1=FFN_1&amp;55.4=false&amp;55.5=192&amp;55.6=768&amp;55.7=gaussian&amp;55.8=&amp;55.9=-1&amp;55.10=1&amp;55.11=0&amp;55.0=&amp;55.16=closed&amp;3.16=open&amp;56.1=FFN_2&amp;56.4=false&amp;56.5=768&amp;56.6=192&amp;56.7=gaussian&amp;56.8=&amp;56.9=-1&amp;56.10=1&amp;56.11=0&amp;56.0=&amp;56.16=closed&amp;57.58=sync&amp;57.59=16&amp;57.60=false&amp;57.13=none&amp;57.61=0&amp;57.16=closed&amp;62.17=8&amp;62.15=8&amp;62.18=1&amp;62.16=open&amp;63.64=blocks&amp;63.65=8&amp;63.66=0&amp;63.67=1&amp;63.68=0&amp;63.20=negative&amp;63.21=left&amp;63.22=top&amp;63.23=front&amp;63.16=closed&amp;69.70=10&amp;69.71=true&amp;69.72=4&amp;69.73=0.507&amp;69.74=0.524&amp;69.75=0.5&amp;69.76=12&amp;69.77=false&amp;69.78=false&amp;69.16=closed&amp;79.80=local&amp;79.81=0.1&amp;79.82=0.2&amp;79.83=0.9&amp;79.84=2&amp;79.85=0.75&amp;79.86=0.75&amp;79.87=0.03&amp;79.16=closed&amp;88.8=&amp;88.16=open&amp;89.90=-908.5990219796431&amp;89.91=1012.984380609292&amp;89.92=1378.7815259698948&amp;93.90=57.978218494193676&amp;93.91=-30.847130586978256&amp;93.92=41.66771129059017&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k+blocks=15&amp;folder=16&amp;i+blocks=17&amp;j+blocks=18&amp;left.layout=19&amp;polarity=20&amp;left+placement=21&amp;right+placement=22&amp;result+placement=23&amp;left.left=24&amp;left.left.anim=25&amp;left.left.block=26&amp;left.left.layout=27&amp;left.left.left=28&amp;left.left.left.anim=29&amp;left.left.left.block=30&amp;left.left.left.layout=31&amp;left.left.left.left=32&amp;left.left.left.left.left=33&amp;left.left.left.left.left.left=34&amp;left.left.left.left.left.right=35&amp;left.left.left.left.left.anim=36&amp;left.left.left.left.left.block=37&amp;left.left.left.left.left.layout=38&amp;left.left.left.left.right=39&amp;left.left.left.left.right.anim=40&amp;left.left.left.left.right.block=41&amp;left.left.left.left.right.layout=42&amp;left.left.left.left.right.left=43&amp;left.left.left.left.right.right=44&amp;left.left.left.left.anim=45&amp;left.left.left.left.block=46&amp;left.left.left.left.layout=47&amp;left.left.left.right=48&amp;left.left.left.right.left=49&amp;left.left.left.right.right=50&amp;left.left.left.right.anim=51&amp;left.left.left.right.block=52&amp;left.left.left.right.layout=53&amp;left.left.right=54&amp;left.right=55&amp;right=56&amp;anim=57&amp;fuse=58&amp;speed=59&amp;hide+inputs=60&amp;spin=61&amp;block=62&amp;layout=63&amp;scheme=64&amp;gap=65&amp;scatter=66&amp;molecule=67&amp;blast=68&amp;deco=69&amp;legends=70&amp;shape=71&amp;spotlight=72&amp;row+guides=73&amp;flow+guides=74&amp;lens+size=75&amp;magnification=76&amp;interior+spotlight=77&amp;axes=78&amp;viz=79&amp;sensitivity=80&amp;min+size=81&amp;min+light=82&amp;max+light=83&amp;elem+scale=84&amp;zero+hue=85&amp;hue+gap=86&amp;hue+spread=87&amp;diag=88&amp;cam=89&amp;x=90&amp;y=91&amp;z=92&amp;cam.target=93&amp;compress=94">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/bptlayer_ffnsplitk.jpg" alt="applied to a layer partitioned a la BPT" style="width:100%" /></p>

<h3 id="6d-visualizing-token-at-a-time-decoding">6d Visualizing token-at-a-time decoding</h3>

<p>During autoregressive token-at-a-time decoding, the query vector consists of a single token. It’s instructive to have a mental picture of what an attention layer looks like in that situation - a single embedding row working its way through an enormous tiled plane of weights.</p>

<p>Aside from the emphasizing the sheer immensity of weights compared to activations, this view is also evocative of the notion that <code class="language-plaintext highlighter-rouge">K_t</code> and <code class="language-plaintext highlighter-rouge">V</code> function like dynamically generated layers in a 6-layer MLP, although the mux/demux computations of MHA itself (papered over here, per above) make the correspondence inexact (<a href="https://bhosmer.github.io/mm/index.html?0=layer_out%20%3D%20(attn_out%20%3D%20(attn%20%3D%20(Q%20%3D%20input%20%40%20wQ)%20%40%20K_t)%20%40%20V%20%40%20wO)%20%40%20FFN_1%20%40%20FFN_2&amp;1=layer_out&amp;2=layernorm&amp;16=closed&amp;84=true&amp;3.1=attn_out%20%40%20FFN_1&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=row%20major&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=gelu&amp;12.13=inherit&amp;14.15=1&amp;14.16=open&amp;17.18=positive&amp;17.19=left&amp;17.20=bottom&amp;17.21=back&amp;22.2=layernorm&amp;23.13=inherit&amp;24.15=1&amp;24.16=open&amp;25.18=negative&amp;25.19=left&amp;25.20=top&amp;25.21=front&amp;26.1=attn%20%40%20V&amp;26.4=true&amp;26.5=32&amp;26.6=32&amp;26.7=row%20major&amp;26.8=&amp;26.9=-1&amp;26.10=1&amp;26.11=0&amp;26.2=none&amp;27.13=vmprod&amp;28.15=1&amp;28.16=open&amp;29.18=positive&amp;29.19=left&amp;29.20=bottom&amp;29.21=back&amp;30.1=attn&amp;30.4=true&amp;30.2=softmax(tril(x%2Fsqrt(k)))&amp;31.1=Q&amp;31.4=true&amp;31.2=none&amp;32.1=input&amp;32.4=false&amp;32.5=1&amp;32.6=192&amp;32.7=gaussian&amp;32.9=-1&amp;32.10=1&amp;32.11=0&amp;32.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input0_256_768.csv&amp;32.0=&amp;32.16=open&amp;33.1=wQ&amp;33.4=false&amp;33.5=192&amp;33.6=192&amp;33.7=gaussian&amp;33.9=-1&amp;33.10=1&amp;33.11=0&amp;33.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wq4_768_64.csv&amp;33.0=&amp;33.16=open&amp;34.13=vmprod&amp;35.15=1&amp;36.18=positive&amp;36.19=left&amp;36.20=bottom&amp;36.21=back&amp;31.16=open&amp;37.1=K_t&amp;37.4=false&amp;37.5=192&amp;37.6=256&amp;37.7=gaussian&amp;37.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_input_t0_768_256.csv&amp;37.9=-1&amp;37.10=1&amp;37.11=0&amp;37.0=&amp;37.16=open&amp;38.13=vmprod&amp;39.15=1&amp;39.16=open&amp;40.18=negative&amp;40.19=left&amp;40.20=top&amp;40.21=front&amp;30.16=open&amp;41.1=V&amp;41.4=false&amp;41.16=open&amp;41.5=256&amp;41.6=192&amp;41.7=gaussian&amp;41.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wv4_768_64.csv&amp;41.0=&amp;41.9=-1&amp;41.10=1&amp;41.11=0&amp;26.16=open&amp;42.1=wO&amp;42.4=false&amp;42.5=192&amp;42.6=192&amp;42.7=gaussian&amp;42.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer5_wo4_64_768.csv&amp;42.9=-1&amp;42.10=0.996&amp;42.11=0&amp;42.0=&amp;42.16=closed&amp;22.1=attn_out&amp;22.4=true&amp;22.16=open&amp;43.1=FFN_1&amp;43.4=false&amp;43.5=192&amp;43.6=768&amp;43.7=gaussian&amp;43.8=&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;43.16=closed&amp;3.16=open&amp;44.1=FFN_2&amp;44.4=false&amp;44.5=768&amp;44.6=192&amp;44.7=gaussian&amp;44.8=&amp;44.9=-1&amp;44.10=1&amp;44.11=0&amp;44.0=&amp;44.16=closed&amp;45.46=sync&amp;45.47=16&amp;45.48=false&amp;45.13=none&amp;45.49=0&amp;45.16=closed&amp;50.51=1&amp;50.52=1&amp;50.15=1&amp;50.16=closed&amp;53.54=blocks&amp;53.55=8&amp;53.56=0&amp;53.57=1&amp;53.58=0&amp;53.18=negative&amp;53.19=left&amp;53.20=top&amp;53.21=front&amp;53.16=closed&amp;59.60=10&amp;59.61=true&amp;59.62=4&amp;59.63=0.507&amp;59.64=0.524&amp;59.65=0.5&amp;59.66=12&amp;59.67=false&amp;59.68=false&amp;59.16=closed&amp;69.70=local&amp;69.71=0.1&amp;69.72=0.2&amp;69.73=0.9&amp;69.74=2&amp;69.75=0.75&amp;69.76=0.75&amp;69.77=0.03&amp;69.16=closed&amp;78.8=&amp;78.16=open&amp;79.80=-621.3352100945762&amp;79.81=774.3199147754915&amp;79.82=806.172978523008&amp;83.80=0&amp;83.81=0&amp;83.82=0&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;left.block=14&amp;k%20blocks=15&amp;folder=16&amp;left.layout=17&amp;polarity=18&amp;left%20placement=19&amp;right%20placement=20&amp;result%20placement=21&amp;left.left=22&amp;left.left.anim=23&amp;left.left.block=24&amp;left.left.layout=25&amp;left.left.left=26&amp;left.left.left.anim=27&amp;left.left.left.block=28&amp;left.left.left.layout=29&amp;left.left.left.left=30&amp;left.left.left.left.left=31&amp;left.left.left.left.left.left=32&amp;left.left.left.left.left.right=33&amp;left.left.left.left.left.anim=34&amp;left.left.left.left.left.block=35&amp;left.left.left.left.left.layout=36&amp;left.left.left.left.right=37&amp;left.left.left.left.anim=38&amp;left.left.left.left.block=39&amp;left.left.left.left.layout=40&amp;left.left.left.right=41&amp;left.left.right=42&amp;left.right=43&amp;right=44&amp;anim=45&amp;fuse=46&amp;speed=47&amp;hide%20inputs=48&amp;spin=49&amp;block=50&amp;i%20blocks=51&amp;j%20blocks=52&amp;layout=53&amp;scheme=54&amp;gap=55&amp;scatter=56&amp;molecule=57&amp;blast=58&amp;deco=59&amp;legends=60&amp;shape=61&amp;spotlight=62&amp;row%20guides=63&amp;flow%20guides=64&amp;lens%20size=65&amp;magnification=66&amp;interior%20spotlight=67&amp;axes=68&amp;viz=69&amp;sensitivity=70&amp;min%20size=71&amp;min%20light=72&amp;max%20light=73&amp;elem%20scale=74&amp;zero%20hue=75&amp;hue%20gap=76&amp;hue%20spread=77&amp;diag=78&amp;cam=79&amp;x=80&amp;y=81&amp;z=82&amp;cam.target=83&amp;compress=84">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/decoding.jpg" alt="the mux/demux computations of MHA itself" style="width:100%" /></p>

<h2 id="7-lora">7 LoRA</h2>

<p>The recent LoRA paper (<a href="https://arxiv.org/pdf/2106.09685.pdf">LoRA: Low-Rank Adaptation of Large Language Models</a>) describes an efficient finetuning technique based on the idea that weight deltas introduced during finetuning are low-rank. Per the paper, this “allows us to train some dense layers in a neural network indirectly by optimizing rank decomposition matrices of the dense layers’ change during adaptation […], while keeping the pre-trained weights frozen.”</p>

<h3 id="7a-the-basic-idea">7a The basic idea</h3>

<p>In a nutshell, the key move is to train the <em>factors</em> of a weight matrix rather than the matrix itself: replace an <code class="language-plaintext highlighter-rouge">I x J</code> weights tensor with a matmul of an <code class="language-plaintext highlighter-rouge">I x K</code> tensor and a <code class="language-plaintext highlighter-rouge">K x J</code> tensor, holding <code class="language-plaintext highlighter-rouge">K</code> to some small number.</p>

<p>If <code class="language-plaintext highlighter-rouge">K</code> is small enough the size win can be huge, but the tradeoff is that lowering it lowers the rank of what the product can express. As a quick illustration of both the size savings and the structuring effect on the result, here’s a matmul of random <code class="language-plaintext highlighter-rouge">128 x 4</code> left and <code class="language-plaintext highlighter-rouge">4 x 128</code> right arguments - a.k.a. a rank-4 factorization of a <code class="language-plaintext highlighter-rouge">128 x 128</code> matrix. Notice the vertical and horizontal patterning in <code class="language-plaintext highlighter-rouge">L @ R</code> (<a href="https://bhosmer.github.io/mm/?0=L%20%40%20R&amp;1=L%20%40%20R&amp;2=none&amp;12=closed&amp;59=true&amp;3.1=L&amp;3.4=false&amp;3.5=128&amp;3.6=4&amp;3.7=gaussian&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.0=&amp;3.12=open&amp;13.1=R&amp;13.4=false&amp;13.5=4&amp;13.6=128&amp;13.7=gaussian&amp;13.8=&amp;13.9=-1&amp;13.10=1&amp;13.11=0&amp;13.0=&amp;14.15=none&amp;14.16=1&amp;14.17=false&amp;14.18=none&amp;14.19=0&amp;14.20=1&amp;14.21=1&amp;14.22=1&amp;23.20=1&amp;23.22=1&amp;23.21=1&amp;24.25=blocks&amp;24.26=11.214&amp;24.27=0&amp;24.28=1&amp;24.29=0&amp;24.30=negative&amp;24.31=left&amp;24.32=top&amp;24.33=front&amp;24.12=open&amp;34.35=10&amp;34.36=true&amp;34.37=2&amp;34.38=1&amp;34.39=0&amp;34.40=0.5&amp;34.41=10&amp;34.42=false&amp;34.43=false&amp;34.12=open&amp;44.45=local&amp;44.46=0.3&amp;44.47=0.5&amp;44.48=0.7&amp;44.49=1.25&amp;44.50=0.77&amp;44.51=0.74&amp;44.52=0.04&amp;44.12=open&amp;53.8=&amp;54.55=-147.50937470998977&amp;54.56=141.1312665550063&amp;54.57=104.24779022699425&amp;58.55=-7.97607936427614&amp;58.56=3.391570600844088&amp;58.57=-11.685048965074932&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;folder=12&amp;right=13&amp;anim=14&amp;fuse=15&amp;speed=16&amp;hide%20inputs=17&amp;alg=18&amp;spin=19&amp;i%20blocks=20&amp;k%20blocks=21&amp;j%20blocks=22&amp;block=23&amp;layout=24&amp;scheme=25&amp;gap=26&amp;scatter=27&amp;molecule=28&amp;blast=29&amp;polarity=30&amp;left%20placement=31&amp;right%20placement=32&amp;result%20placement=33&amp;deco=34&amp;legends=35&amp;shape=36&amp;spotlight=37&amp;row%20guides=38&amp;flow%20guides=39&amp;lens%20size=40&amp;magnification=41&amp;interior%20spotlight=42&amp;axes=43&amp;viz=44&amp;sensitivity=45&amp;min%20size=46&amp;min%20light=47&amp;max%20light=48&amp;elem%20scale=49&amp;zero%20hue=50&amp;hue%20gap=51&amp;hue%20spread=52&amp;diag=53&amp;cam=54&amp;x=55&amp;y=56&amp;z=57&amp;cam.target=58&amp;compress=59">open in mm</a>):</p>

<p><img src="/assets/images/inside-the-matrix/lora_single.jpg" alt="a matmul of random 128 x 4 left and 4 x 128 right arguments" style="width:100%" /></p>

<h3 id="7b-applying-lora-to-an-attention-head">7b Applying LoRA to an attention head</h3>

<p>The way LoRA applies this factoring move to the fine tuning process is to</p>

<ul>
  <li>create a low-rank factorization for each weight tensor to be fine-tuned and train the factors, keeping the original weights frozen</li>
  <li>after fine tuning, multiply each pair of low-rank factors to get a matrix in the shape of the original weights tensor, and add it to the original pretrained weights tensor</li>
</ul>

<p>The following visualization shows an attention head with the weight tensors <code class="language-plaintext highlighter-rouge">wQ</code>, <code class="language-plaintext highlighter-rouge">wK_t</code>, <code class="language-plaintext highlighter-rouge">wV</code>, <code class="language-plaintext highlighter-rouge">wO</code> replaced by low rank factorizations <code class="language-plaintext highlighter-rouge">wQ_A @ wQ_B</code>, etc. Visually, the factor matrices show up as low fences along the edges of the windmill blades (<a href="https://bhosmer.github.io/mm/index.html?0=out%20%3D%20(attn%20%3D%20(Q%20%3D%20input%20%40%20(wQ%20%3D%20wQ_A%20%40%20wQ_B))%20%40%20(K_t%20%3D%20(wK_t%20%3D%20wK_t_A%20%40%20wK_t_B)%20%40%20input_t))%20%40%20(V%20%3D%20input%20%40%20(wV%20%3D%20wV_A%20%40%20wV_B))%20%40%20(wO%20%3D%20wO_A%20%40%20wO_B)&amp;1=out&amp;2=none&amp;15=closed&amp;104=true&amp;3.1=attn%20%40%20V&amp;3.4=true&amp;3.5=32&amp;3.6=32&amp;3.7=rows&amp;3.8=&amp;3.9=-1&amp;3.10=1&amp;3.11=0&amp;3.2=none&amp;12.13=inherit&amp;12.14=1&amp;12.15=open&amp;16.17=positive&amp;16.18=left&amp;16.19=bottom&amp;16.20=back&amp;21.1=attn&amp;21.4=true&amp;21.2=softmax(tril(x%2Fsqrt(k)))&amp;22.1=Q&amp;22.4=true&amp;22.2=none&amp;23.1=input&amp;23.4=false&amp;23.5=64&amp;23.6=96&amp;23.7=gaussian&amp;23.9=-1&amp;23.10=1&amp;23.11=0&amp;23.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;23.0=&amp;23.15=closed&amp;24.1=wQ&amp;24.4=true&amp;24.2=none&amp;25.1=wQ_A&amp;25.4=false&amp;25.5=96&amp;25.6=8&amp;25.7=gaussian&amp;25.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wq0_768_64.csv&amp;25.9=-1&amp;25.10=1&amp;25.11=0&amp;25.0=&amp;25.15=closed&amp;26.1=wQ_B&amp;26.4=false&amp;26.5=8&amp;26.6=32&amp;26.7=gaussian&amp;26.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wq0_768_64.csv&amp;26.9=-1&amp;26.10=1&amp;26.11=0&amp;26.0=&amp;26.15=open&amp;27.13=inherit&amp;27.14=1&amp;27.15=closed&amp;28.17=negative&amp;28.18=right&amp;28.19=top&amp;28.20=back&amp;29.30=1&amp;24.15=closed&amp;31.13=inherit&amp;31.14=1&amp;31.15=closed&amp;32.17=positive&amp;32.18=left&amp;32.19=bottom&amp;32.20=back&amp;33.30=1&amp;22.15=closed&amp;34.2=none&amp;35.13=inherit&amp;35.14=1&amp;35.15=closed&amp;36.17=positive&amp;36.18=right&amp;36.19=top&amp;36.20=back&amp;37.1=wK_t&amp;37.4=true&amp;37.2=none&amp;38.1=wK_t_A&amp;38.4=false&amp;38.5=32&amp;38.6=8&amp;38.7=gaussian&amp;38.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wk_t0_64_768.csv&amp;38.9=-1&amp;38.10=1&amp;38.11=0&amp;38.0=&amp;38.15=open&amp;39.1=wK_t_B&amp;39.4=false&amp;39.5=8&amp;39.6=96&amp;39.7=gaussian&amp;39.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wk_t0_64_768.csv&amp;39.9=-1&amp;39.10=1&amp;39.11=0&amp;39.0=&amp;39.15=closed&amp;40.13=inherit&amp;40.14=1&amp;40.15=open&amp;41.17=negative&amp;41.18=left&amp;41.19=bottom&amp;41.20=back&amp;42.30=1&amp;37.15=closed&amp;43.1=input_t&amp;43.4=false&amp;43.5=96&amp;43.6=64&amp;43.7=gaussian&amp;43.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input_t0_768_256.csv&amp;43.9=-1&amp;43.10=1&amp;43.11=0&amp;43.0=&amp;43.15=closed&amp;34.1=K_t&amp;34.4=true&amp;44.30=1&amp;34.15=closed&amp;45.13=inherit&amp;45.14=1&amp;45.15=closed&amp;46.17=negative&amp;46.18=left&amp;46.19=top&amp;46.20=front&amp;47.30=1&amp;21.15=closed&amp;48.1=V&amp;48.4=true&amp;48.2=none&amp;49.1=input&amp;49.4=false&amp;49.5=64&amp;49.6=96&amp;49.7=gaussian&amp;49.9=-1&amp;49.10=1&amp;49.11=0&amp;49.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_input0_256_768.csv&amp;49.0=&amp;49.15=closed&amp;50.1=wV&amp;50.4=true&amp;50.2=none&amp;51.1=wV_A&amp;51.4=false&amp;51.5=96&amp;51.6=8&amp;51.7=gaussian&amp;51.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wv0_768_64.csv&amp;51.9=-1&amp;51.10=1&amp;51.11=0&amp;51.0=&amp;51.15=open&amp;52.1=wV_B&amp;52.4=false&amp;52.5=8&amp;52.6=32&amp;52.7=gaussian&amp;52.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wv0_768_64.csv&amp;52.9=-1&amp;52.10=1&amp;52.11=0&amp;52.0=&amp;52.15=open&amp;53.13=inherit&amp;53.14=1&amp;53.15=open&amp;54.17=positive&amp;54.18=left&amp;54.19=bottom&amp;54.20=back&amp;55.30=1&amp;50.15=closed&amp;56.13=inherit&amp;56.14=1&amp;56.15=closed&amp;57.17=negative&amp;57.18=right&amp;57.19=top&amp;57.20=back&amp;58.30=1&amp;48.15=closed&amp;3.15=closed&amp;59.30=1&amp;60.1=wO&amp;60.4=true&amp;60.5=32&amp;60.6=32&amp;60.7=cols&amp;60.8=&amp;60.9=-1&amp;60.10=1&amp;60.11=0&amp;60.2=none&amp;61.1=wO_A&amp;61.4=false&amp;61.5=32&amp;61.6=8&amp;61.7=gaussian&amp;61.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wo0_64_768.csv&amp;61.9=-1&amp;61.10=1&amp;61.11=0&amp;61.0=&amp;61.15=open&amp;62.1=wO_B&amp;62.4=false&amp;62.5=8&amp;62.6=96&amp;62.7=gaussian&amp;62.8=https%3A%2F%2Fraw.githubusercontent.com%2Fbhosmer%2Ftestdata%2Fmain%2Fweights%2Fgpt2%2Flayer0_wo0_64_768.csv&amp;62.9=-1&amp;62.10=1&amp;62.11=0&amp;62.0=&amp;62.15=closed&amp;63.13=inherit&amp;63.14=1&amp;63.15=closed&amp;64.17=positive&amp;64.18=right&amp;64.19=top&amp;64.20=back&amp;60.15=closed&amp;65.30=1&amp;66.67=none&amp;66.68=100&amp;66.69=false&amp;66.13=none&amp;66.70=-3&amp;66.71=1&amp;66.30=1&amp;66.14=1&amp;66.15=open&amp;72.71=1&amp;72.14=1&amp;72.30=1&amp;73.74=blocks&amp;73.75=2&amp;73.76=8&amp;73.77=2&amp;73.78=0&amp;73.17=negative&amp;73.18=left&amp;73.19=top&amp;73.20=front&amp;73.15=closed&amp;79.80=6.5&amp;79.81=false&amp;79.82=1&amp;79.83=1&amp;79.84=0.757&amp;79.85=0.5&amp;79.86=10&amp;79.87=false&amp;79.88=false&amp;79.15=open&amp;89.90=local&amp;89.91=0.2&amp;89.92=0.3&amp;89.93=1&amp;89.94=1.25&amp;89.95=0.75&amp;89.96=0.75&amp;89.97=0.03&amp;89.15=closed&amp;98.8=&amp;98.15=closed&amp;99.100=-172.19348886030096&amp;99.101=179.87607098671913&amp;99.102=291.20723943546824&amp;103.100=-6.083689158200286&amp;103.101=-2.2203698054118064&amp;103.102=-20.406063431589725&amp;expr=0&amp;name=1&amp;epilog=2&amp;left=3&amp;matmul=4&amp;h=5&amp;w=6&amp;init=7&amp;url=8&amp;min=9&amp;max=10&amp;dropout=11&amp;left.anim=12&amp;alg=13&amp;j%20blocks=14&amp;folder=15&amp;left.layout=16&amp;polarity=17&amp;left%20placement=18&amp;right%20placement=19&amp;result%20placement=20&amp;left.left=21&amp;left.left.left=22&amp;left.left.left.left=23&amp;left.left.left.right=24&amp;left.left.left.right.left=25&amp;left.left.left.right.right=26&amp;left.left.left.right.anim=27&amp;left.left.left.right.layout=28&amp;left.left.left.right.block=29&amp;k%20blocks=30&amp;left.left.left.anim=31&amp;left.left.left.layout=32&amp;left.left.left.block=33&amp;left.left.right=34&amp;left.left.right.anim=35&amp;left.left.right.layout=36&amp;left.left.right.left=37&amp;left.left.right.left.left=38&amp;left.left.right.left.right=39&amp;left.left.right.left.anim=40&amp;left.left.right.left.layout=41&amp;left.left.right.left.block=42&amp;left.left.right.right=43&amp;left.left.right.block=44&amp;left.left.anim=45&amp;left.left.layout=46&amp;left.left.block=47&amp;left.right=48&amp;left.right.left=49&amp;left.right.right=50&amp;left.right.right.left=51&amp;left.right.right.right=52&amp;left.right.right.anim=53&amp;left.right.right.layout=54&amp;left.right.right.block=55&amp;left.right.anim=56&amp;left.right.layout=57&amp;left.right.block=58&amp;left.block=59&amp;right=60&amp;right.left=61&amp;right.right=62&amp;right.anim=63&amp;right.layout=64&amp;right.block=65&amp;anim=66&amp;fuse=67&amp;speed=68&amp;hide%20inputs=69&amp;spin=70&amp;i%20blocks=71&amp;block=72&amp;layout=73&amp;scheme=74&amp;gap=75&amp;scatter=76&amp;molecule=77&amp;blast=78&amp;deco=79&amp;legends=80&amp;shape=81&amp;spotlight=82&amp;row%20guides=83&amp;flow%20guides=84&amp;lens%20size=85&amp;magnification=86&amp;interior%20spotlight=87&amp;axes=88&amp;viz=89&amp;sensitivity=90&amp;min%20size=91&amp;min%20light=92&amp;max%20light=93&amp;elem%20scale=94&amp;zero%20hue=95&amp;hue%20gap=96&amp;hue%20spread=97&amp;diag=98&amp;cam=99&amp;x=100&amp;y=101&amp;z=102&amp;cam.target=103&amp;compress=104">open in mm</a> - spacebar stops the spin):</p>

<p align="center">
  <video width="100%" controls="">
    <source src="/assets/videos/inside-the-matrix/lora_spin4b.mp4" type="video/mp4" />
  </video>
</p>

<h2 id="8-wrapup">8 Wrapup</h2>

<h3 id="8a-call-for-feedback">8a Call for feedback</h3>

<p>I’ve found this way of visualizing matmul expressions extremely helpful for building intuition and reasoning about not just matrix multiplication itself, but also many aspects of ML models and their computation, from efficiency to interpretability.</p>

<p>if you try it out and have suggestions or comments, I definitely want to hear, either in the comments here or <a href="https://github.com/bhosmer/mm">in the repo</a>.</p>

<h3 id="8b-next-steps">8b Next steps</h3>

<ul>
  <li>There’s a <a href="https://bhosmer.github.io/mm/examples/attngpt2/index.html">GPT2 attention head explorer</a> built on top of the tool which I’m currently using to inventory and classify the attention head traits found in that model. (This was the tool I used to find and explore the attention heads in this note.) Once complete I plan to post a note with the inventory.</li>
  <li>As mentioned up top, embedding these visualizations in Python notebooks is <a href="https://colab.research.google.com/drive/1wZIoU20eRWKtRNCW7e5Iugm3MhfaE1f7?usp=sharing">dead simple</a>. But session URLs can get… unwieldy, so it will be useful to have Python-side utilities for constructing them from configuration objects, similar to the simple JavaScript helpers used in the <a href="https://bhosmer.github.io/mm/ref.html">reference guide</a>.</li>
  <li>If you’ve got a use case you think might benefit from visualizations like this but it’s not obvious how to use the tool to do it, get in touch! I’m not necessarily looking to expand its core visualization capabilities that much further (right tool for the job, etc.), but e.g. the API for driving it programmatically is pretty basic, there’s plenty that can be done there.</li>
</ul>

                </article>
            </div>
        </div>
    </div>

<!--    


 -->
    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="/docs">View Docs</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="lf-grid">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org" class="footer-logo">
          <img src="/assets/images/logo-icon.svg" alt="PyTorch logo" width="40">
        </a>
      </div>

      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook"><path fill="currentColor" d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z"/></svg>	
        </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X"><path fill="currentColor" d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66"/></svg>
        </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube"><path fill="currentColor" d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z"/></svg>	
        </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn"><rect width="512" height="512" rx="0" fill="currentColor"/><circle fill="#000" cx="142" cy="138" r="37"/><path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198"/><path fill="#000" d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
        </a></li>
        <li><a href="https://social.lfx.dev/@pytorch" rel="me" target="_blank" title="PyTorch on Mastodon">
          <svg fill="currentColor" aria-label="Mastodon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" xml:space="preserve"><path d="M21.327 8.566c0-4.339-2.843-5.61-2.843-5.61-1.433-.658-3.894-.935-6.451-.956h-.063c-2.557.021-5.016.298-6.45.956 0 0-2.843 1.272-2.843 5.61 0 .993-.019 2.181.012 3.441.103 4.243.778 8.425 4.701 9.463 1.809.479 3.362.579 4.612.51 2.268-.126 3.541-.809 3.541-.809l-.075-1.646s-1.621.511-3.441.449c-1.804-.062-3.707-.194-3.999-2.409a4.523 4.523 0 0 1-.04-.621s1.77.433 4.014.536c1.372.063 2.658-.08 3.965-.236 2.506-.299 4.688-1.843 4.962-3.254.434-2.223.398-5.424.398-5.424zm-3.353 5.59h-2.081V9.057c0-1.075-.452-1.62-1.357-1.62-1 0-1.501.647-1.501 1.927v2.791h-2.069V9.364c0-1.28-.501-1.927-1.502-1.927-.905 0-1.357.546-1.357 1.62v5.099H6.026V8.903c0-1.074.273-1.927.823-2.558.566-.631 1.307-.955 2.228-.955 1.065 0 1.872.409 2.405 1.228l.518.869.519-.869c.533-.819 1.34-1.228 2.405-1.228.92 0 1.662.324 2.228.955.549.631.822 1.484.822 2.558v5.253z"/></svg>
        </a></li>
      </ul>
    </div>

    <div class="privacy-policy">
      <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation. 
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see 
          <a href="https://www.linuxfoundation.org/legal/policies/">Linux Foundation Policies</a>. The PyTorch Foundation supports the PyTorch open source 
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC, 
          please see <a href="https://www.lfprojects.org/policies/">LF Projects, LLC Policies</a>. <a href="https://www.linuxfoundation.org/privacy">Privacy Policy</a> and <a href="https://www.linuxfoundation.org/terms">Terms of Use</a>.</p>
      </div>
    </div>
  </div>
  <img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>
        <li class="navSearchWrapper reactNavSearchWrapper tabletSearchWrapper" key="search">
          <div class="mobile-search-border">
            <input
              id="mobile-search-input"
              type="text"
              title="Search"
            />
            <div id="mobile-search-icon"></div>
          </div>
        </li>

        <li class="resources-mobile-menu-title">
          <a>Learn</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/get-started">Get Started</a> 
          </li>
          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Ecosystem</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/ecosystem">Tools</a>
          </li>
          <li>
            <a href="/#community-module">Community</a>
          </li>
          <li>
            <a href="https://discuss.pytorch.org">Forums</a>
          </li>
          <li>
            <a href="/resources">Developer Resources</a>
          </li>
          <li>
            <a href="/ecosystem/contributor-awards-2023">Contributor Awards - 2023</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Edge</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/edge">About PyTorch Edge</a>
          </li>
          <li>
            <a href="/executorch-overview">ExecuTorch</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Docs</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/docs">PyTorch</a>
          </li>
          <li>
            <a href="/pytorch-domains">PyTorch Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/blog">PyTorch Blog</a>
          </li>
          <li>
            <a href="/community-blog">Community Blog</a>
          </li>
          <li>
            <a href="/videos">Videos</a>
          </li>
          <li>
            <a href="/community-stories">Community Stories</a>
          </li>
          <li>
            <a href="/events">Events</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="/governing-board">Governing Board</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a href="/join">Become a Member</a>
        </li>
        <li class="resources-mobile-menu-title">
          <a href="https://github.com/pytorch/pytorch" title="Go to PyTorch GitHub"><div id="topnav-gh-icon"></div></a>
        </li>

      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>

  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script>

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header, .announcement-header, .comm-stories-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>


  <script src="/assets/track-events.js"></script>
  <script>trackEvents.bind();</script>



<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="/assets/images/pytorch-x.svg">
  </div>
</div>


</body>

</html>
