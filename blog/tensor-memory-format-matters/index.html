<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
  <!-- End Google Tag Manager -->
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      Efficient PyTorch: Tensor Memory Format Matters | PyTorch
    
  </title>
  <meta name="robots" content="index, follow" />

<meta name="description" content="Ensuring the right memory format for your inputs can significantly impact the running time of your PyTorch vision models. When in doubt, choose a Channels Last memory format.

" />

  <meta property="og:image" content="https://pytorch.org/" />
  <meta name="twitter:image" content="https://pytorch.org/" />

<meta property="og:locale" content="en_US" />
<meta property="og:type" content="website" />
<meta property="og:title" content="Efficient PyTorch: Tensor Memory Format Matters" />
<meta property="og:description" content="Ensuring the right memory format for your inputs can significantly impact the running time of your PyTorch vision models. When in doubt, choose a Channels Last memory format.

" />
<meta property="og:site_name" content="PyTorch" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:title" content="Efficient PyTorch: Tensor Memory Format Matters" />
<meta name="twitter:description" content="Ensuring the right memory format for your inputs can significantly impact the running time of your PyTorch vision models. When in doubt, choose a Channels Last memory format.

" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
  
    <script
  async
  src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"
></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() {
    dataLayer.push(arguments);
  }
  gtag("js", new Date());
  gtag("config", "UA-117752657-2");
</script>

    <script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window,document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '243028289693773');
    fbq('track', 'PageView');
</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

    <!-- Twitter universal website tag code -->
<img height="1" width="1" style="display:none;" alt="" src="https://analytics.twitter.com/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__analytics.twitter.com_i_adsct-3Fp-5Fid-3DTwitter-26p-5Fuser-5Fid-3D0-26txn-5Fid-3Do2gi1-26events-3D-255B-255B-2522pageview-2522-252Cnull-255D-255D-26tw-5Fsale-5Famount-3D0-26tw-5Forder-5Fquantity-3D0&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=o6i4D0V0088WH2RnzIoqiF-vj45PL-2sTrsxQ0SNO3A&e=)" />
<img height="1" width="1" style="display:none;" alt="" src="//t.co/i/adsct?p_id=Twitter&p_user_id=0&txn_id=o2gi1&events=%5B%5B%22pageview%22%2Cnull%5D%5D&tw_sale_amount=0&tw_order_quantity=0 (https://urldefense.proofpoint.com/v2/url?u=https-3A__linkprotect.cudasvc.com_url-3Fa-3Dhttp-253a-252f-252ft.co-252fi-252fadsct-253fp-5Fid-253dTwitter-2526p-5Fuser-5Fid-253d0-2526txn-5Fid-253do2gi1-2526events-253d-25255B-25255B-252522pageview-252522-25252Cnull-25255D-25255D-2526tw-5Fsale-5Famount-253d0-2526tw-5Forder-5Fquantity-253d0-26c-3DE-2C1-2CC33dLwIhtuEcl5FhdztSnUwsioeej5k-2DWy0RYREBAq51kGji32A2Cw94YU9vQBpY5tPN3AukEw3C-5F-2DlbtndnLoR7-5FA-5FLoH0Rr7zLtP1ykptN-26typo-3D1&d=DwMGaQ&c=5VD0RTtNlTh3ycd41b3MUw&r=GMr8XYCDyeQQZuD3noL91A&m=dAJyokk16UvYy-vMrGn_JwYiGfp_eEgo25B9iGDCG-A&s=Abgc3XBkhESv8XBYtLchdDZyISGsK6v_BB6cLMJGyCw&e=)" />
<!-- End Twitter universal website tag code -->

  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Pythorch Blog Posts" />
</head>


<body class="blog">
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <div class="main-background blog-background blog-detail-background"></div>
    <div class="hello-bar">
        <div class="container">
          Join us in Silicon Valley September 18-19 at the 2024 PyTorch Conference. <a target="_blank" href="https://events.linuxfoundation.org/pytorch-conference/">Learn more</a>.
        </div>
      </div>
      
    <div class="container-fluid header-holder blog-detail-header">
        <div class="container">
            

<div class="header-container">
  <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Learn
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/get-started">
            <span class=dropdown-title>Get Started</span>
            <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/">
            <span class="dropdown-title">Tutorials</span>
            <p>Whats new in PyTorch tutorials</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
            <span class="dropdown-title">Learn the Basics</span>
            <p>Familiarize yourself with PyTorch concepts and modules</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
            <span class="dropdown-title">PyTorch Recipes</span>
            <p>Bite-size, ready-to-deploy PyTorch code examples</p>
          </a>
          <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
            <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
            <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Ecosystem 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/ecosystem">
            <span class="dropdown-title">Tools</span>
            <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="/#community-module">
            <span class=dropdown-title>Community</span>
            <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
          </a>
          <a class="nav-dropdown-item" href="https://discuss.pytorch.org" target="_blank">
            <span class=dropdown-title>Forums</span>
            <p>A place to discuss PyTorch code, issues, install, research</p>
          </a>
          <a class="nav-dropdown-item" href="/resources">
            <span class=dropdown-title>Developer Resources</span>
            <p>Find resources and get questions answered</p>
          </a>
          <a class="nav-dropdown-item" href="/ecosystem/contributor-awards-2023">
            <span class="dropdown-title">Contributor Awards - 2023</span>
            <p>Award winners announced at this year's PyTorch Conference</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Edge 
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/edge">
            <span class="dropdown-title">About PyTorch Edge</span>
            <p>Build innovative and privacy-aware AI experiences for edge devices</p>
          </a>
          <a class="nav-dropdown-item" href="/executorch-overview">
            <span class="dropdown-title">ExecuTorch</span>
            <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="docsDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Docs
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="https://pytorch.org/docs">
            <span class="dropdown-title">PyTorch</span>
            <p>Explore the documentation for comprehensive guidance on how to use PyTorch.</p>
          </a>
          <a class="nav-dropdown-item" href="/pytorch-domains">
            <span class="dropdown-title">PyTorch Domains</span>
            <p> Read the PyTorch Domains documentation to learn more about domain-specific libraries.</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="dropdownMenuButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          Blog & News
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/blog">
            <span class="dropdown-title">PyTorch Blog</span>
            <p>Catch up on the latest technical news and happenings</p>
          </a>
          <a class="nav-dropdown-item" href="/community-blog">
            <span class="dropdown-title">Community Blog</span>
            <p>Stories from the PyTorch ecosystem</p>
          </a>
          <a class="nav-dropdown-item" href="/videos">
            <span class="dropdown-title">Videos</span>
            <p>Learn about the latest PyTorch tutorials, new, and more </p>
          </a>
          <a class="nav-dropdown-item" href="/community-stories">
            <span class="dropdown-title">Community Stories</span>
            <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
          </a>
          <a class="nav-dropdown-item" href="/events">
            <span class=dropdown-title>Events</span>
            <p>Find events, webinars, and podcasts</p>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
        <a class="with-down-arrow">
          About
        </a>
        <div class="resources-dropdown-menu">
          <a class="nav-dropdown-item" href="/foundation">
            <span class=dropdown-title>PyTorch Foundation</span>
            <p>Learn more about the PyTorch Foundation.</p>
          </a>
          <a class="nav-dropdown-item" href="/governing-board">
            <span class=dropdown-title>Governing Board</span>
          </a>
        </div>
      </div>
    </li>

    <li class="main-menu-item">
      <a href="/join" data-cta="join">
        Become a Member
      </a>
    </li>

    <li class="main-menu-item" id="github-main-menu-link">
      <a href="https://github.com/pytorch/pytorch" title="Go to PyTorch GitHub">
        <div id="topnav-gh-icon"></div>
      </a>
    </li>

    <li class="navSearchWrapper reactNavSearchWrapper" key="search">
      <div class="search-border">
        <div id="search-icon"></div>
        <input
          id="search-input"
          type="text"
          title="Search"
        />
        <div id="close-search">X</div>
      </div>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

        </div>
    </div>

    <div class="jumbotron jumbotron-fluid blog-detail-jumbotron">
        <div class="container blog-detail-container">
            <p class="featured-post">December 15, 2021</p>
            <h1>
                <a class="blog-title">Efficient PyTorch: Tensor Memory Format Matters</a>
            </h1>
        </div>
    </div>

    <div class="main-content-wrapper blog-detail-wrapper">
        <div class="main-content blog-detail-content">
            <div class="container">
                <img src="/assets/images/logo-icon.svg" class="img-fluid author-icon">
                <article class="pytorch-article">
                    <p class="author">
                      by
                      
                        Dhruv Matani, Suraj Subramanian
                      
                    </p>
                    <p>Ensuring the right memory format for your inputs can significantly impact the running time of your PyTorch vision models. When in doubt, choose a Channels Last memory format.</p>

<p>When dealing with vision models in PyTorch that accept multimedia (for example image Tensorts) as input, the Tensor’s memory format can significantly impact <strong>the inference execution speed of your model on mobile platforms when using the CPU backend along with XNNPACK</strong>. This holds true for training and inference on server platforms as well, but latency is particularly critical for mobile devices and users.</p>

<style type="text/css">
article.pytorch-article table tr th, article.pytorch-article table td {line-height: 1.5rem}
</style>

<h2 id="outline-of-this-article">Outline of this article</h2>
<ol>
  <li>Deep Dive into matrix storage/memory representation in C++. Introduction to <a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">Row and Column major order</a>.</li>
  <li>Impact of looping over a matrix in the same or different order as the storage representation, along with an example.</li>
  <li>Introduction to Cachegrind; a tool to inspect the cache friendliness of your code.</li>
  <li>Memory formats supported by PyTorch Operators.</li>
  <li>Best practices example to ensure efficient model execution with XNNPACK optimizations</li>
</ol>

<h2 id="matrix-storage-representation-in-c">Matrix Storage Representation in C++</h2>

<p>Images are fed into PyTorch ML models as multi-dimensional Tensors. These Tensors have specific memory formats. To understand this concept better, let’s take a look at how a 2-d matrix may be stored in memory.</p>

<p>Broadly speaking, there are 2 main ways of efficiently storing multi-dimensional data in memory.</p>
<ol>
  <li><strong>Row Major Order:</strong> In this format, the matrix is stored in row order, with each row stored before the next row in memory. I.e. row N comes before row N+1.</li>
  <li><strong>Column Major Order:</strong> In this format, the matrix is stored in column-order, with each column stored before the next column in memory. I.e. column N comes before column N+1.</li>
</ol>

<p>You can see the differences graphically below.</p>

<p align="center">
<img src="/assets/images/tensor/image1.png" alt="C++ stores multi-dimensional data in row-major format." width="100%" />
<br />
C++ stores multi-dimensional data in row-major format.
</p>

<h2 id="efficiently-accessing-elements-of-a-2d-matrix">Efficiently accessing elements of a 2d matrix</h2>

<p>Similar to the storage format, there are 2 ways to access data in a 2d matrix.</p>

<ol>
  <li><strong>Loop Over Rows first:</strong> All elements of a row are processed before any element of the next row.</li>
  <li><strong>Loop Over Columns first:</strong> All elements of a column are processed before any element of the next column.</li>
</ol>

<p>For maximum efficiency, one should always access data in the same format in which it is stored. I.e. if the data is stored in row-major order, then one should try to access it in that order.</p>

<p>The code below (main.cpp) shows <a href="https://stackoverflow.com/questions/9936132/why-does-the-order-of-the-loops-affect-performance-when-iterating-over-a-2d-arra">2 ways</a> of accessing all the elements of a 2d 4000x4000 matrix.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#include &lt;iostream&gt;
#include &lt;chrono&gt;
</span>
<span class="o">//</span> <span class="n">loop1</span> <span class="n">accesses</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">matrix</span> <span class="s">'a'</span> <span class="ow">in</span> <span class="n">row</span> <span class="n">major</span> <span class="n">order</span><span class="p">,</span>
<span class="o">//</span> <span class="n">since</span> <span class="n">i</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">outer</span> <span class="n">loop</span> <span class="n">variable</span><span class="p">,</span> <span class="ow">and</span> <span class="n">j</span> <span class="ow">is</span> <span class="n">the</span>
<span class="o">//</span> <span class="n">inner</span> <span class="n">loop</span> <span class="n">variable</span><span class="p">.</span>
<span class="nb">int</span> <span class="n">loop1</span><span class="p">(</span><span class="nb">int</span> <span class="n">a</span><span class="p">[</span><span class="mi">4000</span><span class="p">][</span><span class="mi">4000</span><span class="p">])</span> <span class="p">{</span>
 <span class="nb">int</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
 <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">4000</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
   <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="mi">4000</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
     <span class="n">s</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
   <span class="p">}</span>
 <span class="p">}</span>
 <span class="k">return</span> <span class="n">s</span><span class="p">;</span>
<span class="p">}</span>

<span class="o">//</span> <span class="n">loop2</span> <span class="n">accesses</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">matrix</span> <span class="s">'a'</span> <span class="ow">in</span> <span class="n">column</span> <span class="n">major</span> <span class="n">order</span>
<span class="o">//</span> <span class="n">since</span> <span class="n">j</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">outer</span> <span class="n">loop</span> <span class="n">variable</span><span class="p">,</span> <span class="ow">and</span> <span class="n">i</span> <span class="ow">is</span> <span class="n">the</span>
<span class="o">//</span> <span class="n">inner</span> <span class="n">loop</span> <span class="n">variable</span><span class="p">.</span>
<span class="nb">int</span> <span class="n">loop2</span><span class="p">(</span><span class="nb">int</span> <span class="n">a</span><span class="p">[</span><span class="mi">4000</span><span class="p">][</span><span class="mi">4000</span><span class="p">])</span> <span class="p">{</span>
 <span class="nb">int</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
 <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="mi">4000</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
   <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">4000</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
     <span class="n">s</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
   <span class="p">}</span>
 <span class="p">}</span>
 <span class="k">return</span> <span class="n">s</span><span class="p">;</span>
<span class="p">}</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">()</span> <span class="p">{</span>
 <span class="n">static</span> <span class="nb">int</span> <span class="n">a</span><span class="p">[</span><span class="mi">4000</span><span class="p">][</span><span class="mi">4000</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">};</span>
 <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
   <span class="nb">int</span> <span class="n">x</span> <span class="o">=</span> <span class="n">rand</span><span class="p">()</span> <span class="o">%</span> <span class="mi">4000</span><span class="p">;</span>
   <span class="nb">int</span> <span class="n">y</span> <span class="o">=</span> <span class="n">rand</span><span class="p">()</span> <span class="o">%</span> <span class="mi">4000</span><span class="p">;</span>
   <span class="n">a</span><span class="p">[</span><span class="n">x</span><span class="p">][</span><span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="n">rand</span><span class="p">()</span> <span class="o">%</span> <span class="mi">1000</span><span class="p">;</span>
 <span class="p">}</span>

 <span class="n">auto</span> <span class="n">start</span> <span class="o">=</span> <span class="n">std</span><span class="p">::</span><span class="n">chrono</span><span class="p">::</span><span class="n">high_resolution_clock</span><span class="p">::</span><span class="n">now</span><span class="p">();</span>
 <span class="n">auto</span> <span class="n">end</span> <span class="o">=</span> <span class="n">start</span><span class="p">;</span>
 <span class="nb">int</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

<span class="c1">#if defined RUN_LOOP1
</span> <span class="n">start</span> <span class="o">=</span> <span class="n">std</span><span class="p">::</span><span class="n">chrono</span><span class="p">::</span><span class="n">high_resolution_clock</span><span class="p">::</span><span class="n">now</span><span class="p">();</span>

 <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
 <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
   <span class="n">s</span> <span class="o">+=</span> <span class="n">loop1</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
   <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">%</span> <span class="mi">100</span><span class="p">;</span>
 <span class="p">}</span>
 <span class="n">end</span> <span class="o">=</span> <span class="n">std</span><span class="p">::</span><span class="n">chrono</span><span class="p">::</span><span class="n">high_resolution_clock</span><span class="p">::</span><span class="n">now</span><span class="p">();</span>

 <span class="n">std</span><span class="p">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"s = "</span> <span class="o">&lt;&lt;</span> <span class="n">s</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="p">::</span><span class="n">endl</span><span class="p">;</span>
 <span class="n">std</span><span class="p">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Time for loop1: "</span>
   <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="p">::</span><span class="n">chrono</span><span class="p">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="n">double</span><span class="p">,</span> <span class="n">std</span><span class="p">::</span><span class="n">milli</span><span class="o">&gt;</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">).</span><span class="n">count</span><span class="p">()</span>
   <span class="o">&lt;&lt;</span> <span class="s">"ms"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="p">::</span><span class="n">endl</span><span class="p">;</span>
<span class="c1">#endif
</span>
<span class="c1">#if defined RUN_LOOP2
</span> <span class="n">start</span> <span class="o">=</span> <span class="n">std</span><span class="p">::</span><span class="n">chrono</span><span class="p">::</span><span class="n">high_resolution_clock</span><span class="p">::</span><span class="n">now</span><span class="p">();</span>
 <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
 <span class="k">for</span> <span class="p">(</span><span class="nb">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
   <span class="n">s</span> <span class="o">+=</span> <span class="n">loop2</span><span class="p">(</span><span class="n">a</span><span class="p">);</span>
   <span class="n">s</span> <span class="o">=</span> <span class="n">s</span> <span class="o">%</span> <span class="mi">100</span><span class="p">;</span>
 <span class="p">}</span>
 <span class="n">end</span> <span class="o">=</span> <span class="n">std</span><span class="p">::</span><span class="n">chrono</span><span class="p">::</span><span class="n">high_resolution_clock</span><span class="p">::</span><span class="n">now</span><span class="p">();</span>

 <span class="n">std</span><span class="p">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"s = "</span> <span class="o">&lt;&lt;</span> <span class="n">s</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="p">::</span><span class="n">endl</span><span class="p">;</span>
 <span class="n">std</span><span class="p">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">"Time for loop2: "</span>
   <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="p">::</span><span class="n">chrono</span><span class="p">::</span><span class="n">duration</span><span class="o">&lt;</span><span class="n">double</span><span class="p">,</span> <span class="n">std</span><span class="p">::</span><span class="n">milli</span><span class="o">&gt;</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">).</span><span class="n">count</span><span class="p">()</span>
   <span class="o">&lt;&lt;</span> <span class="s">"ms"</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="p">::</span><span class="n">endl</span><span class="p">;</span>
<span class="c1">#endif
</span><span class="p">}</span>


<span class="n">Let</span><span class="err">’</span><span class="n">s</span> <span class="n">build</span> <span class="ow">and</span> <span class="n">run</span> <span class="n">this</span> <span class="n">program</span> <span class="ow">and</span> <span class="n">see</span> <span class="n">what</span> <span class="n">it</span> <span class="n">prints</span><span class="p">.</span>

<span class="n">g</span><span class="o">++</span> <span class="o">-</span><span class="n">O2</span> <span class="n">main</span><span class="p">.</span><span class="n">cpp</span> <span class="o">-</span><span class="n">DRUN_LOOP1</span> <span class="o">-</span><span class="n">DRUN_LOOP2</span>
<span class="p">.</span><span class="o">/</span><span class="n">a</span><span class="p">.</span><span class="n">out</span>


<span class="n">Prints</span> <span class="n">the</span> <span class="n">following</span><span class="p">:</span>

<span class="n">s</span> <span class="o">=</span> <span class="mi">70</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">loop1</span><span class="p">:</span> <span class="mf">77.0687</span><span class="n">ms</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">70</span>
<span class="n">Time</span> <span class="k">for</span> <span class="n">loop2</span><span class="p">:</span> <span class="mf">1219.49</span><span class="n">ms</span>
</code></pre></div></div>

<p>loop1() is <strong>15x faster</strong> than loop2(). Why is that? Let’s find out below!</p>

<h2 id="measure-cache-misses-using-cachegrind">Measure cache misses using Cachegrind</h2>

<p><a href="https://courses.cs.washington.edu/courses/cse326/05wi/valgrind-doc/cg_main.html">Cachegrind</a> is a cache profiling tool used to see how many I1 (first level instruction), D1 (first level data), and LL (last level) cache misses your program caused.</p>

<p>Let’s build our program with just loop1() and just loop2() to see how cache friendly each of these functions is.</p>

<h3 id="build-and-runprofile-just-loop1">Build and run/profile just loop1()</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">g</span><span class="o">++</span> <span class="o">-</span><span class="n">O2</span> <span class="n">main</span><span class="p">.</span><span class="n">cpp</span> <span class="o">-</span><span class="n">DRUN_LOOP1</span>
<span class="n">valgrind</span> <span class="o">--</span><span class="n">tool</span><span class="o">=</span><span class="n">cachegrind</span> <span class="p">.</span><span class="o">/</span><span class="n">a</span><span class="p">.</span><span class="n">out</span>
</code></pre></div></div>

<h4 id="prints">Prints:</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">==</span><span class="mi">3299700</span><span class="o">==</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">I</span>   <span class="n">refs</span><span class="p">:</span>      <span class="mi">643</span><span class="p">,</span><span class="mi">156</span><span class="p">,</span><span class="mi">721</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">I1</span>  <span class="n">misses</span><span class="p">:</span>          <span class="mi">2</span><span class="p">,</span><span class="mi">077</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">LLi</span> <span class="n">misses</span><span class="p">:</span>          <span class="mi">2</span><span class="p">,</span><span class="mi">021</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">I1</span>  <span class="n">miss</span> <span class="n">rate</span><span class="p">:</span>        <span class="mf">0.00</span><span class="o">%</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">LLi</span> <span class="n">miss</span> <span class="n">rate</span><span class="p">:</span>        <span class="mf">0.00</span><span class="o">%</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">D</span>   <span class="n">refs</span><span class="p">:</span>      <span class="mi">160</span><span class="p">,</span><span class="mi">952</span><span class="p">,</span><span class="mi">192</span>  <span class="p">(</span><span class="mi">160</span><span class="p">,</span><span class="mi">695</span><span class="p">,</span><span class="mi">444</span> <span class="n">rd</span>   <span class="o">+</span> <span class="mi">256</span><span class="p">,</span><span class="mi">748</span> <span class="n">wr</span><span class="p">)</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">D1</span>  <span class="n">misses</span><span class="p">:</span>     <span class="mi">10</span><span class="p">,</span><span class="mi">021</span><span class="p">,</span><span class="mi">300</span>  <span class="p">(</span> <span class="mi">10</span><span class="p">,</span><span class="mi">018</span><span class="p">,</span><span class="mi">723</span> <span class="n">rd</span>   <span class="o">+</span>   <span class="mi">2</span><span class="p">,</span><span class="mi">577</span> <span class="n">wr</span><span class="p">)</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">LLd</span> <span class="n">misses</span><span class="p">:</span>     <span class="mi">10</span><span class="p">,</span><span class="mi">010</span><span class="p">,</span><span class="mi">916</span>  <span class="p">(</span> <span class="mi">10</span><span class="p">,</span><span class="mi">009</span><span class="p">,</span><span class="mi">147</span> <span class="n">rd</span>   <span class="o">+</span>   <span class="mi">1</span><span class="p">,</span><span class="mi">769</span> <span class="n">wr</span><span class="p">)</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">D1</span>  <span class="n">miss</span> <span class="n">rate</span><span class="p">:</span>         <span class="mf">6.2</span><span class="o">%</span> <span class="p">(</span>        <span class="mf">6.2</span><span class="o">%</span>     <span class="o">+</span>     <span class="mf">1.0</span><span class="o">%</span>  <span class="p">)</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">LLd</span> <span class="n">miss</span> <span class="n">rate</span><span class="p">:</span>         <span class="mf">6.2</span><span class="o">%</span> <span class="p">(</span>        <span class="mf">6.2</span><span class="o">%</span>     <span class="o">+</span>     <span class="mf">0.7</span><span class="o">%</span>  <span class="p">)</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">LL</span> <span class="n">refs</span><span class="p">:</span>        <span class="mi">10</span><span class="p">,</span><span class="mi">023</span><span class="p">,</span><span class="mi">377</span>  <span class="p">(</span> <span class="mi">10</span><span class="p">,</span><span class="mi">020</span><span class="p">,</span><span class="mi">800</span> <span class="n">rd</span>   <span class="o">+</span>   <span class="mi">2</span><span class="p">,</span><span class="mi">577</span> <span class="n">wr</span><span class="p">)</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">LL</span> <span class="n">misses</span><span class="p">:</span>      <span class="mi">10</span><span class="p">,</span><span class="mi">012</span><span class="p">,</span><span class="mi">937</span>  <span class="p">(</span> <span class="mi">10</span><span class="p">,</span><span class="mi">011</span><span class="p">,</span><span class="mi">168</span> <span class="n">rd</span>   <span class="o">+</span>   <span class="mi">1</span><span class="p">,</span><span class="mi">769</span> <span class="n">wr</span><span class="p">)</span>
<span class="o">==</span><span class="mi">3299700</span><span class="o">==</span> <span class="n">LL</span> <span class="n">miss</span> <span class="n">rate</span><span class="p">:</span>          <span class="mf">1.2</span><span class="o">%</span> <span class="p">(</span>        <span class="mf">1.2</span><span class="o">%</span>     <span class="o">+</span>     <span class="mf">0.7</span><span class="o">%</span>  <span class="p">)</span>
</code></pre></div></div>

<h3 id="build-and-runprofile-just-loop2">Build and run/profile just loop2()</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">g</span><span class="o">++</span> <span class="o">-</span><span class="n">O2</span> <span class="n">main</span><span class="p">.</span><span class="n">cpp</span> <span class="o">-</span><span class="n">DRUN_LOOP2</span>
<span class="n">valgrind</span> <span class="o">--</span><span class="n">tool</span><span class="o">=</span><span class="n">cachegrind</span> <span class="p">.</span><span class="o">/</span><span class="n">a</span><span class="p">.</span><span class="n">out</span>
</code></pre></div></div>

<h4 id="prints-1">Prints:</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">==</span><span class="mi">3300389</span><span class="o">==</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">I</span>   <span class="n">refs</span><span class="p">:</span>      <span class="mi">643</span><span class="p">,</span><span class="mi">156</span><span class="p">,</span><span class="mi">726</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">I1</span>  <span class="n">misses</span><span class="p">:</span>          <span class="mi">2</span><span class="p">,</span><span class="mi">075</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">LLi</span> <span class="n">misses</span><span class="p">:</span>          <span class="mi">2</span><span class="p">,</span><span class="mi">018</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">I1</span>  <span class="n">miss</span> <span class="n">rate</span><span class="p">:</span>        <span class="mf">0.00</span><span class="o">%</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">LLi</span> <span class="n">miss</span> <span class="n">rate</span><span class="p">:</span>        <span class="mf">0.00</span><span class="o">%</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">D</span>   <span class="n">refs</span><span class="p">:</span>      <span class="mi">160</span><span class="p">,</span><span class="mi">952</span><span class="p">,</span><span class="mi">196</span>  <span class="p">(</span><span class="mi">160</span><span class="p">,</span><span class="mi">695</span><span class="p">,</span><span class="mi">447</span> <span class="n">rd</span>   <span class="o">+</span> <span class="mi">256</span><span class="p">,</span><span class="mi">749</span> <span class="n">wr</span><span class="p">)</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">D1</span>  <span class="n">misses</span><span class="p">:</span>    <span class="mi">160</span><span class="p">,</span><span class="mi">021</span><span class="p">,</span><span class="mi">290</span>  <span class="p">(</span><span class="mi">160</span><span class="p">,</span><span class="mi">018</span><span class="p">,</span><span class="mi">713</span> <span class="n">rd</span>   <span class="o">+</span>   <span class="mi">2</span><span class="p">,</span><span class="mi">577</span> <span class="n">wr</span><span class="p">)</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">LLd</span> <span class="n">misses</span><span class="p">:</span>     <span class="mi">10</span><span class="p">,</span><span class="mi">014</span><span class="p">,</span><span class="mi">907</span>  <span class="p">(</span> <span class="mi">10</span><span class="p">,</span><span class="mi">013</span><span class="p">,</span><span class="mi">138</span> <span class="n">rd</span>   <span class="o">+</span>   <span class="mi">1</span><span class="p">,</span><span class="mi">769</span> <span class="n">wr</span><span class="p">)</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">D1</span>  <span class="n">miss</span> <span class="n">rate</span><span class="p">:</span>        <span class="mf">99.4</span><span class="o">%</span> <span class="p">(</span>       <span class="mf">99.6</span><span class="o">%</span>     <span class="o">+</span>     <span class="mf">1.0</span><span class="o">%</span>  <span class="p">)</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">LLd</span> <span class="n">miss</span> <span class="n">rate</span><span class="p">:</span>         <span class="mf">6.2</span><span class="o">%</span> <span class="p">(</span>        <span class="mf">6.2</span><span class="o">%</span>     <span class="o">+</span>     <span class="mf">0.7</span><span class="o">%</span>  <span class="p">)</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">LL</span> <span class="n">refs</span><span class="p">:</span>       <span class="mi">160</span><span class="p">,</span><span class="mi">023</span><span class="p">,</span><span class="mi">365</span>  <span class="p">(</span><span class="mi">160</span><span class="p">,</span><span class="mi">020</span><span class="p">,</span><span class="mi">788</span> <span class="n">rd</span>   <span class="o">+</span>   <span class="mi">2</span><span class="p">,</span><span class="mi">577</span> <span class="n">wr</span><span class="p">)</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">LL</span> <span class="n">misses</span><span class="p">:</span>      <span class="mi">10</span><span class="p">,</span><span class="mi">016</span><span class="p">,</span><span class="mi">925</span>  <span class="p">(</span> <span class="mi">10</span><span class="p">,</span><span class="mi">015</span><span class="p">,</span><span class="mi">156</span> <span class="n">rd</span>   <span class="o">+</span>   <span class="mi">1</span><span class="p">,</span><span class="mi">769</span> <span class="n">wr</span><span class="p">)</span>
<span class="o">==</span><span class="mi">3300389</span><span class="o">==</span> <span class="n">LL</span> <span class="n">miss</span> <span class="n">rate</span><span class="p">:</span>          <span class="mf">1.2</span><span class="o">%</span> <span class="p">(</span>        <span class="mf">1.2</span><span class="o">%</span>     <span class="o">+</span>     <span class="mf">0.7</span><span class="o">%</span>  <span class="p">)</span>
</code></pre></div></div>

<p>The main differences between the 2 runs are:</p>
<ol>
  <li><strong>D1 misses:</strong> 10M v/s 160M</li>
  <li><strong>D1 miss rate:</strong> 6.2% v/s 99.4%</li>
</ol>

<p>As you can see, <code class="language-plaintext highlighter-rouge">loop2()</code> causes many many more (<strong>~16x more</strong>) L1 data cache misses than loop1(). This is why <code class="language-plaintext highlighter-rouge">loop1()</code> is ~15x faster than loop2().</p>

<h2 id="memory-formats-supported-by-pytorch-operators">Memory Formats supported by PyTorch Operators</h2>

<p>While PyTorch operators expect all tensors to be in <a href="https://discuss.pytorch.org/t/why-does-pytorch-prefer-using-nchw/83637/4">Channels First (NCHW) dimension format</a>, PyTorch operators support 3 output <a href="https://github.com/pytorch/pytorch/blob/master/c10/core/MemoryFormat.h">memory formats</a>.</p>

<ol>
  <li><strong>Contiguous:</strong> Tensor memory is in the same order as the tensor’s dimensions.</li>
  <li><strong>ChannelsLast:</strong> Irrespective of the dimension order, the 2d (image) tensor is laid out as an HWC or <a href="https://oneapi-src.github.io/oneDNN/dev_guide_understanding_memory_formats.html">NHWC</a> (N: batch, H: height, W: width, C: channels) tensor in memory. The dimensions could be permuted in any order.</li>
  <li><strong>ChannelsLast3d:</strong> For 3d tensors (video tensors), the memory is laid out in THWC (Time, Height, Width, Channels) or NTHWC (N: batch, T: time, H: height, W: width, C: channels) format. The dimensions could be permuted in any order.</li>
</ol>

<p>The reason that ChannelsLast is preferred for vision models is because <a href="https://github.com/google/XNNPACK">XNNPACK</a> (kernel acceleration library) used by PyTorch expects all inputs to be in <strong>Channels Last</strong> format, so if the input to the model isn’t channels last, then it must first be converted to channels last, which is an additional operation.</p>

<p>Additionally, most PyTorch operators preserve the input tensor’s memory format, so if the input is Channels First, then the operator needs to first convert to Channels Last, then perform the operation, and then convert back to Channels First.</p>

<p>When you combine it with the fact that accelerated operators work better with a channels last memory format, you’ll notice that having the operator return back a channels-last memory format is better for subsequent operator calls or you’ll end up having every operator convert to channels-last (should it be more efficient for that specific operator).</p>

<p>From the XNNPACK home page:</p>

<blockquote>
  <p>“All operators in XNNPACK support NHWC layout, but additionally allow custom stride along the Channel dimension”.</p>
</blockquote>

<h2 id="pytorch-best-practice">PyTorch Best Practice</h2>

<p>The best way to get the most performance from your PyTorch vision models is to ensure that your input tensor is in a <strong>Channels Last</strong> <a href="https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html">memory format</a> before it is fed into the model.</p>

<p>You can get even more speedups by optimizing your model to use the XNNPACK backend (by simply calling <code class="language-plaintext highlighter-rouge">optimize_for_mobile()</code> on your torchscripted model). Note that XNNPACK models will run slower if the inputs are contiguous, so definitely make sure it is in Channels-Last format.</p>

<h2 id="working-example-showing-speedup">Working example showing speedup</h2>

<p>Run this example on <a href="https://colab.research.google.com/gist/suraj813/ad9aebcbffbdd6d02b23ca7231130a30/channels-last-with-xnnpack.ipynb#scrollTo=xvJN73YWXgDF">Google Colab</a> - note that runtimes on colab CPUs might not reflect accurate performance; it is recommended to run this code on your local machine.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.utils.mobile_optimizer</span> <span class="kn">import</span> <span class="n">optimize_for_mobile</span>
<span class="kn">import</span> <span class="nn">torch.backends.xnnpack</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">print</span><span class="p">(</span><span class="s">"XNNPACK is enabled: "</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">backends</span><span class="p">.</span><span class="n">xnnpack</span><span class="p">.</span><span class="n">enabled</span><span class="p">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

<span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">200</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Contiguous shape: "</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Contiguous stride: "</span><span class="p">,</span> <span class="n">x</span><span class="p">.</span><span class="n">stride</span><span class="p">())</span>
<span class="k">print</span><span class="p">()</span>

<span class="n">xcl</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">channels_last</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Channels-Last shape: "</span><span class="p">,</span> <span class="n">xcl</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Channels-Last stride: "</span><span class="p">,</span> <span class="n">xcl</span><span class="p">.</span><span class="n">stride</span><span class="p">())</span>

<span class="c1">## Outputs:
</span> 
<span class="c1"># XNNPACK is enabled:  True
</span> 
<span class="c1"># Contiguous shape:  torch.Size([1, 3, 200, 200])
# Contiguous stride:  (120000, 40000, 200, 1)
</span> 
<span class="c1"># Channels-Last shape:  torch.Size([1, 3, 200, 200])
# Channels-Last stride:  (120000, 1, 600, 3)
</span>
</code></pre></div></div>

<p>The input shape stays the same for contiguous and channels-last formats. Internally however, the tensor’s layout has changed as you can see in the strides. Now, the number of jumps required to go across channels is only 1 (instead of 40000 in the contiguous tensor).
This better data locality means convolution layers can access all the channels for a given pixel much faster. Let’s see now how the memory format affects runtime:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">resnet34</span><span class="p">,</span> <span class="n">resnet50</span><span class="p">,</span> <span class="n">resnet101</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">resnet34</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="c1"># m = resnet50(pretrained=False)
# m = resnet101(pretrained=False)
</span>
<span class="k">def</span> <span class="nf">get_optimized_model</span><span class="p">(</span><span class="n">mm</span><span class="p">):</span>
  <span class="n">mm</span> <span class="o">=</span> <span class="n">mm</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
  <span class="n">scripted</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">jit</span><span class="p">.</span><span class="n">script</span><span class="p">(</span><span class="n">mm</span><span class="p">)</span>
  <span class="n">optimized</span> <span class="o">=</span> <span class="n">optimize_for_mobile</span><span class="p">(</span><span class="n">scripted</span><span class="p">)</span>  <span class="c1"># explicitly call the xnnpack rewrite 
</span>  <span class="k">return</span> <span class="n">scripted</span><span class="p">,</span> <span class="n">optimized</span>


<span class="k">def</span> <span class="nf">compare_contiguous_CL</span><span class="p">(</span><span class="n">mm</span><span class="p">):</span>
  <span class="c1"># inference on contiguous
</span>  <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">perf_counter</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">mm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">perf_counter</span><span class="p">()</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Contiguous: "</span><span class="p">,</span> <span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">)</span>

  <span class="c1"># inference on channels-last
</span>  <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">perf_counter</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="n">mm</span><span class="p">(</span><span class="n">xcl</span><span class="p">)</span>
  <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="n">perf_counter</span><span class="p">()</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Channels-Last: "</span><span class="p">,</span> <span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">inference_mode</span><span class="p">():</span>
  <span class="n">scripted</span><span class="p">,</span> <span class="n">optimized</span> <span class="o">=</span> <span class="n">get_optimized_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>

  <span class="k">print</span><span class="p">(</span><span class="s">"Runtimes for torchscripted model: "</span><span class="p">)</span>
  <span class="n">compare_contiguous_CL</span><span class="p">(</span><span class="n">scripted</span><span class="p">.</span><span class="nb">eval</span><span class="p">())</span>
  <span class="k">print</span><span class="p">()</span>
  <span class="k">print</span><span class="p">(</span><span class="s">"Runtimes for mobile-optimized model: "</span><span class="p">)</span>
  <span class="n">compare_contiguous_CL</span><span class="p">(</span><span class="n">optimized</span><span class="p">.</span><span class="nb">eval</span><span class="p">())</span>

   
<span class="c1">## Outputs (on an Intel Core i9 CPU):
</span> 
<span class="c1"># Runtimes for torchscripted model:
# Contiguous:  1.6711160129999598
# Channels-Last:  1.6678222839999535
</span> 
<span class="c1"># Runtimes for mobile-optimized model:
# Contiguous:  0.5712863490000473
# Channels-Last:  0.46113000699995155
</span>
</code></pre></div></div>

<h2 id="conclusion">Conclusion</h2>

<p>The Memory Layout of an input tensor can significantly impact a model’s running time. For Vision Models, prefer a <strong>Channels Last</strong> memory format to get the most out of your PyTorch models.</p>

<h2 id="references">References</h2>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Row-_and_column-major_order">Row/Column Major matrix storage order</a></li>
  <li><a href="https://stackoverflow.com/questions/9936132/why-does-the-order-of-the-loops-affect-performance-when-iterating-over-a-2d-arra">Loop order impact on performance</a></li>
  <li><a href="https://courses.cs.washington.edu/courses/cse326/05wi/valgrind-doc/cg_main.html">Cachegrind: a cache-miss profiler</a></li>
  <li><a href="https://oneapi-src.github.io/oneDNN/dev_guide_understanding_memory_formats.html">NHWC format explained</a></li>
  <li><a href="https://discuss.pytorch.org/t/why-does-pytorch-prefer-using-nchw/83637/4">Why does PyTorch prefer NCHW?</a></li>
  <li><a href="https://github.com/google/XNNPACK">XNNPACK</a></li>
  <li><a href="https://pytorch.org/tutorials/intermediate/memory_format_tutorial.html">PyTorch memory format tutorial</a></li>
  <li><a href="https://github.com/pytorch/pytorch/wiki/Operators-with-Channels-Last-support">Supported operators</a></li>
</ul>

                </article>
            </div>
        </div>
    </div>

<!--    


 -->
    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>Docs</h2>
        <p>Access comprehensive developer documentation for PyTorch</p>
        <a class="with-right-arrow" href="/docs">View Docs</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Tutorials</h2>
        <p>Get in-depth tutorials for beginners and advanced developers</p>
        <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>Resources</h2>
        <p>Find development resources and get your questions answered</p>
        <a class="with-right-arrow" href="/resources">View Resources</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="lf-grid">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org" class="footer-logo">
          <img src="/assets/images/logo-icon.svg" alt="PyTorch logo" width="40">
        </a>
      </div>

      <ul class="social-links">
        <li><a href="https://www.facebook.com/pytorch" target="_blank" title="PyTorch on Facebook">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-0.51 -0.26 26.45 26.45" aria-label="Facebook"><path fill="currentColor" d="M25.497 13.075c0-2.45-.698-4.848-2.011-6.911a12.765 12.765 0 0 0-5.398-4.73A12.671 12.671 0 0 0 11.008.38a12.705 12.705 0 0 0-6.529 2.95A12.827 12.827 0 0 0 .563 9.358a12.896 12.896 0 0 0-.07 7.201 12.831 12.831 0 0 0 3.801 6.103 12.709 12.709 0 0 0 6.471 3.078v-8.957H7.53v-3.708h3.235v-2.824c0-3.213 1.903-4.988 4.813-4.988.956.014 1.909.097 2.852.25V8.67h-1.607a1.83 1.83 0 0 0-1.518.497 1.854 1.854 0 0 0-.561 1.505v2.404h3.535l-.563 3.708h-2.97v8.957a12.725 12.725 0 0 0 7.697-4.337 12.87 12.87 0 0 0 3.054-8.328z"/></svg>	
        </a></li>
        <li><a href="https://twitter.com/pytorch" target="_blank" title="PyTorch on X">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 300 300" aria-label="X"><path fill="currentColor" d="M178.57 127.15 290.27 0h-26.46l-97.03 110.38L89.34 0H0l117.13 166.93L0 300.25h26.46l102.4-116.59 81.8 116.59h89.34M36.01 19.54H76.66l187.13 262.13h-40.66"/></svg>
        </a></li>
        <li><a href="https://www.youtube.com/pytorch" target="_blank" title="PyTorch on YouTube">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="0.21 0.27 34.45 25.07" aria-label="YouTube"><path fill="currentColor" d="M33.729 6.084s-.327-2.33-1.317-3.356a4.691 4.691 0 0 0-3.32-1.432c-4.634-.34-11.589-.34-11.589-.34h-.014s-6.954 0-11.59.342a4.692 4.692 0 0 0-3.32 1.432c-.993 1.025-1.315 3.354-1.315 3.354a52.189 52.189 0 0 0-.331 5.473v2.566c.014 1.829.125 3.656.331 5.472 0 0 .322 2.33 1.316 3.36 1.26 1.345 2.916 1.3 3.653 1.445 2.65.26 11.263.34 11.263.34s6.96-.01 11.597-.353a4.691 4.691 0 0 0 3.32-1.432c.993-1.026 1.316-3.356 1.316-3.356.206-1.817.316-3.644.33-5.473v-2.57a52.26 52.26 0 0 0-.33-5.472zM14.076 17.232V7.729l8.951 4.768-8.95 4.735z"/></svg>	
        </a></li>
        <li><a href="https://www.linkedin.com/company/pytorch" target="_blank" title="PyTorch on LinkedIn">
          <svg xmlns="http://www.w3.org/2000/svg" viewbox="-10.23 -10.23 531.96 531.96" aria-label="LinkedIn"><rect width="512" height="512" rx="0" fill="currentColor"/><circle fill="#000" cx="142" cy="138" r="37"/><path stroke="#000" stroke-width="66" d="M244 194v198M142 194v198"/><path fill="#000" d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
        </a></li>
        <li><a href="https://social.lfx.dev/@pytorch" rel="me" target="_blank" title="PyTorch on Mastodon">
          <svg fill="currentColor" aria-label="Mastodon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" xml:space="preserve"><path d="M21.327 8.566c0-4.339-2.843-5.61-2.843-5.61-1.433-.658-3.894-.935-6.451-.956h-.063c-2.557.021-5.016.298-6.45.956 0 0-2.843 1.272-2.843 5.61 0 .993-.019 2.181.012 3.441.103 4.243.778 8.425 4.701 9.463 1.809.479 3.362.579 4.612.51 2.268-.126 3.541-.809 3.541-.809l-.075-1.646s-1.621.511-3.441.449c-1.804-.062-3.707-.194-3.999-2.409a4.523 4.523 0 0 1-.04-.621s1.77.433 4.014.536c1.372.063 2.658-.08 3.965-.236 2.506-.299 4.688-1.843 4.962-3.254.434-2.223.398-5.424.398-5.424zm-3.353 5.59h-2.081V9.057c0-1.075-.452-1.62-1.357-1.62-1 0-1.501.647-1.501 1.927v2.791h-2.069V9.364c0-1.28-.501-1.927-1.502-1.927-.905 0-1.357.546-1.357 1.62v5.099H6.026V8.903c0-1.074.273-1.927.823-2.558.566-.631 1.307-.955 2.228-.955 1.065 0 1.872.409 2.405 1.228l.518.869.519-.869c.533-.819 1.34-1.228 2.405-1.228.92 0 1.662.324 2.228.955.549.631.822 1.484.822 2.558v5.253z"/></svg>
        </a></li>
      </ul>
    </div>

    <div class="privacy-policy">
      <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation. 
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see 
          <a href="https://www.linuxfoundation.org/legal/policies/">Linux Foundation Policies</a>. The PyTorch Foundation supports the PyTorch open source 
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC, 
          please see <a href="https://www.lfprojects.org/policies/">LF Projects, LLC Policies</a>. <a href="https://www.linuxfoundation.org/privacy">Privacy Policy</a> and <a href="https://www.linuxfoundation.org/terms">Terms of Use</a>.</p>
      </div>
    </div>
  </div>
  <img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.org" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>
        <li class="navSearchWrapper reactNavSearchWrapper tabletSearchWrapper" key="search">
          <div class="mobile-search-border">
            <input
              id="mobile-search-input"
              type="text"
              title="Search"
            />
            <div id="mobile-search-icon"></div>
          </div>
        </li>

        <li class="resources-mobile-menu-title">
          <a>Learn</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/get-started">Get Started</a> 
          </li>
          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
          </li>
          <li>
            <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Ecosystem</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/ecosystem">Tools</a>
          </li>
          <li>
            <a href="/#community-module">Community</a>
          </li>
          <li>
            <a href="https://discuss.pytorch.org">Forums</a>
          </li>
          <li>
            <a href="/resources">Developer Resources</a>
          </li>
          <li>
            <a href="/ecosystem/contributor-awards-2023">Contributor Awards - 2023</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Edge</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/edge">About PyTorch Edge</a>
          </li>
          <li>
            <a href="/executorch-overview">ExecuTorch</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>Docs</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="https://pytorch.org/docs">PyTorch</a>
          </li>
          <li>
            <a href="/pytorch-domains">PyTorch Domains</a>
          </li>
        </ul>

        <li class="resources-mobile-menu-title">
          <a>Blog & News</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/blog">PyTorch Blog</a>
          </li>
          <li>
            <a href="/community-blog">Community Blog</a>
          </li>
          <li>
            <a href="/videos">Videos</a>
          </li>
          <li>
            <a href="/community-stories">Community Stories</a>
          </li>
          <li>
            <a href="/events">Events</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a>About</a>
        </li>
        <ul class="resources-mobile-menu-items">
          <li>
            <a href="/foundation">PyTorch Foundation</a>
          </li>
          <li>
            <a href="/governing-board">Governing Board</a>
          </li>
        </ul>
        <li class="resources-mobile-menu-title">
          <a href="/join">Become a Member</a>
        </li>
        <li class="resources-mobile-menu-title">
          <a href="https://github.com/pytorch/pytorch" title="Go to PyTorch GitHub"><div id="topnav-gh-icon"></div></a>
        </li>

      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>

  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script>

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header, .announcement-header, .comm-stories-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>


  <script src="/assets/track-events.js"></script>
  <script>trackEvents.bind();</script>



<div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="/assets/images/pytorch-x.svg">
  </div>
</div>


</body>

</html>
