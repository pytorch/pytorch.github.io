

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Probability distributions - torch.distributions &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/distributions.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  <link rel="stylesheet" href="_static/css/pytorch_theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Multiprocessing package - torch.multiprocessing" href="multiprocessing.html" />
    <link rel="prev" title="Automatic differentiation package - torch.autograd" href="autograd.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html">
          

          
            
            <img src="_static/pytorch-logo-dark.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.4.1 <br/> <a href="https://pytorch.org/docs/versions.html"> version selector &#x25BC</a>
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          

            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd mechanics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#excluding-subgraphs-from-backward">Excluding subgraphs from backward</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/autograd.html#requires-grad"><code class="docutils literal notranslate"><span class="pre">requires_grad</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#how-autograd-encodes-the-history">How autograd encodes the history</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#in-place-operations-with-autograd">In-place operations with autograd</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#in-place-correctness-checks">In-place correctness checks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">Broadcasting semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/broadcasting.html#general-semantics">General semantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/broadcasting.html#in-place-semantics">In-place semantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/broadcasting.html#backwards-compatibility">Backwards compatibility</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/cuda.html#asynchronous-execution">Asynchronous execution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/cuda.html#cuda-streams">CUDA streams</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/cuda.html#memory-management">Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/cuda.html#best-practices">Best practices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/cuda.html#device-agnostic-code">Device-agnostic code</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/cuda.html#use-pinned-memory-buffers">Use pinned memory buffers</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/cuda.html#use-nn-dataparallel-instead-of-multiprocessing">Use nn.DataParallel instead of multiprocessing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">Extending PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/extending.html#extending-torch-autograd">Extending <code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/extending.html#extending-torch-nn">Extending <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/extending.html#adding-a-module">Adding a <code class="docutils literal notranslate"><span class="pre">Module</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/extending.html#writing-custom-c-extensions">Writing custom C++ extensions</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/extending.html#id1">Writing custom C extensions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/faq.html">Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/faq.html#my-model-reports-cuda-runtime-error-2-out-of-memory">My model reports “cuda runtime error(2): out of memory”</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/faq.html#my-gpu-memory-isn-t-freed-properly">My GPU memory isn’t freed properly</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/faq.html#my-data-loader-workers-return-identical-random-numbers">My data loader workers return identical random numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/faq.html#my-recurrent-network-doesn-t-work-with-data-parallelism">My recurrent network doesn’t work with data parallelism</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">Multiprocessing best practices</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/multiprocessing.html#sharing-cuda-tensors">Sharing CUDA tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/multiprocessing.html#best-practices-and-tips">Best practices and tips</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/multiprocessing.html#avoiding-and-fighting-deadlocks">Avoiding and fighting deadlocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/multiprocessing.html#reuse-buffers-passed-through-a-queue">Reuse buffers passed through a Queue</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/multiprocessing.html#asynchronous-multiprocess-training-e-g-hogwild">Asynchronous multiprocess training (e.g. Hogwild)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="notes/multiprocessing.html#hogwild">Hogwild</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">Serialization semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/serialization.html#best-practices">Best practices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/serialization.html#recommended-approach-for-saving-a-model">Recommended approach for saving a model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/windows.html">Windows FAQ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/windows.html#building-from-source">Building from source</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#include-optional-components">Include optional components</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#speeding-cuda-build-for-windows">Speeding CUDA build for Windows</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#one-key-install-script">One key install script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/windows.html#extension">Extension</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#cffi-extension">CFFI Extension</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#cpp-extension">Cpp Extension</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/windows.html#installation">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#package-not-found-in-win-32-channel">Package not found in win-32 channel.</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#why-are-there-no-python-2-packages-for-windows">Why are there no Python 2 packages for Windows?</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#import-error">Import error</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/windows.html#usage-multiprocessing">Usage (multiprocessing)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#multiprocessing-error-without-if-clause-protection">Multiprocessing error without if-clause protection</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#multiprocessing-error-broken-pipe">Multiprocessing error “Broken pipe”</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#multiprocessing-error-driver-shut-down">Multiprocessing error “driver shut down”</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#cuda-ipc-operations">CUDA IPC operations</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="torch.html">torch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.html#tensors">Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.html#creation-ops">Creation Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#indexing-slicing-joining-mutating-ops">Indexing, Slicing, Joining, Mutating Ops</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torch.html#random-sampling">Random sampling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.html#in-place-random-sampling">In-place random sampling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torch.html#serialization">Serialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.html#parallelism">Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.html#locally-disabling-gradient-computation">Locally disabling gradient computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.html#math-operations">Math operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.html#pointwise-ops">Pointwise Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#reduction-ops">Reduction Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#comparison-ops">Comparison Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#spectral-ops">Spectral Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#other-operations">Other Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#blas-and-lapack-operations">BLAS and LAPACK Operations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tensor_attributes.html#torch-dtype">torch.dtype</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_attributes.html#torch-device">torch.device</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_attributes.html#torch-layout">torch.layout</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#random-number-generator">Random Number Generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#communication-collectives">Communication collectives</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#streams-and-events">Streams and events</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#memory-management">Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#nvidia-tools-extension-nvtx">NVIDIA Tools Extension (NVTX)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">torch.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nn.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#containers">Containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#module"><span class="hidden-section">Module</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#sequential"><span class="hidden-section">Sequential</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#modulelist"><span class="hidden-section">ModuleList</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#moduledict"><span class="hidden-section">ModuleDict</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#parameterlist"><span class="hidden-section">ParameterList</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#parameterdict"><span class="hidden-section">ParameterDict</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#convolution-layers">Convolution layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv1d"><span class="hidden-section">Conv1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv2d"><span class="hidden-section">Conv2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv3d"><span class="hidden-section">Conv3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#convtranspose1d"><span class="hidden-section">ConvTranspose1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#convtranspose2d"><span class="hidden-section">ConvTranspose2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#convtranspose3d"><span class="hidden-section">ConvTranspose3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#unfold"><span class="hidden-section">Unfold</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#fold"><span class="hidden-section">Fold</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#pooling-layers">Pooling layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxpool1d"><span class="hidden-section">MaxPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxpool2d"><span class="hidden-section">MaxPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxpool3d"><span class="hidden-section">MaxPool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxunpool1d"><span class="hidden-section">MaxUnpool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxunpool2d"><span class="hidden-section">MaxUnpool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxunpool3d"><span class="hidden-section">MaxUnpool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avgpool1d"><span class="hidden-section">AvgPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avgpool2d"><span class="hidden-section">AvgPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avgpool3d"><span class="hidden-section">AvgPool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#fractionalmaxpool2d"><span class="hidden-section">FractionalMaxPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lppool1d"><span class="hidden-section">LPPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lppool2d"><span class="hidden-section">LPPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptivemaxpool1d"><span class="hidden-section">AdaptiveMaxPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptivemaxpool2d"><span class="hidden-section">AdaptiveMaxPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptivemaxpool3d"><span class="hidden-section">AdaptiveMaxPool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptiveavgpool1d"><span class="hidden-section">AdaptiveAvgPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptiveavgpool2d"><span class="hidden-section">AdaptiveAvgPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptiveavgpool3d"><span class="hidden-section">AdaptiveAvgPool3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#padding-layers">Padding layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#reflectionpad1d"><span class="hidden-section">ReflectionPad1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#reflectionpad2d"><span class="hidden-section">ReflectionPad2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#replicationpad1d"><span class="hidden-section">ReplicationPad1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#replicationpad2d"><span class="hidden-section">ReplicationPad2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#replicationpad3d"><span class="hidden-section">ReplicationPad3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#zeropad2d"><span class="hidden-section">ZeroPad2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#constantpad1d"><span class="hidden-section">ConstantPad1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#constantpad2d"><span class="hidden-section">ConstantPad2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#constantpad3d"><span class="hidden-section">ConstantPad3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#non-linear-activations-weighted-sum-nonlinearity">Non-linear activations (weighted sum, nonlinearity)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#elu"><span class="hidden-section">ELU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hardshrink"><span class="hidden-section">Hardshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hardtanh"><span class="hidden-section">Hardtanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#leakyrelu"><span class="hidden-section">LeakyReLU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#logsigmoid"><span class="hidden-section">LogSigmoid</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#prelu"><span class="hidden-section">PReLU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#relu"><span class="hidden-section">ReLU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#relu6"><span class="hidden-section">ReLU6</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#rrelu"><span class="hidden-section">RReLU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#selu"><span class="hidden-section">SELU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#sigmoid"><span class="hidden-section">Sigmoid</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softplus"><span class="hidden-section">Softplus</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softshrink"><span class="hidden-section">Softshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softsign"><span class="hidden-section">Softsign</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#tanh"><span class="hidden-section">Tanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#tanhshrink"><span class="hidden-section">Tanhshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#threshold"><span class="hidden-section">Threshold</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#non-linear-activations-other">Non-linear activations (other)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softmin"><span class="hidden-section">Softmin</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softmax"><span class="hidden-section">Softmax</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softmax2d"><span class="hidden-section">Softmax2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#logsoftmax"><span class="hidden-section">LogSoftmax</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptivelogsoftmaxwithloss"><span class="hidden-section">AdaptiveLogSoftmaxWithLoss</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#normalization-layers">Normalization layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batchnorm1d"><span class="hidden-section">BatchNorm1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batchnorm2d"><span class="hidden-section">BatchNorm2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batchnorm3d"><span class="hidden-section">BatchNorm3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#groupnorm"><span class="hidden-section">GroupNorm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#instancenorm1d"><span class="hidden-section">InstanceNorm1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#instancenorm2d"><span class="hidden-section">InstanceNorm2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#instancenorm3d"><span class="hidden-section">InstanceNorm3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#layernorm"><span class="hidden-section">LayerNorm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#localresponsenorm"><span class="hidden-section">LocalResponseNorm</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#recurrent-layers">Recurrent layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#rnn"><span class="hidden-section">RNN</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lstm"><span class="hidden-section">LSTM</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#gru"><span class="hidden-section">GRU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#rnncell"><span class="hidden-section">RNNCell</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lstmcell"><span class="hidden-section">LSTMCell</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#grucell"><span class="hidden-section">GRUCell</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#linear-layers">Linear layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#linear"><span class="hidden-section">Linear</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#bilinear"><span class="hidden-section">Bilinear</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#dropout-layers">Dropout layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dropout"><span class="hidden-section">Dropout</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dropout2d"><span class="hidden-section">Dropout2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dropout3d"><span class="hidden-section">Dropout3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#alphadropout"><span class="hidden-section">AlphaDropout</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#sparse-layers">Sparse layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#embedding"><span class="hidden-section">Embedding</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#embeddingbag"><span class="hidden-section">EmbeddingBag</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#distance-functions">Distance functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosinesimilarity"><span class="hidden-section">CosineSimilarity</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pairwisedistance"><span class="hidden-section">PairwiseDistance</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#loss-functions">Loss functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#l1loss"><span class="hidden-section">L1Loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#mseloss"><span class="hidden-section">MSELoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#crossentropyloss"><span class="hidden-section">CrossEntropyLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#nllloss"><span class="hidden-section">NLLLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#poissonnllloss"><span class="hidden-section">PoissonNLLLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#kldivloss"><span class="hidden-section">KLDivLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#bceloss"><span class="hidden-section">BCELoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#bcewithlogitsloss"><span class="hidden-section">BCEWithLogitsLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#marginrankingloss"><span class="hidden-section">MarginRankingLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hingeembeddingloss"><span class="hidden-section">HingeEmbeddingLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabelmarginloss"><span class="hidden-section">MultiLabelMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#smoothl1loss"><span class="hidden-section">SmoothL1Loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softmarginloss"><span class="hidden-section">SoftMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabelsoftmarginloss"><span class="hidden-section">MultiLabelSoftMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosineembeddingloss"><span class="hidden-section">CosineEmbeddingLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multimarginloss"><span class="hidden-section">MultiMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#tripletmarginloss"><span class="hidden-section">TripletMarginLoss</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#vision-layers">Vision layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pixelshuffle"><span class="hidden-section">PixelShuffle</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsample"><span class="hidden-section">Upsample</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsamplingnearest2d"><span class="hidden-section">UpsamplingNearest2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsamplingbilinear2d"><span class="hidden-section">UpsamplingBilinear2d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#dataparallel-layers-multi-gpu-distributed">DataParallel layers (multi-GPU, distributed)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dataparallel"><span class="hidden-section">DataParallel</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#distributeddataparallel"><span class="hidden-section">DistributedDataParallel</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#utilities">Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#clip-grad-norm"><span class="hidden-section">clip_grad_norm_</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#clip-grad-value"><span class="hidden-section">clip_grad_value_</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#parameters-to-vector"><span class="hidden-section">parameters_to_vector</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#vector-to-parameters"><span class="hidden-section">vector_to_parameters</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#weight-norm"><span class="hidden-section">weight_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#remove-weight-norm"><span class="hidden-section">remove_weight_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#spectral-norm"><span class="hidden-section">spectral_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#remove-spectral-norm"><span class="hidden-section">remove_spectral_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#packedsequence"><span class="hidden-section">PackedSequence</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pack-padded-sequence"><span class="hidden-section">pack_padded_sequence</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pad-packed-sequence"><span class="hidden-section">pad_packed_sequence</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pad-sequence"><span class="hidden-section">pad_sequence</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pack-sequence"><span class="hidden-section">pack_sequence</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nn.html#torch-nn-functional">torch.nn.functional</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nn.html#convolution-functions">Convolution functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id20"><span class="hidden-section">conv1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id21"><span class="hidden-section">conv2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id22"><span class="hidden-section">conv3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv-transpose1d"><span class="hidden-section">conv_transpose1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv-transpose2d"><span class="hidden-section">conv_transpose2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv-transpose3d"><span class="hidden-section">conv_transpose3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id23"><span class="hidden-section">unfold</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id24"><span class="hidden-section">fold</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#pooling-functions">Pooling functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avg-pool1d"><span class="hidden-section">avg_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avg-pool2d"><span class="hidden-section">avg_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avg-pool3d"><span class="hidden-section">avg_pool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-pool1d"><span class="hidden-section">max_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-pool2d"><span class="hidden-section">max_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-pool3d"><span class="hidden-section">max_pool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-unpool1d"><span class="hidden-section">max_unpool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-unpool2d"><span class="hidden-section">max_unpool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-unpool3d"><span class="hidden-section">max_unpool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lp-pool1d"><span class="hidden-section">lp_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lp-pool2d"><span class="hidden-section">lp_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-max-pool1d"><span class="hidden-section">adaptive_max_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-max-pool2d"><span class="hidden-section">adaptive_max_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-max-pool3d"><span class="hidden-section">adaptive_max_pool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-avg-pool1d"><span class="hidden-section">adaptive_avg_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-avg-pool2d"><span class="hidden-section">adaptive_avg_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-avg-pool3d"><span class="hidden-section">adaptive_avg_pool3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#non-linear-activation-functions">Non-linear activation functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id25"><span class="hidden-section">threshold</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id26"><span class="hidden-section">relu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id27"><span class="hidden-section">hardtanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id28"><span class="hidden-section">relu6</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id29"><span class="hidden-section">elu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id30"><span class="hidden-section">selu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#leaky-relu"><span class="hidden-section">leaky_relu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id31"><span class="hidden-section">prelu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id32"><span class="hidden-section">rrelu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#glu"><span class="hidden-section">glu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id33"><span class="hidden-section">logsigmoid</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id34"><span class="hidden-section">hardshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id35"><span class="hidden-section">tanhshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id36"><span class="hidden-section">softsign</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id37"><span class="hidden-section">softplus</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id38"><span class="hidden-section">softmin</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id39"><span class="hidden-section">softmax</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id40"><span class="hidden-section">softshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#gumbel-softmax"><span class="hidden-section">gumbel_softmax</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#log-softmax"><span class="hidden-section">log_softmax</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id41"><span class="hidden-section">tanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id42"><span class="hidden-section">sigmoid</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#normalization-functions">Normalization functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batch-norm"><span class="hidden-section">batch_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#instance-norm"><span class="hidden-section">instance_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#layer-norm"><span class="hidden-section">layer_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#local-response-norm"><span class="hidden-section">local_response_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#normalize"><span class="hidden-section">normalize</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#linear-functions">Linear functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id43"><span class="hidden-section">linear</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id44"><span class="hidden-section">bilinear</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#dropout-functions">Dropout functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id45"><span class="hidden-section">dropout</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#alpha-dropout"><span class="hidden-section">alpha_dropout</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id46"><span class="hidden-section">dropout2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id47"><span class="hidden-section">dropout3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#sparse-functions">Sparse functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id48"><span class="hidden-section">embedding</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#embedding-bag"><span class="hidden-section">embedding_bag</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#id49">Distance functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pairwise-distance"><span class="hidden-section">pairwise_distance</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosine-similarity"><span class="hidden-section">cosine_similarity</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#id50">Loss functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#binary-cross-entropy"><span class="hidden-section">binary_cross_entropy</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#poisson-nll-loss"><span class="hidden-section">poisson_nll_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosine-embedding-loss"><span class="hidden-section">cosine_embedding_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cross-entropy"><span class="hidden-section">cross_entropy</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hinge-embedding-loss"><span class="hidden-section">hinge_embedding_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#kl-div"><span class="hidden-section">kl_div</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#l1-loss"><span class="hidden-section">l1_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#mse-loss"><span class="hidden-section">mse_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#margin-ranking-loss"><span class="hidden-section">margin_ranking_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabel-margin-loss"><span class="hidden-section">multilabel_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabel-soft-margin-loss"><span class="hidden-section">multilabel_soft_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multi-margin-loss"><span class="hidden-section">multi_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#nll-loss"><span class="hidden-section">nll_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#binary-cross-entropy-with-logits"><span class="hidden-section">binary_cross_entropy_with_logits</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#smooth-l1-loss"><span class="hidden-section">smooth_l1_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#soft-margin-loss"><span class="hidden-section">soft_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#triplet-margin-loss"><span class="hidden-section">triplet_margin_loss</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#vision-functions">Vision functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pixel-shuffle"><span class="hidden-section">pixel_shuffle</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pad"><span class="hidden-section">pad</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#interpolate"><span class="hidden-section">interpolate</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id51"><span class="hidden-section">upsample</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsample-nearest"><span class="hidden-section">upsample_nearest</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsample-bilinear"><span class="hidden-section">upsample_bilinear</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#grid-sample"><span class="hidden-section">grid_sample</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#affine-grid"><span class="hidden-section">affine_grid</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#dataparallel-functions-multi-gpu-distributed">DataParallel functions (multi-GPU, distributed)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#data-parallel"><span class="hidden-section">data_parallel</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nn.html#torch-nn-init">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a><ul>
<li class="toctree-l2"><a class="reference internal" href="optim.html#how-to-use-an-optimizer">How to use an optimizer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="optim.html#constructing-it">Constructing it</a></li>
<li class="toctree-l3"><a class="reference internal" href="optim.html#per-parameter-options">Per-parameter options</a></li>
<li class="toctree-l3"><a class="reference internal" href="optim.html#taking-an-optimization-step">Taking an optimization step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="optim.html#optimizer-step"><code class="docutils literal notranslate"><span class="pre">optimizer.step()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="optim.html#optimizer-step-closure"><code class="docutils literal notranslate"><span class="pre">optimizer.step(closure)</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="optim.html#algorithms">Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="optim.html#how-to-adjust-learning-rate">How to adjust Learning Rate</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a><ul>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#locally-disabling-gradient-computation">Locally disabling gradient computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#in-place-operations-on-tensors">In-place operations on Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="autograd.html#in-place-correctness-checks">In-place correctness checks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#variable-deprecated">Variable (deprecated)</a></li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#tensor-autograd-functions">Tensor autograd functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#function"><span class="hidden-section">Function</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#numerical-gradient-checking">Numerical gradient checking</a></li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#profiler">Profiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#anomaly-detection">Anomaly detection</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">torch.distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#score-function">Score function</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pathwise-derivative">Pathwise derivative</a></li>
<li class="toctree-l2"><a class="reference internal" href="#distribution"><span class="hidden-section">Distribution</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#exponentialfamily"><span class="hidden-section">ExponentialFamily</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#bernoulli"><span class="hidden-section">Bernoulli</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#beta"><span class="hidden-section">Beta</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#binomial"><span class="hidden-section">Binomial</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#categorical"><span class="hidden-section">Categorical</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#cauchy"><span class="hidden-section">Cauchy</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#chi2"><span class="hidden-section">Chi2</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#dirichlet"><span class="hidden-section">Dirichlet</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#exponential"><span class="hidden-section">Exponential</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#fishersnedecor"><span class="hidden-section">FisherSnedecor</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#gamma"><span class="hidden-section">Gamma</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#geometric"><span class="hidden-section">Geometric</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#gumbel"><span class="hidden-section">Gumbel</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#halfcauchy"><span class="hidden-section">HalfCauchy</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#halfnormal"><span class="hidden-section">HalfNormal</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#independent"><span class="hidden-section">Independent</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#laplace"><span class="hidden-section">Laplace</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#lognormal"><span class="hidden-section">LogNormal</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#multinomial"><span class="hidden-section">Multinomial</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#multivariatenormal"><span class="hidden-section">MultivariateNormal</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#normal"><span class="hidden-section">Normal</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#onehotcategorical"><span class="hidden-section">OneHotCategorical</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#pareto"><span class="hidden-section">Pareto</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#poisson"><span class="hidden-section">Poisson</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#relaxedbernoulli"><span class="hidden-section">RelaxedBernoulli</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#relaxedonehotcategorical"><span class="hidden-section">RelaxedOneHotCategorical</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#studentt"><span class="hidden-section">StudentT</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#transformeddistribution"><span class="hidden-section">TransformedDistribution</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#uniform"><span class="hidden-section">Uniform</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch.distributions.kl"><cite>KL Divergence</cite></a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch.distributions.transforms"><cite>Transforms</cite></a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch.distributions.constraints"><cite>Constraints</cite></a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch.distributions.constraint_registry"><cite>Constraint Registry</cite></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="multiprocessing.html">torch.multiprocessing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="multiprocessing.html#strategy-management">Strategy management</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiprocessing.html#sharing-cuda-tensors">Sharing CUDA tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiprocessing.html#sharing-strategies">Sharing strategies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="multiprocessing.html#file-descriptor-file-descriptor">File descriptor - <code class="docutils literal notranslate"><span class="pre">file_descriptor</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="multiprocessing.html#file-system-file-system">File system - <code class="docutils literal notranslate"><span class="pre">file_system</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a><ul>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#basics">Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#initialization">Initialization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="distributed.html#tcp-initialization">TCP initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed.html#shared-file-system-initialization">Shared file-system initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed.html#environment-variable-initialization">Environment variable initialization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#groups">Groups</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#point-to-point-communication">Point-to-point communication</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#collective-functions">Collective functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#multi-gpu-collective-functions">Multi-GPU collective functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#launch-utility">Launch utility</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="ffi.html">torch.utils.ffi</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">torch.onnx</a><ul>
<li class="toctree-l2"><a class="reference internal" href="onnx.html#example-end-to-end-alexnet-from-pytorch-to-caffe2">Example: End-to-end AlexNet from PyTorch to Caffe2</a></li>
<li class="toctree-l2"><a class="reference internal" href="onnx.html#limitations">Limitations</a></li>
<li class="toctree-l2"><a class="reference internal" href="onnx.html#supported-operators">Supported operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="onnx.html#functions">Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="legacy.html">torch.legacy</a></li>
</ul>
<p class="caption"><span class="caption-text">torchvision Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="torchvision/index.html">torchvision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="torchvision/datasets.html">torchvision.datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#mnist">MNIST</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#fashion-mnist">Fashion-MNIST</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#emnist">EMNIST</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#coco">COCO</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torchvision/datasets.html#captions">Captions</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchvision/datasets.html#detection">Detection</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#lsun">LSUN</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#imagefolder">ImageFolder</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#datasetfolder">DatasetFolder</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#imagenet-12">Imagenet-12</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#cifar">CIFAR</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#stl10">STL10</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#svhn">SVHN</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#phototour">PhotoTour</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/models.html">torchvision.models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#id1">Alexnet</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#id2">VGG</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#id3">ResNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#id4">SqueezeNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#id5">DenseNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#inception-v3">Inception v3</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/transforms.html">torchvision.transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torchvision/transforms.html#transforms-on-pil-image">Transforms on PIL Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/transforms.html#transforms-on-torch-tensor">Transforms on torch.*Tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/transforms.html#conversion-transforms">Conversion Transforms</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/transforms.html#generic-transforms">Generic Transforms</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/transforms.html#module-torchvision.transforms.functional">Functional Transforms</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/utils.html">torchvision.utils</a></li>
</ul>
</li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PyTorch</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Probability distributions - torch.distributions</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/distributions.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-torch.distributions">
<span id="probability-distributions-torch-distributions"></span><h1>Probability distributions - torch.distributions<a class="headerlink" href="#module-torch.distributions" title="Permalink to this headline">¶</a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">distributions</span></code> package contains parameterizable probability distributions
and sampling functions. This allows the construction of stochastic computation
graphs and stochastic gradient estimators for optimization. This package
generally follows the design of the <a class="reference external" href="https://arxiv.org/abs/1711.10604">TensorFlow Distributions</a> package.</p>
<p>It is not possible to directly backpropagate through random samples. However,
there are two main methods for creating surrogate functions that can be
backpropagated through. These are the score function estimator/likelihood ratio
estimator/REINFORCE and the pathwise derivative estimator. REINFORCE is commonly
seen as the basis for policy gradient methods in reinforcement learning, and the
pathwise derivative estimator is commonly seen in the reparameterization trick
in variational autoencoders. Whilst the score function only requires the value
of samples <span class="math notranslate nohighlight">\(f(x)\)</span>, the pathwise derivative requires the derivative
<span class="math notranslate nohighlight">\(f'(x)\)</span>. The next sections discuss these two in a reinforcement learning
example. For more details see
<a class="reference external" href="https://arxiv.org/abs/1506.05254">Gradient Estimation Using Stochastic Computation Graphs</a> .</p>
<div class="section" id="score-function">
<h2>Score function<a class="headerlink" href="#score-function" title="Permalink to this headline">¶</a></h2>
<p>When the probability density function is differentiable with respect to its
parameters, we only need <code class="xref py py-meth docutils literal notranslate"><span class="pre">sample()</span></code> and
<code class="xref py py-meth docutils literal notranslate"><span class="pre">log_prob()</span></code> to implement REINFORCE:</p>
<div class="math notranslate nohighlight">
\[\Delta\theta  = \alpha r \frac{\partial\log p(a|\pi^\theta(s))}{\partial\theta}\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta\)</span> are the parameters, <span class="math notranslate nohighlight">\(\alpha\)</span> is the learning rate,
<span class="math notranslate nohighlight">\(r\)</span> is the reward and <span class="math notranslate nohighlight">\(p(a|\pi^\theta(s))\)</span> is the probability of
taking action <span class="math notranslate nohighlight">\(a\)</span> in state <span class="math notranslate nohighlight">\(s\)</span> given policy <span class="math notranslate nohighlight">\(\pi^\theta\)</span>.</p>
<p>In practice we would sample an action from the output of a network, apply this
action in an environment, and then use <code class="docutils literal notranslate"><span class="pre">log_prob</span></code> to construct an equivalent
loss function. Note that we use a negative because optimizers use gradient
descent, whilst the rule above assumes gradient ascent. With a categorical
policy, the code for implementing REINFORCE would be as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">probs</span> <span class="o">=</span> <span class="n">policy_network</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
<span class="c1"># Note that this is equivalent to what used to be called multinomial</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">m</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">*</span> <span class="n">reward</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="pathwise-derivative">
<h2>Pathwise derivative<a class="headerlink" href="#pathwise-derivative" title="Permalink to this headline">¶</a></h2>
<p>The other way to implement these stochastic/policy gradients would be to use the
reparameterization trick from the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">rsample()</span></code> method, where the
parameterized random variable can be constructed via a parameterized
deterministic function of a parameter-free random variable. The reparameterized
sample therefore becomes differentiable. The code for implementing the pathwise
derivative would be as follows:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="n">policy_network</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="p">)</span>
<span class="c1"># Any distribution with .has_rsample == True could work based on the application</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">rsample</span><span class="p">()</span>
<span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>  <span class="c1"># Assuming that reward is differentiable</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">reward</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="distribution">
<h2><span class="hidden-section">Distribution</span><a class="headerlink" href="#distribution" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.distribution.Distribution">
<em class="property">class </em><code class="descclassname">torch.distributions.distribution.</code><code class="descname">Distribution</code><span class="sig-paren">(</span><em>batch_shape=torch.Size([])</em>, <em>event_shape=torch.Size([])</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></a></p>
<p>Distribution is the abstract base class for probability distributions.</p>
<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.arg_constraints">
<code class="descname">arg_constraints</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary from argument names to
<a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Constraint</span></code></a> objects that
should be satisfied by each argument of this distribution. Args that
are not tensors need not appear in this dict.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.batch_shape">
<code class="descname">batch_shape</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.batch_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the shape over which parameters are batched.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.cdf" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the cumulative density/mass function evaluated at
<cite>value</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>value</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – </td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns entropy of distribution, batched over batch_shape.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Tensor of shape batch_shape.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns tensor containing all values supported by a discrete
distribution. The result will enumerate over dimension 0, so the shape
of the result will be <cite>(cardinality,) + batch_shape + event_shape</cite>
(where <cite>event_shape = ()</cite> for univariate distributions).</p>
<p>Note that this enumerates over all batched tensors in lock-step
<cite>[[0, 0], [1, 1], …]</cite>. To iterate over the full Cartesian product
use <cite>itertools.product(m.enumerate_support())</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Tensor iterating over dimension 0.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.event_shape">
<code class="descname">event_shape</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.event_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the shape of a single sample (without batching).</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.icdf" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the inverse cumulative density/mass function evaluated at
<cite>value</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>value</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – </td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.log_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the log of the probability density/mass function evaluated at
<cite>value</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>value</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – </td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.mean" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the mean of the distribution.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.perplexity">
<code class="descname">perplexity</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.perplexity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.perplexity" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns perplexity of distribution, batched over batch_shape.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Tensor of shape batch_shape.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.rsample" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a sample_shape shaped reparameterized sample or sample_shape
shaped batch of reparameterized samples if the distribution parameters
are batched.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a sample_shape shaped sample or sample_shape shaped batch of
samples if the distribution parameters are batched.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.sample_n">
<code class="descname">sample_n</code><span class="sig-paren">(</span><em>n</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.sample_n"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.sample_n" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates n samples or n batches of samples if the distribution
parameters are batched.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.stddev" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the standard deviation of the distribution.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.support" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a <a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Constraint</span></code></a> object
representing this distribution’s support.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.variance" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the variance of the distribution.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="exponentialfamily">
<h2><span class="hidden-section">ExponentialFamily</span><a class="headerlink" href="#exponentialfamily" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.exp_family.ExponentialFamily">
<em class="property">class </em><code class="descclassname">torch.distributions.exp_family.</code><code class="descname">ExponentialFamily</code><span class="sig-paren">(</span><em>batch_shape=torch.Size([])</em>, <em>event_shape=torch.Size([])</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exp_family.html#ExponentialFamily"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exp_family.ExponentialFamily" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>ExponentialFamily is the abstract base class for probability distributions belonging to an
exponential family, whose probability mass/density function has the form is defined below</p>
<div class="math notranslate nohighlight">
\[p_{F}(x; \theta) = \exp(\langle t(x), \theta\rangle) - F(\theta) + k(x))\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta\)</span> denotes the natural parameters, <span class="math notranslate nohighlight">\(t(x)\)</span> denotes the sufficient statistic,
<span class="math notranslate nohighlight">\(F(\theta)\)</span> is the log normalizer function for a given family and <span class="math notranslate nohighlight">\(k(x)\)</span> is the carrier
measure.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This class is an intermediary between the <cite>Distribution</cite> class and distributions which belong
to an exponential family mainly to check the correctness of the <cite>.entropy()</cite> and analytic KL
divergence methods. We use this class to compute the entropy and KL divergence using the AD frame-
work and Bregman divergences (courtesy of: Frank Nielsen and Richard Nock, Entropies and
Cross-entropies of Exponential Families).</p>
</div>
<dl class="method">
<dt id="torch.distributions.exp_family.ExponentialFamily.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exp_family.html#ExponentialFamily.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exp_family.ExponentialFamily.entropy" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to compute the entropy using Bregman divergence of the log normalizer.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="bernoulli">
<h2><span class="hidden-section">Bernoulli</span><a class="headerlink" href="#bernoulli" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.bernoulli.Bernoulli">
<em class="property">class </em><code class="descclassname">torch.distributions.bernoulli.</code><code class="descname">Bernoulli</code><span class="sig-paren">(</span><em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a Bernoulli distribution parameterized by <cite>probs</cite> or <cite>logits</cite>.</p>
<p>Samples are binary (0 or 1). They take the value <cite>1</cite> with probability <cite>p</cite>
and <cite>0</cite> with probability <cite>1 - p</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.3</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># 30% chance 1; 70% chance 0</span>
<span class="go">tensor([ 0.])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>probs</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the probabilty of sampling <cite>1</cite></li>
<li><strong>logits</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the log-odds of sampling <cite>1</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Interval object at 0x7f65512f4898&gt;}</em><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.bernoulli.Bernoulli.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.bernoulli.Bernoulli.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.has_enumerate_support">
<code class="descname">has_enumerate_support</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.has_enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.bernoulli.Bernoulli.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.logits">
<code class="descname">logits</code><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.logits" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.param_shape">
<code class="descname">param_shape</code><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.param_shape" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.probs">
<code class="descname">probs</code><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.probs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.bernoulli.Bernoulli.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.sample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Boolean object&gt;</em><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="beta">
<h2><span class="hidden-section">Beta</span><a class="headerlink" href="#beta" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.beta.Beta">
<em class="property">class </em><code class="descclassname">torch.distributions.beta.</code><code class="descname">Beta</code><span class="sig-paren">(</span><em>concentration1</em>, <em>concentration0</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/beta.html#Beta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.beta.Beta" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Beta distribution parameterized by <cite>concentration1</cite> and <cite>concentration0</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Beta</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Beta distributed with concentration concentration1 and concentration0</span>
<span class="go">tensor([ 0.1046])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>concentration1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 1st concentration parameter of the distribution
(often referred to as alpha)</li>
<li><strong>concentration0</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – 2nd concentration parameter of the distribution
(often referred to as beta)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.beta.Beta.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'concentration0': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;, 'concentration1': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.beta.Beta.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.concentration0">
<code class="descname">concentration0</code><a class="headerlink" href="#torch.distributions.beta.Beta.concentration0" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.concentration1">
<code class="descname">concentration1</code><a class="headerlink" href="#torch.distributions.beta.Beta.concentration1" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.beta.Beta.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/beta.html#Beta.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.beta.Beta.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.beta.Beta.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.beta.Beta.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/beta.html#Beta.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.beta.Beta.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.beta.Beta.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.beta.Beta.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=()</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/beta.html#Beta.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.beta.Beta.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Interval object&gt;</em><a class="headerlink" href="#torch.distributions.beta.Beta.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.beta.Beta.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="binomial">
<h2><span class="hidden-section">Binomial</span><a class="headerlink" href="#binomial" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.binomial.Binomial">
<em class="property">class </em><code class="descclassname">torch.distributions.binomial.</code><code class="descname">Binomial</code><span class="sig-paren">(</span><em>total_count=1</em>, <em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Binomial distribution parameterized by <cite>total_count</cite> and
either <cite>probs</cite> or <cite>logits</cite> (but not both). <cite>total_count</cite> must be
broadcastable with <cite>probs</cite>/<cite>logits</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Binomial</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span> <span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="go">tensor([   0.,   22.,   71.,  100.])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Binomial</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">5.</span><span class="p">],</span> <span class="p">[</span><span class="mf">10.</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="go">tensor([[ 4.,  5.],</span>
<span class="go">        [ 7.,  6.]])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>total_count</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – number of Bernoulli trials</li>
<li><strong>probs</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – Event probabilities</li>
<li><strong>logits</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – Event log-odds</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Interval object at 0x7f65512f4898&gt;, 'total_count': &lt;torch.distributions.constraints._IntegerGreaterThan object at 0x7f65512f4780&gt;}</em><a class="headerlink" href="#torch.distributions.binomial.Binomial.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.binomial.Binomial.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial.enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.has_enumerate_support">
<code class="descname">has_enumerate_support</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.binomial.Binomial.has_enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.binomial.Binomial.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.logits">
<code class="descname">logits</code><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial.logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial.logits" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.binomial.Binomial.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.param_shape">
<code class="descname">param_shape</code><a class="headerlink" href="#torch.distributions.binomial.Binomial.param_shape" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.probs">
<code class="descname">probs</code><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial.probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial.probs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.binomial.Binomial.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial.sample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.binomial.Binomial.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.binomial.Binomial.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="categorical">
<h2><span class="hidden-section">Categorical</span><a class="headerlink" href="#categorical" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.categorical.Categorical">
<em class="property">class </em><code class="descclassname">torch.distributions.categorical.</code><code class="descname">Categorical</code><span class="sig-paren">(</span><em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a categorical distribution parameterized by either <a class="reference internal" href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code class="xref py py-attr docutils literal notranslate"><span class="pre">probs</span></code></a> or
<a class="reference internal" href="#torch.distributions.categorical.Categorical.logits" title="torch.distributions.categorical.Categorical.logits"><code class="xref py py-attr docutils literal notranslate"><span class="pre">logits</span></code></a> (but not both).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">It is equivalent to the distribution that <a class="reference internal" href="torch.html#torch.multinomial" title="torch.multinomial"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.multinomial()</span></code></a>
samples from.</p>
</div>
<p>Samples are integers from <cite>0 … K-1</cite> where <cite>K</cite> is probs.size(-1).</p>
<p>If <a class="reference internal" href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code class="xref py py-attr docutils literal notranslate"><span class="pre">probs</span></code></a> is 1D with length-<cite>K</cite>, each element is the relative
probability of sampling the class at that index.</p>
<p>If <a class="reference internal" href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code class="xref py py-attr docutils literal notranslate"><span class="pre">probs</span></code></a> is 2D, it is treated as a batch of relative probability
vectors.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><a class="reference internal" href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code class="xref py py-attr docutils literal notranslate"><span class="pre">probs</span></code></a> must be non-negative, finite and have a non-zero sum,
and it will be normalized to sum to 1.</p>
</div>
<p>See also: <a class="reference internal" href="torch.html#torch.multinomial" title="torch.multinomial"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.multinomial()</span></code></a></p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span> <span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># equal probability of 0, 1, 2, 3</span>
<span class="go">tensor(3)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>probs</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – event probabilities</li>
<li><strong>logits</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – event log probabilities</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Simplex object at 0x7f65512f48d0&gt;}</em><a class="headerlink" href="#torch.distributions.categorical.Categorical.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.categorical.Categorical.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.categorical.Categorical.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.has_enumerate_support">
<code class="descname">has_enumerate_support</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.categorical.Categorical.has_enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.categorical.Categorical.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.logits">
<code class="descname">logits</code><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.logits" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.categorical.Categorical.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.param_shape">
<code class="descname">param_shape</code><a class="headerlink" href="#torch.distributions.categorical.Categorical.param_shape" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.probs">
<code class="descname">probs</code><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.probs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.categorical.Categorical.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.sample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.categorical.Categorical.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.categorical.Categorical.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="cauchy">
<h2><span class="hidden-section">Cauchy</span><a class="headerlink" href="#cauchy" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.cauchy.Cauchy">
<em class="property">class </em><code class="descclassname">torch.distributions.cauchy.</code><code class="descname">Cauchy</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Samples from a Cauchy (Lorentz) distribution. The distribution of the ratio of
independent normally distributed random variables with means <cite>0</cite> follows a
Cauchy distribution.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Cauchy</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># sample from a Cauchy distribution with loc=0 and scale=1</span>
<span class="go">tensor([ 2.3214])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – mode or median of the distribution.</li>
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – half width at half maximum.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.cauchy.Cauchy.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'loc': &lt;torch.distributions.constraints._Real object at 0x7f65512f47f0&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.cauchy.Cauchy.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.cdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.cauchy.Cauchy.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.cauchy.Cauchy.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.cauchy.Cauchy.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.icdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.cauchy.Cauchy.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.cauchy.Cauchy.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.cauchy.Cauchy.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.cauchy.Cauchy.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.cauchy.Cauchy.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="chi2">
<h2><span class="hidden-section">Chi2</span><a class="headerlink" href="#chi2" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.chi2.Chi2">
<em class="property">class </em><code class="descclassname">torch.distributions.chi2.</code><code class="descname">Chi2</code><span class="sig-paren">(</span><em>df</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/chi2.html#Chi2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.chi2.Chi2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.gamma.Gamma" title="torch.distributions.gamma.Gamma"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.gamma.Gamma</span></code></a></p>
<p>Creates a Chi2 distribution parameterized by shape parameter <cite>df</cite>.
This is exactly equivalent to Gamma(alpha=0.5*df, beta=0.5)</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Chi2</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Chi2 distributed with shape df=1</span>
<span class="go">tensor([ 0.1046])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>df</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – shape parameter of the distribution</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.chi2.Chi2.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'df': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.chi2.Chi2.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.chi2.Chi2.df">
<code class="descname">df</code><a class="headerlink" href="#torch.distributions.chi2.Chi2.df" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="dirichlet">
<h2><span class="hidden-section">Dirichlet</span><a class="headerlink" href="#dirichlet" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.dirichlet.Dirichlet">
<em class="property">class </em><code class="descclassname">torch.distributions.dirichlet.</code><code class="descname">Dirichlet</code><span class="sig-paren">(</span><em>concentration</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/dirichlet.html#Dirichlet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a Dirichlet distribution parameterized by concentration <cite>concentration</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Dirichlet</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Dirichlet distributed with concentrarion concentration</span>
<span class="go">tensor([ 0.1046,  0.8954])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>concentration</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – concentration parameter of the distribution
(often referred to as alpha)</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.dirichlet.Dirichlet.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'concentration': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.dirichlet.Dirichlet.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/dirichlet.html#Dirichlet.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.dirichlet.Dirichlet.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.dirichlet.Dirichlet.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/dirichlet.html#Dirichlet.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.dirichlet.Dirichlet.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.dirichlet.Dirichlet.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=()</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/dirichlet.html#Dirichlet.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.dirichlet.Dirichlet.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Simplex object&gt;</em><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.dirichlet.Dirichlet.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="exponential">
<h2><span class="hidden-section">Exponential</span><a class="headerlink" href="#exponential" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.exponential.Exponential">
<em class="property">class </em><code class="descclassname">torch.distributions.exponential.</code><code class="descname">Exponential</code><span class="sig-paren">(</span><em>rate</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a Exponential distribution parameterized by <cite>rate</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Exponential</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Exponential distributed with rate=1</span>
<span class="go">tensor([ 0.1046])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – rate = 1 / scale of the distribution</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'rate': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.exponential.Exponential.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.exponential.Exponential.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential.cdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.exponential.Exponential.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.exponential.Exponential.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.exponential.Exponential.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential.icdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.exponential.Exponential.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.exponential.Exponential.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.exponential.Exponential.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.exponential.Exponential.stddev" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._GreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.exponential.Exponential.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.exponential.Exponential.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="fishersnedecor">
<h2><span class="hidden-section">FisherSnedecor</span><a class="headerlink" href="#fishersnedecor" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor">
<em class="property">class </em><code class="descclassname">torch.distributions.fishersnedecor.</code><code class="descname">FisherSnedecor</code><span class="sig-paren">(</span><em>df1</em>, <em>df2</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/fishersnedecor.html#FisherSnedecor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Fisher-Snedecor distribution parameterized by <cite>df1</cite> and <cite>df2</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">FisherSnedecor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Fisher-Snedecor-distributed with df1=1 and df2=2</span>
<span class="go">tensor([ 0.2453])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>df1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – degrees of freedom parameter 1</li>
<li><strong>df2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – degrees of freedom parameter 2</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'df1': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;, 'df2': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/fishersnedecor.html#FisherSnedecor.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/fishersnedecor.html#FisherSnedecor.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._GreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="gamma">
<h2><span class="hidden-section">Gamma</span><a class="headerlink" href="#gamma" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.gamma.Gamma">
<em class="property">class </em><code class="descclassname">torch.distributions.gamma.</code><code class="descname">Gamma</code><span class="sig-paren">(</span><em>concentration</em>, <em>rate</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gamma.html#Gamma"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gamma.Gamma" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a Gamma distribution parameterized by shape <cite>concentration</cite> and <cite>rate</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Gamma distributed with concentration=1 and rate=1</span>
<span class="go">tensor([ 0.1046])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>concentration</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – shape parameter of the distribution
(often referred to as alpha)</li>
<li><strong>rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – rate = 1 / scale of the distribution
(often referred to as beta)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.gamma.Gamma.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'concentration': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;, 'rate': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.gamma.Gamma.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.gamma.Gamma.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gamma.html#Gamma.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gamma.Gamma.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gamma.Gamma.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.gamma.Gamma.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.gamma.Gamma.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gamma.html#Gamma.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gamma.Gamma.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gamma.Gamma.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.gamma.Gamma.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.gamma.Gamma.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gamma.html#Gamma.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gamma.Gamma.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gamma.Gamma.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._GreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.gamma.Gamma.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gamma.Gamma.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.gamma.Gamma.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="geometric">
<h2><span class="hidden-section">Geometric</span><a class="headerlink" href="#geometric" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.geometric.Geometric">
<em class="property">class </em><code class="descclassname">torch.distributions.geometric.</code><code class="descname">Geometric</code><span class="sig-paren">(</span><em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Geometric distribution parameterized by <cite>probs</cite>, where <cite>probs</cite> is the probability of success of Bernoulli
trials. It represents the probability that in k + 1 Bernoulli trials, the first k trials failed, before
seeing a success.</p>
<p>Samples are non-negative integers [0, inf).</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Geometric</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.3</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># underlying Bernoulli has 30% chance 1; 70% chance 0</span>
<span class="go">tensor([ 2.])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>probs</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the probabilty of sampling <cite>1</cite>. Must be in range (0, 1]</li>
<li><strong>logits</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the log-odds of sampling <cite>1</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Interval object at 0x7f65512f4898&gt;}</em><a class="headerlink" href="#torch.distributions.geometric.Geometric.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.geometric.Geometric.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.geometric.Geometric.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.logits">
<code class="descname">logits</code><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric.logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric.logits" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.geometric.Geometric.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.probs">
<code class="descname">probs</code><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric.probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric.probs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.geometric.Geometric.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric.sample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._IntegerGreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.geometric.Geometric.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.geometric.Geometric.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="gumbel">
<h2><span class="hidden-section">Gumbel</span><a class="headerlink" href="#gumbel" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.gumbel.Gumbel">
<em class="property">class </em><code class="descclassname">torch.distributions.gumbel.</code><code class="descname">Gumbel</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gumbel.html#Gumbel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gumbel.Gumbel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Samples from a Gumbel Distribution.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Gumbel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># sample from Gumbel distribution with loc=1, scale=2</span>
<span class="go">tensor([ 1.0124])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – Location parameter of the distribution</li>
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – Scale parameter of the distribution</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.gumbel.Gumbel.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'loc': &lt;torch.distributions.constraints._Real object at 0x7f65512f47f0&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.gumbel.Gumbel.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gumbel.html#Gumbel.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gumbel.Gumbel.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gumbel.Gumbel.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.stddev" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gumbel.Gumbel.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gumbel.Gumbel.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="halfcauchy">
<h2><span class="hidden-section">HalfCauchy</span><a class="headerlink" href="#halfcauchy" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.half_cauchy.HalfCauchy">
<em class="property">class </em><code class="descclassname">torch.distributions.half_cauchy.</code><code class="descname">HalfCauchy</code><span class="sig-paren">(</span><em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/half_cauchy.html#HalfCauchy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.half_cauchy.HalfCauchy" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Creates a half-normal distribution parameterized by <cite>scale</cite> where:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">~</span> <span class="n">Cauchy</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="o">|</span><span class="n">X</span><span class="o">|</span> <span class="o">~</span> <span class="n">HalfCauchy</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">HalfCauchy</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># half-cauchy distributed with scale=1</span>
<span class="go">tensor([ 2.3214])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – scale of the full Cauchy distribution</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.half_cauchy.HalfCauchy.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'scale': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.half_cauchy.HalfCauchy.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.half_cauchy.HalfCauchy.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/half_cauchy.html#HalfCauchy.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.half_cauchy.HalfCauchy.cdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.half_cauchy.HalfCauchy.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/half_cauchy.html#HalfCauchy.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.half_cauchy.HalfCauchy.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.half_cauchy.HalfCauchy.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.half_cauchy.HalfCauchy.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.half_cauchy.HalfCauchy.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>prob</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/half_cauchy.html#HalfCauchy.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.half_cauchy.HalfCauchy.icdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.half_cauchy.HalfCauchy.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/half_cauchy.html#HalfCauchy.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.half_cauchy.HalfCauchy.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.half_cauchy.HalfCauchy.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.half_cauchy.HalfCauchy.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.half_cauchy.HalfCauchy.scale">
<code class="descname">scale</code><a class="headerlink" href="#torch.distributions.half_cauchy.HalfCauchy.scale" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.half_cauchy.HalfCauchy.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._GreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.half_cauchy.HalfCauchy.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.half_cauchy.HalfCauchy.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.half_cauchy.HalfCauchy.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="halfnormal">
<h2><span class="hidden-section">HalfNormal</span><a class="headerlink" href="#halfnormal" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.half_normal.HalfNormal">
<em class="property">class </em><code class="descclassname">torch.distributions.half_normal.</code><code class="descname">HalfNormal</code><span class="sig-paren">(</span><em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/half_normal.html#HalfNormal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.half_normal.HalfNormal" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Creates a half-normal distribution parameterized by <cite>scale</cite> where:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="o">|</span><span class="n">X</span><span class="o">|</span> <span class="o">~</span> <span class="n">HalfNormal</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">HalfNormal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># half-normal distributed with scale=1</span>
<span class="go">tensor([ 0.1046])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – scale of the full Normal distribution</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.half_normal.HalfNormal.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'scale': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.half_normal.HalfNormal.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.half_normal.HalfNormal.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/half_normal.html#HalfNormal.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.half_normal.HalfNormal.cdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.half_normal.HalfNormal.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/half_normal.html#HalfNormal.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.half_normal.HalfNormal.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.half_normal.HalfNormal.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.half_normal.HalfNormal.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.half_normal.HalfNormal.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>prob</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/half_normal.html#HalfNormal.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.half_normal.HalfNormal.icdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.half_normal.HalfNormal.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/half_normal.html#HalfNormal.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.half_normal.HalfNormal.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.half_normal.HalfNormal.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.half_normal.HalfNormal.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.half_normal.HalfNormal.scale">
<code class="descname">scale</code><a class="headerlink" href="#torch.distributions.half_normal.HalfNormal.scale" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.half_normal.HalfNormal.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._GreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.half_normal.HalfNormal.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.half_normal.HalfNormal.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.half_normal.HalfNormal.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="independent">
<h2><span class="hidden-section">Independent</span><a class="headerlink" href="#independent" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.independent.Independent">
<em class="property">class </em><code class="descclassname">torch.distributions.independent.</code><code class="descname">Independent</code><span class="sig-paren">(</span><em>base_distribution</em>, <em>reinterpreted_batch_ndims</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Reinterprets some of the batch dims of a distribution as event dims.</p>
<p>This is mainly useful for changing the shape of the result of
<a class="reference internal" href="#torch.distributions.independent.Independent.log_prob" title="torch.distributions.independent.Independent.log_prob"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log_prob()</span></code></a>. For example to create a diagonal Normal distribution with
the same shape as a Multivariate Normal distribution (so they are
interchangeable), you can:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mvn</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">scale</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">mvn</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">mvn</span><span class="o">.</span><span class="n">event_shape</span><span class="p">]</span>
<span class="go">[torch.Size(()), torch.Size((3,))]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">normal</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">normal</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">normal</span><span class="o">.</span><span class="n">event_shape</span><span class="p">]</span>
<span class="go">[torch.Size((3,)), torch.Size(())]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">diagn</span> <span class="o">=</span> <span class="n">Independent</span><span class="p">(</span><span class="n">normal</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">diagn</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">diagn</span><span class="o">.</span><span class="n">event_shape</span><span class="p">]</span>
<span class="go">[torch.Size(()), torch.Size((3,))]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>base_distribution</strong> (<a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><em>torch.distributions.distribution.Distribution</em></a>) – a
base distribution</li>
<li><strong>reinterpreted_batch_ndims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – the number of batch dims to
reinterpret as event dims</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.independent.Independent.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {}</em><a class="headerlink" href="#torch.distributions.independent.Independent.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.independent.Independent.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.independent.Independent.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent.enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.independent.Independent.has_enumerate_support">
<code class="descname">has_enumerate_support</code><a class="headerlink" href="#torch.distributions.independent.Independent.has_enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.independent.Independent.has_rsample">
<code class="descname">has_rsample</code><a class="headerlink" href="#torch.distributions.independent.Independent.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.independent.Independent.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.independent.Independent.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.independent.Independent.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.independent.Independent.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.independent.Independent.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent.sample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.independent.Independent.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.independent.Independent.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.independent.Independent.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.independent.Independent.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="laplace">
<h2><span class="hidden-section">Laplace</span><a class="headerlink" href="#laplace" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.laplace.Laplace">
<em class="property">class </em><code class="descclassname">torch.distributions.laplace.</code><code class="descname">Laplace</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Laplace distribution parameterized by <cite>loc</cite> and ‘scale’.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Laplace</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Laplace distributed with loc=0, scale=1</span>
<span class="go">tensor([ 0.1046])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – mean of the distribution</li>
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – scale of the distribution</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'loc': &lt;torch.distributions.constraints._Real object at 0x7f65512f47f0&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.laplace.Laplace.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.laplace.Laplace.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace.cdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.laplace.Laplace.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.laplace.Laplace.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.laplace.Laplace.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace.icdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.laplace.Laplace.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.laplace.Laplace.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.laplace.Laplace.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.laplace.Laplace.stddev" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.laplace.Laplace.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.laplace.Laplace.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="lognormal">
<h2><span class="hidden-section">LogNormal</span><a class="headerlink" href="#lognormal" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.log_normal.LogNormal">
<em class="property">class </em><code class="descclassname">torch.distributions.log_normal.</code><code class="descname">LogNormal</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/log_normal.html#LogNormal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.log_normal.LogNormal" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Creates a log-normal distribution parameterized by
<cite>loc</cite> and <cite>scale</cite> where:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">~</span> <span class="n">LogNormal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">LogNormal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># log-normal distributed with mean=0 and stddev=1</span>
<span class="go">tensor([ 0.1046])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – mean of log of distribution</li>
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – standard deviation of log of the distribution</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'loc': &lt;torch.distributions.constraints._Real object at 0x7f65512f47f0&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.log_normal.LogNormal.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/log_normal.html#LogNormal.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.loc">
<code class="descname">loc</code><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.loc" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.scale">
<code class="descname">scale</code><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.scale" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._GreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="multinomial">
<h2><span class="hidden-section">Multinomial</span><a class="headerlink" href="#multinomial" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.multinomial.Multinomial">
<em class="property">class </em><code class="descclassname">torch.distributions.multinomial.</code><code class="descname">Multinomial</code><span class="sig-paren">(</span><em>total_count=1</em>, <em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multinomial.html#Multinomial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multinomial.Multinomial" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Multinomial distribution parameterized by <cite>total_count</cite> and
either <cite>probs</cite> or <cite>logits</cite> (but not both). The innermost dimension of
<cite>probs</cite> indexes over categories. All other dimensions index over batches.</p>
<p>Note that <cite>total_count</cite> need not be specified if only <a class="reference internal" href="#torch.distributions.multinomial.Multinomial.log_prob" title="torch.distributions.multinomial.Multinomial.log_prob"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log_prob()</span></code></a> is
called (see example below)</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><a class="reference internal" href="#torch.distributions.multinomial.Multinomial.probs" title="torch.distributions.multinomial.Multinomial.probs"><code class="xref py py-attr docutils literal notranslate"><span class="pre">probs</span></code></a> must be non-negative, finite and have a non-zero sum,
and it will be normalized to sum to 1.</p>
</div>
<ul class="simple">
<li><a class="reference internal" href="#torch.distributions.multinomial.Multinomial.sample" title="torch.distributions.multinomial.Multinomial.sample"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sample()</span></code></a> requires a single shared <cite>total_count</cite> for all
parameters and samples.</li>
<li><a class="reference internal" href="#torch.distributions.multinomial.Multinomial.log_prob" title="torch.distributions.multinomial.Multinomial.log_prob"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log_prob()</span></code></a> allows different <cite>total_count</cite> for each parameter and
sample.</li>
</ul>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Multinomial</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># equal probability of 0, 1, 2, 3</span>
<span class="go">tensor([ 21.,  24.,  30.,  25.])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">Multinomial</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]))</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">tensor([-4.1338])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>total_count</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – number of trials</li>
<li><strong>probs</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – event probabilities</li>
<li><strong>logits</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – event log probabilities</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'logits': &lt;torch.distributions.constraints._Real object at 0x7f65512f47f0&gt;}</em><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.multinomial.Multinomial.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multinomial.html#Multinomial.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.logits">
<code class="descname">logits</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.logits" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.param_shape">
<code class="descname">param_shape</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.param_shape" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.probs">
<code class="descname">probs</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.probs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.multinomial.Multinomial.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multinomial.html#Multinomial.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.sample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="multivariatenormal">
<h2><span class="hidden-section">MultivariateNormal</span><a class="headerlink" href="#multivariatenormal" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal">
<em class="property">class </em><code class="descclassname">torch.distributions.multivariate_normal.</code><code class="descname">MultivariateNormal</code><span class="sig-paren">(</span><em>loc</em>, <em>covariance_matrix=None</em>, <em>precision_matrix=None</em>, <em>scale_tril=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a multivariate normal (also called Gaussian) distribution
parameterized by a mean vector and a covariance matrix.</p>
<p>The multivariate normal distribution can be parameterized either
in terms of a positive definite covariance matrix <span class="math notranslate nohighlight">\(\mathbf{\Sigma}\)</span>
or a positive definite precision matrix <span class="math notranslate nohighlight">\(\mathbf{\Sigma}^{-1}\)</span>
or a lower-triangular matrix <span class="math notranslate nohighlight">\(\mathbf{L}\)</span> with positive-valued
diagonal entries, such that
<span class="math notranslate nohighlight">\(\mathbf{\Sigma} = \mathbf{L}\mathbf{L}^\top\)</span>. This triangular matrix
can be obtained via e.g. Cholesky decomposition of the covariance.</p>
<p class="rubric">Example</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># normally distributed with mean=`[0,0]` and covariance_matrix=`I`</span>
<span class="go">tensor([-0.2102, -0.5429])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – mean of the distribution</li>
<li><strong>covariance_matrix</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – positive-definite covariance matrix</li>
<li><strong>precision_matrix</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – positive-definite precision matrix</li>
<li><strong>scale_tril</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – lower-triangular factor of covariance, with positive-valued diagonal</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Only one of <a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix"><code class="xref py py-attr docutils literal notranslate"><span class="pre">covariance_matrix</span></code></a> or <a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix"><code class="xref py py-attr docutils literal notranslate"><span class="pre">precision_matrix</span></code></a> or
<a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril" title="torch.distributions.multivariate_normal.MultivariateNormal.scale_tril"><code class="xref py py-attr docutils literal notranslate"><span class="pre">scale_tril</span></code></a> can be specified.</p>
<p class="last">Using <a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril" title="torch.distributions.multivariate_normal.MultivariateNormal.scale_tril"><code class="xref py py-attr docutils literal notranslate"><span class="pre">scale_tril</span></code></a> will be more efficient: all computations internally
are based on <a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril" title="torch.distributions.multivariate_normal.MultivariateNormal.scale_tril"><code class="xref py py-attr docutils literal notranslate"><span class="pre">scale_tril</span></code></a>. If <a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix"><code class="xref py py-attr docutils literal notranslate"><span class="pre">covariance_matrix</span></code></a> or
<a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix"><code class="xref py py-attr docutils literal notranslate"><span class="pre">precision_matrix</span></code></a> is passed instead, it is only used to compute
the corresponding lower triangular matrices using a Cholesky decomposition.</p>
</div>
<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'covariance_matrix': &lt;torch.distributions.constraints._PositiveDefinite object at 0x7f65512f4978&gt;, 'loc': &lt;torch.distributions.constraints._RealVector object at 0x7f65512f4828&gt;, 'precision_matrix': &lt;torch.distributions.constraints._PositiveDefinite object at 0x7f65512f4978&gt;, 'scale_tril': &lt;torch.distributions.constraints._LowerCholesky object at 0x7f65512f4940&gt;}</em><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix">
<code class="descname">covariance_matrix</code><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.covariance_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix">
<code class="descname">precision_matrix</code><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.precision_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.scale_tril">
<code class="descname">scale_tril</code><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.scale_tril"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="normal">
<h2><span class="hidden-section">Normal</span><a class="headerlink" href="#normal" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.normal.Normal">
<em class="property">class </em><code class="descclassname">torch.distributions.normal.</code><code class="descname">Normal</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a normal (also called Gaussian) distribution parameterized by
<cite>loc</cite> and <cite>scale</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># normally distributed with loc=0 and scale=1</span>
<span class="go">tensor([ 0.1046])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – mean of the distribution (often referred to as mu)</li>
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – standard deviation of the distribution
(often referred to as sigma)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.normal.Normal.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'loc': &lt;torch.distributions.constraints._Real object at 0x7f65512f47f0&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.normal.Normal.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.cdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.normal.Normal.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.normal.Normal.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.icdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.normal.Normal.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.normal.Normal.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.sample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.normal.Normal.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.normal.Normal.stddev" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.normal.Normal.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.normal.Normal.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.normal.Normal.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.normal.Normal.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="onehotcategorical">
<h2><span class="hidden-section">OneHotCategorical</span><a class="headerlink" href="#onehotcategorical" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical">
<em class="property">class </em><code class="descclassname">torch.distributions.one_hot_categorical.</code><code class="descname">OneHotCategorical</code><span class="sig-paren">(</span><em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/one_hot_categorical.html#OneHotCategorical"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a one-hot categorical distribution parameterized by <a class="reference internal" href="#torch.distributions.one_hot_categorical.OneHotCategorical.probs" title="torch.distributions.one_hot_categorical.OneHotCategorical.probs"><code class="xref py py-attr docutils literal notranslate"><span class="pre">probs</span></code></a> or
<a class="reference internal" href="#torch.distributions.one_hot_categorical.OneHotCategorical.logits" title="torch.distributions.one_hot_categorical.OneHotCategorical.logits"><code class="xref py py-attr docutils literal notranslate"><span class="pre">logits</span></code></a>.</p>
<p>Samples are one-hot coded vectors of size <code class="docutils literal notranslate"><span class="pre">probs.size(-1)</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><a class="reference internal" href="#torch.distributions.one_hot_categorical.OneHotCategorical.probs" title="torch.distributions.one_hot_categorical.OneHotCategorical.probs"><code class="xref py py-attr docutils literal notranslate"><span class="pre">probs</span></code></a> must be non-negative, finite and have a non-zero sum,
and it will be normalized to sum to 1.</p>
</div>
<p>See also: <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.distributions.Categorical()</span></code> for specifications of
<a class="reference internal" href="#torch.distributions.one_hot_categorical.OneHotCategorical.probs" title="torch.distributions.one_hot_categorical.OneHotCategorical.probs"><code class="xref py py-attr docutils literal notranslate"><span class="pre">probs</span></code></a> and <a class="reference internal" href="#torch.distributions.one_hot_categorical.OneHotCategorical.logits" title="torch.distributions.one_hot_categorical.OneHotCategorical.logits"><code class="xref py py-attr docutils literal notranslate"><span class="pre">logits</span></code></a>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">OneHotCategorical</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span> <span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># equal probability of 0, 1, 2, 3</span>
<span class="go">tensor([ 0.,  0.,  0.,  1.])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>probs</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – event probabilities</li>
<li><strong>logits</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – event log probabilities</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Simplex object at 0x7f65512f48d0&gt;}</em><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/one_hot_categorical.html#OneHotCategorical.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/one_hot_categorical.html#OneHotCategorical.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.has_enumerate_support">
<code class="descname">has_enumerate_support</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.has_enumerate_support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/one_hot_categorical.html#OneHotCategorical.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.logits">
<code class="descname">logits</code><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.logits" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.param_shape">
<code class="descname">param_shape</code><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.param_shape" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.probs">
<code class="descname">probs</code><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.probs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/one_hot_categorical.html#OneHotCategorical.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.sample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Simplex object&gt;</em><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="pareto">
<h2><span class="hidden-section">Pareto</span><a class="headerlink" href="#pareto" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.pareto.Pareto">
<em class="property">class </em><code class="descclassname">torch.distributions.pareto.</code><code class="descname">Pareto</code><span class="sig-paren">(</span><em>scale</em>, <em>alpha</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/pareto.html#Pareto"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.pareto.Pareto" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Samples from a Pareto Type 1 distribution.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Pareto</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># sample from a Pareto distribution with scale=1 and alpha=1</span>
<span class="go">tensor([ 1.5623])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – Scale parameter of the distribution</li>
<li><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – Shape parameter of the distribution</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.pareto.Pareto.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'alpha': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.pareto.Pareto.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.pareto.Pareto.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/pareto.html#Pareto.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.pareto.Pareto.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.pareto.Pareto.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.pareto.Pareto.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.pareto.Pareto.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.pareto.Pareto.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.pareto.Pareto.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.pareto.Pareto.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="poisson">
<h2><span class="hidden-section">Poisson</span><a class="headerlink" href="#poisson" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.poisson.Poisson">
<em class="property">class </em><code class="descclassname">torch.distributions.poisson.</code><code class="descname">Poisson</code><span class="sig-paren">(</span><em>rate</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/poisson.html#Poisson"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.poisson.Poisson" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a Poisson distribution parameterized by <cite>rate</cite>, the rate parameter.</p>
<p>Samples are nonnegative integers, with a pmf given by</p>
<div class="math notranslate nohighlight">
\[\mathrm{rate}^k \frac{e^{-\mathrm{rate}}}{k!}\]</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Poisson</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="go">tensor([ 3.])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>rate</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the rate parameter</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.poisson.Poisson.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'rate': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.poisson.Poisson.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.poisson.Poisson.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/poisson.html#Poisson.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.poisson.Poisson.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.poisson.Poisson.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.poisson.Poisson.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.poisson.Poisson.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/poisson.html#Poisson.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.poisson.Poisson.sample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.poisson.Poisson.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._IntegerGreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.poisson.Poisson.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.poisson.Poisson.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.poisson.Poisson.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="relaxedbernoulli">
<h2><span class="hidden-section">RelaxedBernoulli</span><a class="headerlink" href="#relaxedbernoulli" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli">
<em class="property">class </em><code class="descclassname">torch.distributions.relaxed_bernoulli.</code><code class="descname">RelaxedBernoulli</code><span class="sig-paren">(</span><em>temperature</em>, <em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/relaxed_bernoulli.html#RelaxedBernoulli"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Creates a RelaxedBernoulli distribution, parametrized by <cite>temperature</cite>, and either
<cite>probs</cite> or <cite>logits</cite>. This is a relaxed version of the <cite>Bernoulli</cite> distribution, so
the values are in (0, 1), and has reparametrizable samples.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">RelaxedBernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.2</span><span class="p">]),</span>
<span class="go">                         torch.tensor([0.1, 0.2, 0.3, 0.99]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="go">tensor([ 0.2951,  0.3442,  0.8918,  0.9021])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>temperature</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – relaxation temperature</li>
<li><strong>probs</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the probabilty of sampling <cite>1</cite></li>
<li><strong>logits</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the log-odds of sampling <cite>1</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Interval object at 0x7f65512f4898&gt;}</em><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits">
<code class="descname">logits</code><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs">
<code class="descname">probs</code><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Interval object&gt;</em><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature">
<code class="descname">temperature</code><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="relaxedonehotcategorical">
<h2><span class="hidden-section">RelaxedOneHotCategorical</span><a class="headerlink" href="#relaxedonehotcategorical" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical">
<em class="property">class </em><code class="descclassname">torch.distributions.relaxed_categorical.</code><code class="descname">RelaxedOneHotCategorical</code><span class="sig-paren">(</span><em>temperature</em>, <em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/relaxed_categorical.html#RelaxedOneHotCategorical"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Creates a RelaxedOneHotCategorical distribution parametrized by
<a class="reference internal" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature" title="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature"><code class="xref py py-attr docutils literal notranslate"><span class="pre">temperature</span></code></a>, and either <a class="reference internal" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs" title="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs"><code class="xref py py-attr docutils literal notranslate"><span class="pre">probs</span></code></a> or <a class="reference internal" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits" title="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits"><code class="xref py py-attr docutils literal notranslate"><span class="pre">logits</span></code></a>.
This is a relaxed version of the <code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotCategorical</span></code> distribution, so
its samples are on simplex, and are reparametrizable.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">RelaxedOneHotCategorical</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.2</span><span class="p">]),</span>
<span class="go">                                 torch.tensor([0.1, 0.2, 0.3, 0.4]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="go">tensor([ 0.1294,  0.2324,  0.3859,  0.2523])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>temperature</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – relaxation temperature</li>
<li><strong>probs</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – event probabilities</li>
<li><strong>logits</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the log probability of each event.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Simplex object at 0x7f65512f48d0&gt;}</em><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits">
<code class="descname">logits</code><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs">
<code class="descname">probs</code><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Simplex object&gt;</em><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature">
<code class="descname">temperature</code><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="studentt">
<h2><span class="hidden-section">StudentT</span><a class="headerlink" href="#studentt" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.studentT.StudentT">
<em class="property">class </em><code class="descclassname">torch.distributions.studentT.</code><code class="descname">StudentT</code><span class="sig-paren">(</span><em>df</em>, <em>loc=0.0</em>, <em>scale=1.0</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/studentT.html#StudentT"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.studentT.StudentT" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Student’s t-distribution parameterized by <cite>df</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">StudentT</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Student&#39;s t-distributed with degrees of freedom=2</span>
<span class="go">tensor([ 0.1046])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>df</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – degrees of freedom</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.studentT.StudentT.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'df': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;, 'loc': &lt;torch.distributions.constraints._Real object at 0x7f65512f47f0&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object at 0x7f65512f4860&gt;}</em><a class="headerlink" href="#torch.distributions.studentT.StudentT.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.studentT.StudentT.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/studentT.html#StudentT.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.studentT.StudentT.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.studentT.StudentT.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.studentT.StudentT.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.studentT.StudentT.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/studentT.html#StudentT.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.studentT.StudentT.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.studentT.StudentT.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.studentT.StudentT.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.studentT.StudentT.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/studentT.html#StudentT.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.studentT.StudentT.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.studentT.StudentT.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.studentT.StudentT.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.studentT.StudentT.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.studentT.StudentT.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="transformeddistribution">
<h2><span class="hidden-section">TransformedDistribution</span><a class="headerlink" href="#transformeddistribution" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution">
<em class="property">class </em><code class="descclassname">torch.distributions.transformed_distribution.</code><code class="descname">TransformedDistribution</code><span class="sig-paren">(</span><em>base_distribution</em>, <em>transforms</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Extension of the Distribution class, which applies a sequence of Transforms
to a base distribution.  Let f be the composition of transforms applied:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">~</span> <span class="n">BaseDistribution</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">~</span> <span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">BaseDistribution</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
<span class="n">log</span> <span class="n">p</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">=</span> <span class="n">log</span> <span class="n">p</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">log</span> <span class="o">|</span><span class="n">det</span> <span class="p">(</span><span class="n">dX</span><span class="o">/</span><span class="n">dY</span><span class="p">)</span><span class="o">|</span>
</pre></div>
</div>
<p>Note that the <code class="docutils literal notranslate"><span class="pre">.event_shape</span></code> of a <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransformedDistribution</span></code></a> is the
maximum shape of its base distribution and its transforms, since transforms
can introduce correlations among events.</p>
<p>An example for the usage of <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">TransformedDistribution</span></code></a> would be:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Building a Logistic Distribution</span>
<span class="c1"># X ~ Uniform(0, 1)</span>
<span class="c1"># f = a + b * logit(X)</span>
<span class="c1"># Y ~ f(X) ~ Logistic(a, b)</span>
<span class="n">base_distribution</span> <span class="o">=</span> <span class="n">Uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">transforms</span> <span class="o">=</span> <span class="p">[</span><span class="n">SigmoidTransform</span><span class="p">()</span><span class="o">.</span><span class="n">inv</span><span class="p">,</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">a</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">b</span><span class="p">)]</span>
<span class="n">logistic</span> <span class="o">=</span> <span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">base_distribution</span><span class="p">,</span> <span class="n">transforms</span><span class="p">)</span>
</pre></div>
</div>
<p>For more examples, please look at the implementations of
<a class="reference internal" href="#torch.distributions.gumbel.Gumbel" title="torch.distributions.gumbel.Gumbel"><code class="xref py py-class docutils literal notranslate"><span class="pre">Gumbel</span></code></a>,
<a class="reference internal" href="#torch.distributions.half_cauchy.HalfCauchy" title="torch.distributions.half_cauchy.HalfCauchy"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalfCauchy</span></code></a>,
<a class="reference internal" href="#torch.distributions.half_normal.HalfNormal" title="torch.distributions.half_normal.HalfNormal"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalfNormal</span></code></a>,
<a class="reference internal" href="#torch.distributions.log_normal.LogNormal" title="torch.distributions.log_normal.LogNormal"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogNormal</span></code></a>,
<a class="reference internal" href="#torch.distributions.pareto.Pareto" title="torch.distributions.pareto.Pareto"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pareto</span></code></a>,
<a class="reference internal" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli" title="torch.distributions.relaxed_bernoulli.RelaxedBernoulli"><code class="xref py py-class docutils literal notranslate"><span class="pre">RelaxedBernoulli</span></code></a> and
<a class="reference internal" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical" title="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical"><code class="xref py py-class docutils literal notranslate"><span class="pre">RelaxedOneHotCategorical</span></code></a></p>
<dl class="attribute">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {}</em><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.cdf" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the cumulative distribution function by inverting the
transform(s) and computing the score of the base distribution.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.has_rsample">
<code class="descname">has_rsample</code><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.icdf" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the inverse cumulative distribution function using
transform(s) and computing the score of the base distribution.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.log_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Scores the sample by inverting the transform(s) and computing the score
using the score of the base distribution and the log abs det jacobian.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.rsample" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a sample_shape shaped reparameterized sample or sample_shape
shaped batch of reparameterized samples if the distribution parameters
are batched. Samples first from base distribution and applies
<cite>transform()</cite> for every transform in the list.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Generates a sample_shape shaped sample or sample_shape shaped batch of
samples if the distribution parameters are batched. Samples first from
base distribution and applies <cite>transform()</cite> for every transform in the
list.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="uniform">
<h2><span class="hidden-section">Uniform</span><a class="headerlink" href="#uniform" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.uniform.Uniform">
<em class="property">class </em><code class="descclassname">torch.distributions.uniform.</code><code class="descname">Uniform</code><span class="sig-paren">(</span><em>low</em>, <em>high</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Generates uniformly distributed random samples from the half-open interval
<cite>[low, high)</cite>.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Uniform</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">5.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># uniformly distributed in the range [0.0, 5.0)</span>
<span class="go">tensor([ 2.3418])</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>low</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – lower range (inclusive).</li>
<li><strong>high</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – upper range (exclusive).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'high': &lt;torch.distributions.constraints._Dependent object at 0x7f65512f46d8&gt;, 'low': &lt;torch.distributions.constraints._Dependent object at 0x7f65512f46d8&gt;}</em><a class="headerlink" href="#torch.distributions.uniform.Uniform.arg_constraints" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.uniform.Uniform.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform.cdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.uniform.Uniform.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform.entropy" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.uniform.Uniform.has_rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.uniform.Uniform.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform.icdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.uniform.Uniform.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform.log_prob" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.uniform.Uniform.mean" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.uniform.Uniform.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform.rsample" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.uniform.Uniform.stddev" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.uniform.Uniform.support" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.uniform.Uniform.variance" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-torch.distributions.kl">
<span id="kl-divergence"></span><h2><cite>KL Divergence</cite><a class="headerlink" href="#module-torch.distributions.kl" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="torch.distributions.kl.kl_divergence">
<code class="descclassname">torch.distributions.kl.</code><code class="descname">kl_divergence</code><span class="sig-paren">(</span><em>p</em>, <em>q</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/kl.html#kl_divergence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.kl.kl_divergence" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute Kullback-Leibler divergence <span class="math notranslate nohighlight">\(KL(p \| q)\)</span> between two distributions.</p>
<div class="math notranslate nohighlight">
\[KL(p \| q) = \int p(x) \log\frac {p(x)} {q(x)} \,dx\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>p</strong> (<a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><em>Distribution</em></a>) – A <code class="xref py py-class docutils literal notranslate"><span class="pre">Distribution</span></code> object.</li>
<li><strong>q</strong> (<a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><em>Distribution</em></a>) – A <code class="xref py py-class docutils literal notranslate"><span class="pre">Distribution</span></code> object.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A batch of KL divergences of shape <cite>batch_shape</cite>.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first"><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#NotImplementedError" title="(in Python v3.7)"><code class="xref py py-exc docutils literal notranslate"><span class="pre">NotImplementedError</span></code></a> – If the distribution types have not been registered via
<a class="reference internal" href="#torch.distributions.kl.register_kl" title="torch.distributions.kl.register_kl"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_kl()</span></code></a>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.distributions.kl.register_kl">
<code class="descclassname">torch.distributions.kl.</code><code class="descname">register_kl</code><span class="sig-paren">(</span><em>type_p</em>, <em>type_q</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/kl.html#register_kl"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.kl.register_kl" title="Permalink to this definition">¶</a></dt>
<dd><p>Decorator to register a pairwise function with <a class="reference internal" href="#torch.distributions.kl.kl_divergence" title="torch.distributions.kl.kl_divergence"><code class="xref py py-meth docutils literal notranslate"><span class="pre">kl_divergence()</span></code></a>.
Usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@register_kl</span><span class="p">(</span><span class="n">Normal</span><span class="p">,</span> <span class="n">Normal</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">kl_normal_normal</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
    <span class="c1"># insert implementation here</span>
</pre></div>
</div>
<p>Lookup returns the most specific (type,type) match ordered by subclass. If
the match is ambiguous, a <cite>RuntimeWarning</cite> is raised. For example to
resolve the ambiguous situation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@register_kl</span><span class="p">(</span><span class="n">BaseP</span><span class="p">,</span> <span class="n">DerivedQ</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">kl_version1</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span> <span class="o">...</span>
<span class="nd">@register_kl</span><span class="p">(</span><span class="n">DerivedP</span><span class="p">,</span> <span class="n">BaseQ</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">kl_version2</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span> <span class="o">...</span>
</pre></div>
</div>
<p>you should register a third most-specific implementation, e.g.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">register_kl</span><span class="p">(</span><span class="n">DerivedP</span><span class="p">,</span> <span class="n">DerivedQ</span><span class="p">)(</span><span class="n">kl_version1</span><span class="p">)</span>  <span class="c1"># Break the tie.</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>type_p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.7)"><em>type</em></a>) – A subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">Distribution</span></code>.</li>
<li><strong>type_q</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.7)"><em>type</em></a>) – A subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">Distribution</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-torch.distributions.transforms">
<span id="transforms"></span><h2><cite>Transforms</cite><a class="headerlink" href="#module-torch.distributions.transforms" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.distributions.transforms.Transform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">Transform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#Transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.Transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract class for invertable transformations with computable log
det jacobians. They are primarily used in
<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.TransformedDistribution</span></code>.</p>
<p>Caching is useful for tranforms whose inverses are either expensive or
numerically unstable. Note that care must be taken with memoized values
since the autograd graph may be reversed. For example while the following
works with or without caching:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">t</span><span class="o">.</span><span class="n">log_abs_det_jacobian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># x will receive gradients.</span>
</pre></div>
</div>
<p>However the following will error when caching due to dependency reversal:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">grad</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="p">[</span><span class="n">y</span><span class="p">])</span>  <span class="c1"># error because z is x</span>
</pre></div>
</div>
<p>Derived classes should implement one or both of <code class="xref py py-meth docutils literal notranslate"><span class="pre">_call()</span></code> or
<code class="xref py py-meth docutils literal notranslate"><span class="pre">_inverse()</span></code>. Derived classes that set <cite>bijective=True</cite> should also
implement <a class="reference internal" href="#torch.distributions.transforms.Transform.log_abs_det_jacobian" title="torch.distributions.transforms.Transform.log_abs_det_jacobian"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log_abs_det_jacobian()</span></code></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>cache_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Size of cache. If zero, no caching is done. If one,
the latest single value is cached. Only 0 and 1 are supported.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>domain</strong> (<a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Constraint</span></code></a>) – The constraint representing valid inputs to this transform.</li>
<li><strong>codomain</strong> (<a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Constraint</span></code></a>) – The constraint representing valid outputs to this transform
which are inputs to the inverse transform.</li>
<li><strong>bijective</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Whether this transform is bijective. A transform
<code class="docutils literal notranslate"><span class="pre">t</span></code> is bijective iff <code class="docutils literal notranslate"><span class="pre">t.inv(t(x))</span> <span class="pre">==</span> <span class="pre">x</span></code> and
<code class="docutils literal notranslate"><span class="pre">t(t.inv(y))</span> <span class="pre">==</span> <span class="pre">y</span></code> for every <code class="docutils literal notranslate"><span class="pre">x</span></code> in the domain and <code class="docutils literal notranslate"><span class="pre">y</span></code> in
the codomain. Transforms that are not bijective should at least
maintain the weaker pseudoinverse properties
<code class="docutils literal notranslate"><span class="pre">t(t.inv(t(x))</span> <span class="pre">==</span> <span class="pre">t(x)</span></code> and <code class="docutils literal notranslate"><span class="pre">t.inv(t(t.inv(y)))</span> <span class="pre">==</span> <span class="pre">t.inv(y)</span></code>.</li>
<li><strong>sign</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – For bijective univariate transforms, this
should be +1 or -1 depending on whether transform is monotone
increasing or decreasing.</li>
<li><strong>event_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of dimensions that are correlated together in
the transform <code class="docutils literal notranslate"><span class="pre">event_shape</span></code>. This should be 0 for pointwise
transforms, 1 for transforms that act jointly on vectors, 2 for
transforms that act jointly on matrices, etc.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.transforms.Transform.inv">
<code class="descname">inv</code><a class="headerlink" href="#torch.distributions.transforms.Transform.inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the inverse <a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code></a> of this transform.
This should satisfy <code class="docutils literal notranslate"><span class="pre">t.inv.inv</span> <span class="pre">is</span> <span class="pre">t</span></code>.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.transforms.Transform.sign">
<code class="descname">sign</code><a class="headerlink" href="#torch.distributions.transforms.Transform.sign" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the sign of the determinant of the Jacobian, if applicable.
In general this only makes sense for bijective transforms.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.transforms.Transform.log_abs_det_jacobian">
<code class="descname">log_abs_det_jacobian</code><span class="sig-paren">(</span><em>x</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#Transform.log_abs_det_jacobian"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.Transform.log_abs_det_jacobian" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the log det jacobian <cite>log |dy/dx|</cite> given input and output.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.ComposeTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">ComposeTransform</code><span class="sig-paren">(</span><em>parts</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#ComposeTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.ComposeTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Composes multiple transforms in a chain.
The transforms being composed are responsible for caching.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>parts</strong> (list of <a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code></a>) – A list of transforms to compose.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.ExpTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">ExpTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#ExpTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.ExpTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform via the mapping <span class="math notranslate nohighlight">\(y = \exp(x)\)</span>.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.PowerTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">PowerTransform</code><span class="sig-paren">(</span><em>exponent</em>, <em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#PowerTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.PowerTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform via the mapping <span class="math notranslate nohighlight">\(y = x^{\text{exponent}}\)</span>.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.SigmoidTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">SigmoidTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#SigmoidTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.SigmoidTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform via the mapping <span class="math notranslate nohighlight">\(y = \frac{1}{1 + \exp(-x)}\)</span> and <span class="math notranslate nohighlight">\(x = \text{logit}(y)\)</span>.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.AbsTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">AbsTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#AbsTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.AbsTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform via the mapping <span class="math notranslate nohighlight">\(y = |x|\)</span>.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.AffineTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">AffineTransform</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>event_dim=0</em>, <em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#AffineTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.AffineTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform via the pointwise affine mapping <span class="math notranslate nohighlight">\(y = \text{loc} + \text{scale} \times x\)</span>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – Location parameter.</li>
<li><strong>scale</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – Scale parameter.</li>
<li><strong>event_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Optional size of <cite>event_shape</cite>. This should be zero
for univariate random variables, 1 for distributions over vectors,
2 for distributions over matrices, etc.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.SoftmaxTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">SoftmaxTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#SoftmaxTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.SoftmaxTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform from unconstrained space to the simplex via <span class="math notranslate nohighlight">\(y = \exp(x)\)</span> then
normalizing.</p>
<p>This is not bijective and cannot be used for HMC. However this acts mostly
coordinate-wise (except for the final normalization), and thus is
appropriate for coordinate-wise optimization algorithms.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.StickBreakingTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">StickBreakingTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#StickBreakingTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.StickBreakingTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform from unconstrained space to the simplex of one additional
dimension via a stick-breaking process.</p>
<p>This transform arises as an iterated sigmoid transform in a stick-breaking
construction of the <cite>Dirichlet</cite> distribution: the first logit is
transformed via sigmoid to the first probability and the probability of
everything else, and then the process recurses.</p>
<p>This is bijective and appropriate for use in HMC; however it mixes
coordinates together and is less appropriate for optimization.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.LowerCholeskyTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">LowerCholeskyTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#LowerCholeskyTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.LowerCholeskyTransform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform from unconstrained matrices to lower-triangular matrices with
nonnegative diagonal entries.</p>
<p>This is useful for parameterizing positive definite matrices in terms of
their Cholesky factorization.</p>
</dd></dl>

</div>
<div class="section" id="module-torch.distributions.constraints">
<span id="constraints"></span><h2><cite>Constraints</cite><a class="headerlink" href="#module-torch.distributions.constraints" title="Permalink to this headline">¶</a></h2>
<p>The following constraints are implemented:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">constraints.boolean</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.dependent</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.greater_than(lower_bound)</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.integer_interval(lower_bound,</span> <span class="pre">upper_bound)</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.interval(lower_bound,</span> <span class="pre">upper_bound)</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.lower_cholesky</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.lower_triangular</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.nonnegative_integer</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.positive</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.positive_definite</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.positive_integer</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.real</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.real_vector</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.simplex</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">constraints.unit_interval</span></code></li>
</ul>
<dl class="class">
<dt id="torch.distributions.constraints.Constraint">
<em class="property">class </em><code class="descclassname">torch.distributions.constraints.</code><code class="descname">Constraint</code><a class="reference internal" href="_modules/torch/distributions/constraints.html#Constraint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.constraints.Constraint" title="Permalink to this definition">¶</a></dt>
<dd><p>Abstract base class for constraints.</p>
<p>A constraint object represents a region over which a variable is valid,
e.g. within which a variable can be optimized.</p>
<dl class="method">
<dt id="torch.distributions.constraints.Constraint.check">
<code class="descname">check</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/constraints.html#Constraint.check"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.constraints.Constraint.check" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a byte tensor of <cite>sample_shape + batch_shape</cite> indicating
whether each event in value satisfies this constraint.</p>
</dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.constraints.dependent_property">
<code class="descclassname">torch.distributions.constraints.</code><code class="descname">dependent_property</code><a class="headerlink" href="#torch.distributions.constraints.dependent_property" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.constraints._DependentProperty</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.constraints.integer_interval">
<code class="descclassname">torch.distributions.constraints.</code><code class="descname">integer_interval</code><a class="headerlink" href="#torch.distributions.constraints.integer_interval" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.constraints._IntegerInterval</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.constraints.greater_than">
<code class="descclassname">torch.distributions.constraints.</code><code class="descname">greater_than</code><a class="headerlink" href="#torch.distributions.constraints.greater_than" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.constraints._GreaterThan</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.constraints.less_than">
<code class="descclassname">torch.distributions.constraints.</code><code class="descname">less_than</code><a class="headerlink" href="#torch.distributions.constraints.less_than" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.constraints._LessThan</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.constraints.interval">
<code class="descclassname">torch.distributions.constraints.</code><code class="descname">interval</code><a class="headerlink" href="#torch.distributions.constraints.interval" title="Permalink to this definition">¶</a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.distributions.constraints._Interval</span></code></p>
</dd></dl>

</div>
<div class="section" id="module-torch.distributions.constraint_registry">
<span id="constraint-registry"></span><h2><cite>Constraint Registry</cite><a class="headerlink" href="#module-torch.distributions.constraint_registry" title="Permalink to this headline">¶</a></h2>
<p>PyTorch provides two global <a class="reference internal" href="#torch.distributions.constraint_registry.ConstraintRegistry" title="torch.distributions.constraint_registry.ConstraintRegistry"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConstraintRegistry</span></code></a> objects that link
<a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Constraint</span></code></a> objects to
<a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code></a> objects. These objects both
input constraints and return transforms, but they have different guarantees on
bijectivity.</p>
<ol class="arabic simple">
<li><code class="docutils literal notranslate"><span class="pre">biject_to(constraint)</span></code> looks up a bijective
<a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code></a> from <code class="docutils literal notranslate"><span class="pre">constraints.real</span></code>
to the given <code class="docutils literal notranslate"><span class="pre">constraint</span></code>. The returned transform is guaranteed to have
<code class="docutils literal notranslate"><span class="pre">.bijective</span> <span class="pre">=</span> <span class="pre">True</span></code> and should implement <code class="docutils literal notranslate"><span class="pre">.log_abs_det_jacobian()</span></code>.</li>
<li><code class="docutils literal notranslate"><span class="pre">transform_to(constraint)</span></code> looks up a not-necessarily bijective
<a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code></a> from <code class="docutils literal notranslate"><span class="pre">constraints.real</span></code>
to the given <code class="docutils literal notranslate"><span class="pre">constraint</span></code>. The returned transform is not guaranteed to
implement <code class="docutils literal notranslate"><span class="pre">.log_abs_det_jacobian()</span></code>.</li>
</ol>
<p>The <code class="docutils literal notranslate"><span class="pre">transform_to()</span></code> registry is useful for performing unconstrained
optimization on constrained parameters of probability distributions, which are
indicated by each distribution’s <code class="docutils literal notranslate"><span class="pre">.arg_constraints</span></code> dict. These transforms often
overparameterize a space in order to avoid rotation; they are thus more
suitable for coordinate-wise optimization algorithms like Adam:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">loc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">unconstrained</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">scale</span> <span class="o">=</span> <span class="n">transform_to</span><span class="p">(</span><span class="n">Normal</span><span class="o">.</span><span class="n">arg_constraints</span><span class="p">[</span><span class="s1">&#39;scale&#39;</span><span class="p">])(</span><span class="n">unconstrained</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">biject_to()</span></code> registry is useful for Hamiltonian Monte Carlo, where
samples from a probability distribution with constrained <code class="docutils literal notranslate"><span class="pre">.support</span></code> are
propagated in an unconstrained space, and algorithms are typically rotation
invariant.:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">dist</span> <span class="o">=</span> <span class="n">Exponential</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
<span class="n">unconstrained</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">biject_to</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">support</span><span class="p">)(</span><span class="n">unconstrained</span><span class="p">)</span>
<span class="n">potential_energy</span> <span class="o">=</span> <span class="o">-</span><span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">An example where <code class="docutils literal notranslate"><span class="pre">transform_to</span></code> and <code class="docutils literal notranslate"><span class="pre">biject_to</span></code> differ is
<code class="docutils literal notranslate"><span class="pre">constraints.simplex</span></code>: <code class="docutils literal notranslate"><span class="pre">transform_to(constraints.simplex)</span></code> returns a
<a class="reference internal" href="#torch.distributions.transforms.SoftmaxTransform" title="torch.distributions.transforms.SoftmaxTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">SoftmaxTransform</span></code></a> that simply
exponentiates and normalizes its inputs; this is a cheap and mostly
coordinate-wise operation appropriate for algorithms like SVI. In
contrast, <code class="docutils literal notranslate"><span class="pre">biject_to(constraints.simplex)</span></code> returns a
<a class="reference internal" href="#torch.distributions.transforms.StickBreakingTransform" title="torch.distributions.transforms.StickBreakingTransform"><code class="xref py py-class docutils literal notranslate"><span class="pre">StickBreakingTransform</span></code></a> that
bijects its input down to a one-fewer-dimensional space; this a more
expensive less numerically stable transform but is needed for algorithms
like HMC.</p>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">biject_to</span></code> and <code class="docutils literal notranslate"><span class="pre">transform_to</span></code> objects can be extended by user-defined
constraints and transforms using their <code class="docutils literal notranslate"><span class="pre">.register()</span></code> method either as a
function on singleton constraints:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">transform_to</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">my_constraint</span><span class="p">,</span> <span class="n">my_transform</span><span class="p">)</span>
</pre></div>
</div>
<p>or as a decorator on parameterized constraints:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@transform_to</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">MyConstraintClass</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">my_factory</span><span class="p">(</span><span class="n">constraint</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">constraint</span><span class="p">,</span> <span class="n">MyConstraintClass</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">MyTransform</span><span class="p">(</span><span class="n">constraint</span><span class="o">.</span><span class="n">param1</span><span class="p">,</span> <span class="n">constraint</span><span class="o">.</span><span class="n">param2</span><span class="p">)</span>
</pre></div>
</div>
<p>You can create your own registry by creating a new <a class="reference internal" href="#torch.distributions.constraint_registry.ConstraintRegistry" title="torch.distributions.constraint_registry.ConstraintRegistry"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConstraintRegistry</span></code></a>
object.</p>
<dl class="class">
<dt id="torch.distributions.constraint_registry.ConstraintRegistry">
<em class="property">class </em><code class="descclassname">torch.distributions.constraint_registry.</code><code class="descname">ConstraintRegistry</code><a class="reference internal" href="_modules/torch/distributions/constraint_registry.html#ConstraintRegistry"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.constraint_registry.ConstraintRegistry" title="Permalink to this definition">¶</a></dt>
<dd><p>Registry to link constraints to transforms.</p>
<dl class="method">
<dt id="torch.distributions.constraint_registry.ConstraintRegistry.register">
<code class="descname">register</code><span class="sig-paren">(</span><em>constraint</em>, <em>factory=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/constraint_registry.html#ConstraintRegistry.register"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.constraint_registry.ConstraintRegistry.register" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a <a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Constraint</span></code></a>
subclass in this registry. Usage:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@my_registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">MyConstraintClass</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">construct_transform</span><span class="p">(</span><span class="n">constraint</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">constraint</span><span class="p">,</span> <span class="n">MyConstraint</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">MyTransform</span><span class="p">(</span><span class="n">constraint</span><span class="o">.</span><span class="n">arg_constraints</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>constraint</strong> (subclass of <a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Constraint</span></code></a>) – A subclass of <a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal notranslate"><span class="pre">Constraint</span></code></a>, or
a singleton object of the desired class.</li>
<li><strong>factory</strong> (<em>callable</em>) – A callable that inputs a constraint object and returns
a  <a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal notranslate"><span class="pre">Transform</span></code></a> object.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="multiprocessing.html" class="btn btn-neutral float-right" title="Multiprocessing package - torch.multiprocessing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="autograd.html" class="btn btn-neutral" title="Automatic differentiation package - torch.autograd" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Torch Contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'master',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-1', 'auto');
  ga('send', 'pageview');

</script>


</body>
</html>