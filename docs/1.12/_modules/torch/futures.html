


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.futures &mdash; PyTorch 1.12 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/futures.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />


  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  


  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>1.12 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          


            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notes/amp_examples.html">CUDA Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../config_mod.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">Module code</a> &gt;</li>
        
          <li><a href="../torch.html">torch</a> &gt;</li>
        
      <li>torch.futures</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.futures</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">cast</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Generic</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">TypeVar</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">T</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">)</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;S&quot;</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">_PyFutureMeta</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Future</span><span class="p">),</span> <span class="nb">type</span><span class="p">(</span><span class="n">Generic</span><span class="p">)):</span>  <span class="c1"># type: ignore[misc, no-redef]</span>
    <span class="k">pass</span>

<span class="k">class</span> <span class="nc">Future</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Future</span><span class="p">,</span> <span class="n">Generic</span><span class="p">[</span><span class="n">T</span><span class="p">],</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">_PyFutureMeta</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper around a ``torch._C.Future`` which encapsulates an asynchronous</span>
<span class="sd">    execution of a callable, e.g. :meth:`~torch.distributed.rpc.rpc_async`. It</span>
<span class="sd">    also exposes a set of APIs to add callback functions and set results.</span>

<span class="sd">    .. warning:: GPU support is a beta feature, subject to changes.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">devices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create an empty unset ``Future``. If the future is intended to hold</span>
<span class="sd">        values containing CUDA tensors, (a superset of) their CUDA devices must</span>
<span class="sd">        be specified at construction. (This is only supported if</span>
<span class="sd">        ``torch.cuda.is_available()`` returns ``True``). This is needed to</span>
<span class="sd">        ensure proper CUDA stream synchronization. The child futures, returned</span>
<span class="sd">        by the ``then`` method, will inherit these devices.</span>

<span class="sd">        Args:</span>
<span class="sd">            devices(``List[Union[int, str, torch.device]]``, optional): the set</span>
<span class="sd">                of devices on which tensors contained in this future&#39;s value are</span>
<span class="sd">                allowed to reside and on which callbacks are allowed to operate.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">devices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">devices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">devices</span><span class="p">])</span>

<div class="viewcode-block" id="Future.done"><a class="viewcode-back" href="../../futures.html#torch.futures.Future.done">[docs]</a>    <span class="k">def</span> <span class="nf">done</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return ``True`` if this ``Future`` is done. A ``Future`` is done if it</span>
<span class="sd">        has a result or an exception.</span>

<span class="sd">        If the value contains tensors that reside on GPUs, ``Future.done()``</span>
<span class="sd">        will return ``True`` even if the asynchronous kernels that are</span>
<span class="sd">        populating those tensors haven&#39;t yet completed running on the device,</span>
<span class="sd">        because at such stage the result is already usable, provided one</span>
<span class="sd">        performs the appropriate synchronizations (see :meth:`wait`).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">done</span><span class="p">()</span></div>

<div class="viewcode-block" id="Future.wait"><a class="viewcode-back" href="../../futures.html#torch.futures.Future.wait">[docs]</a>    <span class="k">def</span> <span class="nf">wait</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Block until the value of this ``Future`` is ready.</span>

<span class="sd">        If the value contains tensors that reside on GPUs, then an additional</span>
<span class="sd">        synchronization is performed with the kernels (executing on the device)</span>
<span class="sd">        which may be asynchronously populating those tensors. Such sync is</span>
<span class="sd">        non-blocking, which means that ``wait()`` will insert the necessary</span>
<span class="sd">        instructions in the current streams to ensure that further operations</span>
<span class="sd">        enqueued on those streams will be properly scheduled after the async</span>
<span class="sd">        kernels but, once that is done, ``wait()`` will return, even if those</span>
<span class="sd">        kernels are still running. No further synchronization is required when</span>
<span class="sd">        accessing and using the values, as long as one doesn&#39;t change streams.</span>

<span class="sd">        Returns:</span>
<span class="sd">            The value held by this ``Future``. If the function (callback or RPC)</span>
<span class="sd">            creating the value has thrown an error, this ``wait`` method will</span>
<span class="sd">            also throw an error.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span></div>

<div class="viewcode-block" id="Future.value"><a class="viewcode-back" href="../../futures.html#torch.futures.Future.value">[docs]</a>    <span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Obtain the value of an already-completed future.</span>

<span class="sd">        This method should only be called after a call to :meth:`wait` has</span>
<span class="sd">        completed, or inside a callback function passed to :meth:`then`. In</span>
<span class="sd">        other cases this ``Future`` may not yet hold a value and calling</span>
<span class="sd">        ``value()`` could fail.</span>

<span class="sd">        If the value contains tensors that reside on GPUs, then this method will</span>
<span class="sd">        *not* perform any additional synchronization. This should be done</span>
<span class="sd">        beforehand, separately, through a call to :meth:`wait` (except within</span>
<span class="sd">        callbacks, for which it&#39;s already being taken care of by :meth:`then`).</span>

<span class="sd">        Returns:</span>
<span class="sd">            The value held by this ``Future``. If the function (callback or RPC)</span>
<span class="sd">            creating the value has thrown an error, this ``value()`` method will</span>
<span class="sd">            also throw an error.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">value</span><span class="p">()</span></div>

<div class="viewcode-block" id="Future.then"><a class="viewcode-back" href="../../futures.html#torch.futures.Future.then">[docs]</a>    <span class="k">def</span> <span class="nf">then</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">callback</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Future</span><span class="p">[</span><span class="n">T</span><span class="p">]],</span> <span class="n">S</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Future</span><span class="p">[</span><span class="n">S</span><span class="p">]:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Append the given callback function to this ``Future``, which will be run</span>
<span class="sd">        when the ``Future`` is completed.  Multiple callbacks can be added to</span>
<span class="sd">        the same ``Future``, but the order in which they will be executed cannot</span>
<span class="sd">        be guaranteed (to enforce a certain order consider chaining:</span>
<span class="sd">        ``fut.then(cb1).then(cb2)``). The callback must take one argument, which</span>
<span class="sd">        is the reference to this ``Future``. The callback function can use the</span>
<span class="sd">        :meth:`value` method to get the value. Note that if this ``Future`` is</span>
<span class="sd">        already completed, the given callback will be run immediately inline.</span>

<span class="sd">        If the ``Future``&#39;s value contains tensors that reside on GPUs, the</span>
<span class="sd">        callback might be invoked while the async kernels that are populating</span>
<span class="sd">        those tensors haven&#39;t yet finished executing on the device. However, the</span>
<span class="sd">        callback will be invoked with some dedicated streams set as current</span>
<span class="sd">        (fetched from a global pool) which will be synchronized with those</span>
<span class="sd">        kernels. Hence any operation performed by the callback on these tensors</span>
<span class="sd">        will be scheduled on the device after the kernels complete. In other</span>
<span class="sd">        words, as long as the callback doesn&#39;t switch streams, it can safely</span>
<span class="sd">        manipulate the result without any additional synchronization. This is</span>
<span class="sd">        similar to the non-blocking behavior of :meth:`wait`.</span>

<span class="sd">        Similarly, if the callback returns a value that contains tensors that</span>
<span class="sd">        reside on a GPU, it can do so even if the kernels that are producing</span>
<span class="sd">        these tensors are still running on the device, as long as the callback</span>
<span class="sd">        didn&#39;t change streams during its execution. If one wants to change</span>
<span class="sd">        streams, one must be careful to re-synchronize them with the original</span>
<span class="sd">        streams, that is, those that were current when the callback was invoked.</span>

<span class="sd">        Args:</span>
<span class="sd">            callback(``Callable``): a ``Callable`` that takes this ``Future`` as</span>
<span class="sd">                                    the only argument.</span>

<span class="sd">        Returns:</span>
<span class="sd">            A new ``Future`` object that holds the return value of the</span>
<span class="sd">            ``callback`` and will be marked as completed when the given</span>
<span class="sd">            ``callback`` finishes.</span>

<span class="sd">        .. note:: Note that if the callback function throws, either</span>
<span class="sd">            through the original future being completed with an exception and</span>
<span class="sd">            calling ``fut.wait()``, or through other code in the callback, the</span>
<span class="sd">            future returned by ``then`` will be marked appropriately with the</span>
<span class="sd">            encountered error. However, if this callback later completes</span>
<span class="sd">            additional futures, those futures are not marked as completed with</span>
<span class="sd">            an error and the user is responsible for handling completion/waiting</span>
<span class="sd">            on those futures independently.</span>

<span class="sd">        Example::</span>
<span class="sd">            &gt;&gt;&gt; def callback(fut):</span>
<span class="sd">            ...     print(f&quot;RPC return value is {fut.wait()}.&quot;)</span>
<span class="sd">            &gt;&gt;&gt; fut = torch.futures.Future()</span>
<span class="sd">            &gt;&gt;&gt; # The inserted callback will print the return value when</span>
<span class="sd">            &gt;&gt;&gt; # receiving the response from &quot;worker1&quot;</span>
<span class="sd">            &gt;&gt;&gt; cb_fut = fut.then(callback)</span>
<span class="sd">            &gt;&gt;&gt; chain_cb_fut = cb_fut.then(</span>
<span class="sd">            ...     lambda x : print(f&quot;Chained cb done. {x.wait()}&quot;)</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; fut.set_result(5)</span>
<span class="sd">            RPC return value is 5.</span>
<span class="sd">            Chained cb done. None</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">Future</span><span class="p">[</span><span class="n">S</span><span class="p">],</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">then</span><span class="p">(</span><span class="n">callback</span><span class="p">))</span></div>

<div class="viewcode-block" id="Future.add_done_callback"><a class="viewcode-back" href="../../futures.html#torch.futures.Future.add_done_callback">[docs]</a>    <span class="k">def</span> <span class="nf">add_done_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">callback</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Future</span><span class="p">[</span><span class="n">T</span><span class="p">]],</span> <span class="kc">None</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Append the given callback function to this ``Future``, which will be run</span>
<span class="sd">        when the ``Future`` is completed.  Multiple callbacks can be added to</span>
<span class="sd">        the same ``Future``, but the order in which they will be executed cannot</span>
<span class="sd">        be guaranteed. The callback must take one argument, which is the</span>
<span class="sd">        reference to this ``Future``. The callback function can use the</span>
<span class="sd">        :meth:`value` method to get the value. Note that if this ``Future`` is</span>
<span class="sd">        already completed, the given callback will be run inline.</span>

<span class="sd">        We recommend that you use the :meth:`then` method as it provides a way</span>
<span class="sd">        to synchronize after your callback has completed. ``add_done_callback``</span>
<span class="sd">        can be cheaper if your callback does not return anything. But both</span>
<span class="sd">        :meth:`then` and ``add_done_callback`` use the same callback</span>
<span class="sd">        registration API under the hood.</span>

<span class="sd">        With respect to GPU tensors, this method behaves in the same way as</span>
<span class="sd">        :meth:`then`.</span>

<span class="sd">        Args:</span>
<span class="sd">            callback(``Future``): a ``Callable`` that takes in one argument,</span>
<span class="sd">                which is the reference to this ``Future``.</span>

<span class="sd">        .. note:: Note that if the callback function throws, either</span>
<span class="sd">            through the original future being completed with an exception and</span>
<span class="sd">            calling ``fut.wait()``, or through other code in the callback,</span>
<span class="sd">            error handling must be carefully taken care of. For example, if</span>
<span class="sd">            this callback later completes additional futures, those futures are</span>
<span class="sd">            not marked as completed with an error and the user is responsible</span>
<span class="sd">            for handling completion/waiting on those futures independently.</span>

<span class="sd">        Example::</span>
<span class="sd">            &gt;&gt;&gt; def callback(fut):</span>
<span class="sd">            ...     print(f&quot;This will run after the future has finished.&quot;)</span>
<span class="sd">            ...     print(fut.wait())</span>
<span class="sd">            &gt;&gt;&gt; fut = torch.futures.Future()</span>
<span class="sd">            &gt;&gt;&gt; fut.add_done_callback(callback)</span>
<span class="sd">            &gt;&gt;&gt; fut.set_result(5)</span>
<span class="sd">            This will run after the future has finished.</span>
<span class="sd">            5</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">add_done_callback</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span></div>

<div class="viewcode-block" id="Future.set_result"><a class="viewcode-back" href="../../futures.html#torch.futures.Future.set_result">[docs]</a>    <span class="k">def</span> <span class="nf">set_result</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">:</span> <span class="n">T</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the result for this ``Future``, which will mark this ``Future`` as</span>
<span class="sd">        completed and trigger all attached callbacks. Note that a ``Future``</span>
<span class="sd">        cannot be marked completed twice.</span>

<span class="sd">        If the result contains tensors that reside on GPUs, this method can be</span>
<span class="sd">        called even if the asynchronous kernels that are populating those</span>
<span class="sd">        tensors haven&#39;t yet completed running on the device, provided that the</span>
<span class="sd">        streams on which those kernels were enqueued are set as the current ones</span>
<span class="sd">        when this method is called. Put simply, it&#39;s safe to call this method</span>
<span class="sd">        immediately after launching those kernels, without any additional</span>
<span class="sd">        synchronization, as long as one doesn&#39;t change streams in between. This</span>
<span class="sd">        method will record events on all the relevant current streams and will</span>
<span class="sd">        use them to ensure proper scheduling for all the consumers of this</span>
<span class="sd">        ``Future``.</span>

<span class="sd">        Args:</span>
<span class="sd">            result (object): the result object of this ``Future``.</span>

<span class="sd">        Example::</span>
<span class="sd">            &gt;&gt;&gt; import threading</span>
<span class="sd">            &gt;&gt;&gt; import time</span>
<span class="sd">            &gt;&gt;&gt; def slow_set_future(fut, value):</span>
<span class="sd">            ...     time.sleep(0.5)</span>
<span class="sd">            ...     fut.set_result(value)</span>
<span class="sd">            &gt;&gt;&gt; fut = torch.futures.Future()</span>
<span class="sd">            &gt;&gt;&gt; t = threading.Thread(</span>
<span class="sd">            ...     target=slow_set_future,</span>
<span class="sd">            ...     args=(fut, torch.ones(2) * 3)</span>
<span class="sd">            ... )</span>
<span class="sd">            &gt;&gt;&gt; t.start()</span>
<span class="sd">            &gt;&gt;&gt; print(fut.wait())</span>
<span class="sd">            tensor([3., 3.])</span>
<span class="sd">            &gt;&gt;&gt; t.join()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">set_result</span><span class="p">(</span><span class="n">result</span><span class="p">)</span></div>

<div class="viewcode-block" id="Future.set_exception"><a class="viewcode-back" href="../../futures.html#torch.futures.Future.set_exception">[docs]</a>    <span class="k">def</span> <span class="nf">set_exception</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">result</span><span class="p">:</span> <span class="n">T</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set an exception for this ``Future``, which will mark this ``Future`` as</span>
<span class="sd">        completed with an error and trigger all attached callbacks. Note that</span>
<span class="sd">        when calling wait()/value() on this ``Future``, the exception set here</span>
<span class="sd">        will be raised inline.</span>

<span class="sd">        Args:</span>
<span class="sd">            result (BaseException): the exception for this ``Future``.</span>

<span class="sd">        Example::</span>
<span class="sd">            &gt;&gt;&gt; fut = torch.futures.Future()</span>
<span class="sd">            &gt;&gt;&gt; fut.set_exception(ValueError(&quot;foo&quot;))</span>
<span class="sd">            &gt;&gt;&gt; fut.wait()</span>
<span class="sd">            Traceback (most recent call last):</span>
<span class="sd">            ...</span>
<span class="sd">            ValueError: foo</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="ne">Exception</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">result</span><span class="si">}</span><span class="s2"> is of type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">result</span><span class="p">)</span><span class="si">}</span><span class="s2">, not an Exception.&quot;</span>

        <span class="k">def</span> <span class="nf">raise_error</span><span class="p">(</span><span class="n">fut_result</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">fut_result</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_set_unwrap_func</span><span class="p">(</span><span class="n">raise_error</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_result</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>  <span class="c1"># type: ignore[arg-type]</span></div>


<div class="viewcode-block" id="collect_all"><a class="viewcode-back" href="../../futures.html#torch.futures.collect_all">[docs]</a><span class="k">def</span> <span class="nf">collect_all</span><span class="p">(</span><span class="n">futures</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Future</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Future</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Future</span><span class="p">]]:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Collects the provided :class:`~torch.futures.Future` objects into a single</span>
<span class="sd">    combined :class:`~torch.futures.Future` that is completed when all of the</span>
<span class="sd">    sub-futures are completed.</span>

<span class="sd">    Args:</span>
<span class="sd">        futures (list): a list of :class:`~torch.futures.Future` objects.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Returns a :class:`~torch.futures.Future` object to a list of the passed</span>
<span class="sd">        in Futures.</span>

<span class="sd">    Example::</span>
<span class="sd">        &gt;&gt;&gt; fut0 = torch.futures.Future()</span>
<span class="sd">        &gt;&gt;&gt; fut1 = torch.futures.Future()</span>
<span class="sd">        &gt;&gt;&gt; fut = torch.futures.collect_all([fut0, fut1])</span>
<span class="sd">        &gt;&gt;&gt; fut0.set_result(0)</span>
<span class="sd">        &gt;&gt;&gt; fut1.set_result(1)</span>
<span class="sd">        &gt;&gt;&gt; fut_list = fut.wait()</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;fut0 result = {fut_list[0].wait()}&quot;)</span>
<span class="sd">        fut0 result = 0</span>
<span class="sd">        &gt;&gt;&gt; print(f&quot;fut1 result = {fut_list[1].wait()}&quot;)</span>
<span class="sd">        fut1 result = 1</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="n">Future</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Future</span><span class="p">]],</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_collect_all</span><span class="p">(</span><span class="n">cast</span><span class="p">(</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Future</span><span class="p">],</span> <span class="n">futures</span><span class="p">)))</span></div>


<div class="viewcode-block" id="wait_all"><a class="viewcode-back" href="../../futures.html#torch.futures.wait_all">[docs]</a><span class="k">def</span> <span class="nf">wait_all</span><span class="p">(</span><span class="n">futures</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Future</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Waits for all provided futures to be complete, and returns</span>
<span class="sd">    the list of completed values. If any of the futures encounters an error,</span>
<span class="sd">    the method will exit early and report the error not waiting for other</span>
<span class="sd">    futures to complete.</span>

<span class="sd">    Args:</span>
<span class="sd">        futures (list): a list of :class:`~torch.futures.Future` object.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A list of the completed :class:`~torch.futures.Future` results. This</span>
<span class="sd">        method will throw an error if ``wait`` on any</span>
<span class="sd">        :class:`~torch.futures.Future` throws.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">fut</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span> <span class="k">for</span> <span class="n">fut</span> <span class="ow">in</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_collect_all</span><span class="p">(</span><span class="n">cast</span><span class="p">(</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Future</span><span class="p">],</span> <span class="n">futures</span><span class="p">))</span><span class="o">.</span><span class="n">wait</span><span class="p">()]</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/clipboard.min.js"></script>
         <script src="../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>