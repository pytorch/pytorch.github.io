


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.overrides &mdash; PyTorch 1.12 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/overrides.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />


  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  


  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>1.12 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          


            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notes/amp_examples.html">CUDA Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../config_mod.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">Module code</a> &gt;</li>
        
          <li><a href="../torch.html">torch</a> &gt;</li>
        
      <li>torch.overrides</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.overrides</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Python implementation of ``__torch_function__``</span>

<span class="sd">While most of the torch API and handling for ``__torch_function__`` happens</span>
<span class="sd">at the C++ level, some of the torch API is written in Python so we need</span>
<span class="sd">python-level handling for ``__torch_function__`` overrides as well. The main</span>
<span class="sd">developer-facing functionality in this file are handle_torch_function and</span>
<span class="sd">has_torch_function. See torch/functional.py and test/test_overrides.py</span>
<span class="sd">for usage examples.</span>

<span class="sd">Note</span>
<span class="sd">----</span>
<span class="sd">heavily inspired by NumPy&#39;s ``__array_function__`` (see:</span>
<span class="sd">https://github.com/pytorch/pytorch/issues/24015 and</span>
<span class="sd">https://www.numpy.org/neps/nep-0018-array-function-protocol.html</span>
<span class="sd">)</span>

<span class="sd">If changing this file in a way that can affect ``__torch_function__`` overhead,</span>
<span class="sd">please report the benchmarks in ``benchmarks/overrides_benchmark``. See the</span>
<span class="sd">instructions in the ``README.md`` in that directory.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">__future__</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">types</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span> <span class="nn">contextlib</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch._C</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_has_torch_function</span><span class="p">,</span> <span class="n">_has_torch_function_unary</span><span class="p">,</span>
    <span class="n">_has_torch_function_variadic</span><span class="p">,</span> <span class="n">_add_docstr</span><span class="p">,</span> <span class="n">_set_torch_function_mode</span><span class="p">,</span> <span class="n">_get_torch_function_mode</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">torch.utils._mode_utils</span> <span class="kn">import</span> <span class="n">_enable_mode</span><span class="p">,</span> <span class="n">_push_mode</span><span class="p">,</span> <span class="n">_ModeInfo</span><span class="p">,</span> <span class="n">_wrap_init</span><span class="p">,</span> <span class="n">MetaInitErrorInfo</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;get_ignored_functions&quot;</span><span class="p">,</span>
    <span class="s2">&quot;get_overridable_functions&quot;</span><span class="p">,</span>
    <span class="s2">&quot;get_testing_overrides&quot;</span><span class="p">,</span>
    <span class="s2">&quot;handle_torch_function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;has_torch_function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resolve_name&quot;</span><span class="p">,</span>
    <span class="s2">&quot;is_tensor_like&quot;</span><span class="p">,</span>
    <span class="s2">&quot;is_tensor_method_or_property&quot;</span><span class="p">,</span>
    <span class="s2">&quot;wrap_torch_function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;enable_reentrant_dispatch&quot;</span><span class="p">,</span>
<span class="p">]</span>

<div class="viewcode-block" id="get_ignored_functions"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.get_ignored_functions">[docs]</a><span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_ignored_functions</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">Callable</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return public functions that cannot be overridden by ``__torch_function__``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Set[Callable]</span>
<span class="sd">        A tuple of functions that are publicly available in the torch API but cannot</span>
<span class="sd">        be overridden with ``__torch_function__``. Mostly this is because none of the</span>
<span class="sd">        arguments of these functions are tensors or tensor-likes.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; torch.Tensor.as_subclass in torch.overrides.get_ignored_functions()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; torch.add in torch.overrides.get_ignored_functions()</span>
<span class="sd">    False</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_storage</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_default_tensor_type</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_rng_state</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_rng_state</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fork</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_num_interop_threads</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_num_threads</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">init_num_threads</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">import_ir_module</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">import_ir_module_from_buffer</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_anomaly_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_grad_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">merge_type_from_type_comment</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">parse_ir</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">parse_schema</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">parse_type_comment</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_anomaly_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_flush_denormal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_num_interop_threads</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">wait</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_device</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">default_generator</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_cuda</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_cudnn</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_lapack</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_mkl</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_mps</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_mkldnn</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_openmp</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">iinfo</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">memory_format</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">qscheme</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_inference_mode_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">align_tensors</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">as_strided</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bartlett_window</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">blackman_window</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">can_cast</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_affine_grid_generator</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_batch_norm</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_convolution</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_convolution_transpose</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_convolution_relu</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_convolution_add_relu</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_grid_sampler</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_is_acceptable</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">empty_strided</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">empty_quantized</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fftfreq</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfftfreq</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">from_file</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fill</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hamming_window</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hann_window</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">kaiser_window</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mkldnn_adaptive_avg_pool2d</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mkldnn_convolution</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mkldnn_max_pool2d</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mkldnn_max_pool3d</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mkldnn_linear_backward_weights</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nested_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">promote_types</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">range</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">result_type</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">scalar_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_compressed_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_csr_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_csc_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_bsr_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_bsc_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tril_indices</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">vander</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_jit_internal</span><span class="o">.</span><span class="n">boolean_dispatch</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">assert_int_or_pair</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample_bilinear</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample_nearest</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">has_torch_function</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">has_torch_function_unary</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">has_torch_function_variadic</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">handle_torch_function</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hardsigmoid</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span>
        <span class="c1"># Doesn&#39;t actually take or return tensor arguments</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">,</span>
        <span class="c1"># These are deprecated; don&#39;t test them</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">eye</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">dirac</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">orthogonal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">sparse</span><span class="p">,</span>
        <span class="n">has_torch_function</span><span class="p">,</span>
        <span class="n">handle_torch_function</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_autocast_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_cpu_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_autocast_cpu_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_cpu_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_autocast_cpu_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_autocast_gpu_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_gpu_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">autocast_increment_nesting</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">autocast_decrement_nesting</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_autocast_cache_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_cache_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hardswish</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_vulkan_available</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">are_deterministic_algorithms_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">use_deterministic_algorithms</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_deterministic_algorithms_warn_only_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_deterministic_debug_mode</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_deterministic_debug_mode</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_float32_matmul_precision</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_float32_matmul_precision</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unify_type_list</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_warn_always_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_warn_always</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">vitals_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_vital</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">read_vitals</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">asarray</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__delitem__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__init__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__iter__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__init_subclass__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__delattr__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__torch_function__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__torch_dispatch__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__new__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__subclasshook__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">as_subclass</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">reinforce</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_tensor</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_empty</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_empty_strided</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_ones</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_full</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_make_subclass</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">solve</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">unflatten</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse_coo</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse_csr</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse_csc</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse_bsr</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse_bsc</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_reduce_ex_internal</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_fix_weakref</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_make_wrapper_subclass</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_python_dispatch</span><span class="o">.</span><span class="fm">__get__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_conj</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_conj_physical</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_neg_view</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_is_zerotensor</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_addmm_activation</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_nested_tensor_layer_norm</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_padded_tensor</span><span class="p">,</span>
    <span class="p">}</span></div>


<span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_default_nowrap_functions</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">Callable</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return public functions that do not wrap in a subclass when invoked by</span>
<span class="sd">    the default ``Tensor.__torch_function__`` that preserves subclasses.  Typically,</span>
<span class="sd">    these functions represent field accesses (i.e., retrieving a Tensor that</span>
<span class="sd">    is stored somewhere on the Tensor) as opposed to computation.  Users of</span>
<span class="sd">    these functions expect object identity to be preserved over multiple accesses</span>
<span class="sd">    (e.g., ``a.grad is a.grad``) which cannot be upheld if we&#39;re wrapping on</span>
<span class="sd">    the fly every time (furthermore, the tensor stored here might already be</span>
<span class="sd">    the subclass, in which case wrapping really ought not to happen).</span>

<span class="sd">    Not ALL property accessors have this property; for example ``Tensor.T`` actually</span>
<span class="sd">    just creates a new transposed tensor on the fly, and so we SHOULD interpose on</span>
<span class="sd">    these calls (you need to check the implementation of the function to see if</span>
<span class="sd">    this is the case or not).  Additionally, if a property accessor doesn&#39;t return a Tensor,</span>
<span class="sd">    it doesn&#39;t have to be on this list (though it is harmless if it is).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_base</span><span class="o">.</span><span class="fm">__get__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">,</span>
    <span class="p">}</span>


<div class="viewcode-block" id="get_testing_overrides"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.get_testing_overrides">[docs]</a><span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_testing_overrides</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Return a dict containing dummy overrides for all overridable functions</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Dict[Callable, Callable]</span>
<span class="sd">        A dictionary that maps overridable functions in the PyTorch API to</span>
<span class="sd">        lambda functions that have the same signature as the real function</span>
<span class="sd">        and unconditionally return -1. These lambda functions are useful</span>
<span class="sd">        for testing API coverage for a type that defines ``__torch_function__``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import inspect</span>
<span class="sd">    &gt;&gt;&gt; my_add = torch.overrides.get_testing_overrides()[torch.add]</span>
<span class="sd">    &gt;&gt;&gt; inspect.signature(my_add)</span>
<span class="sd">    &lt;Signature (input, other, out=None)&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Every function in the PyTorchAPI that can be overriden needs an entry</span>
    <span class="c1"># in this dict.</span>
    <span class="c1">#</span>
    <span class="c1"># Optimally we would use inspect to get the function signature and define</span>
    <span class="c1"># the lambda function procedurally but that is blocked by generating</span>
    <span class="c1"># function signatures for native kernels that can be consumed by inspect.</span>
    <span class="c1"># See Issue #28233.</span>
    <span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="n">ret</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">absolute</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">adaptive_avg_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">adaptive_max_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">output_size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">acos</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">adjoint</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arccos</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">acosh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arccosh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addbmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addcdiv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addcmul</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addmv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">affine_grid_generator</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">theta</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">trol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">equal_nan</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">alpha_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">amax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">amin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">aminmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">angle</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">argmin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">argsort</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">asin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_assert_async</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arcsin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">asinh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arcsinh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atan</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arctan</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atan2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arctan2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atanh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arctanh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atleast_3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">avg_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">baddbmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_backward_elemt</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">grad_out</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">sum_dy</span><span class="p">,</span> <span class="n">sum_dy_xmu</span><span class="p">,</span> <span class="n">count_tensor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_backward_reduce</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">grad_out</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">input_g</span><span class="p">,</span> <span class="n">weight_g</span><span class="p">,</span> <span class="n">bias_g</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_elemt</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_gather_stats</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">count</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_gather_stats_with_counts</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">count</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_stats</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_update_stats</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">momentum</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bilinear</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                 <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">pos_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bincount</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">binomial</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">count</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_and</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_not</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_or</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_xor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_left_shift</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_right_shift</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">block_diag</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_tensors</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bucketize</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">,</span> <span class="n">out_int32</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cartesian_prod</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># alias for torch.cat</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cdist</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">compute_mode</span><span class="o">=</span><span class="s1">&#39;use_mm_for_euclid_dist_if_necessary&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ceil</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">celu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">alhpa</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">chain_matmul</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">matrices</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">channel_shuffle</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">groups</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cholesky</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky_ex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">check_errors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cholesky_inverse</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cholesky_solve</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">choose_qparams_optimized</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">numel</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">bit_width</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">chunks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clamp_max</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">column_stack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cov</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">correction</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fweights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">aweights</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">combinations</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">with_replacement</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">complex</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">copysign</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">polar</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">abs</span><span class="p">,</span> <span class="n">ang</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conj</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conj_physical</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">resolve_conj</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">resolve_neg</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">constant_pad_nd</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">convolution</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">output_adding</span><span class="p">,</span> <span class="n">groups</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv_tbc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv_transpose1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv_transpose2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv_transpose3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cosine_embedding_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cosh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cosine_similarity</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cross</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cross</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span>
                         <span class="n">zero_infinity</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cummax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cummin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cumulative_trapezoid</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logcumsumexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">deg2rad</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dequantize</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">det</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># alias for torch.det  # type: ignore[attr-defined]</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">detach</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diagflat</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diff</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">prepend</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diagonal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diagonal_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">digamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">divide</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dsmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hsmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dsplit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices_or_sections</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dstack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">eig</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">UPLO</span><span class="o">=</span><span class="s2">&quot;L&quot;</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">UPLO</span><span class="o">=</span><span class="s2">&quot;L&quot;</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">equation</span><span class="p">,</span> <span class="o">*</span><span class="n">operands</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">embedding</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                          <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">embedding_bag</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                              <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">per_sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">erf</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">erfc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">erfinv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">exp2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">expm1</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fake_quantize_per_channel_affine</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fake_quantize_per_tensor_affine</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fused_moving_avg_obs_fake_quant</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">observer_on</span><span class="p">,</span> <span class="n">fake_quant_on</span><span class="p">,</span> <span class="n">averaging_const</span><span class="p">,</span> <span class="n">running_min</span><span class="p">,</span>
                                                <span class="n">running_max</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">,</span> <span class="n">ch_axis</span><span class="p">,</span>
                                                <span class="n">per_row_fake_quant</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">symmetric_quant</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_linear_fp16_weight</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">packed_weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_linear_fp16_weight_fp32_activation</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">packed_weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_linear_int8_weight</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">packed</span><span class="p">,</span> <span class="n">col_offsets</span><span class="p">,</span> <span class="n">weight_scale</span><span class="p">,</span> <span class="n">weight_zero_point</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_linear_int8_weight_fp32_activation</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">packed</span><span class="p">,</span> <span class="n">col_offsets</span><span class="p">,</span> <span class="n">weight_scale</span><span class="p">,</span>
                                                          <span class="n">weight_zero_point</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_linear_quantize_weight</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_pack_gemm_matrix_fp16</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_pack_quantized_matrix</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">feature_alpha_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">feature_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">irfft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">hfft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ihfft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">hfft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ihfft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">hfftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ihfftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">irfftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">irfft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fftshift</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifftshift</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fix</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dims</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fliplr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">flipud</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">frobenius_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">floor_divide</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">float_power</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fmod</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">frac</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">frexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lu_unpack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">LU_data</span><span class="p">,</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="n">unpack_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unpack_pivots</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sparse_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gcd</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ge</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">geqrf</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">i0</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">inner</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">outer</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ger</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># alias for torch.outer</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gradient</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">spacing</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edge_order</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">grid_sampler</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">grid_sampler_2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">grid_sampler_3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">group_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">num_groups</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gru</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">gropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gru_cell</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_hh</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gt</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">greater</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hardshrink</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">heaviside</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hinge_embedding_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">histc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">histogram</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">histogramdd</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">householder_product</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">tau</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hspmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hsplit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices_or_sections</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hypot</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">igamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">igammac</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">imag</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_add</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_put</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">accumulate</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_fill</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_reduce</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">include_input</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isin</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">e</span><span class="p">,</span> <span class="n">te</span><span class="p">,</span> <span class="n">assume_unique</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">invert</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isreal</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isposinf</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isneginf</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">instance_norm</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">use_input_stats</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span>
                              <span class="n">cudnn_enabled</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">int_repr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv_ex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">check_errors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_complex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_conj</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_neg</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_distributed</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_inference</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_nonzero</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_same_size</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_signed</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">equal_nan</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">istft</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n_fft</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                      <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">onesided</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_complex</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">kl_div</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">log_target</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">kron</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">kthvalue</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">ldl_factor_ex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_errors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">ldl_factor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">ldl_solve</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">LD</span><span class="p">,</span> <span class="n">pivots</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">esp</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lcm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ldexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">le</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">less_equal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lerp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lobpcg</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">iK</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">largest</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">tracker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ortho_iparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ortho_fparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ortho_bparams</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log10</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log1p</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logaddexp2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logdet</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">xlogy</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logical_and</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logical_not</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logical_or</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logical_xor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lstm</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">data</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lstm_cell</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_hh</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lstsq</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lt</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">less</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lu</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">A</span><span class="p">,</span> <span class="n">pivot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_infos</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lu_solve</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">b</span><span class="p">,</span> <span class="n">LU_data</span><span class="p">,</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">margin_ranking_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># type: ignore[attr-defined]  # noqa: B950</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">masked_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">source</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">pivot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu_factor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">pivot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu_factor_ex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">pivot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">check_errors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matmul</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># alias for torch.matmul</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">symmetric</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">multi_dot</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">matrix_exp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_exp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">maximum</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">max_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">max_pool3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">max_pool1d_with_indices</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                        <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nanmean</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">median</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nanmedian</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">minimum</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fmin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_batch_norm</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span>
                                  <span class="n">exponential_average_factor</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_convolution</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_convolution_transpose</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span>
                                             <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_depthwise_convolution</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span>
                                             <span class="n">deterministic</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_rnn</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">,</span>
                           <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">dropout_state</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mode</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">movedim</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">destination</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">destination</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">msort</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">multiply</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mvlgamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">narrow</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">narrow_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_batch_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_layer_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_group_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">HxW</span><span class="p">,</span> <span class="n">group</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_channel_shuffle</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">groups</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">not_equal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">negative</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nextafter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_avg_pool2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_avg_pool3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool1d_with_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool2d_with_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool3d_with_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">affine_grid</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">theta</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">alpha_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                         <span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">divisor_override</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">avg_pool3d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                         <span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">divisor_override</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                         <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">bilinear</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                   <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                               <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">pos_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">celu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cosine_embedding_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                    <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span>
                                            <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">label_smoothing</span><span class="o">=</span><span class="mf">0.0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                       <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">zero_infinity</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">elu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">embedding</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
                                        <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">embedding_bag</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">offsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                            <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">per_sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                            <span class="n">include_last_offset</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">feature_alpha_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fold</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fractional_max_pool2d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_ratio</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                    <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">_random_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fractional_max_pool2d_with_indices</span><span class="p">:</span> <span class="p">(</span>
            <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_ratio</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">_random_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fractional_max_pool3d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_ratio</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                    <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">_random_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fractional_max_pool3d_with_indices</span><span class="p">:</span> <span class="p">(</span>
            <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_ratio</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">_random_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gaussian_nll_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gelu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">approximate</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">glu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">grid_sample</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">group_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">num_groups</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gumbel_softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">logits</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hard</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hardshrink</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hardtanh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">min_val</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">max_val</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hinge_embedding_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                   <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">instance_norm</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">running_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">running_var</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                            <span class="n">use_input_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">interpolate</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                          <span class="n">recompute_scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">antialias</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">kl_div</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">log_target</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">l1_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">local_response_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">1.0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">logsigmoid</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">lp_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">norm_type</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">lp_pool2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">norm_type</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">margin_ranking_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                  <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool1d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                         <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool1d_with_indices</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                      <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                         <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool2d_with_indices</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                      <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool3d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                         <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool3d_with_indices</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                      <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_unpool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_unpool2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_unpool3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">multi_head_attention_forward</span><span class="p">:</span> <span class="p">(</span>
            <span class="k">lambda</span> <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">embed_dim_to_check</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">in_proj_weight</span><span class="p">,</span> <span class="n">in_proj_bias</span><span class="p">,</span> <span class="n">bias_k</span><span class="p">,</span> <span class="n">bias_v</span><span class="p">,</span>
            <span class="n">add_zero_attn</span><span class="p">,</span> <span class="n">dropout_p</span><span class="p">,</span> <span class="n">out_proj_weight</span><span class="p">,</span> <span class="n">out_proj_bias</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">need_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_separate_proj_weight</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">q_proj_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_proj_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">v_proj_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">static_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">static_v</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">average_attn_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">multi_margin_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">multilabel_margin_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                     <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">multilabel_soft_margin_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                          <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span>
                                       <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pairwise_distance</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">poisson_nll_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">log_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                               <span class="n">eps</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">prelu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu6</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">rrelu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.125</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">0.3333333333333333</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">selu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">silu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mish</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">smooth_l1_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">huber_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1.</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">soft_margin_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softplus</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softshrink</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softsign</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">tanhshrink</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">triplet_margin_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span>
                                                  <span class="n">swap</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">triplet_margin_with_distance_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span>
                                                                <span class="n">distance_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                                                                <span class="n">swap</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">unfold</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_in&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">argwhere</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="s1">&#39;fro&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">vector_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="s1">&#39;fro&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">norm_except_dim</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">,</span> <span class="nb">pow</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nuclear_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="s1">&#39;fro&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">orgqr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">tau</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ormqr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">input3</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transpose</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pairwise_distance</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">permute</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pca_lowrank</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pdist</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pinverse</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="mf">1e-15</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="mf">1e-15</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pixel_shuffle</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">upscale_factor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pixel_unshuffle</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">downscale_factor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">poisson</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">poisson_nll_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">log_input</span><span class="p">,</span> <span class="n">full</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">reduction</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">polygamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">positive</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">prelu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">put</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">accumulate</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">q_per_channel_axis</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">q_per_channel_scales</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">q_per_channel_zero_points</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">q_scale</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">q_zero_point</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">qr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">some</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;reduced&#39;</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nanquantile</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantize_per_channel</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">zero_points</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantize_per_tensor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantize_per_tensor_dynamic</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">reduce_range</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_batch_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">output_scale</span><span class="p">,</span> <span class="n">output_zero_point</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_gru_cell</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span>
                                   <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_lstm_cell</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span>
                                    <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_max_pool1d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,),</span>
                                     <span class="n">dilation</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_max_pool2d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                                     <span class="n">dilation</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_rnn_relu_cell</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span>
                                        <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_rnn_tanh_cell</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span>
                                        <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rad2deg</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randint_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ravel</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">real</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">vdot</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">view_as_real</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">view_as_complex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">reciprocal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">remainder</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">renorm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">maxnorm</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rnn_relu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rnn_relu_cell</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_hh</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rnn_tanh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rnn_tanh_cell</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_hh</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">shifts</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rot90</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">row_stack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># alias for torch.vstack</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_rowwise_prune</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">weight</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">compressed_indices_dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rrelu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">1.</span> <span class="o">/</span> <span class="mi">8</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span> <span class="o">/</span> <span class="mi">3</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rsub</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">saddmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">scatter_add</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">scatter_reduce</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">include_self</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">sorted_sequence</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out_int32</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">segment_reduce</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">data</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">unsafe</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">select</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">select_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">slice_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">selu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">signbit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sgn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sinc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sinh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">slogdet</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">slogdet</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">smm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">spmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">stable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">split_size_or_sections</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">split_with_sizes</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">split_size_or_sections</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sspaddmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">std_mean</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">stft</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n_fft</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;reflect&#39;</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">onesided</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_complex</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sub</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">subtract</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nansum</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">some</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">svd_lowrank</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svdvals</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">symeig</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">swapdims</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">axis0</span><span class="p">,</span> <span class="n">axis1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">entr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erf</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfcx</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfinv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">exp2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">expm1</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">expit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">polygamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">digamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">psi</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">gammainc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">gammaincc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">gammaln</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">i0</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">i0e</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">i1</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">i1e</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">logit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">log1p</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">round</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">sinc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">multigammaln</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">ndtri</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">ndtr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">log_ndtr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">xlog1py</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">zeta</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">t</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">take</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">take_along_dim</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tan</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">tensorinv</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">ind</span><span class="o">=</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">tensorsolve</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensordot</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensor_split</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices_or_sections</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tile</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dims</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">trace</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">trapz</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">trapezoid</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">triangular_solve</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transpose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">unitriangular</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unitriangular</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">triplet_margin_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">swap</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

                                    <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">true_divide</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">trunc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unique_consecutive</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unsafe_chunk</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">chunks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unsafe_split</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">split_size_or_sections</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unsafe_split_with_sizes</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">split_size_or_sections</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">vander</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">var_mean</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">vsplit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices_or_sections</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">condition</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_fw_primal_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">level</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_make_dual_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">primal</span><span class="p">,</span> <span class="n">tangent</span><span class="p">,</span> <span class="n">level</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">view_as_real_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">view_as_complex_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_conj_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_neg_view_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">as_strided_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">storage_offset</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_sparse_broadcast_to_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diagonal_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">expand_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">implicit</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">narrow_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">permute_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_reshape_alias_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">select_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">detach_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">slice_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">split_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">split_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">split_with_sizes_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">split_sizes</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">squeeze_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">squeeze_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">t_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">transpose_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_values_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">values_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">crow_indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">col_indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ccol_indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">row_indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unbind_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">view_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">view_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unfold_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">alias_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__floordiv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rfloordiv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__ifloordiv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__truediv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rtruediv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__itruediv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__lshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rlshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__ilshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rrshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__irshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__and__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__or__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__xor__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__float__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__complex__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__array__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__bool__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__contains__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__neg__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__invert__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__mod__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rmod__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__imod__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__array_wrap__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">array</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__deepcopy__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__int__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__long__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__hash__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__index__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__len__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__format__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">format_spec</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__reduce_ex__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">proto</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__reversed__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">tensor_contents</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">H</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">mT</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">mH</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_backward_hooks</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_base</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_cdata</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_grad_fn</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">grad_fn</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_version</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_autocast_to_reduced_precision</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">cuda_enabled</span><span class="p">,</span> <span class="n">cpu_enabled</span><span class="p">,</span> <span class="n">cuda_dtype</span><span class="p">,</span> <span class="n">cpu_dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_autocast_to_full_precision</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">cuda_enabled</span><span class="p">,</span> <span class="n">cpu_enabled</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_cuda</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_xpu</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_ipu</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_leaf</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">retains_grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_meta</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_mps</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_nested</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_ort</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_mkldnn</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_quantized</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_sparse</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_sparse_csr</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_vulkan</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">layout</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">names</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">ndim</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">output_nr</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">requires_grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">volatile</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">real</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">imag</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__cuda_array_interface__</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">type</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_coalesced_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_dimI</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_dimV</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_is_view</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_nnz</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">crow_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">col_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">ccol_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">row_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_update_names</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_values</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">adjoint</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">align_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">align_to</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">ellipsis_idx</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">apply_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">callable</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">as_strided</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">as_strided_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">backward</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">gradient</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">byte</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">char</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">cauchy_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">median</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">coalesce</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_coalesced_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">coalesced</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">contiguous</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">contiguous_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">copy_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">xpu</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">ipu</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">dense_dim</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">diagonal_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">double</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">cdouble</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">element_size</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">expand</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">expand_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">exponential_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">fill_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">fill_diagonal_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">float</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">cfloat</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">geometric_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">get_device</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">half</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">chalf</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">has_names</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">int</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_coalesced</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_inference</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_pinned</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_set_to</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_shared</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">item</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">log_normal_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">long</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">map_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">callable</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">map2_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">callable</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">mm</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">mat2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">narrow_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">ndimension</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">nelement</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">normal_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">put_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">accumulate</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">qscheme</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">random_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">from_</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">record_stream</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">stream</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">refine_names</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">register_hook</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">rename</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">repeat</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">reshape_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">resize</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">resize_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">resize_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">resize_as_sparse_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">retain_grad</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">set_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">storage_offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">select_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">short</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">size</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">slice_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sparse_dim</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sparse_mask</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sparse_resize_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size1</span><span class="p">,</span> <span class="n">size2</span><span class="p">,</span> <span class="n">dense_dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sparse_resize_and_clear_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size1</span><span class="p">,</span> <span class="n">size2</span><span class="p">,</span> <span class="n">dense_dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sspaddmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">storage</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_storage</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">storage_offset</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">storage_type</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sum_to_size</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">tile</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">reps</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_dense</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_to_dense</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">tolist</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_mkldnn</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">type_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">unfold</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">uniform_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">from_</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">values</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">view</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">view_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">zero_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__dlpack__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__dlpack_device__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">cond</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">driver</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">ret2</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">ignored</span> <span class="o">=</span> <span class="n">get_ignored_functions</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">ret</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Generate methods like __add__ and add_ by default from add</span>
        <span class="n">names</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>  <span class="c1"># Default method</span>
            <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span><span class="p">,</span>  <span class="c1"># Inplace variant</span>
            <span class="s2">&quot;__&quot;</span> <span class="o">+</span> <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span><span class="p">,</span>  <span class="c1"># Dunder method</span>
            <span class="s2">&quot;__i&quot;</span> <span class="o">+</span> <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span><span class="p">,</span>  <span class="c1"># Inplace dunder method</span>
            <span class="s2">&quot;__r&quot;</span> <span class="o">+</span> <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span><span class="p">,</span>  <span class="c1"># Reverse dunder method</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;bitwise_&quot;</span><span class="p">):</span>
            <span class="c1"># bitwise_&lt;op&gt; have dunder methods of the form __&lt;op&gt;__</span>
            <span class="c1"># And so on.</span>
            <span class="n">subname</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;bitwise_&quot;</span><span class="p">):]</span>
            <span class="n">names</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
                <span class="s2">&quot;__&quot;</span> <span class="o">+</span> <span class="n">subname</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span><span class="p">,</span>
                <span class="s2">&quot;__i&quot;</span> <span class="o">+</span> <span class="n">subname</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span><span class="p">,</span>
                <span class="s2">&quot;__r&quot;</span> <span class="o">+</span> <span class="n">subname</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span>
            <span class="p">])</span>

        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
            <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">func</span><span class="p">)</span> <span class="ow">and</span> <span class="n">func</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ret</span> <span class="ow">and</span> <span class="n">func</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ignored</span><span class="p">:</span>
                <span class="n">ret2</span><span class="p">[</span><span class="n">func</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

    <span class="n">ret</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ret2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ret</span></div>

<div class="viewcode-block" id="wrap_torch_function"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.wrap_torch_function">[docs]</a><span class="k">def</span> <span class="nf">wrap_torch_function</span><span class="p">(</span><span class="n">dispatcher</span><span class="p">:</span> <span class="n">Callable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wraps a given function with ``__torch_function__`` -related functionality.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    dispatcher: Callable</span>
<span class="sd">        A callable that returns an iterable of Tensor-likes passed into the function.</span>

<span class="sd">    Note</span>
<span class="sd">    ----</span>
<span class="sd">    This decorator may reduce the performance of your code. Generally, it&#39;s enough to express</span>
<span class="sd">    your code as a series of functions that, themselves, support __torch_function__. If you</span>
<span class="sd">    find yourself in the rare situation where this is not the case, e.g. if you&#39;re wrapping a</span>
<span class="sd">    low-level library and you also need it to work for Tensor-likes, then this function is available.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; def dispatcher(a): # Must have the same signature as func</span>
<span class="sd">    ...     return (a,)</span>
<span class="sd">    &gt;&gt;&gt; @torch.overrides.wrap_torch_function(dispatcher)</span>
<span class="sd">    &gt;&gt;&gt; def func(a): # This will make func dispatchable by __torch_function__</span>
<span class="sd">    ...     return a + 0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">inner</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
        <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">relevant_args</span> <span class="o">=</span> <span class="n">dispatcher</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">has_torch_function</span><span class="p">(</span><span class="n">relevant_args</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">handle_torch_function</span><span class="p">(</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">relevant_args</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">wrapped</span>

    <span class="k">return</span> <span class="n">inner</span></div>

<span class="k">def</span> <span class="nf">_get_overloaded_args</span><span class="p">(</span><span class="n">relevant_args</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Returns a list of arguments on which to call __torch_function__.</span>

<span class="sd">    Checks arguments in relevant_args for __torch_function__ implementations,</span>
<span class="sd">    storing references to the arguments and their types in overloaded_args and</span>
<span class="sd">    overloaded_types in order of calling precedence. Only distinct types are</span>
<span class="sd">    considered. If a type is a subclass of another type it will have higher</span>
<span class="sd">    precedence, otherwise the precedence order is the same as the order of</span>
<span class="sd">    arguments in relevant_args, that is, from left-to-right in the argument list.</span>

<span class="sd">    The precedence-determining algorithm implemented in this function is</span>
<span class="sd">    described in `NEP-0018`_.</span>

<span class="sd">    See torch::append_overloaded_arg for the equivalent function in the C++</span>
<span class="sd">    implementation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    relevant_args : iterable of array-like</span>
<span class="sd">        Iterable of array-like arguments to check for __torch_function__</span>
<span class="sd">        methods.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    overloaded_args : list</span>
<span class="sd">        Arguments from relevant_args on which to call __torch_function__</span>
<span class="sd">        methods, in the order in which they should be called.</span>

<span class="sd">    .. _NEP-0018:</span>
<span class="sd">       https://numpy.org/neps/nep-0018-array-function-protocol.html</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># If torch function is not enabled, there are no overloaded types</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_is_torch_function_enabled</span><span class="p">():</span>
        <span class="k">return</span> <span class="p">[]</span>
    <span class="c1"># Runtime is O(num_arguments * num_unique_types)</span>
    <span class="n">overloaded_types</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Type</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">overloaded_args</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">relevant_args</span><span class="p">:</span>
        <span class="n">arg_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
        <span class="c1"># We only collect arguments if they have a unique type, which ensures</span>
        <span class="c1"># reasonable performance even with a long list of possibly overloaded</span>
        <span class="c1"># arguments.</span>
        <span class="c1">#</span>
        <span class="c1"># NB: Important to exclude _disabled_torch_function_impl, otherwise</span>
        <span class="c1"># https://github.com/pytorch/pytorch/issues/64687</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">arg_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">overloaded_types</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">arg_type</span><span class="p">,</span> <span class="s1">&#39;__torch_function__&#39;</span><span class="p">)</span> <span class="ow">and</span>
                <span class="n">arg_type</span><span class="o">.</span><span class="n">__torch_function__</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_disabled_torch_function_impl</span><span class="p">):</span>
            <span class="c1"># Create lists explicitly for the first type (usually the only one</span>
            <span class="c1"># done) to avoid setting up the iterator for overloaded_args.</span>
            <span class="k">if</span> <span class="n">overloaded_types</span><span class="p">:</span>
                <span class="n">overloaded_types</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">arg_type</span><span class="p">)</span>
                <span class="c1"># By default, insert argument at the end, but if it is</span>
                <span class="c1"># subclass of another argument, insert it before that argument.</span>
                <span class="c1"># This ensures &quot;subclasses before superclasses&quot;.</span>
                <span class="n">index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">overloaded_args</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">old_arg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">overloaded_args</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">arg_type</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">old_arg</span><span class="p">)):</span>
                        <span class="n">index</span> <span class="o">=</span> <span class="n">i</span>
                        <span class="k">break</span>
                <span class="n">overloaded_args</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">arg</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">overloaded_types</span> <span class="o">=</span> <span class="p">{</span><span class="n">arg_type</span><span class="p">}</span>
                <span class="n">overloaded_args</span> <span class="o">=</span> <span class="p">[</span><span class="n">arg</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">overloaded_args</span>


<div class="viewcode-block" id="handle_torch_function"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.handle_torch_function">[docs]</a><span class="k">def</span> <span class="nf">handle_torch_function</span><span class="p">(</span>
        <span class="n">public_api</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">relevant_args</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Implement a function with checks for ``__torch_function__`` overrides.</span>

<span class="sd">    See torch::autograd::handle_torch_function for the equivalent of this</span>
<span class="sd">    function in the C++ implementation.</span>

<span class="sd">    Arguments</span>
<span class="sd">    ---------</span>
<span class="sd">    public_api : function</span>
<span class="sd">        Function exposed by the public torch API originally called like</span>
<span class="sd">        ``public_api(*args, **kwargs)`` on which arguments are now being</span>
<span class="sd">        checked.</span>
<span class="sd">    relevant_args : iterable</span>
<span class="sd">        Iterable of arguments to check for __torch_function__ methods.</span>
<span class="sd">    args : tuple</span>
<span class="sd">        Arbitrary positional arguments originally passed into ``public_api``.</span>
<span class="sd">    kwargs : tuple</span>
<span class="sd">        Arbitrary keyword arguments originally passed into ``public_api``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    object</span>
<span class="sd">        Result from calling ``implementation`` or an ``__torch_function__``</span>
<span class="sd">        method, as appropriate.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    TypeError : if no implementation is found.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; def func(a):</span>
<span class="sd">    ...     if has_torch_function_unary(a):</span>
<span class="sd">    ...         return handle_torch_function(func, (a,), a)</span>
<span class="sd">    ...     return a + 0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check for __torch_function__ methods.</span>
    <span class="n">overloaded_args</span> <span class="o">=</span> <span class="n">_get_overloaded_args</span><span class="p">(</span><span class="n">relevant_args</span><span class="p">)</span>
    <span class="c1"># overloaded_args already have unique types.</span>
    <span class="n">types</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">type</span><span class="p">,</span> <span class="n">overloaded_args</span><span class="p">))</span>

    <span class="c1"># Check for __torch_function__ mode.</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">_get_torch_function_mode</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># NB: unlike on tensors, modes are instances</span>
        <span class="k">with</span> <span class="n">_no_torch_function_mode</span><span class="p">():</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">__torch_function__</span><span class="p">(</span><span class="n">public_api</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">NotImplemented</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span>

    <span class="c1"># Call overrides</span>
    <span class="k">for</span> <span class="n">overloaded_arg</span> <span class="ow">in</span> <span class="n">overloaded_args</span><span class="p">:</span>
        <span class="c1"># This call needs to become a classmethod call in the future.</span>
        <span class="c1"># See https://github.com/pytorch/pytorch/issues/63767</span>
        <span class="n">torch_func_method</span> <span class="o">=</span> <span class="n">overloaded_arg</span><span class="o">.</span><span class="n">__torch_function__</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch_func_method</span><span class="p">,</span> <span class="s2">&quot;__self__&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch_func_method</span><span class="o">.</span><span class="vm">__self__</span> <span class="ow">is</span> <span class="n">overloaded_arg</span> <span class="ow">and</span> \
                <span class="n">torch_func_method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_disabled_torch_function_impl</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Defining your `__torch_function__ as a plain method is deprecated and &quot;</span>
                          <span class="s2">&quot;will be an error in future, please define it as a classmethod.&quot;</span><span class="p">,</span>
                          <span class="ne">DeprecationWarning</span><span class="p">)</span>

        <span class="c1"># Use `public_api` instead of `implementation` so __torch_function__</span>
        <span class="c1"># implementations can do equality/identity comparisons.</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">torch_func_method</span><span class="p">(</span><span class="n">public_api</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">NotImplemented</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span>

    <span class="n">func_name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">.</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">public_api</span><span class="o">.</span><span class="vm">__module__</span><span class="p">,</span> <span class="n">public_api</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;no implementation found for &#39;</span><span class="si">{}</span><span class="s2">&#39; on types that implement &quot;</span>
        <span class="s1">&#39;__torch_function__: </span><span class="si">{}</span><span class="s1">&#39;</span>
    <span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">overloaded_args</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; nor in mode </span><span class="si">{</span><span class="n">mode</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span></div>

<span class="n">has_torch_function</span> <span class="o">=</span> <span class="n">_add_docstr</span><span class="p">(</span>
    <span class="n">_has_torch_function</span><span class="p">,</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Check for __torch_function__ implementations in the elements of an iterable</span>
<span class="sd">    or if a __torch_function__ mode is enabled.  Considers exact ``Tensor`` s</span>
<span class="sd">    and ``Parameter`` s non-dispatchable.  Use this to guard a call to</span>
<span class="sd">    :func:`handle_torch_function`; don&#39;t use it to test if something</span>
<span class="sd">    is Tensor-like, use :func:`is_tensor_like` instead.</span>
<span class="sd">    Arguments</span>
<span class="sd">    ---------</span>
<span class="sd">    relevant_args : iterable</span>
<span class="sd">        Iterable or aguments to check for __torch_function__ methods.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    bool</span>
<span class="sd">        True if any of the elements of relevant_args have __torch_function__</span>
<span class="sd">        implementations, False otherwise.</span>
<span class="sd">    See Also</span>
<span class="sd">    ________</span>
<span class="sd">    torch.is_tensor_like</span>
<span class="sd">        Checks if something is a Tensor-like, including an exact ``Tensor``.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<span class="p">)</span>

<span class="n">has_torch_function_unary</span> <span class="o">=</span> <span class="n">_add_docstr</span><span class="p">(</span>
    <span class="n">_has_torch_function_unary</span><span class="p">,</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Special case of `has_torch_function` for single inputs.</span>
<span class="sd">    Instead of:</span>
<span class="sd">      `has_torch_function((t,))`</span>
<span class="sd">    call:</span>
<span class="sd">      `has_torch_function_unary(t)`</span>
<span class="sd">    which skips unnecessary packing and unpacking work.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<span class="p">)</span>

<span class="n">has_torch_function_variadic</span> <span class="o">=</span> <span class="n">_add_docstr</span><span class="p">(</span>
    <span class="n">_has_torch_function_variadic</span><span class="p">,</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Special case of `has_torch_function` that skips tuple creation.</span>

<span class="sd">    This uses the METH_FASTCALL protocol introduced in Python 3.7</span>

<span class="sd">    Instead of:</span>
<span class="sd">      `has_torch_function((a, b))`</span>
<span class="sd">    call:</span>
<span class="sd">      `has_torch_function_variadic(a, b)`</span>
<span class="sd">    which skips unnecessary packing and unpacking work.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<span class="p">)</span>

<span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_get_overridable_functions</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]],</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
    <span class="n">overridable_funcs</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">tested_namespaces</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">__all__</span> <span class="o">+</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_VariableFunctions</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch.functional&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">functional</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">__all__</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;torch.nn.functional&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch.nn.init&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch.Tensor&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch.linalg&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch.fft&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch.special&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="p">)),</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">namespace_str</span><span class="p">,</span> <span class="n">namespace</span><span class="p">,</span> <span class="n">ns_funcs</span> <span class="ow">in</span> <span class="n">tested_namespaces</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">func_name</span> <span class="ow">in</span> <span class="n">ns_funcs</span><span class="p">:</span>
            <span class="n">ignore</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="c1"># ignore private functions or functions that are deleted in torch.__init__</span>
            <span class="k">if</span> <span class="n">namespace</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">func_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="k">elif</span> <span class="n">func_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">):</span>
                    <span class="n">ignore</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="n">func_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">):</span>
                    <span class="n">ignore</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="ow">not</span> <span class="n">func_name</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">islower</span><span class="p">():</span>
                    <span class="n">ignore</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="n">func_name</span> <span class="o">==</span> <span class="s1">&#39;unique_dim&#39;</span><span class="p">:</span>
                    <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">namespace</span><span class="p">,</span> <span class="n">func_name</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="nb">object</span><span class="p">,</span> <span class="n">func_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="n">func</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="n">func_name</span> <span class="o">==</span> <span class="s1">&#39;__weakref__&#39;</span><span class="p">:</span>
                    <span class="k">continue</span>
            <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">namespace</span><span class="p">,</span> <span class="n">func_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">namespace</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="nb">object</span><span class="p">,</span> <span class="n">func_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="n">func</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="c1"># ignore re-exported modules</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="o">.</span><span class="n">ModuleType</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="c1"># ignore __future__ imports</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">__future__</span><span class="o">.</span><span class="n">_Feature</span><span class="p">):</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">func</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="s2">&quot;__get__&quot;</span><span class="p">):</span>
                <span class="n">index</span><span class="p">[</span><span class="n">func</span><span class="o">.</span><span class="fm">__get__</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">namespace_str</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s2">.__get__&quot;</span>
                <span class="n">index</span><span class="p">[</span><span class="n">func</span><span class="o">.</span><span class="fm">__set__</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">namespace_str</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s2">.__set__&quot;</span>
                <span class="k">if</span> <span class="n">ignore</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="n">func</span><span class="o">.</span><span class="fm">__get__</span> <span class="ow">in</span> <span class="n">get_ignored_functions</span><span class="p">():</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">.</span><span class="si">{}</span><span class="s2"> is in the tuple returned by torch._overrides.get_ignored_functions &quot;</span>
                           <span class="s2">&quot;but still has an explicit override&quot;</span><span class="p">)</span>
                    <span class="k">assert</span> <span class="n">func</span><span class="o">.</span><span class="fm">__get__</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">get_testing_overrides</span><span class="p">(),</span> <span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">namespace</span><span class="p">,</span> <span class="n">func</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">overridable_funcs</span><span class="p">[</span><span class="n">func</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="fm">__get__</span><span class="p">)</span>
                    <span class="k">continue</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
                <span class="k">continue</span>

            <span class="n">index</span><span class="p">[</span><span class="n">func</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">namespace_str</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="k">if</span> <span class="n">ignore</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># cannot be overriden by __torch_function__</span>
            <span class="k">if</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">get_ignored_functions</span><span class="p">():</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">.</span><span class="si">{}</span><span class="s2"> is in the tuple returned by torch._overrides.get_ignored_functions &quot;</span>
                       <span class="s2">&quot;but still has an explicit override&quot;</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">func</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">get_testing_overrides</span><span class="p">(),</span> <span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">namespace</span><span class="p">,</span> <span class="n">func</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="n">overridable_funcs</span><span class="p">[</span><span class="n">namespace</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">overridable_funcs</span><span class="p">,</span> <span class="n">index</span>

<div class="viewcode-block" id="get_overridable_functions"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.get_overridable_functions">[docs]</a><span class="k">def</span> <span class="nf">get_overridable_functions</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;List functions that are overridable via __torch_function__</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Dict[Any, List[Callable]]</span>
<span class="sd">        A dictionary that maps namespaces that contain overridable functions</span>
<span class="sd">        to functions in that namespace that can be overridden.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_get_overridable_functions</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="resolve_name"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.resolve_name">[docs]</a><span class="k">def</span> <span class="nf">resolve_name</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get a human readable string name for a function passed to</span>
<span class="sd">    __torch_function__</span>

<span class="sd">    Arguments</span>
<span class="sd">    ---------</span>
<span class="sd">    callable : Callable</span>
<span class="sd">        Function to resolve the name of.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    str</span>
<span class="sd">        Name of the function; if eval&#39;ed it should give back the input</span>
<span class="sd">        function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">OpOverload</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_get_overridable_functions</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">f</span><span class="p">)</span></div>

<span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_get_tensor_methods</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">Callable</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot; Returns a set of the overridable methods on ``torch.Tensor`` &quot;&quot;&quot;</span>
    <span class="n">overridable_funcs</span> <span class="o">=</span> <span class="n">get_overridable_functions</span><span class="p">()</span>
    <span class="n">methods</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">overridable_funcs</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">methods</span>

<div class="viewcode-block" id="is_tensor_method_or_property"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.is_tensor_method_or_property">[docs]</a><span class="k">def</span> <span class="nf">is_tensor_method_or_property</span><span class="p">(</span><span class="n">func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns True if the function passed in is a handler for a</span>
<span class="sd">    method or property belonging to ``torch.Tensor``, as passed</span>
<span class="sd">    into ``__torch_function__``.</span>

<span class="sd">    .. note::</span>
<span class="sd">       For properties, their ``__get__`` method must be passed in.</span>

<span class="sd">    This may be needed, in particular, for the following reasons:</span>

<span class="sd">    1. Methods/properties sometimes don&#39;t contain a `__module__` slot.</span>
<span class="sd">    2. They require that the first passed-in argument is an instance</span>
<span class="sd">       of ``torch.Tensor``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_method_or_property(torch.Tensor.add)</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_method_or_property(torch.add)</span>
<span class="sd">    False</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">_get_tensor_methods</span><span class="p">()</span> <span class="ow">or</span> <span class="n">func</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__get__&quot;</span></div>

<div class="viewcode-block" id="is_tensor_like"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.is_tensor_like">[docs]</a><span class="k">def</span> <span class="nf">is_tensor_like</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns ``True`` if the passed-in input is a Tensor-like.</span>

<span class="sd">    Currently, this occurs whenever there&#39;s a ``__torch_function__``</span>
<span class="sd">    attribute on the type of the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    A subclass of tensor is generally a Tensor-like.</span>

<span class="sd">    &gt;&gt;&gt; class SubTensor(torch.Tensor): ...</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_like(SubTensor([0]))</span>
<span class="sd">    True</span>

<span class="sd">    Built-in or user types aren&#39;t usually Tensor-like.</span>

<span class="sd">    &gt;&gt;&gt; is_tensor_like(6)</span>
<span class="sd">    False</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_like(None)</span>
<span class="sd">    False</span>
<span class="sd">    &gt;&gt;&gt; class NotATensor: ...</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_like(NotATensor())</span>
<span class="sd">    False</span>

<span class="sd">    But, they can be made Tensor-like by implementing __torch_function__.</span>

<span class="sd">    &gt;&gt;&gt; class TensorLike:</span>
<span class="sd">    ...     @classmethod</span>
<span class="sd">    ...     def __torch_function__(cls, func, types, args, kwargs):</span>
<span class="sd">    ...         return -1</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_like(TensorLike())</span>
<span class="sd">    True</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">inp</span><span class="p">),</span> <span class="s2">&quot;__torch_function__&quot;</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_wrap_torch_function</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">wrapped</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">enable_torch_function_mode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inner</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">wrapped</span>


<span class="c1"># Implementation note: I had a choice about how much of mode stacks</span>
<span class="c1"># to implement in Python versus in C++.  At time of writing, I did not care</span>
<span class="c1"># too much about implementation efficiency; however, I do care about making it</span>
<span class="c1"># hard for users to implement modes in the wrong way.  In the end, it turned</span>
<span class="c1"># out to be possible to implement mode stacks entirely from userland, with the</span>
<span class="c1"># C++ API providing only _get_torch_function_mode() and</span>
<span class="c1"># _set_torch_function_mode(), so I opted to provide some unsafe C++ bindings and</span>
<span class="c1"># have the bulk of the logic for managing the stack in Python, which helped</span>
<span class="c1"># simplify the C++ API surface.  It would also have been valid to build in the</span>
<span class="c1"># notion of mode stack directly into C++ but in this design it&#39;s substantially</span>
<span class="c1"># more difficult to interact with TorchFunctionModeMeta.</span>


<span class="k">class</span> <span class="nc">_TorchFunctionMetaInitErrorInfo</span><span class="p">(</span><span class="n">MetaInitErrorInfo</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">mode_class_name</span><span class="o">=</span><span class="s2">&quot;TorchDispatchMode&quot;</span><span class="p">,</span> <span class="n">mode_name</span><span class="o">=</span><span class="s2">&quot;torch_dispatch&quot;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TorchFunctionModeMeta</span><span class="p">(</span><span class="nb">type</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Metaclass for :class:`TorchFunctionMode`; it does two things:</span>

<span class="sd">        * Adds an implicit ``inner`` kwarg to ``__init__``, to</span>
<span class="sd">          allow the modes to be chained together to form a stack.</span>

<span class="sd">        * Reenables the inner mode, so that by default PyTorch API calls</span>
<span class="sd">          will compositionally proceed to the next mode on the stack.</span>

<span class="sd">    The default behavior for the second bullet is important, as it is easy to</span>
<span class="sd">    accidentally write ``__torch_function__`` implementations that are not</span>
<span class="sd">    compositional, and the wrapping here makes the obvious code do the</span>
<span class="sd">    right thing (aka, this is why there is a metaclass).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__new__</span><span class="p">(</span><span class="n">metacls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">bases</span><span class="p">,</span> <span class="n">dct</span><span class="p">):</span>
        <span class="k">if</span> <span class="s1">&#39;__init__&#39;</span> <span class="ow">in</span> <span class="n">dct</span><span class="p">:</span>
            <span class="n">dct</span><span class="p">[</span><span class="s1">&#39;__init__&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_wrap_init</span><span class="p">(</span><span class="n">dct</span><span class="p">[</span><span class="s1">&#39;__init__&#39;</span><span class="p">],</span> <span class="n">_TorchFunctionMetaInitErrorInfo</span><span class="p">())</span>
        <span class="k">if</span> <span class="s1">&#39;__torch_function__&#39;</span> <span class="ow">in</span> <span class="n">dct</span><span class="p">:</span>
            <span class="n">dct</span><span class="p">[</span><span class="s1">&#39;__torch_function__&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_wrap_torch_function</span><span class="p">(</span><span class="n">dct</span><span class="p">[</span><span class="s1">&#39;__torch_function__&#39;</span><span class="p">])</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__new__</span><span class="p">(</span><span class="n">metacls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">bases</span><span class="p">,</span> <span class="n">dct</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TorchFunctionMode</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">TorchFunctionModeMeta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A ``TorchFunctionMode`` allows you to override the meaning of all</span>
<span class="sd">    ``__torch_function__`` overrideable functions within a dynamic scope,</span>
<span class="sd">    without having to actually create a tensor subclass or manually</span>
<span class="sd">    monkey-patch functions in the PyTorch API.  Some common situations</span>
<span class="sd">    where you should use a mode:</span>

<span class="sd">        * You want to override the meaning of factory functions, or other</span>
<span class="sd">          functions that do not otherwise take a tensor as an argument</span>
<span class="sd">          (these cannot be overridden with tensor subclasses).</span>

<span class="sd">        * You want to override the behavior of all functions without needing</span>
<span class="sd">          to wrap your inputs in tensor subclasses; e.g., if you are just</span>
<span class="sd">          interested in logging intermediate computations.</span>

<span class="sd">        * You want to control the order of execution of various tensor</span>
<span class="sd">          subclasses explicitly, rather than implicitly via the return of</span>
<span class="sd">          ``NotImplemented``.</span>

<span class="sd">    Independent subclasses of :class:`TorchFunctionMode` are compositional:</span>
<span class="sd">    modes can be pushed onto a stack with :func:`push_torch_function_mode`.</span>
<span class="sd">    When you call functions in the PyTorch API inside your</span>
<span class="sd">    ``__torch_function__`` implementation, by default, they will forward on to</span>
<span class="sd">    the next mode on the mode stack.  If you want recursively call back into</span>
<span class="sd">    your current ``__torch_function__`` implementation, either explicitly</span>
<span class="sd">    invoke ``self.__torch_function__(...)``, or use the context manager</span>
<span class="sd">    ``enable_torch_function_mode(self, replace=self.inner)`` to make PyTorch</span>
<span class="sd">    API self-referential (beware of infinite loops, in this case!)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inner</span><span class="p">:</span> <span class="s2">&quot;TorchFunctionMode&quot;</span>

    <span class="c1"># Force metaclass to generate constructor at the base of the hierarchy</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">__torch_function__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(),</span> <span class="n">kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">push</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">push_torch_function_mode</span><span class="p">(</span><span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">BaseTorchFunctionMode</span><span class="p">(</span><span class="n">TorchFunctionMode</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__torch_function__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(),</span> <span class="n">kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="c1"># This is private API as I&#39;m not sure it&#39;s possible for users to use this</span>
<span class="c1"># compositionally (easy to discard too many modes).  It is useful for</span>
<span class="c1"># library code though, e.g., in handle_torch_function</span>
<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">_no_torch_function_mode</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="kc">None</span><span class="p">]:</span>
    <span class="n">old</span> <span class="o">=</span> <span class="n">_get_torch_function_mode</span><span class="p">()</span>
    <span class="n">_set_torch_function_mode</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">_set_torch_function_mode</span><span class="p">(</span><span class="n">old</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_TorchFunctionModeInfo</span><span class="p">(</span><span class="n">_ModeInfo</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">mode_name</span><span class="o">=</span><span class="s2">&quot;torch_function&quot;</span><span class="p">,</span> <span class="n">mode_class</span><span class="o">=</span><span class="n">TorchFunctionMode</span><span class="p">,</span>
                         <span class="n">base_mode_class</span><span class="o">=</span><span class="n">BaseTorchFunctionMode</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_get_torch_function_mode</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">set_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_set_torch_function_mode</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>


<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">enable_torch_function_mode</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_preexisting</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="kc">None</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Context manager that sets the current :class:`TorchFunctionMode`; see the</span>
<span class="sd">    class for more information on what modes are.  This function is</span>
<span class="sd">    non-compositional; if there is already an existing mode, it will raise an</span>
<span class="sd">    error; prefer using :func:`push_torch_function_mode` if your</span>
<span class="sd">    ``__torch_function__`` implementation can defer to an inner mode.</span>

<span class="sd">    This function is safe to use inside a ``__torch_function__`` mode handler,</span>
<span class="sd">    as the mode is guaranteed to be disabled in this context.  You can use</span>
<span class="sd">    this context manager to reinstate the mode so that calls to overridable</span>
<span class="sd">    APIs recursively call back into your mode handler (this can easily cause</span>
<span class="sd">    infinite loops, so use with care!)</span>

<span class="sd">    Args:</span>
<span class="sd">        mode (:class:`TorchFunctionMode`, Tensor-like class or None): the</span>
<span class="sd">            mode to set as current mode.  If you pass a Tensor-like class,</span>
<span class="sd">            it will be treated as a non-compositional mode with no state,</span>
<span class="sd">            which is convenient if you have an existing tensor subclass</span>
<span class="sd">            that you&#39;d like to apply globally in a quick and dirty way.</span>
<span class="sd">            Passing None will disable the current mode.</span>
<span class="sd">        replace (:class:`TorchFunctionMode` or Tensor-like class): the</span>
<span class="sd">            mode to replace.  You can use this argument to change the mode in</span>
<span class="sd">            a situation where you know what the current mode is (and you are</span>
<span class="sd">            intentionally overwriting it.)  If you don&#39;t know what the current</span>
<span class="sd">            mode is, use ``ignore_preexisting`` instead.</span>
<span class="sd">        ignore_preexisting (bool): if True, ignore any preexisting mode</span>
<span class="sd">            and overwrite it with the passed mode.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_enable_mode</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">_TorchFunctionModeInfo</span><span class="p">(),</span> <span class="n">replace</span><span class="o">=</span><span class="n">replace</span><span class="p">,</span> <span class="n">ignore_preexisting</span><span class="o">=</span><span class="n">ignore_preexisting</span><span class="p">)</span>

<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">push_torch_function_mode</span><span class="p">(</span><span class="n">ctor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Iterator</span><span class="p">[</span><span class="n">TorchFunctionMode</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Context manager that pushes a :class:`TorchFunctionMode` onto the current</span>
<span class="sd">    mode stack; see the class for more information on what modes are.  Stacked</span>
<span class="sd">    modes can delegate to each other by invoking the ``__torch_function__``</span>
<span class="sd">    method for the ``inner`` mode.</span>

<span class="sd">    Args:</span>
<span class="sd">        ctor: a function that when invoked as ``ctor(inner=...)`` produces</span>
<span class="sd">            a :class:`TorchFunctionMode`.  If your :class:`TorchFunctionMode`</span>
<span class="sd">            has no ``__init__`` implementation, you can simply pass the class</span>
<span class="sd">            itself (e.g., ``push_torch_function_mode(MyMode)``); otherwise,</span>
<span class="sd">            use ``functools.partial`` to partially apply the constructor with all</span>
<span class="sd">            non-inner arguments (e.g.,</span>
<span class="sd">            ``push_torch_function_mode(partial(MyMode, arg))``)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_push_mode</span><span class="p">(</span><span class="n">ctor</span><span class="p">,</span> <span class="n">_TorchFunctionModeInfo</span><span class="p">())</span>

<span class="k">class</span> <span class="nc">enable_reentrant_dispatch</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_raii_guard</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_RestorePythonTLSSnapshot</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">exc_value</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">traceback</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_raii_guard</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/clipboard.min.js"></script>
         <script src="../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>