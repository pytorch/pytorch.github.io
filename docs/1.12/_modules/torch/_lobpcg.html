


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch._lobpcg &mdash; PyTorch 1.12 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/_lobpcg.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />


  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  


  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>1.12 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          


            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notes/amp_examples.html">CUDA Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../config_mod.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">Module code</a> &gt;</li>
        
          <li><a href="../torch.html">torch</a> &gt;</li>
        
      <li>torch._lobpcg</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch._lobpcg</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Locally Optimal Block Preconditioned Conjugate Gradient methods.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="c1"># Author: Pearu Peterson</span>
<span class="c1"># Created: February 2020</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">.</span> <span class="kn">import</span> <span class="n">_linalg_utils</span> <span class="k">as</span> <span class="n">_utils</span>
<span class="kn">from</span> <span class="nn">.overrides</span> <span class="kn">import</span> <span class="n">has_torch_function</span><span class="p">,</span> <span class="n">handle_torch_function</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lobpcg&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">_symeig_backward_complete_eigenspace</span><span class="p">(</span><span class="n">D_grad</span><span class="p">,</span> <span class="n">U_grad</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">U</span><span class="p">):</span>
    <span class="c1"># compute F, such that F_ij = (d_j - d_i)^{-1} for i != j, F_ii = 0</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">D</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">D</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">F</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>
    <span class="n">F</span><span class="o">.</span><span class="n">pow_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># A.grad = U (D.grad + (U^T U.grad * F)) U^T</span>
    <span class="n">Ut</span> <span class="o">=</span> <span class="n">U</span><span class="o">.</span><span class="n">mT</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
        <span class="n">U</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="n">D_grad</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">Ut</span><span class="p">,</span> <span class="n">U_grad</span><span class="p">)</span> <span class="o">*</span> <span class="n">F</span><span class="p">,</span>
            <span class="n">Ut</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">res</span>


<span class="k">def</span> <span class="nf">_polynomial_coefficients_given_roots</span><span class="p">(</span><span class="n">roots</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given the `roots` of a polynomial, find the polynomial&#39;s coefficients.</span>

<span class="sd">    If roots = (r_1, ..., r_n), then the method returns</span>
<span class="sd">    coefficients (a_0, a_1, ..., a_n (== 1)) so that</span>
<span class="sd">    p(x) = (x - r_1) * ... * (x - r_n)</span>
<span class="sd">         = x^n + a_{n-1} * x^{n-1} + ... a_1 * x_1 + a_0</span>

<span class="sd">    Note: for better performance requires writing a low-level kernel</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">poly_order</span> <span class="o">=</span> <span class="n">roots</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">poly_coeffs_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">roots</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># we assume p(x) = x^n + a_{n-1} * x^{n-1} + ... + a_1 * x + a_0,</span>
    <span class="c1"># so poly_coeffs = {a_0, ..., a_n, a_{n+1}(== 1)},</span>
    <span class="c1"># but we insert one extra coefficient to enable better vectorization below</span>
    <span class="n">poly_coeffs_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">2</span>
    <span class="n">poly_coeffs</span> <span class="o">=</span> <span class="n">roots</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">poly_coeffs_shape</span><span class="p">)</span>
    <span class="n">poly_coeffs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">poly_coeffs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># perform the Horner&#39;s rule</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">poly_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># note that it is computationally hard to compute backward for this method,</span>
        <span class="c1"># because then given the coefficients it would require finding the roots and/or</span>
        <span class="c1"># calculating the sensitivity based on the Vieta&#39;s theorem.</span>
        <span class="c1"># So the code below tries to circumvent the explicit root finding by series</span>
        <span class="c1"># of operations on memory copies imitating the Horner&#39;s method.</span>
        <span class="c1"># The memory copies are required to construct nodes in the computational graph</span>
        <span class="c1"># by exploting the explicit (not in-place, separate node for each step)</span>
        <span class="c1"># recursion of the Horner&#39;s method.</span>
        <span class="c1"># Needs more memory, O(... * k^2), but with only O(... * k^2) complexity.</span>
        <span class="n">poly_coeffs_new</span> <span class="o">=</span> <span class="n">poly_coeffs</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">if</span> <span class="n">roots</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">else</span> <span class="n">poly_coeffs</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">poly_coeffs_new</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">poly_order</span> <span class="o">-</span> <span class="n">i</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">-=</span> <span class="n">roots</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">poly_coeffs</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">poly_order</span> <span class="o">-</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">poly_coeffs</span> <span class="o">=</span> <span class="n">poly_coeffs_new</span>

    <span class="k">return</span> <span class="n">poly_coeffs</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">poly_order</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_polynomial_value</span><span class="p">(</span><span class="n">poly</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">zero_power</span><span class="p">,</span> <span class="n">transition</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A generic method for computing poly(x) using the Horner&#39;s rule.</span>

<span class="sd">    Args:</span>
<span class="sd">      poly (Tensor): the (possibly batched) 1D Tensor representing</span>
<span class="sd">                     polynomial coefficients such that</span>
<span class="sd">                     poly[..., i] = (a_{i_0}, ..., a{i_n} (==1)), and</span>
<span class="sd">                     poly(x) = poly[..., 0] * zero_power + ... + poly[..., n] * x^n</span>

<span class="sd">      x (Tensor): the value (possible batched) to evalate the polynomial `poly` at.</span>

<span class="sd">      zero_power (Tensor): the represenation of `x^0`. It is application-specific.</span>

<span class="sd">      transition (Callable): the function that accepts some intermediate result `int_val`,</span>
<span class="sd">                             the `x` and a specific polynomial coefficient</span>
<span class="sd">                             `poly[..., k]` for some iteration `k`.</span>
<span class="sd">                             It basically performs one iteration of the Horner&#39;s rule</span>
<span class="sd">                             defined as `x * int_val + poly[..., k] * zero_power`.</span>
<span class="sd">                             Note that `zero_power` is not a parameter,</span>
<span class="sd">                             because the step `+ poly[..., k] * zero_power` depends on `x`,</span>
<span class="sd">                             whether it is a vector, a matrix, or something else, so this</span>
<span class="sd">                             functionality is delegated to the user.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">res</span> <span class="o">=</span> <span class="n">zero_power</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">poly</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">transition</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">poly</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">k</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">res</span>

<span class="k">def</span> <span class="nf">_matrix_polynomial_value</span><span class="p">(</span><span class="n">poly</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">zero_power</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluates `poly(x)` for the (batched) matrix input `x`.</span>
<span class="sd">    Check out `_polynomial_value` function for more details.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># matrix-aware Horner&#39;s rule iteration</span>
    <span class="k">def</span> <span class="nf">transition</span><span class="p">(</span><span class="n">curr_poly_val</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">poly_coeff</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">curr_poly_val</span><span class="p">)</span>
        <span class="n">res</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">poly_coeff</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">if</span> <span class="n">zero_power</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">zero_power</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> \
            <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]))),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">_polynomial_value</span><span class="p">(</span><span class="n">poly</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">zero_power</span><span class="p">,</span> <span class="n">transition</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_vector_polynomial_value</span><span class="p">(</span><span class="n">poly</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">zero_power</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Evaluates `poly(x)` for the (batched) vector input `x`.</span>
<span class="sd">    Check out `_polynomial_value` function for more details.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># vector-aware Horner&#39;s rule iteration</span>
    <span class="k">def</span> <span class="nf">transition</span><span class="p">(</span><span class="n">curr_poly_val</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">poly_coeff</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">addcmul</span><span class="p">(</span><span class="n">poly_coeff</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">curr_poly_val</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">res</span>

    <span class="k">if</span> <span class="n">zero_power</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">zero_power</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">new_ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">_polynomial_value</span><span class="p">(</span><span class="n">poly</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">zero_power</span><span class="p">,</span> <span class="n">transition</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_symeig_backward_partial_eigenspace</span><span class="p">(</span><span class="n">D_grad</span><span class="p">,</span> <span class="n">U_grad</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">largest</span><span class="p">):</span>
    <span class="c1"># compute a projection operator onto an orthogonal subspace spanned by the</span>
    <span class="c1"># columns of U defined as (I - UU^T)</span>
    <span class="n">Ut</span> <span class="o">=</span> <span class="n">U</span><span class="o">.</span><span class="n">mT</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
    <span class="n">proj_U_ortho</span> <span class="o">=</span> <span class="o">-</span><span class="n">U</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">Ut</span><span class="p">)</span>
    <span class="n">proj_U_ortho</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># compute U_ortho, a basis for the orthogonal complement to the span(U),</span>
    <span class="c1"># by projecting a random [..., m, m - k] matrix onto the subspace spanned</span>
    <span class="c1"># by the columns of U.</span>
    <span class="c1">#</span>
    <span class="c1"># fix generator for determinism</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># orthogonal complement to the span(U)</span>
    <span class="n">U_ortho</span> <span class="o">=</span> <span class="n">proj_U_ortho</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span>
            <span class="p">(</span><span class="o">*</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">A</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">D</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">generator</span><span class="o">=</span><span class="n">gen</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="n">U_ortho_t</span> <span class="o">=</span> <span class="n">U_ortho</span><span class="o">.</span><span class="n">mT</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>

    <span class="c1"># compute the coefficients of the characteristic polynomial of the tensor D.</span>
    <span class="c1"># Note that D is diagonal, so the diagonal elements are exactly the roots</span>
    <span class="c1"># of the characteristic polynomial.</span>
    <span class="n">chr_poly_D</span> <span class="o">=</span> <span class="n">_polynomial_coefficients_given_roots</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>

    <span class="c1"># the code belows finds the explicit solution to the Sylvester equation</span>
    <span class="c1"># U_ortho^T A U_ortho dX - dX D = -U_ortho^T A U</span>
    <span class="c1"># and incorporates it into the whole gradient stored in the `res` variable.</span>
    <span class="c1">#</span>
    <span class="c1"># Equivalent to the following naive implementation:</span>
    <span class="c1"># res = A.new_zeros(A.shape)</span>
    <span class="c1"># p_res = A.new_zeros(*A.shape[:-1], D.size(-1))</span>
    <span class="c1"># for k in range(1, chr_poly_D.size(-1)):</span>
    <span class="c1">#     p_res.zero_()</span>
    <span class="c1">#     for i in range(0, k):</span>
    <span class="c1">#         p_res += (A.matrix_power(k - 1 - i) @ U_grad) * D.pow(i).unsqueeze(-2)</span>
    <span class="c1">#     res -= chr_poly_D[k] * (U_ortho @ poly_D_at_A.inverse() @ U_ortho_t @  p_res @ U.t())</span>
    <span class="c1">#</span>
    <span class="c1"># Note that dX is a differential, so the gradient contribution comes from the backward sensitivity</span>
    <span class="c1"># Tr(f(U_grad, D_grad, A, U, D)^T dX) = Tr(g(U_grad, A, U, D)^T dA) for some functions f and g,</span>
    <span class="c1"># and we need to compute g(U_grad, A, U, D)</span>
    <span class="c1">#</span>
    <span class="c1"># The naive implementation is based on the paper</span>
    <span class="c1"># Hu, Qingxi, and Daizhan Cheng.</span>
    <span class="c1"># &quot;The polynomial solution to the Sylvester matrix equation.&quot;</span>
    <span class="c1"># Applied mathematics letters 19.9 (2006): 859-864.</span>
    <span class="c1">#</span>
    <span class="c1"># We can modify the computation of `p_res` from above in a more efficient way</span>
    <span class="c1"># p_res =   U_grad * (chr_poly_D[1] * D.pow(0) + ... + chr_poly_D[k] * D.pow(k)).unsqueeze(-2)</span>
    <span class="c1">#       + A U_grad * (chr_poly_D[2] * D.pow(0) + ... + chr_poly_D[k] * D.pow(k - 1)).unsqueeze(-2)</span>
    <span class="c1">#       + ...</span>
    <span class="c1">#       + A.matrix_power(k - 1) U_grad * chr_poly_D[k]</span>
    <span class="c1"># Note that this saves us from redundant matrix products with A (elimination of matrix_power)</span>
    <span class="n">U_grad_projected</span> <span class="o">=</span> <span class="n">U_grad</span>
    <span class="n">series_acc</span> <span class="o">=</span> <span class="n">U_grad_projected</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">(</span><span class="n">U_grad_projected</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">chr_poly_D</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)):</span>
        <span class="n">poly_D</span> <span class="o">=</span> <span class="n">_vector_polynomial_value</span><span class="p">(</span><span class="n">chr_poly_D</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">k</span><span class="p">:],</span> <span class="n">D</span><span class="p">)</span>
        <span class="n">series_acc</span> <span class="o">+=</span> <span class="n">U_grad_projected</span> <span class="o">*</span> <span class="n">poly_D</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">U_grad_projected</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">U_grad_projected</span><span class="p">)</span>

    <span class="c1"># compute chr_poly_D(A) which essentially is:</span>
    <span class="c1">#</span>
    <span class="c1"># chr_poly_D_at_A = A.new_zeros(A.shape)</span>
    <span class="c1"># for k in range(chr_poly_D.size(-1)):</span>
    <span class="c1">#     chr_poly_D_at_A += chr_poly_D[k] * A.matrix_power(k)</span>
    <span class="c1">#</span>
    <span class="c1"># Note, however, for better performance we use the Horner&#39;s rule</span>
    <span class="n">chr_poly_D_at_A</span> <span class="o">=</span> <span class="n">_matrix_polynomial_value</span><span class="p">(</span><span class="n">chr_poly_D</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>

    <span class="c1"># compute the action of `chr_poly_D_at_A` restricted to U_ortho_t</span>
    <span class="n">chr_poly_D_at_A_to_U_ortho</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
        <span class="n">U_ortho_t</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
            <span class="n">chr_poly_D_at_A</span><span class="p">,</span>
            <span class="n">U_ortho</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># we need to invert &#39;chr_poly_D_at_A_to_U_ortho`, for that we compute its</span>
    <span class="c1"># Cholesky decomposition and then use `torch.cholesky_solve` for better stability.</span>
    <span class="c1"># Cholesky decomposition requires the input to be positive-definite.</span>
    <span class="c1"># Note that `chr_poly_D_at_A_to_U_ortho` is positive-definite if</span>
    <span class="c1"># 1. `largest` == False, or</span>
    <span class="c1"># 2. `largest` == True and `k` is even</span>
    <span class="c1"># under the assumption that `A` has distinct eigenvalues.</span>
    <span class="c1">#</span>
    <span class="c1"># check if `chr_poly_D_at_A_to_U_ortho` is positive-definite or negative-definite</span>
    <span class="n">chr_poly_D_at_A_to_U_ortho_sign</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="p">(</span><span class="n">largest</span> <span class="ow">and</span> <span class="p">(</span><span class="n">k</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span> <span class="k">else</span> <span class="o">+</span><span class="mi">1</span>
    <span class="n">chr_poly_D_at_A_to_U_ortho_L</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span>
        <span class="n">chr_poly_D_at_A_to_U_ortho_sign</span> <span class="o">*</span> <span class="n">chr_poly_D_at_A_to_U_ortho</span>
    <span class="p">)</span>

    <span class="c1"># compute the gradient part in span(U)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">_symeig_backward_complete_eigenspace</span><span class="p">(</span>
        <span class="n">D_grad</span><span class="p">,</span> <span class="n">U_grad</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">U</span>
    <span class="p">)</span>

    <span class="c1"># incorporate the Sylvester equation solution into the full gradient</span>
    <span class="c1"># it resides in span(U_ortho)</span>
    <span class="n">res</span> <span class="o">-=</span> <span class="n">U_ortho</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
        <span class="n">chr_poly_D_at_A_to_U_ortho_sign</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cholesky_solve</span><span class="p">(</span>
            <span class="n">U_ortho_t</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">series_acc</span><span class="p">),</span>
            <span class="n">chr_poly_D_at_A_to_U_ortho_L</span>
        <span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">Ut</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">res</span>

<span class="k">def</span> <span class="nf">_symeig_backward</span><span class="p">(</span><span class="n">D_grad</span><span class="p">,</span> <span class="n">U_grad</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">largest</span><span class="p">):</span>
    <span class="c1"># if `U` is square, then the columns of `U` is a complete eigenspace</span>
    <span class="k">if</span> <span class="n">U</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">U</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_symeig_backward_complete_eigenspace</span><span class="p">(</span>
            <span class="n">D_grad</span><span class="p">,</span> <span class="n">U_grad</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">U</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_symeig_backward_partial_eigenspace</span><span class="p">(</span>
            <span class="n">D_grad</span><span class="p">,</span> <span class="n">U_grad</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">largest</span>
        <span class="p">)</span>

<span class="k">class</span> <span class="nc">LOBPCGAutogradFunction</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span>  <span class="c1"># type: ignore[override]</span>
                <span class="n">A</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">B</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">n</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">iK</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">niter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">tol</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">largest</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">tracker</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">ortho_iparams</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">ortho_fparams</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                <span class="n">ortho_bparams</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>

        <span class="c1"># makes sure that input is contiguous for efficiency.</span>
        <span class="c1"># Note: autograd does not support dense gradients for sparse input yet.</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">A</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">)</span> <span class="k">else</span> <span class="n">A</span>
        <span class="k">if</span> <span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">B</span> <span class="o">=</span> <span class="n">B</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">B</span><span class="o">.</span><span class="n">is_sparse</span><span class="p">)</span> <span class="k">else</span> <span class="n">B</span>

        <span class="n">D</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">_lobpcg</span><span class="p">(</span>
            <span class="n">A</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span>
            <span class="n">n</span><span class="p">,</span> <span class="n">iK</span><span class="p">,</span> <span class="n">niter</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">largest</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">tracker</span><span class="p">,</span>
            <span class="n">ortho_iparams</span><span class="p">,</span> <span class="n">ortho_fparams</span><span class="p">,</span> <span class="n">ortho_bparams</span>
        <span class="p">)</span>

        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">largest</span> <span class="o">=</span> <span class="n">largest</span>

        <span class="k">return</span> <span class="n">D</span><span class="p">,</span> <span class="n">U</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">D_grad</span><span class="p">,</span> <span class="n">U_grad</span><span class="p">):</span>
        <span class="n">A_grad</span> <span class="o">=</span> <span class="n">B_grad</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="mi">14</span>

        <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">U</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
        <span class="n">largest</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">largest</span>

        <span class="c1"># lobpcg.backward has some limitations. Checks for unsupported input</span>
        <span class="k">if</span> <span class="n">A</span><span class="o">.</span><span class="n">is_sparse</span> <span class="ow">or</span> <span class="p">(</span><span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">B</span><span class="o">.</span><span class="n">is_sparse</span> <span class="ow">and</span> <span class="n">ctx</span><span class="o">.</span><span class="n">needs_input_grad</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;lobpcg.backward does not support sparse input yet.&#39;</span>
                <span class="s1">&#39;Note that lobpcg.forward does though.&#39;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">A</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">complex64</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">complex128</span><span class="p">)</span> <span class="ow">or</span> \
           <span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">B</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">complex64</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">complex128</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;lobpcg.backward does not support complex input yet.&#39;</span>
                <span class="s1">&#39;Note that lobpcg.forward does though.&#39;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;lobpcg.backward does not support backward with B != I yet.&#39;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">largest</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">largest</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># symeig backward</span>
        <span class="k">if</span> <span class="n">B</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">A_grad</span> <span class="o">=</span> <span class="n">_symeig_backward</span><span class="p">(</span>
                <span class="n">D_grad</span><span class="p">,</span> <span class="n">U_grad</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">largest</span>
            <span class="p">)</span>

        <span class="c1"># A has index 0</span>
        <span class="n">grads</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">A_grad</span>
        <span class="c1"># B has index 2</span>
        <span class="n">grads</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">B_grad</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">grads</span><span class="p">)</span>


<div class="viewcode-block" id="lobpcg"><a class="viewcode-back" href="../../generated/torch.lobpcg.html#torch.lobpcg">[docs]</a><span class="k">def</span> <span class="nf">lobpcg</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
           <span class="n">k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">B</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">n</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">iK</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">niter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">tol</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">largest</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">tracker</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">ortho_iparams</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">ortho_fparams</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
           <span class="n">ortho_bparams</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
           <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>

    <span class="sd">&quot;&quot;&quot;Find the k largest (or smallest) eigenvalues and the corresponding</span>
<span class="sd">    eigenvectors of a symmetric positive definite generalized</span>
<span class="sd">    eigenvalue problem using matrix-free LOBPCG methods.</span>

<span class="sd">    This function is a front-end to the following LOBPCG algorithms</span>
<span class="sd">    selectable via `method` argument:</span>

<span class="sd">      `method=&quot;basic&quot;` - the LOBPCG method introduced by Andrew</span>
<span class="sd">      Knyazev, see [Knyazev2001]. A less robust method, may fail when</span>
<span class="sd">      Cholesky is applied to singular input.</span>

<span class="sd">      `method=&quot;ortho&quot;` - the LOBPCG method with orthogonal basis</span>
<span class="sd">      selection [StathopoulosEtal2002]. A robust method.</span>

<span class="sd">    Supported inputs are dense, sparse, and batches of dense matrices.</span>

<span class="sd">    .. note:: In general, the basic method spends least time per</span>
<span class="sd">      iteration. However, the robust methods converge much faster and</span>
<span class="sd">      are more stable. So, the usage of the basic method is generally</span>
<span class="sd">      not recommended but there exist cases where the usage of the</span>
<span class="sd">      basic method may be preferred.</span>

<span class="sd">    .. warning:: The backward method does not support sparse and complex inputs.</span>
<span class="sd">      It works only when `B` is not provided (i.e. `B == None`).</span>
<span class="sd">      We are actively working on extensions, and the details of</span>
<span class="sd">      the algorithms are going to be published promptly.</span>

<span class="sd">    .. warning:: While it is assumed that `A` is symmetric, `A.grad` is not.</span>
<span class="sd">      To make sure that `A.grad` is symmetric, so that `A - t * A.grad` is symmetric</span>
<span class="sd">      in first-order optimization routines, prior to running `lobpcg`</span>
<span class="sd">      we do the following symmetrization map: `A -&gt; (A + A.t()) / 2`.</span>
<span class="sd">      The map is performed only when the `A` requires gradients.</span>

<span class="sd">    Args:</span>

<span class="sd">      A (Tensor): the input tensor of size :math:`(*, m, m)`</span>

<span class="sd">      B (Tensor, optional): the input tensor of size :math:`(*, m,</span>
<span class="sd">                  m)`. When not specified, `B` is interpereted as</span>
<span class="sd">                  identity matrix.</span>

<span class="sd">      X (tensor, optional): the input tensor of size :math:`(*, m, n)`</span>
<span class="sd">                  where `k &lt;= n &lt;= m`. When specified, it is used as</span>
<span class="sd">                  initial approximation of eigenvectors. X must be a</span>
<span class="sd">                  dense tensor.</span>

<span class="sd">      iK (tensor, optional): the input tensor of size :math:`(*, m,</span>
<span class="sd">                  m)`. When specified, it will be used as preconditioner.</span>

<span class="sd">      k (integer, optional): the number of requested</span>
<span class="sd">                  eigenpairs. Default is the number of :math:`X`</span>
<span class="sd">                  columns (when specified) or `1`.</span>

<span class="sd">      n (integer, optional): if :math:`X` is not specified then `n`</span>
<span class="sd">                  specifies the size of the generated random</span>
<span class="sd">                  approximation of eigenvectors. Default value for `n`</span>
<span class="sd">                  is `k`. If :math:`X` is specified, the value of `n`</span>
<span class="sd">                  (when specified) must be the number of :math:`X`</span>
<span class="sd">                  columns.</span>

<span class="sd">      tol (float, optional): residual tolerance for stopping</span>
<span class="sd">                 criterion. Default is `feps ** 0.5` where `feps` is</span>
<span class="sd">                 smallest non-zero floating-point number of the given</span>
<span class="sd">                 input tensor `A` data type.</span>

<span class="sd">      largest (bool, optional): when True, solve the eigenproblem for</span>
<span class="sd">                 the largest eigenvalues. Otherwise, solve the</span>
<span class="sd">                 eigenproblem for smallest eigenvalues. Default is</span>
<span class="sd">                 `True`.</span>

<span class="sd">      method (str, optional): select LOBPCG method. See the</span>
<span class="sd">                 description of the function above. Default is</span>
<span class="sd">                 &quot;ortho&quot;.</span>

<span class="sd">      niter (int, optional): maximum number of iterations. When</span>
<span class="sd">                 reached, the iteration process is hard-stopped and</span>
<span class="sd">                 the current approximation of eigenpairs is returned.</span>
<span class="sd">                 For infinite iteration but until convergence criteria</span>
<span class="sd">                 is met, use `-1`.</span>

<span class="sd">      tracker (callable, optional) : a function for tracing the</span>
<span class="sd">                 iteration process. When specified, it is called at</span>
<span class="sd">                 each iteration step with LOBPCG instance as an</span>
<span class="sd">                 argument. The LOBPCG instance holds the full state of</span>
<span class="sd">                 the iteration process in the following attributes:</span>

<span class="sd">                   `iparams`, `fparams`, `bparams` - dictionaries of</span>
<span class="sd">                   integer, float, and boolean valued input</span>
<span class="sd">                   parameters, respectively</span>

<span class="sd">                   `ivars`, `fvars`, `bvars`, `tvars` - dictionaries</span>
<span class="sd">                   of integer, float, boolean, and Tensor valued</span>
<span class="sd">                   iteration variables, respectively.</span>

<span class="sd">                   `A`, `B`, `iK` - input Tensor arguments.</span>

<span class="sd">                   `E`, `X`, `S`, `R` - iteration Tensor variables.</span>

<span class="sd">                 For instance:</span>

<span class="sd">                   `ivars[&quot;istep&quot;]` - the current iteration step</span>
<span class="sd">                   `X` - the current approximation of eigenvectors</span>
<span class="sd">                   `E` - the current approximation of eigenvalues</span>
<span class="sd">                   `R` - the current residual</span>
<span class="sd">                   `ivars[&quot;converged_count&quot;]` - the current number of converged eigenpairs</span>
<span class="sd">                   `tvars[&quot;rerr&quot;]` - the current state of convergence criteria</span>

<span class="sd">                 Note that when `tracker` stores Tensor objects from</span>
<span class="sd">                 the LOBPCG instance, it must make copies of these.</span>

<span class="sd">                 If `tracker` sets `bvars[&quot;force_stop&quot;] = True`, the</span>
<span class="sd">                 iteration process will be hard-stopped.</span>

<span class="sd">      ortho_iparams, ortho_fparams, ortho_bparams (dict, optional):</span>
<span class="sd">                 various parameters to LOBPCG algorithm when using</span>
<span class="sd">                 `method=&quot;ortho&quot;`.</span>

<span class="sd">    Returns:</span>

<span class="sd">      E (Tensor): tensor of eigenvalues of size :math:`(*, k)`</span>

<span class="sd">      X (Tensor): tensor of eigenvectors of size :math:`(*, m, k)`</span>

<span class="sd">    References:</span>

<span class="sd">      [Knyazev2001] Andrew V. Knyazev. (2001) Toward the Optimal</span>
<span class="sd">      Preconditioned Eigensolver: Locally Optimal Block Preconditioned</span>
<span class="sd">      Conjugate Gradient Method. SIAM J. Sci. Comput., 23(2),</span>
<span class="sd">      517-541. (25 pages)</span>
<span class="sd">      https://epubs.siam.org/doi/abs/10.1137/S1064827500366124</span>

<span class="sd">      [StathopoulosEtal2002] Andreas Stathopoulos and Kesheng</span>
<span class="sd">      Wu. (2002) A Block Orthogonalization Procedure with Constant</span>
<span class="sd">      Synchronization Requirements. SIAM J. Sci. Comput., 23(6),</span>
<span class="sd">      2165-2182. (18 pages)</span>
<span class="sd">      https://epubs.siam.org/doi/10.1137/S1064827500370883</span>

<span class="sd">      [DuerschEtal2018] Jed A. Duersch, Meiyue Shao, Chao Yang, Ming</span>
<span class="sd">      Gu. (2018) A Robust and Efficient Implementation of LOBPCG.</span>
<span class="sd">      SIAM J. Sci. Comput., 40(5), C655-C676. (22 pages)</span>
<span class="sd">      https://epubs.siam.org/doi/abs/10.1137/17M1129830</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">():</span>
        <span class="n">tensor_ops</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">iK</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">type</span><span class="p">,</span> <span class="n">tensor_ops</span><span class="p">))</span><span class="o">.</span><span class="n">issubset</span><span class="p">((</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)))</span> <span class="ow">and</span> <span class="n">has_torch_function</span><span class="p">(</span><span class="n">tensor_ops</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">handle_torch_function</span><span class="p">(</span>
                <span class="n">lobpcg</span><span class="p">,</span> <span class="n">tensor_ops</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
                <span class="n">B</span><span class="o">=</span><span class="n">B</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">iK</span><span class="o">=</span><span class="n">iK</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="n">niter</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
                <span class="n">largest</span><span class="o">=</span><span class="n">largest</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span> <span class="n">tracker</span><span class="o">=</span><span class="n">tracker</span><span class="p">,</span>
                <span class="n">ortho_iparams</span><span class="o">=</span><span class="n">ortho_iparams</span><span class="p">,</span>
                <span class="n">ortho_fparams</span><span class="o">=</span><span class="n">ortho_fparams</span><span class="p">,</span>
                <span class="n">ortho_bparams</span><span class="o">=</span><span class="n">ortho_bparams</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">_jit_internal</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">A</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">or</span> <span class="p">(</span><span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">B</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">):</span>
            <span class="c1"># While it is expected that `A` is symmetric,</span>
            <span class="c1"># the `A_grad` might be not. Therefore we perform the trick below,</span>
            <span class="c1"># so that `A_grad` becomes symmetric.</span>
            <span class="c1"># The symmetrization is important for first-order optimization methods,</span>
            <span class="c1"># so that (A - alpha * A_grad) is still a symmetric matrix.</span>
            <span class="c1"># Same holds for `B`.</span>
            <span class="n">A_sym</span> <span class="o">=</span> <span class="p">(</span><span class="n">A</span> <span class="o">+</span> <span class="n">A</span><span class="o">.</span><span class="n">mT</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="n">B_sym</span> <span class="o">=</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="n">B</span><span class="o">.</span><span class="n">mT</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span> <span class="k">if</span> <span class="p">(</span><span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>

            <span class="k">return</span> <span class="n">LOBPCGAutogradFunction</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
                <span class="n">A_sym</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">B_sym</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">iK</span><span class="p">,</span> <span class="n">niter</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">largest</span><span class="p">,</span>
                <span class="n">method</span><span class="p">,</span> <span class="n">tracker</span><span class="p">,</span> <span class="n">ortho_iparams</span><span class="p">,</span> <span class="n">ortho_fparams</span><span class="p">,</span> <span class="n">ortho_bparams</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">A</span><span class="o">.</span><span class="n">requires_grad</span> <span class="ow">or</span> <span class="p">(</span><span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">B</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s1">&#39;Script and require grads is not supported atm.&#39;</span>
                <span class="s1">&#39;If you just want to do the forward, use .detach()&#39;</span>
                <span class="s1">&#39;on A and B before calling into lobpcg&#39;</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="n">_lobpcg</span><span class="p">(</span>
        <span class="n">A</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">iK</span><span class="p">,</span> <span class="n">niter</span><span class="p">,</span> <span class="n">tol</span><span class="p">,</span> <span class="n">largest</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">tracker</span><span class="p">,</span>
        <span class="n">ortho_iparams</span><span class="p">,</span> <span class="n">ortho_fparams</span><span class="p">,</span> <span class="n">ortho_bparams</span>
    <span class="p">)</span></div>

<span class="k">def</span> <span class="nf">_lobpcg</span><span class="p">(</span><span class="n">A</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">B</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">n</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">iK</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">niter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">tol</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">largest</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">tracker</span><span class="p">:</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">ortho_iparams</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">ortho_fparams</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">ortho_bparams</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>

    <span class="c1"># A must be square:</span>
    <span class="k">assert</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># A and B must have the same shapes:</span>
        <span class="k">assert</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">get_floating_dtype</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">device</span>
    <span class="k">if</span> <span class="n">tol</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">feps</span> <span class="o">=</span> <span class="p">{</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span> <span class="mf">1.2e-07</span><span class="p">,</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">:</span> <span class="mf">2.23e-16</span><span class="p">}[</span><span class="n">dtype</span><span class="p">]</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="n">feps</span> <span class="o">**</span> <span class="mf">0.5</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">k</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">k</span>
    <span class="n">n</span> <span class="o">=</span> <span class="p">(</span><span class="n">k</span> <span class="k">if</span> <span class="n">n</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">n</span><span class="p">)</span> <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">m</span> <span class="o">&lt;</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">n</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;LPBPCG algorithm is not applicable when the number of A rows (=</span><span class="si">{}</span><span class="s1">)&#39;</span>
            <span class="s1">&#39; is smaller than 3 x the number of requested eigenpairs (=</span><span class="si">{}</span><span class="s1">)&#39;</span>
            <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

    <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;ortho&#39;</span> <span class="k">if</span> <span class="n">method</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">method</span>

    <span class="n">iparams</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;m&#39;</span><span class="p">:</span> <span class="n">m</span><span class="p">,</span>
        <span class="s1">&#39;n&#39;</span><span class="p">:</span> <span class="n">n</span><span class="p">,</span>
        <span class="s1">&#39;k&#39;</span><span class="p">:</span> <span class="n">k</span><span class="p">,</span>
        <span class="s1">&#39;niter&#39;</span><span class="p">:</span> <span class="mi">1000</span> <span class="k">if</span> <span class="n">niter</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">niter</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">fparams</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;tol&#39;</span><span class="p">:</span> <span class="n">tol</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">bparams</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;largest&#39;</span><span class="p">:</span> <span class="kc">True</span> <span class="k">if</span> <span class="n">largest</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">largest</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;ortho&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">ortho_iparams</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">iparams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ortho_iparams</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ortho_fparams</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">fparams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ortho_fparams</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">ortho_bparams</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">bparams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ortho_bparams</span><span class="p">)</span>
        <span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;ortho_i_max&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iparams</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;ortho_i_max&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;ortho_j_max&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">iparams</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;ortho_j_max&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">fparams</span><span class="p">[</span><span class="s1">&#39;ortho_tol&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fparams</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;ortho_tol&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="p">)</span>
        <span class="n">fparams</span><span class="p">[</span><span class="s1">&#39;ortho_tol_drop&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fparams</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;ortho_tol_drop&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="p">)</span>
        <span class="n">fparams</span><span class="p">[</span><span class="s1">&#39;ortho_tol_replace&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fparams</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;ortho_tol_replace&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="p">)</span>
        <span class="n">bparams</span><span class="p">[</span><span class="s1">&#39;ortho_use_drop&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">bparams</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;ortho_use_drop&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">():</span>
        <span class="n">LOBPCG</span><span class="o">.</span><span class="n">call_tracker</span> <span class="o">=</span> <span class="n">LOBPCG_call_tracker</span>  <span class="c1"># type: ignore[assignment]</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">N</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])))</span>
        <span class="n">bA</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">N</span><span class="p">,)</span> <span class="o">+</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
        <span class="n">bB</span> <span class="o">=</span> <span class="n">B</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">N</span><span class="p">,)</span> <span class="o">+</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span> <span class="k">if</span> <span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">bX</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">N</span><span class="p">,)</span> <span class="o">+</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span> <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">bE</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="n">bXret</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="n">A_</span> <span class="o">=</span> <span class="n">bA</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">B_</span> <span class="o">=</span> <span class="n">bB</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">if</span> <span class="n">bB</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>
            <span class="n">X_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">bX</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">bX</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">X_</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="p">(</span><span class="n">X_</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
            <span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;batch_index&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
            <span class="n">worker</span> <span class="o">=</span> <span class="n">LOBPCG</span><span class="p">(</span><span class="n">A_</span><span class="p">,</span> <span class="n">B_</span><span class="p">,</span> <span class="n">X_</span><span class="p">,</span> <span class="n">iK</span><span class="p">,</span> <span class="n">iparams</span><span class="p">,</span> <span class="n">fparams</span><span class="p">,</span> <span class="n">bparams</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">tracker</span><span class="p">)</span>
            <span class="n">worker</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
            <span class="n">bE</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">worker</span><span class="o">.</span><span class="n">E</span><span class="p">[:</span><span class="n">k</span><span class="p">]</span>
            <span class="n">bXret</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">worker</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="n">k</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">():</span>
            <span class="n">LOBPCG</span><span class="o">.</span><span class="n">call_tracker</span> <span class="o">=</span> <span class="n">LOBPCG_call_tracker_orig</span>  <span class="c1"># type: ignore[assignment]</span>

        <span class="k">return</span> <span class="n">bE</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">k</span><span class="p">,)),</span> <span class="n">bXret</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span> <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">X</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>

    <span class="n">worker</span> <span class="o">=</span> <span class="n">LOBPCG</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">iK</span><span class="p">,</span> <span class="n">iparams</span><span class="p">,</span> <span class="n">fparams</span><span class="p">,</span> <span class="n">bparams</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">tracker</span><span class="p">)</span>

    <span class="n">worker</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">():</span>
        <span class="n">LOBPCG</span><span class="o">.</span><span class="n">call_tracker</span> <span class="o">=</span> <span class="n">LOBPCG_call_tracker_orig</span>  <span class="c1"># type: ignore[assignment]</span>

    <span class="k">return</span> <span class="n">worker</span><span class="o">.</span><span class="n">E</span><span class="p">[:</span><span class="n">k</span><span class="p">],</span> <span class="n">worker</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="n">k</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">LOBPCG</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Worker class of LOBPCG methods.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">A</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
                 <span class="n">B</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
                 <span class="n">X</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
                 <span class="n">iK</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>
                 <span class="n">iparams</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
                 <span class="n">fparams</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span>
                 <span class="n">bparams</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">],</span>
                 <span class="n">method</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                 <span class="n">tracker</span><span class="p">:</span> <span class="kc">None</span>
                 <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="c1"># constant parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">A</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">=</span> <span class="n">B</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iK</span> <span class="o">=</span> <span class="n">iK</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">iparams</span> <span class="o">=</span> <span class="n">iparams</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fparams</span> <span class="o">=</span> <span class="n">fparams</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bparams</span> <span class="o">=</span> <span class="n">bparams</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">=</span> <span class="n">method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span> <span class="o">=</span> <span class="n">tracker</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;n&#39;</span><span class="p">]</span>

        <span class="c1"># variable parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">E</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">R</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">S</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">n</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tvars</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;istep&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fvars</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;_&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bvars</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;_&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;LOPBCG:&#39;</span><span class="p">]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  iparams=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iparams</span><span class="p">)]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  fparams=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fparams</span><span class="p">)]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  bparams=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bparams</span><span class="p">)]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  ivars=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">)]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  fvars=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fvars</span><span class="p">)]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  bvars=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bvars</span><span class="p">)]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  tvars=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tvars</span><span class="p">)]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  A=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">)]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  B=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">)]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  iK=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iK</span><span class="p">)]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  X=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)]</span>
        <span class="n">lines</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;  E=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">E</span><span class="p">)]</span>
        <span class="n">r</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
            <span class="n">r</span> <span class="o">+=</span> <span class="n">line</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set and update iteration variables.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;istep&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">X_norm</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
            <span class="n">iX_norm</span> <span class="o">=</span> <span class="n">X_norm</span> <span class="o">**</span> <span class="o">-</span><span class="mi">1</span>
            <span class="n">A_norm</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">_utils</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)))</span> <span class="o">*</span> <span class="n">iX_norm</span>
            <span class="n">B_norm</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">_utils</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)))</span> <span class="o">*</span> <span class="n">iX_norm</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fvars</span><span class="p">[</span><span class="s1">&#39;X_norm&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_norm</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fvars</span><span class="p">[</span><span class="s1">&#39;A_norm&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">A_norm</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fvars</span><span class="p">[</span><span class="s1">&#39;B_norm&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">B_norm</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;iterations_left&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;niter&#39;</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_end&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;ortho&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_ortho</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_update_basic</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;iterations_left&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;iterations_left&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;istep&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;istep&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="k">def</span> <span class="nf">update_residual</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Update residual R from A, B, X, E.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mm</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">matmul</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">R</span> <span class="o">=</span> <span class="n">mm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span> <span class="o">-</span> <span class="n">mm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">E</span>

    <span class="k">def</span> <span class="nf">update_converged_count</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Determine the number of converged eigenpairs using backward stable</span>
<span class="sd">        convergence criterion, see discussion in Sec 4.3 of [DuerschEtal2018].</span>

<span class="sd">        Users may redefine this method for custom convergence criteria.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># (...) -&gt; int</span>
        <span class="n">prev_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_count&#39;</span><span class="p">]</span>
        <span class="n">tol</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fparams</span><span class="p">[</span><span class="s1">&#39;tol&#39;</span><span class="p">]</span>
        <span class="n">A_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fvars</span><span class="p">[</span><span class="s1">&#39;A_norm&#39;</span><span class="p">]</span>
        <span class="n">B_norm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fvars</span><span class="p">[</span><span class="s1">&#39;B_norm&#39;</span><span class="p">]</span>
        <span class="n">E</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">E</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">R</span>
        <span class="n">rerr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">A_norm</span> <span class="o">+</span> <span class="n">E</span><span class="p">[:</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="n">B_norm</span><span class="p">))</span> <span class="o">**</span> <span class="o">-</span><span class="mi">1</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="n">rerr</span> <span class="o">&lt;</span> <span class="n">tol</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">converged</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">b</span><span class="p">:</span>
                <span class="c1"># ignore convergence of following pairs to ensure</span>
                <span class="c1"># strict ordering of eigenpairs</span>
                <span class="k">break</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">assert</span> <span class="n">count</span> <span class="o">&gt;=</span> <span class="n">prev_count</span><span class="p">,</span> <span class="s1">&#39;the number of converged eigenpairs &#39;</span> \
            <span class="s1">&#39;(was </span><span class="si">{}</span><span class="s1">, got </span><span class="si">{}</span><span class="s1">) cannot decrease&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">prev_count</span><span class="p">,</span> <span class="n">count</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">count</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tvars</span><span class="p">[</span><span class="s1">&#39;rerr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rerr</span>
        <span class="k">return</span> <span class="n">count</span>

    <span class="k">def</span> <span class="nf">stop_iteration</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return True to stop iterations.</span>

<span class="sd">        Note that tracker (if defined) can force-stop iterations by</span>
<span class="sd">        setting ``worker.bvars[&#39;force_stop&#39;] = True``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bvars</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;force_stop&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;iterations_left&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span>
                <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_count&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;k&#39;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run LOBPCG iterations.</span>

<span class="sd">        Use this method as a template for implementing LOBPCG</span>
<span class="sd">        iteration scheme with custom tracker that is compatible with</span>
<span class="sd">        TorchScript.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">call_tracker</span><span class="p">()</span>

        <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_iteration</span><span class="p">():</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">is_scripting</span><span class="p">()</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">call_tracker</span><span class="p">()</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">unused</span>
    <span class="k">def</span> <span class="nf">call_tracker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Interface for tracking iteration process in Python mode.</span>

<span class="sd">        Tracking the iteration process is disabled in TorchScript</span>
<span class="sd">        mode. In fact, one should specify tracker=None when JIT</span>
<span class="sd">        compiling functions using lobpcg.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># do nothing when in TorchScript mode</span>
        <span class="k">pass</span>

    <span class="c1"># Internal methods</span>

    <span class="k">def</span> <span class="nf">_update_basic</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update or initialize iteration variables when `method == &quot;basic&quot;`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span>
        <span class="n">ns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_end&#39;</span><span class="p">]</span>
        <span class="n">nc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_count&#39;</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;n&#39;</span><span class="p">]</span>
        <span class="n">largest</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bparams</span><span class="p">[</span><span class="s1">&#39;largest&#39;</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;istep&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">Ri</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rayleigh_ritz_transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
            <span class="n">M</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">qform</span><span class="p">(</span><span class="n">_utils</span><span class="o">.</span><span class="n">qform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">),</span> <span class="n">Ri</span><span class="p">)</span>
            <span class="n">E</span><span class="p">,</span> <span class="n">Z</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">symeig</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">largest</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">mm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">mm</span><span class="p">(</span><span class="n">Ri</span><span class="p">,</span> <span class="n">Z</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">E</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">E</span>
            <span class="n">np</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_residual</span><span class="p">()</span>
            <span class="n">nc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_converged_count</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span>

            <span class="n">W</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iK</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">R</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_end&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ns</span> <span class="o">=</span> <span class="n">n</span> <span class="o">+</span> <span class="n">np</span> <span class="o">+</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[:,</span> <span class="n">n</span> <span class="o">+</span> <span class="n">np</span><span class="p">:</span><span class="n">ns</span><span class="p">]</span> <span class="o">=</span> <span class="n">W</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">S_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[:,</span> <span class="n">nc</span><span class="p">:</span><span class="n">ns</span><span class="p">]</span>
            <span class="n">Ri</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rayleigh_ritz_transform</span><span class="p">(</span><span class="n">S_</span><span class="p">)</span>
            <span class="n">M</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">qform</span><span class="p">(</span><span class="n">_utils</span><span class="o">.</span><span class="n">qform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="n">S_</span><span class="p">),</span> <span class="n">Ri</span><span class="p">)</span>
            <span class="n">E_</span><span class="p">,</span> <span class="n">Z</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">symeig</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">largest</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="n">nc</span><span class="p">:]</span> <span class="o">=</span> <span class="n">mm</span><span class="p">(</span><span class="n">S_</span><span class="p">,</span> <span class="n">mm</span><span class="p">(</span><span class="n">Ri</span><span class="p">,</span> <span class="n">Z</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n</span> <span class="o">-</span> <span class="n">nc</span><span class="p">]))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">E</span><span class="p">[</span><span class="n">nc</span><span class="p">:]</span> <span class="o">=</span> <span class="n">E_</span><span class="p">[:</span><span class="n">n</span> <span class="o">-</span> <span class="n">nc</span><span class="p">]</span>
            <span class="n">P</span> <span class="o">=</span> <span class="n">mm</span><span class="p">(</span><span class="n">S_</span><span class="p">,</span> <span class="n">mm</span><span class="p">(</span><span class="n">Ri</span><span class="p">,</span> <span class="n">Z</span><span class="p">[:,</span> <span class="n">n</span><span class="p">:</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span> <span class="o">-</span> <span class="n">nc</span><span class="p">]))</span>
            <span class="n">np</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">update_residual</span><span class="p">()</span>
            <span class="n">nc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_converged_count</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[:,</span> <span class="n">n</span><span class="p">:</span><span class="n">n</span> <span class="o">+</span> <span class="n">np</span><span class="p">]</span> <span class="o">=</span> <span class="n">P</span>
            <span class="n">W</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">iK</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">R</span><span class="p">[:,</span> <span class="n">nc</span><span class="p">:])</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_end&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ns</span> <span class="o">=</span> <span class="n">n</span> <span class="o">+</span> <span class="n">np</span> <span class="o">+</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[:,</span> <span class="n">n</span> <span class="o">+</span> <span class="n">np</span><span class="p">:</span><span class="n">ns</span><span class="p">]</span> <span class="o">=</span> <span class="n">W</span>

    <span class="k">def</span> <span class="nf">_update_ortho</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update or initialize iteration variables when `method == &quot;ortho&quot;`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span>
        <span class="n">ns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_end&#39;</span><span class="p">]</span>
        <span class="n">nc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_count&#39;</span><span class="p">]</span>
        <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;n&#39;</span><span class="p">]</span>
        <span class="n">largest</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bparams</span><span class="p">[</span><span class="s1">&#39;largest&#39;</span><span class="p">]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;istep&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">Ri</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_rayleigh_ritz_transform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
            <span class="n">M</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">qform</span><span class="p">(</span><span class="n">_utils</span><span class="o">.</span><span class="n">qform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">),</span> <span class="n">Ri</span><span class="p">)</span>
            <span class="n">E</span><span class="p">,</span> <span class="n">Z</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">symeig</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">largest</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">mm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">mm</span><span class="p">(</span><span class="n">Ri</span><span class="p">,</span> <span class="n">Z</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_residual</span><span class="p">()</span>
            <span class="n">np</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">nc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_converged_count</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_ortho</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">R</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
            <span class="n">ns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_end&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">n</span> <span class="o">+</span> <span class="n">np</span> <span class="o">+</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[:,</span> <span class="n">n</span> <span class="o">+</span> <span class="n">np</span><span class="p">:</span><span class="n">ns</span><span class="p">]</span> <span class="o">=</span> <span class="n">W</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">S_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[:,</span> <span class="n">nc</span><span class="p">:</span><span class="n">ns</span><span class="p">]</span>
            <span class="c1"># Rayleigh-Ritz procedure</span>
            <span class="n">E_</span><span class="p">,</span> <span class="n">Z</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">symeig</span><span class="p">(</span><span class="n">_utils</span><span class="o">.</span><span class="n">qform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="n">S_</span><span class="p">),</span> <span class="n">largest</span><span class="p">)</span>

            <span class="c1"># Update E, X, P</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">[:,</span> <span class="n">nc</span><span class="p">:]</span> <span class="o">=</span> <span class="n">mm</span><span class="p">(</span><span class="n">S_</span><span class="p">,</span> <span class="n">Z</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n</span> <span class="o">-</span> <span class="n">nc</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">E</span><span class="p">[</span><span class="n">nc</span><span class="p">:]</span> <span class="o">=</span> <span class="n">E_</span><span class="p">[:</span><span class="n">n</span> <span class="o">-</span> <span class="n">nc</span><span class="p">]</span>
            <span class="n">P</span> <span class="o">=</span> <span class="n">mm</span><span class="p">(</span><span class="n">S_</span><span class="p">,</span> <span class="n">mm</span><span class="p">(</span><span class="n">Z</span><span class="p">[:,</span> <span class="n">n</span> <span class="o">-</span> <span class="n">nc</span><span class="p">:],</span> <span class="n">_utils</span><span class="o">.</span><span class="n">basis</span><span class="p">(</span><span class="n">_utils</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">Z</span><span class="p">[:</span><span class="n">n</span> <span class="o">-</span> <span class="n">nc</span><span class="p">,</span> <span class="n">n</span> <span class="o">-</span> <span class="n">nc</span><span class="p">:]))))</span>
            <span class="n">np</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># check convergence</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">update_residual</span><span class="p">()</span>
            <span class="n">nc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_converged_count</span><span class="p">()</span>

            <span class="c1"># update S</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">X</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[:,</span> <span class="n">n</span><span class="p">:</span><span class="n">n</span> <span class="o">+</span> <span class="n">np</span><span class="p">]</span> <span class="o">=</span> <span class="n">P</span>
            <span class="n">W</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_ortho</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">R</span><span class="p">[:,</span> <span class="n">nc</span><span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n</span> <span class="o">+</span> <span class="n">np</span><span class="p">])</span>
            <span class="n">ns</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;converged_end&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">n</span> <span class="o">+</span> <span class="n">np</span> <span class="o">+</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">S</span><span class="p">[:,</span> <span class="n">n</span> <span class="o">+</span> <span class="n">np</span><span class="p">:</span><span class="n">ns</span><span class="p">]</span> <span class="o">=</span> <span class="n">W</span>

    <span class="k">def</span> <span class="nf">_get_rayleigh_ritz_transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return a transformation matrix that is used in Rayleigh-Ritz</span>
<span class="sd">        procedure for reducing a general eigenvalue problem :math:`(S^TAS)</span>
<span class="sd">        C = (S^TBS) C E` to a standard eigenvalue problem :math: `(Ri^T</span>
<span class="sd">        S^TAS Ri) Z = Z E` where `C = Ri Z`.</span>

<span class="sd">        .. note:: In the original Rayleight-Ritz procedure in</span>
<span class="sd">          [DuerschEtal2018], the problem is formulated as follows::</span>

<span class="sd">            SAS = S^T A S</span>
<span class="sd">            SBS = S^T B S</span>
<span class="sd">            D = (&lt;diagonal matrix of SBS&gt;) ** -1/2</span>
<span class="sd">            R^T R = Cholesky(D SBS D)</span>
<span class="sd">            Ri = D R^-1</span>
<span class="sd">            solve symeig problem Ri^T SAS Ri Z = Theta Z</span>
<span class="sd">            C = Ri Z</span>

<span class="sd">          To reduce the number of matrix products (denoted by empty</span>
<span class="sd">          space between matrices), here we introduce element-wise</span>
<span class="sd">          products (denoted by symbol `*`) so that the Rayleight-Ritz</span>
<span class="sd">          procedure becomes::</span>

<span class="sd">            SAS = S^T A S</span>
<span class="sd">            SBS = S^T B S</span>
<span class="sd">            d = (&lt;diagonal of SBS&gt;) ** -1/2    # this is 1-d column vector</span>
<span class="sd">            dd = d d^T                         # this is 2-d matrix</span>
<span class="sd">            R^T R = Cholesky(dd * SBS)</span>
<span class="sd">            Ri = R^-1 * d                      # broadcasting</span>
<span class="sd">            solve symeig problem Ri^T SAS Ri Z = Theta Z</span>
<span class="sd">            C = Ri Z</span>

<span class="sd">          where `dd` is 2-d matrix that replaces matrix products `D M</span>
<span class="sd">          D` with one element-wise product `M * dd`; and `d` replaces</span>
<span class="sd">          matrix product `D M` with element-wise product `M *</span>
<span class="sd">          d`. Also, creating the diagonal matrix `D` is avoided.</span>

<span class="sd">        Args:</span>
<span class="sd">        S (Tensor): the matrix basis for the search subspace, size is</span>
<span class="sd">                    :math:`(m, n)`.</span>

<span class="sd">        Returns:</span>
<span class="sd">        Ri (tensor): upper-triangular transformation matrix of size</span>
<span class="sd">                     :math:`(n, n)`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">B</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span>
        <span class="n">mm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span>
        <span class="n">SBS</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">qform</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
        <span class="n">d_row</span> <span class="o">=</span> <span class="n">SBS</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>
        <span class="n">d_col</span> <span class="o">=</span> <span class="n">d_row</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">d_row</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="c1"># TODO use torch.linalg.cholesky_solve once it is implemented</span>
        <span class="n">R</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">((</span><span class="n">SBS</span> <span class="o">*</span> <span class="n">d_row</span><span class="p">)</span> <span class="o">*</span> <span class="n">d_col</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">d_row</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(),</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_svqb</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                  <span class="n">U</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>     <span class="c1"># Tensor</span>
                  <span class="n">drop</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>  <span class="c1"># bool</span>
                  <span class="n">tau</span><span class="p">:</span> <span class="nb">float</span>    <span class="c1"># float</span>
                  <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return B-orthonormal U.</span>

<span class="sd">        .. note:: When `drop` is `False` then `svqb` is based on the</span>
<span class="sd">                  Algorithm 4 from [DuerschPhD2015] that is a slight</span>
<span class="sd">                  modification of the corresponding algorithm</span>
<span class="sd">                  introduced in [StathopolousWu2002].</span>

<span class="sd">        Args:</span>

<span class="sd">          U (Tensor) : initial approximation, size is (m, n)</span>
<span class="sd">          drop (bool) : when True, drop columns that</span>
<span class="sd">                     contribution to the `span([U])` is small.</span>
<span class="sd">          tau (float) : positive tolerance</span>

<span class="sd">        Returns:</span>

<span class="sd">          U (Tensor) : B-orthonormal columns (:math:`U^T B U = I`), size</span>
<span class="sd">                       is (m, n1), where `n1 = n` if `drop` is `False,</span>
<span class="sd">                       otherwise `n1 &lt;= n`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">U</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">U</span>
        <span class="n">UBU</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">qform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">UBU</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Detect and drop exact zero columns from U. While the test</span>
        <span class="c1"># `abs(d) == 0` is unlikely to be True for random data, it is</span>
        <span class="c1"># possible to construct input data to lobpcg where it will be</span>
        <span class="c1"># True leading to a failure (notice the `d ** -0.5` operation</span>
        <span class="c1"># in the original algorithm). To prevent the failure, we drop</span>
        <span class="c1"># the exact zero columns here and then continue with the</span>
        <span class="c1"># original algorithm below.</span>
        <span class="n">nz</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">nz</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nz</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nz</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
            <span class="n">U</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,</span> <span class="n">nz</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">U</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">U</span>
            <span class="n">UBU</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">qform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
            <span class="n">d</span> <span class="o">=</span> <span class="n">UBU</span><span class="o">.</span><span class="n">diagonal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">nz</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">nz</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>

        <span class="c1"># The original algorithm 4 from [DuerschPhD2015].</span>
        <span class="n">d_col</span> <span class="o">=</span> <span class="p">(</span><span class="n">d</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">DUBUD</span> <span class="o">=</span> <span class="p">(</span><span class="n">UBU</span> <span class="o">*</span> <span class="n">d_col</span><span class="p">)</span> <span class="o">*</span> <span class="n">_utils</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">d_col</span><span class="p">)</span>
        <span class="n">E</span><span class="p">,</span> <span class="n">Z</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">symeig</span><span class="p">(</span><span class="n">DUBUD</span><span class="p">)</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">tau</span> <span class="o">*</span> <span class="nb">abs</span><span class="p">(</span><span class="n">E</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">drop</span><span class="p">:</span>
            <span class="n">keep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">E</span> <span class="o">&gt;</span> <span class="n">t</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">keep</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keep</span>
            <span class="n">E</span> <span class="o">=</span> <span class="n">E</span><span class="p">[</span><span class="n">keep</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="n">Z</span> <span class="o">=</span> <span class="n">Z</span><span class="p">[:,</span> <span class="n">keep</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="n">d_col</span> <span class="o">=</span> <span class="n">d_col</span><span class="p">[</span><span class="n">keep</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">E</span><span class="p">[(</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">E</span> <span class="o">&lt;</span> <span class="n">t</span><span class="p">))[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">t</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">U</span> <span class="o">*</span> <span class="n">_utils</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">d_col</span><span class="p">),</span> <span class="n">Z</span> <span class="o">*</span> <span class="n">E</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_ortho</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return B-orthonormal U with columns are B-orthogonal to V.</span>

<span class="sd">        .. note:: When `bparams[&quot;ortho_use_drop&quot;] == False` then</span>
<span class="sd">                  `_get_ortho` is based on the Algorithm 3 from</span>
<span class="sd">                  [DuerschPhD2015] that is a slight modification of</span>
<span class="sd">                  the corresponding algorithm introduced in</span>
<span class="sd">                  [StathopolousWu2002]. Otherwise, the method</span>
<span class="sd">                  implements Algorithm 6 from [DuerschPhD2015]</span>

<span class="sd">        .. note:: If all U columns are B-collinear to V then the</span>
<span class="sd">                  returned tensor U will be empty.</span>

<span class="sd">        Args:</span>

<span class="sd">          U (Tensor) : initial approximation, size is (m, n)</span>
<span class="sd">          V (Tensor) : B-orthogonal external basis, size is (m, k)</span>

<span class="sd">        Returns:</span>

<span class="sd">          U (Tensor) : B-orthonormal columns (:math:`U^T B U = I`)</span>
<span class="sd">                       such that :math:`V^T B U=0`, size is (m, n1),</span>
<span class="sd">                       where `n1 = n` if `drop` is `False, otherwise</span>
<span class="sd">                       `n1 &lt;= n`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span>
        <span class="n">mm_B</span> <span class="o">=</span> <span class="n">_utils</span><span class="o">.</span><span class="n">matmul</span>
        <span class="n">m</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">]</span>
        <span class="n">tau_ortho</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fparams</span><span class="p">[</span><span class="s1">&#39;ortho_tol&#39;</span><span class="p">]</span>
        <span class="n">tau_drop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fparams</span><span class="p">[</span><span class="s1">&#39;ortho_tol_drop&#39;</span><span class="p">]</span>
        <span class="n">tau_replace</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fparams</span><span class="p">[</span><span class="s1">&#39;ortho_tol_replace&#39;</span><span class="p">]</span>
        <span class="n">i_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;ortho_i_max&#39;</span><span class="p">]</span>
        <span class="n">j_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">iparams</span><span class="p">[</span><span class="s1">&#39;ortho_j_max&#39;</span><span class="p">]</span>
        <span class="c1"># when use_drop==True, enable dropping U columns that have</span>
        <span class="c1"># small contribution to the `span([U, V])`.</span>
        <span class="n">use_drop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bparams</span><span class="p">[</span><span class="s1">&#39;ortho_use_drop&#39;</span><span class="p">]</span>

        <span class="c1"># clean up variables from the previous call</span>
        <span class="k">for</span> <span class="n">vkey</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fvars</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">if</span> <span class="n">vkey</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;ortho_&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">vkey</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_rerr&#39;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">fvars</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">vkey</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;ortho_i&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;ortho_j&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

        <span class="n">BV_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">mm_B</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="n">V</span><span class="p">))</span>
        <span class="n">BU</span> <span class="o">=</span> <span class="n">mm_B</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
        <span class="n">VBU</span> <span class="o">=</span> <span class="n">mm</span><span class="p">(</span><span class="n">_utils</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">V</span><span class="p">),</span> <span class="n">BU</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">stats</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">i_max</span><span class="p">):</span>
            <span class="n">U</span> <span class="o">=</span> <span class="n">U</span> <span class="o">-</span> <span class="n">mm</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">VBU</span><span class="p">)</span>
            <span class="n">drop</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">tau_svqb</span> <span class="o">=</span> <span class="n">tau_drop</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">j_max</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">use_drop</span><span class="p">:</span>
                    <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_svqb</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">drop</span><span class="p">,</span> <span class="n">tau_svqb</span><span class="p">)</span>
                    <span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span>
                    <span class="n">tau_svqb</span> <span class="o">=</span> <span class="n">tau_replace</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">U</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_svqb</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">tau_replace</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">U</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># all initial U columns are B-collinear to V</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;ortho_i&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;ortho_j&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span>
                    <span class="k">return</span> <span class="n">U</span>
                <span class="n">BU</span> <span class="o">=</span> <span class="n">mm_B</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
                <span class="n">UBU</span> <span class="o">=</span> <span class="n">mm</span><span class="p">(</span><span class="n">_utils</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">U</span><span class="p">),</span> <span class="n">BU</span><span class="p">)</span>
                <span class="n">U_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>
                <span class="n">BU_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">BU</span><span class="p">)</span>
                <span class="n">R</span> <span class="o">=</span> <span class="n">UBU</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">UBU</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                    <span class="n">device</span><span class="o">=</span><span class="n">UBU</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                                    <span class="n">dtype</span><span class="o">=</span><span class="n">UBU</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
                <span class="n">R_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
                <span class="c1"># https://github.com/pytorch/pytorch/issues/33810 workaround:</span>
                <span class="n">rerr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">R_norm</span><span class="p">)</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">BU_norm</span> <span class="o">*</span> <span class="n">U_norm</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mi">1</span>
                <span class="n">vkey</span> <span class="o">=</span> <span class="s1">&#39;ortho_UBUmI_rerr[</span><span class="si">{}</span><span class="s1">, </span><span class="si">{}</span><span class="s1">]&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">fvars</span><span class="p">[</span><span class="n">vkey</span><span class="p">]</span> <span class="o">=</span> <span class="n">rerr</span>
                <span class="k">if</span> <span class="n">rerr</span> <span class="o">&lt;</span> <span class="n">tau_ortho</span><span class="p">:</span>
                    <span class="k">break</span>
            <span class="n">VBU</span> <span class="o">=</span> <span class="n">mm</span><span class="p">(</span><span class="n">_utils</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">V</span><span class="p">),</span> <span class="n">BU</span><span class="p">)</span>
            <span class="n">VBU_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">VBU</span><span class="p">)</span>
            <span class="n">U_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>
            <span class="n">rerr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">VBU_norm</span><span class="p">)</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">BV_norm</span> <span class="o">*</span> <span class="n">U_norm</span><span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mi">1</span>
            <span class="n">vkey</span> <span class="o">=</span> <span class="s1">&#39;ortho_VBU_rerr[</span><span class="si">{}</span><span class="s1">]&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">fvars</span><span class="p">[</span><span class="n">vkey</span><span class="p">]</span> <span class="o">=</span> <span class="n">rerr</span>
            <span class="k">if</span> <span class="n">rerr</span> <span class="o">&lt;</span> <span class="n">tau_ortho</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="k">if</span> <span class="n">m</span> <span class="o">&lt;</span> <span class="n">U</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">V</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
                <span class="c1"># TorchScript needs the class var to be assigned to a local to</span>
                <span class="c1"># do optional type refinement</span>
                <span class="n">B</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span>
                <span class="k">assert</span> <span class="n">B</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s1">&#39;Overdetermined shape of U:&#39;</span>
                    <span class="s1">&#39; #B-cols(=</span><span class="si">{}</span><span class="s1">) &gt;= #U-cols(=</span><span class="si">{}</span><span class="s1">) + #V-cols(=</span><span class="si">{}</span><span class="s1">) must hold&#39;</span>
                    <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">U</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">V</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;ortho_i&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ivars</span><span class="p">[</span><span class="s1">&#39;ortho_j&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span>
        <span class="k">return</span> <span class="n">U</span>


<span class="c1"># Calling tracker is separated from LOBPCG definitions because</span>
<span class="c1"># TorchScript does not support user-defined callback arguments:</span>
<span class="n">LOBPCG_call_tracker_orig</span> <span class="o">=</span> <span class="n">LOBPCG</span><span class="o">.</span><span class="n">call_tracker</span>
<span class="k">def</span> <span class="nf">LOBPCG_call_tracker</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tracker</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/clipboard.min.js"></script>
         <script src="../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>