


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.Tensor &mdash; PyTorch 1.12 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/tensors.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
  <link rel="stylesheet" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="torch.Tensor.new_tensor" href="generated/torch.Tensor.new_tensor.html" />
    <link rel="prev" title="torch.nn.functional.torch.nn.parallel.data_parallel" href="generated/torch.nn.functional.torch.nn.parallel.data_parallel.html" />


  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  


  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>1.12 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          


            
            
              
            
            
<p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community/build_ci_governance.html">PyTorch Governance | Build + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/design.html">PyTorch Design Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/governance.html">PyTorch Governance | Mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/persons_of_interest.html">PyTorch Governance | Maintainers</a></li>
</ul>
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/amp_examples.html">CUDA Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">torch::deploy</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="config_mod.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>torch.Tensor</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/tensors.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="torch-tensor">
<span id="tensor-doc"></span><h1>torch.Tensor<a class="headerlink" href="#torch-tensor" title="Permalink to this headline">Â¶</a></h1>
<p>A <a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a> is a multi-dimensional matrix containing elements of
a single data type.</p>
<div class="section" id="data-types">
<h2>Data types<a class="headerlink" href="#data-types" title="Permalink to this headline">Â¶</a></h2>
<p>Torch defines 10 tensor types with CPU and GPU variants which are as follows:</p>
<table class="docutils colwidths-auto align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Data type</p></th>
<th class="head"><p>dtype</p></th>
<th class="head"><p>CPU tensor</p></th>
<th class="head"><p>GPU tensor</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>32-bit floating point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.float32</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.float</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.cuda.FloatTensor</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>64-bit floating point</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.float64</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.double</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.DoubleTensor</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.cuda.DoubleTensor</span></code></p></td>
</tr>
<tr class="row-even"><td><p>16-bit floating point <a class="footnote-reference brackets" href="#id4" id="id1">1</a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.float16</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.half</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.HalfTensor</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.cuda.HalfTensor</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>16-bit floating point <a class="footnote-reference brackets" href="#id5" id="id2">2</a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.bfloat16</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.BFloat16Tensor</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.cuda.BFloat16Tensor</span></code></p></td>
</tr>
<tr class="row-even"><td><p>32-bit complex</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.complex32</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.chalf</span></code></p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>64-bit complex</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.complex64</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.cfloat</span></code></p></td>
<td></td>
<td></td>
</tr>
<tr class="row-even"><td><p>128-bit complex</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.complex128</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.cdouble</span></code></p></td>
<td></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>8-bit integer (unsigned)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.uint8</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.ByteTensor</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.cuda.ByteTensor</span></code></p></td>
</tr>
<tr class="row-even"><td><p>8-bit integer (signed)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.int8</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.CharTensor</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.cuda.CharTensor</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>16-bit integer (signed)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.int16</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.short</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.ShortTensor</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.cuda.ShortTensor</span></code></p></td>
</tr>
<tr class="row-even"><td><p>32-bit integer (signed)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.int32</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.int</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.IntTensor</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.cuda.IntTensor</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>64-bit integer (signed)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.int64</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.long</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.LongTensor</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.cuda.LongTensor</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Boolean</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.bool</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.BoolTensor</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.cuda.BoolTensor</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>quantized 8-bit integer (unsigned)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.quint8</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.ByteTensor</span></code></p></td>
<td><p>/</p></td>
</tr>
<tr class="row-even"><td><p>quantized 8-bit integer (signed)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.qint8</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.CharTensor</span></code></p></td>
<td><p>/</p></td>
</tr>
<tr class="row-odd"><td><p>quantized 32-bit integer (signed)</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.qint32</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.IntTensor</span></code></p></td>
<td><p>/</p></td>
</tr>
<tr class="row-even"><td><p>quantized 4-bit integer (unsigned) <a class="footnote-reference brackets" href="#id6" id="id3">3</a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">torch.quint4x2</span></code></p></td>
<td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.ByteTensor</span></code></p></td>
<td><p>/</p></td>
</tr>
</tbody>
</table>
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Sometimes referred to as binary16: uses 1 sign, 5 exponent, and 10
significand bits. Useful when precision is important at the expense of range.</p>
</dd>
<dt class="label" id="id5"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Sometimes referred to as Brain Floating Point: uses 1 sign, 8 exponent, and 7
significand bits. Useful when range is important, since it has the same
number of exponent bits as <code class="docutils literal notranslate"><span class="pre">float32</span></code></p>
</dd>
<dt class="label" id="id6"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>quantized 4-bit integer is stored as a 8-bit signed integer. Currently itâ€™s only supported in EmbeddingBag operator.</p>
</dd>
</dl>
<p><a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a> is an alias for the default tensor type (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.FloatTensor</span></code>).</p>
</div>
<div class="section" id="initializing-and-basic-operations">
<h2>Initializing and basic operations<a class="headerlink" href="#initializing-and-basic-operations" title="Permalink to this headline">Â¶</a></h2>
<p>A tensor can be constructed from a Python <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.10)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a> or sequence using the
<a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.tensor()</span></code></a> constructor:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]])</span>
<span class="go">tensor([[ 1.0000, -1.0000],</span>
<span class="go">        [ 1.0000, -1.0000]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]]))</span>
<span class="go">tensor([[ 1,  2,  3],</span>
<span class="go">        [ 4,  5,  6]])</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p><a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.tensor()</span></code></a> always copies <code class="xref py py-attr docutils literal notranslate"><span class="pre">data</span></code>. If you have a Tensor
<code class="xref py py-attr docutils literal notranslate"><span class="pre">data</span></code> and just want to change its <code class="docutils literal notranslate"><span class="pre">requires_grad</span></code> flag, use
<a class="reference internal" href="generated/torch.Tensor.requires_grad_.html#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">requires_grad_()</span></code></a> or
<a class="reference internal" href="generated/torch.Tensor.detach.html#torch.Tensor.detach" title="torch.Tensor.detach"><code class="xref py py-meth docutils literal notranslate"><span class="pre">detach()</span></code></a> to avoid a copy.
If you have a numpy array and want to avoid a copy, use
<a class="reference internal" href="generated/torch.as_tensor.html#torch.as_tensor" title="torch.as_tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.as_tensor()</span></code></a>.</p>
</div>
<p>A tensor of specific data type can be constructed by passing a
<a class="reference internal" href="tensor_attributes.html#torch.dtype" title="torch.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code></a> and/or a <a class="reference internal" href="tensor_attributes.html#torch.device" title="torch.device"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a> to a
constructor or tensor creation op:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="go">tensor([[ 0,  0,  0,  0],</span>
<span class="go">        [ 0,  0,  0,  0]], dtype=torch.int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cuda0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">cuda0</span><span class="p">)</span>
<span class="go">tensor([[ 1.0000,  1.0000,  1.0000,  1.0000],</span>
<span class="go">        [ 1.0000,  1.0000,  1.0000,  1.0000]], dtype=torch.float64, device=&#39;cuda:0&#39;)</span>
</pre></div>
</div>
<p>For more information about building Tensors, see <a class="reference internal" href="torch.html#tensor-creation-ops"><span class="std std-ref">Creation Ops</span></a></p>
<p>The contents of a tensor can be accessed and modified using Pythonâ€™s indexing
and slicing notation:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">2</span><span class="p">])</span>
<span class="go">tensor(6)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">8</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">tensor([[ 1,  8,  3],</span>
<span class="go">        [ 4,  5,  6]])</span>
</pre></div>
</div>
<p>Use <a class="reference internal" href="generated/torch.Tensor.item.html#torch.Tensor.item" title="torch.Tensor.item"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.item()</span></code></a> to get a Python number from a tensor containing a
single value:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">tensor([[ 1]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">2.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>
<span class="go">tensor(2.5000)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="go">2.5</span>
</pre></div>
</div>
<p>For more information about indexing, see <a class="reference internal" href="torch.html#indexing-slicing-joining"><span class="std std-ref">Indexing, Slicing, Joining, Mutating Ops</span></a></p>
<p>A tensor can be created with <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad=True</span></code> so that
<a class="reference internal" href="autograd.html#module-torch.autograd" title="torch.autograd"><code class="xref py py-mod docutils literal notranslate"><span class="pre">torch.autograd</span></code></a> records operations on them for automatic differentiation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">grad</span>
<span class="go">tensor([[ 2.0000, -2.0000],</span>
<span class="go">        [ 2.0000,  2.0000]])</span>
</pre></div>
</div>
<p>Each tensor has an associated <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Storage</span></code>, which holds its data.
The tensor class also provides multi-dimensional, <a class="reference external" href="https://en.wikipedia.org/wiki/Stride_of_an_array">strided</a>
view of a storage and defines numeric operations on it.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For more information on tensor views, see <a class="reference internal" href="tensor_view.html#tensor-view-doc"><span class="std std-ref">Tensor Views</span></a>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For more information on the <a class="reference internal" href="tensor_attributes.html#torch.dtype" title="torch.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code></a>, <a class="reference internal" href="tensor_attributes.html#torch.device" title="torch.device"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a>, and
<a class="reference internal" href="tensor_attributes.html#torch.layout" title="torch.layout"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.layout</span></code></a> attributes of a <a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a>, see
<a class="reference internal" href="tensor_attributes.html#tensor-attributes-doc"><span class="std std-ref">Tensor Attributes</span></a>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Methods which mutate a tensor are marked with an underscore suffix.
For example, <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.FloatTensor.abs_()</span></code> computes the absolute value
in-place and returns the modified tensor, while <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.FloatTensor.abs()</span></code>
computes the result in a new tensor.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To change an existing tensorâ€™s <a class="reference internal" href="tensor_attributes.html#torch.device" title="torch.device"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a> and/or <a class="reference internal" href="tensor_attributes.html#torch.dtype" title="torch.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code></a>, consider using
<a class="reference internal" href="generated/torch.Tensor.to.html#torch.Tensor.to" title="torch.Tensor.to"><code class="xref py py-meth docutils literal notranslate"><span class="pre">to()</span></code></a> method on the tensor.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Current implementation of <a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a> introduces memory overhead,
thus it might lead to unexpectedly high memory usage in the applications with many tiny tensors.
If this is your case, consider using one large structure.</p>
</div>
</div>
<div class="section" id="tensor-class-reference">
<h2>Tensor class reference<a class="headerlink" href="#tensor-class-reference" title="Permalink to this headline">Â¶</a></h2>
<dl class="py class">
<dt id="torch.Tensor">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">torch.</span></code><code class="sig-name descname"><span class="pre">Tensor</span></code><a class="headerlink" href="#torch.Tensor" title="Permalink to this definition">Â¶</a></dt>
<dd><p>There are a few main ways to create a tensor, depending on your use case.</p>
<ul class="simple">
<li><p>To create a tensor with pre-existing data, use <a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.tensor()</span></code></a>.</p></li>
<li><p>To create a tensor with specific size, use <code class="docutils literal notranslate"><span class="pre">torch.*</span></code> tensor creation
ops (see <a class="reference internal" href="torch.html#tensor-creation-ops"><span class="std std-ref">Creation Ops</span></a>).</p></li>
<li><p>To create a tensor with the same size (and similar types) as another tensor,
use <code class="docutils literal notranslate"><span class="pre">torch.*_like</span></code> tensor creation ops
(see <a class="reference internal" href="torch.html#tensor-creation-ops"><span class="std std-ref">Creation Ops</span></a>).</p></li>
<li><p>To create a tensor with similar type but different size as another tensor,
use <code class="docutils literal notranslate"><span class="pre">tensor.new_*</span></code> creation ops.</p></li>
</ul>
</dd></dl>

<dl class="py attribute">
<dt id="torch.Tensor.T">
<code class="sig-prename descclassname"><span class="pre">Tensor.</span></code><code class="sig-name descname"><span class="pre">T</span></code><a class="headerlink" href="#torch.Tensor.T" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a view of this tensor with its dimensions reversed.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">n</span></code> is the number of dimensions in <code class="docutils literal notranslate"><span class="pre">x</span></code>,
<code class="docutils literal notranslate"><span class="pre">x.T</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">x.permute(n-1,</span> <span class="pre">n-2,</span> <span class="pre">...,</span> <span class="pre">0)</span></code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The use of <a class="reference internal" href="#torch.Tensor.T" title="torch.Tensor.T"><code class="xref py py-func docutils literal notranslate"><span class="pre">Tensor.T()</span></code></a> on tensors of dimension other than 2 to reverse their shape
is deprecated and it will throw an error in a future release. Consider <a class="reference internal" href="#torch.Tensor.mT" title="torch.Tensor.mT"><code class="xref py py-attr docutils literal notranslate"><span class="pre">mT</span></code></a>
to transpose batches of matrices or <cite>x.permute(*torch.arange(x.ndim - 1, -1, -1))</cite> to reverse
the dimensions of a tensor.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="torch.Tensor.H">
<code class="sig-prename descclassname"><span class="pre">Tensor.</span></code><code class="sig-name descname"><span class="pre">H</span></code><a class="headerlink" href="#torch.Tensor.H" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a view of a matrix (2-D tensor) conjugated and transposed.</p>
<p><code class="docutils literal notranslate"><span class="pre">x.H</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">x.transpose(0,</span> <span class="pre">1).conj()</span></code> for complex matrices and
<code class="docutils literal notranslate"><span class="pre">x.transpose(0,</span> <span class="pre">1)</span></code> for real matrices.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p><a class="reference internal" href="#torch.Tensor.mH" title="torch.Tensor.mH"><code class="xref py py-attr docutils literal notranslate"><span class="pre">mH</span></code></a>: An attribute that also works on batches of matrices.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="torch.Tensor.mT">
<code class="sig-prename descclassname"><span class="pre">Tensor.</span></code><code class="sig-name descname"><span class="pre">mT</span></code><a class="headerlink" href="#torch.Tensor.mT" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns a view of this tensor with the last two dimensions transposed.</p>
<p><code class="docutils literal notranslate"><span class="pre">x.mT</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">x.transpose(-2,</span> <span class="pre">-1)</span></code>.</p>
</dd></dl>

<dl class="py attribute">
<dt id="torch.Tensor.mH">
<code class="sig-prename descclassname"><span class="pre">Tensor.</span></code><code class="sig-name descname"><span class="pre">mH</span></code><a class="headerlink" href="#torch.Tensor.mH" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Accessing this property is equivalent to calling <a class="reference internal" href="generated/torch.adjoint.html#torch.adjoint" title="torch.adjoint"><code class="xref py py-func docutils literal notranslate"><span class="pre">adjoint()</span></code></a>.</p>
</dd></dl>

<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.new_tensor.html#torch.Tensor.new_tensor" title="torch.Tensor.new_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.new_tensor</span></code></a></p></td>
<td><p>Returns a new Tensor with <code class="xref py py-attr docutils literal notranslate"><span class="pre">data</span></code> as the tensor data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.new_full.html#torch.Tensor.new_full" title="torch.Tensor.new_full"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.new_full</span></code></a></p></td>
<td><p>Returns a Tensor of size <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> filled with <code class="xref py py-attr docutils literal notranslate"><span class="pre">fill_value</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.new_empty.html#torch.Tensor.new_empty" title="torch.Tensor.new_empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.new_empty</span></code></a></p></td>
<td><p>Returns a Tensor of size <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> filled with uninitialized data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.new_ones.html#torch.Tensor.new_ones" title="torch.Tensor.new_ones"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.new_ones</span></code></a></p></td>
<td><p>Returns a Tensor of size <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> filled with <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.new_zeros.html#torch.Tensor.new_zeros" title="torch.Tensor.new_zeros"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.new_zeros</span></code></a></p></td>
<td><p>Returns a Tensor of size <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> filled with <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.is_cuda.html#torch.Tensor.is_cuda" title="torch.Tensor.is_cuda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_cuda</span></code></a></p></td>
<td><p>Is <code class="docutils literal notranslate"><span class="pre">True</span></code> if the Tensor is stored on the GPU, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.is_quantized.html#torch.Tensor.is_quantized" title="torch.Tensor.is_quantized"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_quantized</span></code></a></p></td>
<td><p>Is <code class="docutils literal notranslate"><span class="pre">True</span></code> if the Tensor is quantized, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.is_meta.html#torch.Tensor.is_meta" title="torch.Tensor.is_meta"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_meta</span></code></a></p></td>
<td><p>Is <code class="docutils literal notranslate"><span class="pre">True</span></code> if the Tensor is a meta tensor, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.device.html#torch.Tensor.device" title="torch.Tensor.device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.device</span></code></a></p></td>
<td><p>Is the <a class="reference internal" href="tensor_attributes.html#torch.device" title="torch.device"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code></a> where this Tensor is.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.grad.html#torch.Tensor.grad" title="torch.Tensor.grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.grad</span></code></a></p></td>
<td><p>This attribute is <code class="docutils literal notranslate"><span class="pre">None</span></code> by default and becomes a Tensor the first time a call to <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code> computes gradients for <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.ndim.html#torch.Tensor.ndim" title="torch.Tensor.ndim"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ndim</span></code></a></p></td>
<td><p>Alias for <a class="reference internal" href="generated/torch.Tensor.dim.html#torch.Tensor.dim" title="torch.Tensor.dim"><code class="xref py py-meth docutils literal notranslate"><span class="pre">dim()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.real.html#torch.Tensor.real" title="torch.Tensor.real"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.real</span></code></a></p></td>
<td><p>Returns a new tensor containing real values of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor for a complex-valued input tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.imag.html#torch.Tensor.imag" title="torch.Tensor.imag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.imag</span></code></a></p></td>
<td><p>Returns a new tensor containing imaginary values of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.abs.html#torch.Tensor.abs" title="torch.Tensor.abs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.abs</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.abs.html#torch.abs" title="torch.abs"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.abs()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.abs_.html#torch.Tensor.abs_" title="torch.Tensor.abs_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.abs_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.abs.html#torch.Tensor.abs" title="torch.Tensor.abs"><code class="xref py py-meth docutils literal notranslate"><span class="pre">abs()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.absolute.html#torch.Tensor.absolute" title="torch.Tensor.absolute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.absolute</span></code></a></p></td>
<td><p>Alias for <a class="reference internal" href="generated/torch.abs.html#torch.abs" title="torch.abs"><code class="xref py py-func docutils literal notranslate"><span class="pre">abs()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.absolute_.html#torch.Tensor.absolute_" title="torch.Tensor.absolute_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.absolute_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.absolute.html#torch.Tensor.absolute" title="torch.Tensor.absolute"><code class="xref py py-meth docutils literal notranslate"><span class="pre">absolute()</span></code></a> Alias for <code class="xref py py-func docutils literal notranslate"><span class="pre">abs_()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.acos.html#torch.Tensor.acos" title="torch.Tensor.acos"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.acos</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.acos.html#torch.acos" title="torch.acos"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.acos()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.acos_.html#torch.Tensor.acos_" title="torch.Tensor.acos_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.acos_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.acos.html#torch.Tensor.acos" title="torch.Tensor.acos"><code class="xref py py-meth docutils literal notranslate"><span class="pre">acos()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.arccos.html#torch.Tensor.arccos" title="torch.Tensor.arccos"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arccos</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.arccos.html#torch.arccos" title="torch.arccos"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.arccos()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.arccos_.html#torch.Tensor.arccos_" title="torch.Tensor.arccos_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arccos_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.arccos.html#torch.Tensor.arccos" title="torch.Tensor.arccos"><code class="xref py py-meth docutils literal notranslate"><span class="pre">arccos()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.add.html#torch.Tensor.add" title="torch.Tensor.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.add</span></code></a></p></td>
<td><p>Add a scalar or tensor to <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.add_.html#torch.Tensor.add_" title="torch.Tensor.add_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.add_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.add.html#torch.Tensor.add" title="torch.Tensor.add"><code class="xref py py-meth docutils literal notranslate"><span class="pre">add()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.addbmm.html#torch.Tensor.addbmm" title="torch.Tensor.addbmm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addbmm</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.addbmm.html#torch.addbmm" title="torch.addbmm"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.addbmm()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.addbmm_.html#torch.Tensor.addbmm_" title="torch.Tensor.addbmm_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addbmm_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.addbmm.html#torch.Tensor.addbmm" title="torch.Tensor.addbmm"><code class="xref py py-meth docutils literal notranslate"><span class="pre">addbmm()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.addcdiv.html#torch.Tensor.addcdiv" title="torch.Tensor.addcdiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addcdiv</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.addcdiv.html#torch.addcdiv" title="torch.addcdiv"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.addcdiv()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.addcdiv_.html#torch.Tensor.addcdiv_" title="torch.Tensor.addcdiv_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addcdiv_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.addcdiv.html#torch.Tensor.addcdiv" title="torch.Tensor.addcdiv"><code class="xref py py-meth docutils literal notranslate"><span class="pre">addcdiv()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.addcmul.html#torch.Tensor.addcmul" title="torch.Tensor.addcmul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addcmul</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.addcmul.html#torch.addcmul" title="torch.addcmul"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.addcmul()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.addcmul_.html#torch.Tensor.addcmul_" title="torch.Tensor.addcmul_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addcmul_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.addcmul.html#torch.Tensor.addcmul" title="torch.Tensor.addcmul"><code class="xref py py-meth docutils literal notranslate"><span class="pre">addcmul()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.addmm.html#torch.Tensor.addmm" title="torch.Tensor.addmm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addmm</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.addmm.html#torch.addmm" title="torch.addmm"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.addmm()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.addmm_.html#torch.Tensor.addmm_" title="torch.Tensor.addmm_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addmm_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.addmm.html#torch.Tensor.addmm" title="torch.Tensor.addmm"><code class="xref py py-meth docutils literal notranslate"><span class="pre">addmm()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.sspaddmm.html#torch.Tensor.sspaddmm" title="torch.Tensor.sspaddmm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sspaddmm</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.sspaddmm.html#torch.sspaddmm" title="torch.sspaddmm"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sspaddmm()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.addmv.html#torch.Tensor.addmv" title="torch.Tensor.addmv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addmv</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.addmv.html#torch.addmv" title="torch.addmv"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.addmv()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.addmv_.html#torch.Tensor.addmv_" title="torch.Tensor.addmv_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addmv_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.addmv.html#torch.Tensor.addmv" title="torch.Tensor.addmv"><code class="xref py py-meth docutils literal notranslate"><span class="pre">addmv()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.addr.html#torch.Tensor.addr" title="torch.Tensor.addr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addr</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.addr.html#torch.addr" title="torch.addr"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.addr()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.addr_.html#torch.Tensor.addr_" title="torch.Tensor.addr_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.addr_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.addr.html#torch.Tensor.addr" title="torch.Tensor.addr"><code class="xref py py-meth docutils literal notranslate"><span class="pre">addr()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.adjoint.html#torch.Tensor.adjoint" title="torch.Tensor.adjoint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.adjoint</span></code></a></p></td>
<td><p>Alias for <a class="reference internal" href="generated/torch.adjoint.html#torch.adjoint" title="torch.adjoint"><code class="xref py py-func docutils literal notranslate"><span class="pre">adjoint()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.allclose.html#torch.Tensor.allclose" title="torch.Tensor.allclose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.allclose</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.allclose.html#torch.allclose" title="torch.allclose"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.allclose()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.amax.html#torch.Tensor.amax" title="torch.Tensor.amax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.amax</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.amax.html#torch.amax" title="torch.amax"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.amax()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.amin.html#torch.Tensor.amin" title="torch.Tensor.amin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.amin</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.amin.html#torch.amin" title="torch.amin"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.amin()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.aminmax.html#torch.Tensor.aminmax" title="torch.Tensor.aminmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.aminmax</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.aminmax.html#torch.aminmax" title="torch.aminmax"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.aminmax()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.angle.html#torch.Tensor.angle" title="torch.Tensor.angle"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.angle</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.angle.html#torch.angle" title="torch.angle"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.angle()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.apply_.html#torch.Tensor.apply_" title="torch.Tensor.apply_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.apply_</span></code></a></p></td>
<td><p>Applies the function <code class="xref py py-attr docutils literal notranslate"><span class="pre">callable</span></code> to each element in the tensor, replacing each element with the value returned by <code class="xref py py-attr docutils literal notranslate"><span class="pre">callable</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.argmax.html#torch.Tensor.argmax" title="torch.Tensor.argmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.argmax</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.argmax.html#torch.argmax" title="torch.argmax"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.argmax()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.argmin.html#torch.Tensor.argmin" title="torch.Tensor.argmin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.argmin</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.argmin.html#torch.argmin" title="torch.argmin"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.argmin()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.argsort.html#torch.Tensor.argsort" title="torch.Tensor.argsort"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.argsort</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.argsort.html#torch.argsort" title="torch.argsort"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.argsort()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.argwhere.html#torch.Tensor.argwhere" title="torch.Tensor.argwhere"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.argwhere</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.argwhere.html#torch.argwhere" title="torch.argwhere"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.argwhere()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.asin.html#torch.Tensor.asin" title="torch.Tensor.asin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.asin</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.asin.html#torch.asin" title="torch.asin"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.asin()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.asin_.html#torch.Tensor.asin_" title="torch.Tensor.asin_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.asin_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.asin.html#torch.Tensor.asin" title="torch.Tensor.asin"><code class="xref py py-meth docutils literal notranslate"><span class="pre">asin()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.arcsin.html#torch.Tensor.arcsin" title="torch.Tensor.arcsin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arcsin</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.arcsin.html#torch.arcsin" title="torch.arcsin"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.arcsin()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.arcsin_.html#torch.Tensor.arcsin_" title="torch.Tensor.arcsin_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arcsin_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.arcsin.html#torch.Tensor.arcsin" title="torch.Tensor.arcsin"><code class="xref py py-meth docutils literal notranslate"><span class="pre">arcsin()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.as_strided.html#torch.Tensor.as_strided" title="torch.Tensor.as_strided"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.as_strided</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.as_strided.html#torch.as_strided" title="torch.as_strided"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.as_strided()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.atan.html#torch.Tensor.atan" title="torch.Tensor.atan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.atan</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.atan.html#torch.atan" title="torch.atan"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.atan()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.atan_.html#torch.Tensor.atan_" title="torch.Tensor.atan_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.atan_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.atan.html#torch.Tensor.atan" title="torch.Tensor.atan"><code class="xref py py-meth docutils literal notranslate"><span class="pre">atan()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.arctan.html#torch.Tensor.arctan" title="torch.Tensor.arctan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arctan</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.arctan.html#torch.arctan" title="torch.arctan"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.arctan()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.arctan_.html#torch.Tensor.arctan_" title="torch.Tensor.arctan_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arctan_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.arctan.html#torch.Tensor.arctan" title="torch.Tensor.arctan"><code class="xref py py-meth docutils literal notranslate"><span class="pre">arctan()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.atan2.html#torch.Tensor.atan2" title="torch.Tensor.atan2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.atan2</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.atan2.html#torch.atan2" title="torch.atan2"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.atan2()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.atan2_.html#torch.Tensor.atan2_" title="torch.Tensor.atan2_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.atan2_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.atan2.html#torch.Tensor.atan2" title="torch.Tensor.atan2"><code class="xref py py-meth docutils literal notranslate"><span class="pre">atan2()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.arctan2.html#torch.Tensor.arctan2" title="torch.Tensor.arctan2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arctan2</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.arctan2.html#torch.arctan2" title="torch.arctan2"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.arctan2()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.arctan2_.html#torch.Tensor.arctan2_" title="torch.Tensor.arctan2_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arctan2_</span></code></a></p></td>
<td><p>atan2_(other) -&gt; Tensor</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.all.html#torch.Tensor.all" title="torch.Tensor.all"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.all</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.all.html#torch.all" title="torch.all"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.all()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.any.html#torch.Tensor.any" title="torch.Tensor.any"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.any</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.any.html#torch.any" title="torch.any"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.any()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.backward.html#torch.Tensor.backward" title="torch.Tensor.backward"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.backward</span></code></a></p></td>
<td><p>Computes the gradient of current tensor w.r.t.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.baddbmm.html#torch.Tensor.baddbmm" title="torch.Tensor.baddbmm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.baddbmm</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.baddbmm.html#torch.baddbmm" title="torch.baddbmm"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.baddbmm()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.baddbmm_.html#torch.Tensor.baddbmm_" title="torch.Tensor.baddbmm_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.baddbmm_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.baddbmm.html#torch.Tensor.baddbmm" title="torch.Tensor.baddbmm"><code class="xref py py-meth docutils literal notranslate"><span class="pre">baddbmm()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.bernoulli.html#torch.Tensor.bernoulli" title="torch.Tensor.bernoulli"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bernoulli</span></code></a></p></td>
<td><p>Returns a result tensor where each <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="monospace">result[i]</mtext></mrow><annotation encoding="application/x-tex">\texttt{result[i]}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord text"><span class="mord texttt">result[i]</span></span></span></span></span></span> is independently sampled from <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Bernoulli</mtext><mo stretchy="false">(</mo><mtext mathvariant="monospace">self[i]</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Bernoulli}(\texttt{self[i]})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Bernoulli</span></span><span class="mopen">(</span><span class="mord text"><span class="mord texttt">self[i]</span></span><span class="mclose">)</span></span></span></span></span>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.bernoulli_.html#torch.Tensor.bernoulli_" title="torch.Tensor.bernoulli_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bernoulli_</span></code></a></p></td>
<td><p>Fills each location of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> with an independent sample from <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Bernoulli</mtext><mo stretchy="false">(</mo><mtext mathvariant="monospace">p</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Bernoulli}(\texttt{p})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">Bernoulli</span></span><span class="mopen">(</span><span class="mord text"><span class="mord texttt">p</span></span><span class="mclose">)</span></span></span></span></span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.bfloat16.html#torch.Tensor.bfloat16" title="torch.Tensor.bfloat16"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bfloat16</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.bfloat16()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.bfloat16)</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.bincount.html#torch.Tensor.bincount" title="torch.Tensor.bincount"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bincount</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.bincount.html#torch.bincount" title="torch.bincount"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.bincount()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_not.html#torch.Tensor.bitwise_not" title="torch.Tensor.bitwise_not"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_not</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.bitwise_not.html#torch.bitwise_not" title="torch.bitwise_not"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.bitwise_not()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_not_.html#torch.Tensor.bitwise_not_" title="torch.Tensor.bitwise_not_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_not_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.bitwise_not.html#torch.Tensor.bitwise_not" title="torch.Tensor.bitwise_not"><code class="xref py py-meth docutils literal notranslate"><span class="pre">bitwise_not()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_and.html#torch.Tensor.bitwise_and" title="torch.Tensor.bitwise_and"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_and</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.bitwise_and.html#torch.bitwise_and" title="torch.bitwise_and"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.bitwise_and()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_and_.html#torch.Tensor.bitwise_and_" title="torch.Tensor.bitwise_and_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_and_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.bitwise_and.html#torch.Tensor.bitwise_and" title="torch.Tensor.bitwise_and"><code class="xref py py-meth docutils literal notranslate"><span class="pre">bitwise_and()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_or.html#torch.Tensor.bitwise_or" title="torch.Tensor.bitwise_or"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_or</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.bitwise_or.html#torch.bitwise_or" title="torch.bitwise_or"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.bitwise_or()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_or_.html#torch.Tensor.bitwise_or_" title="torch.Tensor.bitwise_or_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_or_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.bitwise_or.html#torch.Tensor.bitwise_or" title="torch.Tensor.bitwise_or"><code class="xref py py-meth docutils literal notranslate"><span class="pre">bitwise_or()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_xor.html#torch.Tensor.bitwise_xor" title="torch.Tensor.bitwise_xor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_xor</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.bitwise_xor.html#torch.bitwise_xor" title="torch.bitwise_xor"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.bitwise_xor()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_xor_.html#torch.Tensor.bitwise_xor_" title="torch.Tensor.bitwise_xor_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_xor_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.bitwise_xor.html#torch.Tensor.bitwise_xor" title="torch.Tensor.bitwise_xor"><code class="xref py py-meth docutils literal notranslate"><span class="pre">bitwise_xor()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_left_shift.html#torch.Tensor.bitwise_left_shift" title="torch.Tensor.bitwise_left_shift"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_left_shift</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.bitwise_left_shift.html#torch.bitwise_left_shift" title="torch.bitwise_left_shift"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.bitwise_left_shift()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_left_shift_.html#torch.Tensor.bitwise_left_shift_" title="torch.Tensor.bitwise_left_shift_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_left_shift_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.bitwise_left_shift.html#torch.Tensor.bitwise_left_shift" title="torch.Tensor.bitwise_left_shift"><code class="xref py py-meth docutils literal notranslate"><span class="pre">bitwise_left_shift()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_right_shift.html#torch.Tensor.bitwise_right_shift" title="torch.Tensor.bitwise_right_shift"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_right_shift</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.bitwise_right_shift.html#torch.bitwise_right_shift" title="torch.bitwise_right_shift"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.bitwise_right_shift()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.bitwise_right_shift_.html#torch.Tensor.bitwise_right_shift_" title="torch.Tensor.bitwise_right_shift_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bitwise_right_shift_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.bitwise_right_shift.html#torch.Tensor.bitwise_right_shift" title="torch.Tensor.bitwise_right_shift"><code class="xref py py-meth docutils literal notranslate"><span class="pre">bitwise_right_shift()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.bmm.html#torch.Tensor.bmm" title="torch.Tensor.bmm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bmm</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.bmm.html#torch.bmm" title="torch.bmm"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.bmm()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.bool.html#torch.Tensor.bool" title="torch.Tensor.bool"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.bool</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.bool()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.bool)</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.byte.html#torch.Tensor.byte" title="torch.Tensor.byte"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.byte</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.byte()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.uint8)</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.broadcast_to.html#torch.Tensor.broadcast_to" title="torch.Tensor.broadcast_to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.broadcast_to</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.broadcast_to.html#torch.broadcast_to" title="torch.broadcast_to"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.broadcast_to()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.cauchy_.html#torch.Tensor.cauchy_" title="torch.Tensor.cauchy_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cauchy_</span></code></a></p></td>
<td><p>Fills the tensor with numbers drawn from the Cauchy distribution:</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.ceil.html#torch.Tensor.ceil" title="torch.Tensor.ceil"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ceil</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.ceil.html#torch.ceil" title="torch.ceil"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.ceil()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.ceil_.html#torch.Tensor.ceil_" title="torch.Tensor.ceil_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ceil_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.ceil.html#torch.Tensor.ceil" title="torch.Tensor.ceil"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ceil()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.char.html#torch.Tensor.char" title="torch.Tensor.char"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.char</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.char()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.int8)</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.cholesky.html#torch.Tensor.cholesky" title="torch.Tensor.cholesky"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cholesky</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.cholesky.html#torch.cholesky" title="torch.cholesky"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cholesky()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.cholesky_inverse.html#torch.Tensor.cholesky_inverse" title="torch.Tensor.cholesky_inverse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cholesky_inverse</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.cholesky_inverse.html#torch.cholesky_inverse" title="torch.cholesky_inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cholesky_inverse()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.cholesky_solve.html#torch.Tensor.cholesky_solve" title="torch.Tensor.cholesky_solve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cholesky_solve</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.cholesky_solve.html#torch.cholesky_solve" title="torch.cholesky_solve"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cholesky_solve()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.chunk.html#torch.Tensor.chunk" title="torch.Tensor.chunk"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.chunk</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.chunk.html#torch.chunk" title="torch.chunk"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.chunk()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.clamp.html#torch.Tensor.clamp" title="torch.Tensor.clamp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.clamp</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.clamp.html#torch.clamp" title="torch.clamp"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.clamp()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.clamp_.html#torch.Tensor.clamp_" title="torch.Tensor.clamp_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.clamp_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.clamp.html#torch.Tensor.clamp" title="torch.Tensor.clamp"><code class="xref py py-meth docutils literal notranslate"><span class="pre">clamp()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.clip.html#torch.Tensor.clip" title="torch.Tensor.clip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.clip</span></code></a></p></td>
<td><p>Alias for <a class="reference internal" href="generated/torch.Tensor.clamp.html#torch.Tensor.clamp" title="torch.Tensor.clamp"><code class="xref py py-meth docutils literal notranslate"><span class="pre">clamp()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.clip_.html#torch.Tensor.clip_" title="torch.Tensor.clip_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.clip_</span></code></a></p></td>
<td><p>Alias for <a class="reference internal" href="generated/torch.Tensor.clamp_.html#torch.Tensor.clamp_" title="torch.Tensor.clamp_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">clamp_()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.clone.html#torch.Tensor.clone" title="torch.Tensor.clone"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.clone</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.clone.html#torch.clone" title="torch.clone"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.clone()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.contiguous.html#torch.Tensor.contiguous" title="torch.Tensor.contiguous"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.contiguous</span></code></a></p></td>
<td><p>Returns a contiguous in memory tensor containing the same data as <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.copy_.html#torch.Tensor.copy_" title="torch.Tensor.copy_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.copy_</span></code></a></p></td>
<td><p>Copies the elements from <code class="xref py py-attr docutils literal notranslate"><span class="pre">src</span></code> into <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor and returns <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.conj.html#torch.Tensor.conj" title="torch.Tensor.conj"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.conj</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.conj.html#torch.conj" title="torch.conj"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.conj()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.conj_physical.html#torch.Tensor.conj_physical" title="torch.Tensor.conj_physical"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.conj_physical</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.conj_physical.html#torch.conj_physical" title="torch.conj_physical"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.conj_physical()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.conj_physical_.html#torch.Tensor.conj_physical_" title="torch.Tensor.conj_physical_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.conj_physical_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.conj_physical.html#torch.Tensor.conj_physical" title="torch.Tensor.conj_physical"><code class="xref py py-meth docutils literal notranslate"><span class="pre">conj_physical()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.resolve_conj.html#torch.Tensor.resolve_conj" title="torch.Tensor.resolve_conj"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.resolve_conj</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.resolve_conj.html#torch.resolve_conj" title="torch.resolve_conj"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.resolve_conj()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.resolve_neg.html#torch.Tensor.resolve_neg" title="torch.Tensor.resolve_neg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.resolve_neg</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.resolve_neg.html#torch.resolve_neg" title="torch.resolve_neg"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.resolve_neg()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.copysign.html#torch.Tensor.copysign" title="torch.Tensor.copysign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.copysign</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.copysign.html#torch.copysign" title="torch.copysign"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.copysign()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.copysign_.html#torch.Tensor.copysign_" title="torch.Tensor.copysign_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.copysign_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.copysign.html#torch.Tensor.copysign" title="torch.Tensor.copysign"><code class="xref py py-meth docutils literal notranslate"><span class="pre">copysign()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.cos.html#torch.Tensor.cos" title="torch.Tensor.cos"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cos</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.cos.html#torch.cos" title="torch.cos"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cos()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.cos_.html#torch.Tensor.cos_" title="torch.Tensor.cos_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cos_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.cos.html#torch.Tensor.cos" title="torch.Tensor.cos"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cos()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.cosh.html#torch.Tensor.cosh" title="torch.Tensor.cosh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cosh</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.cosh.html#torch.cosh" title="torch.cosh"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cosh()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.cosh_.html#torch.Tensor.cosh_" title="torch.Tensor.cosh_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cosh_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.cosh.html#torch.Tensor.cosh" title="torch.Tensor.cosh"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cosh()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.corrcoef.html#torch.Tensor.corrcoef" title="torch.Tensor.corrcoef"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.corrcoef</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.corrcoef.html#torch.corrcoef" title="torch.corrcoef"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.corrcoef()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.count_nonzero.html#torch.Tensor.count_nonzero" title="torch.Tensor.count_nonzero"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.count_nonzero</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.count_nonzero.html#torch.count_nonzero" title="torch.count_nonzero"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.count_nonzero()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.cov.html#torch.Tensor.cov" title="torch.Tensor.cov"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cov</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.cov.html#torch.cov" title="torch.cov"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cov()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.acosh.html#torch.Tensor.acosh" title="torch.Tensor.acosh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.acosh</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.acosh.html#torch.acosh" title="torch.acosh"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.acosh()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.acosh_.html#torch.Tensor.acosh_" title="torch.Tensor.acosh_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.acosh_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.acosh.html#torch.Tensor.acosh" title="torch.Tensor.acosh"><code class="xref py py-meth docutils literal notranslate"><span class="pre">acosh()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.arccosh.html#torch.Tensor.arccosh" title="torch.Tensor.arccosh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arccosh</span></code></a></p></td>
<td><p>acosh() -&gt; Tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.arccosh_.html#torch.Tensor.arccosh_" title="torch.Tensor.arccosh_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arccosh_</span></code></a></p></td>
<td><p>acosh_() -&gt; Tensor</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.cpu.html#torch.Tensor.cpu" title="torch.Tensor.cpu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cpu</span></code></a></p></td>
<td><p>Returns a copy of this object in CPU memory.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.cross.html#torch.Tensor.cross" title="torch.Tensor.cross"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cross</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.cross.html#torch.cross" title="torch.cross"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cross()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.cuda.html#torch.Tensor.cuda" title="torch.Tensor.cuda"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cuda</span></code></a></p></td>
<td><p>Returns a copy of this object in CUDA memory.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.logcumsumexp.html#torch.Tensor.logcumsumexp" title="torch.Tensor.logcumsumexp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logcumsumexp</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.logcumsumexp.html#torch.logcumsumexp" title="torch.logcumsumexp"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.logcumsumexp()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.cummax.html#torch.Tensor.cummax" title="torch.Tensor.cummax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cummax</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.cummax.html#torch.cummax" title="torch.cummax"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cummax()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.cummin.html#torch.Tensor.cummin" title="torch.Tensor.cummin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cummin</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.cummin.html#torch.cummin" title="torch.cummin"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cummin()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.cumprod.html#torch.Tensor.cumprod" title="torch.Tensor.cumprod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cumprod</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.cumprod.html#torch.cumprod" title="torch.cumprod"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cumprod()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.cumprod_.html#torch.Tensor.cumprod_" title="torch.Tensor.cumprod_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cumprod_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.cumprod.html#torch.Tensor.cumprod" title="torch.Tensor.cumprod"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cumprod()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.cumsum.html#torch.Tensor.cumsum" title="torch.Tensor.cumsum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cumsum</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.cumsum.html#torch.cumsum" title="torch.cumsum"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.cumsum()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.cumsum_.html#torch.Tensor.cumsum_" title="torch.Tensor.cumsum_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cumsum_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.cumsum.html#torch.Tensor.cumsum" title="torch.Tensor.cumsum"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cumsum()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.chalf.html#torch.Tensor.chalf" title="torch.Tensor.chalf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.chalf</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.chalf()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.complex32)</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.cfloat.html#torch.Tensor.cfloat" title="torch.Tensor.cfloat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cfloat</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.cfloat()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.complex64)</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.cdouble.html#torch.Tensor.cdouble" title="torch.Tensor.cdouble"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.cdouble</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.cdouble()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.complex128)</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.data_ptr.html#torch.Tensor.data_ptr" title="torch.Tensor.data_ptr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.data_ptr</span></code></a></p></td>
<td><p>Returns the address of the first element of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.deg2rad.html#torch.Tensor.deg2rad" title="torch.Tensor.deg2rad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.deg2rad</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.deg2rad.html#torch.deg2rad" title="torch.deg2rad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.deg2rad()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.dequantize.html#torch.Tensor.dequantize" title="torch.Tensor.dequantize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.dequantize</span></code></a></p></td>
<td><p>Given a quantized Tensor, dequantize it and return the dequantized float Tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.det.html#torch.Tensor.det" title="torch.Tensor.det"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.det</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.det.html#torch.det" title="torch.det"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.det()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.dense_dim.html#torch.Tensor.dense_dim" title="torch.Tensor.dense_dim"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.dense_dim</span></code></a></p></td>
<td><p>Return the number of dense dimensions in a <a class="reference internal" href="sparse.html#sparse-docs"><span class="std std-ref">sparse tensor</span></a> <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.detach.html#torch.Tensor.detach" title="torch.Tensor.detach"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.detach</span></code></a></p></td>
<td><p>Returns a new Tensor, detached from the current graph.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.detach_.html#torch.Tensor.detach_" title="torch.Tensor.detach_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.detach_</span></code></a></p></td>
<td><p>Detaches the Tensor from the graph that created it, making it a leaf.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.diag.html#torch.Tensor.diag" title="torch.Tensor.diag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.diag</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.diag.html#torch.diag" title="torch.diag"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.diag()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.diag_embed.html#torch.Tensor.diag_embed" title="torch.Tensor.diag_embed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.diag_embed</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.diag_embed.html#torch.diag_embed" title="torch.diag_embed"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.diag_embed()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.diagflat.html#torch.Tensor.diagflat" title="torch.Tensor.diagflat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.diagflat</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.diagflat.html#torch.diagflat" title="torch.diagflat"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.diagflat()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.diagonal.html#torch.Tensor.diagonal" title="torch.Tensor.diagonal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.diagonal</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.diagonal.html#torch.diagonal" title="torch.diagonal"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.diagonal()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.diagonal_scatter.html#torch.Tensor.diagonal_scatter" title="torch.Tensor.diagonal_scatter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.diagonal_scatter</span></code></a></p></td>
<td><p>diagonal(src, offset=0, dim1=0, dim2=1) -&gt; Tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.fill_diagonal_.html#torch.Tensor.fill_diagonal_" title="torch.Tensor.fill_diagonal_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.fill_diagonal_</span></code></a></p></td>
<td><p>Fill the main diagonal of a tensor that has at least 2-dimensions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.fmax.html#torch.Tensor.fmax" title="torch.Tensor.fmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.fmax</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.fmax.html#torch.fmax" title="torch.fmax"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.fmax()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.fmin.html#torch.Tensor.fmin" title="torch.Tensor.fmin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.fmin</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.fmin.html#torch.fmin" title="torch.fmin"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.fmin()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.diff.html#torch.Tensor.diff" title="torch.Tensor.diff"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.diff</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.diff.html#torch.diff" title="torch.diff"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.diff()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.digamma.html#torch.Tensor.digamma" title="torch.Tensor.digamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.digamma</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.digamma.html#torch.digamma" title="torch.digamma"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.digamma()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.digamma_.html#torch.Tensor.digamma_" title="torch.Tensor.digamma_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.digamma_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.digamma.html#torch.Tensor.digamma" title="torch.Tensor.digamma"><code class="xref py py-meth docutils literal notranslate"><span class="pre">digamma()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.dim.html#torch.Tensor.dim" title="torch.Tensor.dim"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.dim</span></code></a></p></td>
<td><p>Returns the number of dimensions of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.dist.html#torch.Tensor.dist" title="torch.Tensor.dist"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.dist</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.dist.html#torch.dist" title="torch.dist"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.dist()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.div.html#torch.Tensor.div" title="torch.Tensor.div"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.div</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.div.html#torch.div" title="torch.div"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.div()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.div_.html#torch.Tensor.div_" title="torch.Tensor.div_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.div_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.div.html#torch.Tensor.div" title="torch.Tensor.div"><code class="xref py py-meth docutils literal notranslate"><span class="pre">div()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.divide.html#torch.Tensor.divide" title="torch.Tensor.divide"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.divide</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.divide.html#torch.divide" title="torch.divide"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.divide()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.divide_.html#torch.Tensor.divide_" title="torch.Tensor.divide_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.divide_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.divide.html#torch.Tensor.divide" title="torch.Tensor.divide"><code class="xref py py-meth docutils literal notranslate"><span class="pre">divide()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.dot.html#torch.Tensor.dot" title="torch.Tensor.dot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.dot</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.dot.html#torch.dot" title="torch.dot"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.dot()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.double.html#torch.Tensor.double" title="torch.Tensor.double"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.double</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.double()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.float64)</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.dsplit.html#torch.Tensor.dsplit" title="torch.Tensor.dsplit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.dsplit</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.dsplit.html#torch.dsplit" title="torch.dsplit"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.dsplit()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.eig.html#torch.Tensor.eig" title="torch.Tensor.eig"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.eig</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.eig.html#torch.eig" title="torch.eig"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.eig()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.element_size.html#torch.Tensor.element_size" title="torch.Tensor.element_size"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.element_size</span></code></a></p></td>
<td><p>Returns the size in bytes of an individual element.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.eq.html#torch.Tensor.eq" title="torch.Tensor.eq"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.eq</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.eq.html#torch.eq" title="torch.eq"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.eq()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.eq_.html#torch.Tensor.eq_" title="torch.Tensor.eq_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.eq_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.eq.html#torch.Tensor.eq" title="torch.Tensor.eq"><code class="xref py py-meth docutils literal notranslate"><span class="pre">eq()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.equal.html#torch.Tensor.equal" title="torch.Tensor.equal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.equal</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.equal.html#torch.equal" title="torch.equal"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.equal()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.erf.html#torch.Tensor.erf" title="torch.Tensor.erf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.erf</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.erf.html#torch.erf" title="torch.erf"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.erf()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.erf_.html#torch.Tensor.erf_" title="torch.Tensor.erf_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.erf_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.erf.html#torch.Tensor.erf" title="torch.Tensor.erf"><code class="xref py py-meth docutils literal notranslate"><span class="pre">erf()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.erfc.html#torch.Tensor.erfc" title="torch.Tensor.erfc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.erfc</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.erfc.html#torch.erfc" title="torch.erfc"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.erfc()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.erfc_.html#torch.Tensor.erfc_" title="torch.Tensor.erfc_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.erfc_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.erfc.html#torch.Tensor.erfc" title="torch.Tensor.erfc"><code class="xref py py-meth docutils literal notranslate"><span class="pre">erfc()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.erfinv.html#torch.Tensor.erfinv" title="torch.Tensor.erfinv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.erfinv</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.erfinv.html#torch.erfinv" title="torch.erfinv"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.erfinv()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.erfinv_.html#torch.Tensor.erfinv_" title="torch.Tensor.erfinv_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.erfinv_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.erfinv.html#torch.Tensor.erfinv" title="torch.Tensor.erfinv"><code class="xref py py-meth docutils literal notranslate"><span class="pre">erfinv()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.exp.html#torch.Tensor.exp" title="torch.Tensor.exp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.exp</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.exp.html#torch.exp" title="torch.exp"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.exp()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.exp_.html#torch.Tensor.exp_" title="torch.Tensor.exp_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.exp_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.exp.html#torch.Tensor.exp" title="torch.Tensor.exp"><code class="xref py py-meth docutils literal notranslate"><span class="pre">exp()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.expm1.html#torch.Tensor.expm1" title="torch.Tensor.expm1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.expm1</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.expm1.html#torch.expm1" title="torch.expm1"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.expm1()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.expm1_.html#torch.Tensor.expm1_" title="torch.Tensor.expm1_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.expm1_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.expm1.html#torch.Tensor.expm1" title="torch.Tensor.expm1"><code class="xref py py-meth docutils literal notranslate"><span class="pre">expm1()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.expand.html#torch.Tensor.expand" title="torch.Tensor.expand"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.expand</span></code></a></p></td>
<td><p>Returns a new view of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor with singleton dimensions expanded to a larger size.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.expand_as.html#torch.Tensor.expand_as" title="torch.Tensor.expand_as"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.expand_as</span></code></a></p></td>
<td><p>Expand this tensor to the same size as <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.exponential_.html#torch.Tensor.exponential_" title="torch.Tensor.exponential_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.exponential_</span></code></a></p></td>
<td><p>Fills <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor with elements drawn from the exponential distribution:</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.fix.html#torch.Tensor.fix" title="torch.Tensor.fix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.fix</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.fix.html#torch.fix" title="torch.fix"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.fix()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.fix_.html#torch.Tensor.fix_" title="torch.Tensor.fix_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.fix_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.fix.html#torch.Tensor.fix" title="torch.Tensor.fix"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fix()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.fill_.html#torch.Tensor.fill_" title="torch.Tensor.fill_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.fill_</span></code></a></p></td>
<td><p>Fills <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor with the specified value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.flatten.html#torch.Tensor.flatten" title="torch.Tensor.flatten"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.flatten</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.flatten.html#torch.flatten" title="torch.flatten"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.flatten()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.flip.html#torch.Tensor.flip" title="torch.Tensor.flip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.flip</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.flip.html#torch.flip" title="torch.flip"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.flip()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.fliplr.html#torch.Tensor.fliplr" title="torch.Tensor.fliplr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.fliplr</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.fliplr.html#torch.fliplr" title="torch.fliplr"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.fliplr()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.flipud.html#torch.Tensor.flipud" title="torch.Tensor.flipud"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.flipud</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.flipud.html#torch.flipud" title="torch.flipud"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.flipud()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.float.html#torch.Tensor.float" title="torch.Tensor.float"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.float</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.float()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.float32)</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.float_power.html#torch.Tensor.float_power" title="torch.Tensor.float_power"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.float_power</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.float_power.html#torch.float_power" title="torch.float_power"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.float_power()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.float_power_.html#torch.Tensor.float_power_" title="torch.Tensor.float_power_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.float_power_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.float_power.html#torch.Tensor.float_power" title="torch.Tensor.float_power"><code class="xref py py-meth docutils literal notranslate"><span class="pre">float_power()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.floor.html#torch.Tensor.floor" title="torch.Tensor.floor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.floor</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.floor.html#torch.floor" title="torch.floor"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.floor()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.floor_.html#torch.Tensor.floor_" title="torch.Tensor.floor_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.floor_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.floor.html#torch.Tensor.floor" title="torch.Tensor.floor"><code class="xref py py-meth docutils literal notranslate"><span class="pre">floor()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.floor_divide.html#torch.Tensor.floor_divide" title="torch.Tensor.floor_divide"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.floor_divide</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.floor_divide.html#torch.floor_divide" title="torch.floor_divide"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.floor_divide()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.floor_divide_.html#torch.Tensor.floor_divide_" title="torch.Tensor.floor_divide_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.floor_divide_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.floor_divide.html#torch.Tensor.floor_divide" title="torch.Tensor.floor_divide"><code class="xref py py-meth docutils literal notranslate"><span class="pre">floor_divide()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.fmod.html#torch.Tensor.fmod" title="torch.Tensor.fmod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.fmod</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.fmod.html#torch.fmod" title="torch.fmod"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.fmod()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.fmod_.html#torch.Tensor.fmod_" title="torch.Tensor.fmod_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.fmod_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.fmod.html#torch.Tensor.fmod" title="torch.Tensor.fmod"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fmod()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.frac.html#torch.Tensor.frac" title="torch.Tensor.frac"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.frac</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.frac.html#torch.frac" title="torch.frac"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.frac()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.frac_.html#torch.Tensor.frac_" title="torch.Tensor.frac_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.frac_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.frac.html#torch.Tensor.frac" title="torch.Tensor.frac"><code class="xref py py-meth docutils literal notranslate"><span class="pre">frac()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.frexp.html#torch.Tensor.frexp" title="torch.Tensor.frexp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.frexp</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.frexp.html#torch.frexp" title="torch.frexp"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.frexp()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.gather.html#torch.Tensor.gather" title="torch.Tensor.gather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.gather</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.gather.html#torch.gather" title="torch.gather"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.gather()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.gcd.html#torch.Tensor.gcd" title="torch.Tensor.gcd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.gcd</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.gcd.html#torch.gcd" title="torch.gcd"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.gcd()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.gcd_.html#torch.Tensor.gcd_" title="torch.Tensor.gcd_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.gcd_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.gcd.html#torch.Tensor.gcd" title="torch.Tensor.gcd"><code class="xref py py-meth docutils literal notranslate"><span class="pre">gcd()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.ge.html#torch.Tensor.ge" title="torch.Tensor.ge"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ge</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.ge.html#torch.ge" title="torch.ge"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.ge()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.ge_.html#torch.Tensor.ge_" title="torch.Tensor.ge_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ge_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.ge.html#torch.Tensor.ge" title="torch.Tensor.ge"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ge()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.greater_equal.html#torch.Tensor.greater_equal" title="torch.Tensor.greater_equal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.greater_equal</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.greater_equal.html#torch.greater_equal" title="torch.greater_equal"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.greater_equal()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.greater_equal_.html#torch.Tensor.greater_equal_" title="torch.Tensor.greater_equal_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.greater_equal_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.greater_equal.html#torch.Tensor.greater_equal" title="torch.Tensor.greater_equal"><code class="xref py py-meth docutils literal notranslate"><span class="pre">greater_equal()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.geometric_.html#torch.Tensor.geometric_" title="torch.Tensor.geometric_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.geometric_</span></code></a></p></td>
<td><p>Fills <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor with elements drawn from the geometric distribution:</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.geqrf.html#torch.Tensor.geqrf" title="torch.Tensor.geqrf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.geqrf</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.geqrf.html#torch.geqrf" title="torch.geqrf"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.geqrf()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.ger.html#torch.Tensor.ger" title="torch.Tensor.ger"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ger</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.ger.html#torch.ger" title="torch.ger"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.ger()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.get_device.html#torch.Tensor.get_device" title="torch.Tensor.get_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.get_device</span></code></a></p></td>
<td><p>For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.gt.html#torch.Tensor.gt" title="torch.Tensor.gt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.gt</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.gt.html#torch.gt" title="torch.gt"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.gt()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.gt_.html#torch.Tensor.gt_" title="torch.Tensor.gt_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.gt_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.gt.html#torch.Tensor.gt" title="torch.Tensor.gt"><code class="xref py py-meth docutils literal notranslate"><span class="pre">gt()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.greater.html#torch.Tensor.greater" title="torch.Tensor.greater"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.greater</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.greater.html#torch.greater" title="torch.greater"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.greater()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.greater_.html#torch.Tensor.greater_" title="torch.Tensor.greater_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.greater_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.greater.html#torch.Tensor.greater" title="torch.Tensor.greater"><code class="xref py py-meth docutils literal notranslate"><span class="pre">greater()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.half.html#torch.Tensor.half" title="torch.Tensor.half"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.half</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.half()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.float16)</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.hardshrink.html#torch.Tensor.hardshrink" title="torch.Tensor.hardshrink"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.hardshrink</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.nn.functional.hardshrink.html#torch.nn.functional.hardshrink" title="torch.nn.functional.hardshrink"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.hardshrink()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.heaviside.html#torch.Tensor.heaviside" title="torch.Tensor.heaviside"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.heaviside</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.heaviside.html#torch.heaviside" title="torch.heaviside"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.heaviside()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.histc.html#torch.Tensor.histc" title="torch.Tensor.histc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.histc</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.histc.html#torch.histc" title="torch.histc"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.histc()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.histogram.html#torch.Tensor.histogram" title="torch.Tensor.histogram"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.histogram</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.histogram.html#torch.histogram" title="torch.histogram"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.histogram()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.hsplit.html#torch.Tensor.hsplit" title="torch.Tensor.hsplit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.hsplit</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.hsplit.html#torch.hsplit" title="torch.hsplit"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.hsplit()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.hypot.html#torch.Tensor.hypot" title="torch.Tensor.hypot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.hypot</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.hypot.html#torch.hypot" title="torch.hypot"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.hypot()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.hypot_.html#torch.Tensor.hypot_" title="torch.Tensor.hypot_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.hypot_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.hypot.html#torch.Tensor.hypot" title="torch.Tensor.hypot"><code class="xref py py-meth docutils literal notranslate"><span class="pre">hypot()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.i0.html#torch.Tensor.i0" title="torch.Tensor.i0"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.i0</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.i0.html#torch.i0" title="torch.i0"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.i0()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.i0_.html#torch.Tensor.i0_" title="torch.Tensor.i0_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.i0_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.i0.html#torch.Tensor.i0" title="torch.Tensor.i0"><code class="xref py py-meth docutils literal notranslate"><span class="pre">i0()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.igamma.html#torch.Tensor.igamma" title="torch.Tensor.igamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.igamma</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.igamma.html#torch.igamma" title="torch.igamma"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.igamma()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.igamma_.html#torch.Tensor.igamma_" title="torch.Tensor.igamma_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.igamma_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.igamma.html#torch.Tensor.igamma" title="torch.Tensor.igamma"><code class="xref py py-meth docutils literal notranslate"><span class="pre">igamma()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.igammac.html#torch.Tensor.igammac" title="torch.Tensor.igammac"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.igammac</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.igammac.html#torch.igammac" title="torch.igammac"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.igammac()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.igammac_.html#torch.Tensor.igammac_" title="torch.Tensor.igammac_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.igammac_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.igammac.html#torch.Tensor.igammac" title="torch.Tensor.igammac"><code class="xref py py-meth docutils literal notranslate"><span class="pre">igammac()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.index_add_.html#torch.Tensor.index_add_" title="torch.Tensor.index_add_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.index_add_</span></code></a></p></td>
<td><p>Accumulate the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">alpha</span></code> times <code class="docutils literal notranslate"><span class="pre">source</span></code> into the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor by adding to the indices in the order given in <code class="xref py py-attr docutils literal notranslate"><span class="pre">index</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.index_add.html#torch.Tensor.index_add" title="torch.Tensor.index_add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.index_add</span></code></a></p></td>
<td><p>Out-of-place version of <a class="reference internal" href="generated/torch.Tensor.index_add_.html#torch.Tensor.index_add_" title="torch.Tensor.index_add_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.index_add_()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.index_copy_.html#torch.Tensor.index_copy_" title="torch.Tensor.index_copy_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.index_copy_</span></code></a></p></td>
<td><p>Copies the elements of <a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">tensor</span></code></a> into the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor by selecting the indices in the order given in <code class="xref py py-attr docutils literal notranslate"><span class="pre">index</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.index_copy.html#torch.Tensor.index_copy" title="torch.Tensor.index_copy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.index_copy</span></code></a></p></td>
<td><p>Out-of-place version of <a class="reference internal" href="generated/torch.Tensor.index_copy_.html#torch.Tensor.index_copy_" title="torch.Tensor.index_copy_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.index_copy_()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.index_fill_.html#torch.Tensor.index_fill_" title="torch.Tensor.index_fill_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.index_fill_</span></code></a></p></td>
<td><p>Fills the elements of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor with value <code class="xref py py-attr docutils literal notranslate"><span class="pre">value</span></code> by selecting the indices in the order given in <code class="xref py py-attr docutils literal notranslate"><span class="pre">index</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.index_fill.html#torch.Tensor.index_fill" title="torch.Tensor.index_fill"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.index_fill</span></code></a></p></td>
<td><p>Out-of-place version of <a class="reference internal" href="generated/torch.Tensor.index_fill_.html#torch.Tensor.index_fill_" title="torch.Tensor.index_fill_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.index_fill_()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.index_put_.html#torch.Tensor.index_put_" title="torch.Tensor.index_put_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.index_put_</span></code></a></p></td>
<td><p>Puts values from the tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">values</span></code> into the tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> using the indices specified in <code class="xref py py-attr docutils literal notranslate"><span class="pre">indices</span></code> (which is a tuple of Tensors).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.index_put.html#torch.Tensor.index_put" title="torch.Tensor.index_put"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.index_put</span></code></a></p></td>
<td><p>Out-place version of <a class="reference internal" href="generated/torch.Tensor.index_put_.html#torch.Tensor.index_put_" title="torch.Tensor.index_put_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">index_put_()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.index_reduce_.html#torch.Tensor.index_reduce_" title="torch.Tensor.index_reduce_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.index_reduce_</span></code></a></p></td>
<td><p>Accumulate the elements of <code class="docutils literal notranslate"><span class="pre">source</span></code> into the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor by accumulating to the indices in the order given in <code class="xref py py-attr docutils literal notranslate"><span class="pre">index</span></code> using the reduction given by the <code class="docutils literal notranslate"><span class="pre">reduce</span></code> argument.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.index_reduce.html#torch.Tensor.index_reduce" title="torch.Tensor.index_reduce"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.index_reduce</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.index_select.html#torch.Tensor.index_select" title="torch.Tensor.index_select"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.index_select</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.index_select.html#torch.index_select" title="torch.index_select"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.index_select()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.indices.html#torch.Tensor.indices" title="torch.Tensor.indices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.indices</span></code></a></p></td>
<td><p>Return the indices tensor of a <a class="reference internal" href="sparse.html#sparse-coo-docs"><span class="std std-ref">sparse COO tensor</span></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.inner.html#torch.Tensor.inner" title="torch.Tensor.inner"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.inner</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.inner.html#torch.inner" title="torch.inner"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.inner()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.int.html#torch.Tensor.int" title="torch.Tensor.int"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.int</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.int()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.int32)</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.int_repr.html#torch.Tensor.int_repr" title="torch.Tensor.int_repr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.int_repr</span></code></a></p></td>
<td><p>Given a quantized Tensor, <code class="docutils literal notranslate"><span class="pre">self.int_repr()</span></code> returns a CPU Tensor with uint8_t as data type that stores the underlying uint8_t values of the given Tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.inverse.html#torch.Tensor.inverse" title="torch.Tensor.inverse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.inverse</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.inverse.html#torch.inverse" title="torch.inverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.inverse()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.isclose.html#torch.Tensor.isclose" title="torch.Tensor.isclose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.isclose</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.isclose.html#torch.isclose" title="torch.isclose"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.isclose()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.isfinite.html#torch.Tensor.isfinite" title="torch.Tensor.isfinite"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.isfinite</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.isfinite.html#torch.isfinite" title="torch.isfinite"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.isfinite()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.isinf.html#torch.Tensor.isinf" title="torch.Tensor.isinf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.isinf</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.isinf.html#torch.isinf" title="torch.isinf"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.isinf()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.isposinf.html#torch.Tensor.isposinf" title="torch.Tensor.isposinf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.isposinf</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.isposinf.html#torch.isposinf" title="torch.isposinf"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.isposinf()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.isneginf.html#torch.Tensor.isneginf" title="torch.Tensor.isneginf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.isneginf</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.isneginf.html#torch.isneginf" title="torch.isneginf"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.isneginf()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.isnan.html#torch.Tensor.isnan" title="torch.Tensor.isnan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.isnan</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.isnan.html#torch.isnan" title="torch.isnan"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.isnan()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.is_contiguous.html#torch.Tensor.is_contiguous" title="torch.Tensor.is_contiguous"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_contiguous</span></code></a></p></td>
<td><p>Returns True if <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor is contiguous in memory in the order specified by memory format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.is_complex.html#torch.Tensor.is_complex" title="torch.Tensor.is_complex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_complex</span></code></a></p></td>
<td><p>Returns True if the data type of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> is a complex data type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.is_conj.html#torch.Tensor.is_conj" title="torch.Tensor.is_conj"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_conj</span></code></a></p></td>
<td><p>Returns True if the conjugate bit of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> is set to true.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.is_floating_point.html#torch.Tensor.is_floating_point" title="torch.Tensor.is_floating_point"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_floating_point</span></code></a></p></td>
<td><p>Returns True if the data type of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> is a floating point data type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.is_inference.html#torch.Tensor.is_inference" title="torch.Tensor.is_inference"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_inference</span></code></a></p></td>
<td><p>See <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.is_inference()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf" title="torch.Tensor.is_leaf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_leaf</span></code></a></p></td>
<td><p>All Tensors that have <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> which is <code class="docutils literal notranslate"><span class="pre">False</span></code> will be leaf Tensors by convention.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.is_pinned.html#torch.Tensor.is_pinned" title="torch.Tensor.is_pinned"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_pinned</span></code></a></p></td>
<td><p>Returns true if this tensor resides in pinned memory.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.is_set_to.html#torch.Tensor.is_set_to" title="torch.Tensor.is_set_to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_set_to</span></code></a></p></td>
<td><p>Returns True if both tensors are pointing to the exact same memory (same storage, offset, size and stride).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.is_shared.html#torch.Tensor.is_shared" title="torch.Tensor.is_shared"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_shared</span></code></a></p></td>
<td><p>Checks if tensor is in shared memory.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.is_signed.html#torch.Tensor.is_signed" title="torch.Tensor.is_signed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_signed</span></code></a></p></td>
<td><p>Returns True if the data type of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> is a signed data type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.is_sparse.html#torch.Tensor.is_sparse" title="torch.Tensor.is_sparse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.is_sparse</span></code></a></p></td>
<td><p>Is <code class="docutils literal notranslate"><span class="pre">True</span></code> if the Tensor uses sparse storage layout, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.istft.html#torch.Tensor.istft" title="torch.Tensor.istft"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.istft</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.istft.html#torch.istft" title="torch.istft"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.istft()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.isreal.html#torch.Tensor.isreal" title="torch.Tensor.isreal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.isreal</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.isreal.html#torch.isreal" title="torch.isreal"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.isreal()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.item.html#torch.Tensor.item" title="torch.Tensor.item"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.item</span></code></a></p></td>
<td><p>Returns the value of this tensor as a standard Python number.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.kthvalue.html#torch.Tensor.kthvalue" title="torch.Tensor.kthvalue"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.kthvalue</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.kthvalue.html#torch.kthvalue" title="torch.kthvalue"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.kthvalue()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.lcm.html#torch.Tensor.lcm" title="torch.Tensor.lcm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.lcm</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.lcm.html#torch.lcm" title="torch.lcm"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.lcm()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.lcm_.html#torch.Tensor.lcm_" title="torch.Tensor.lcm_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.lcm_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.lcm.html#torch.Tensor.lcm" title="torch.Tensor.lcm"><code class="xref py py-meth docutils literal notranslate"><span class="pre">lcm()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.ldexp.html#torch.Tensor.ldexp" title="torch.Tensor.ldexp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ldexp</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.ldexp.html#torch.ldexp" title="torch.ldexp"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.ldexp()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.ldexp_.html#torch.Tensor.ldexp_" title="torch.Tensor.ldexp_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ldexp_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.ldexp.html#torch.Tensor.ldexp" title="torch.Tensor.ldexp"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ldexp()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.le.html#torch.Tensor.le" title="torch.Tensor.le"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.le</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.le.html#torch.le" title="torch.le"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.le()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.le_.html#torch.Tensor.le_" title="torch.Tensor.le_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.le_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.le.html#torch.Tensor.le" title="torch.Tensor.le"><code class="xref py py-meth docutils literal notranslate"><span class="pre">le()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.less_equal.html#torch.Tensor.less_equal" title="torch.Tensor.less_equal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.less_equal</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.less_equal.html#torch.less_equal" title="torch.less_equal"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.less_equal()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.less_equal_.html#torch.Tensor.less_equal_" title="torch.Tensor.less_equal_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.less_equal_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.less_equal.html#torch.Tensor.less_equal" title="torch.Tensor.less_equal"><code class="xref py py-meth docutils literal notranslate"><span class="pre">less_equal()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.lerp.html#torch.Tensor.lerp" title="torch.Tensor.lerp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.lerp</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.lerp.html#torch.lerp" title="torch.lerp"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.lerp()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.lerp_.html#torch.Tensor.lerp_" title="torch.Tensor.lerp_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.lerp_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.lerp.html#torch.Tensor.lerp" title="torch.Tensor.lerp"><code class="xref py py-meth docutils literal notranslate"><span class="pre">lerp()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.lgamma.html#torch.Tensor.lgamma" title="torch.Tensor.lgamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.lgamma</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.lgamma.html#torch.lgamma" title="torch.lgamma"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.lgamma()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.lgamma_.html#torch.Tensor.lgamma_" title="torch.Tensor.lgamma_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.lgamma_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.lgamma.html#torch.Tensor.lgamma" title="torch.Tensor.lgamma"><code class="xref py py-meth docutils literal notranslate"><span class="pre">lgamma()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.log.html#torch.Tensor.log" title="torch.Tensor.log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.log</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.log.html#torch.log" title="torch.log"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.log()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.log_.html#torch.Tensor.log_" title="torch.Tensor.log_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.log_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.log.html#torch.Tensor.log" title="torch.Tensor.log"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.logdet.html#torch.Tensor.logdet" title="torch.Tensor.logdet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logdet</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.logdet.html#torch.logdet" title="torch.logdet"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.logdet()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.log10.html#torch.Tensor.log10" title="torch.Tensor.log10"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.log10</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.log10.html#torch.log10" title="torch.log10"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.log10()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.log10_.html#torch.Tensor.log10_" title="torch.Tensor.log10_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.log10_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.log10.html#torch.Tensor.log10" title="torch.Tensor.log10"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log10()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.log1p.html#torch.Tensor.log1p" title="torch.Tensor.log1p"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.log1p</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.log1p.html#torch.log1p" title="torch.log1p"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.log1p()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.log1p_.html#torch.Tensor.log1p_" title="torch.Tensor.log1p_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.log1p_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.log1p.html#torch.Tensor.log1p" title="torch.Tensor.log1p"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log1p()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.log2.html#torch.Tensor.log2" title="torch.Tensor.log2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.log2</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.log2.html#torch.log2" title="torch.log2"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.log2()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.log2_.html#torch.Tensor.log2_" title="torch.Tensor.log2_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.log2_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.log2.html#torch.Tensor.log2" title="torch.Tensor.log2"><code class="xref py py-meth docutils literal notranslate"><span class="pre">log2()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.log_normal_.html#torch.Tensor.log_normal_" title="torch.Tensor.log_normal_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.log_normal_</span></code></a></p></td>
<td><p>Fills <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor with numbers samples from the log-normal distribution parameterized by the given mean <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Î¼</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Î¼</span></span></span></span></span> and standard deviation <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Ïƒ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">Ïƒ</span></span></span></span></span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.logaddexp.html#torch.Tensor.logaddexp" title="torch.Tensor.logaddexp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logaddexp</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.logaddexp.html#torch.logaddexp" title="torch.logaddexp"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.logaddexp()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.logaddexp2.html#torch.Tensor.logaddexp2" title="torch.Tensor.logaddexp2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logaddexp2</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.logaddexp2.html#torch.logaddexp2" title="torch.logaddexp2"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.logaddexp2()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.logsumexp.html#torch.Tensor.logsumexp" title="torch.Tensor.logsumexp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logsumexp</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.logsumexp.html#torch.logsumexp" title="torch.logsumexp"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.logsumexp()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.logical_and.html#torch.Tensor.logical_and" title="torch.Tensor.logical_and"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logical_and</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.logical_and.html#torch.logical_and" title="torch.logical_and"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.logical_and()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.logical_and_.html#torch.Tensor.logical_and_" title="torch.Tensor.logical_and_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logical_and_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.logical_and.html#torch.Tensor.logical_and" title="torch.Tensor.logical_and"><code class="xref py py-meth docutils literal notranslate"><span class="pre">logical_and()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.logical_not.html#torch.Tensor.logical_not" title="torch.Tensor.logical_not"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logical_not</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.logical_not.html#torch.logical_not" title="torch.logical_not"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.logical_not()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.logical_not_.html#torch.Tensor.logical_not_" title="torch.Tensor.logical_not_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logical_not_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.logical_not.html#torch.Tensor.logical_not" title="torch.Tensor.logical_not"><code class="xref py py-meth docutils literal notranslate"><span class="pre">logical_not()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.logical_or.html#torch.Tensor.logical_or" title="torch.Tensor.logical_or"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logical_or</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.logical_or.html#torch.logical_or" title="torch.logical_or"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.logical_or()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.logical_or_.html#torch.Tensor.logical_or_" title="torch.Tensor.logical_or_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logical_or_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.logical_or.html#torch.Tensor.logical_or" title="torch.Tensor.logical_or"><code class="xref py py-meth docutils literal notranslate"><span class="pre">logical_or()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.logical_xor.html#torch.Tensor.logical_xor" title="torch.Tensor.logical_xor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logical_xor</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.logical_xor.html#torch.logical_xor" title="torch.logical_xor"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.logical_xor()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.logical_xor_.html#torch.Tensor.logical_xor_" title="torch.Tensor.logical_xor_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logical_xor_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.logical_xor.html#torch.Tensor.logical_xor" title="torch.Tensor.logical_xor"><code class="xref py py-meth docutils literal notranslate"><span class="pre">logical_xor()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.logit.html#torch.Tensor.logit" title="torch.Tensor.logit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logit</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.logit.html#torch.logit" title="torch.logit"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.logit()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.logit_.html#torch.Tensor.logit_" title="torch.Tensor.logit_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.logit_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.logit.html#torch.Tensor.logit" title="torch.Tensor.logit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">logit()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.long.html#torch.Tensor.long" title="torch.Tensor.long"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.long</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.long()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.int64)</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.lstsq.html#torch.Tensor.lstsq" title="torch.Tensor.lstsq"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.lstsq</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.lstsq.html#torch.lstsq" title="torch.lstsq"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.lstsq()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.lt.html#torch.Tensor.lt" title="torch.Tensor.lt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.lt</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.lt.html#torch.lt" title="torch.lt"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.lt()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.lt_.html#torch.Tensor.lt_" title="torch.Tensor.lt_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.lt_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.lt.html#torch.Tensor.lt" title="torch.Tensor.lt"><code class="xref py py-meth docutils literal notranslate"><span class="pre">lt()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.less.html#torch.Tensor.less" title="torch.Tensor.less"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.less</span></code></a></p></td>
<td><p>lt(other) -&gt; Tensor</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.less_.html#torch.Tensor.less_" title="torch.Tensor.less_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.less_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.less.html#torch.Tensor.less" title="torch.Tensor.less"><code class="xref py py-meth docutils literal notranslate"><span class="pre">less()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.lu.html#torch.Tensor.lu" title="torch.Tensor.lu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.lu</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.lu.html#torch.lu" title="torch.lu"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.lu()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.lu_solve.html#torch.Tensor.lu_solve" title="torch.Tensor.lu_solve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.lu_solve</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.lu_solve.html#torch.lu_solve" title="torch.lu_solve"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.lu_solve()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.as_subclass.html#torch.Tensor.as_subclass" title="torch.Tensor.as_subclass"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.as_subclass</span></code></a></p></td>
<td><p>Makes a <code class="docutils literal notranslate"><span class="pre">cls</span></code> instance with the same data pointer as <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.map_.html#torch.Tensor.map_" title="torch.Tensor.map_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.map_</span></code></a></p></td>
<td><p>Applies <code class="xref py py-attr docutils literal notranslate"><span class="pre">callable</span></code> for each element in <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor and the given <a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">tensor</span></code></a> and stores the results in <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.masked_scatter_.html#torch.Tensor.masked_scatter_" title="torch.Tensor.masked_scatter_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.masked_scatter_</span></code></a></p></td>
<td><p>Copies elements from <code class="xref py py-attr docutils literal notranslate"><span class="pre">source</span></code> into <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor at positions where the <code class="xref py py-attr docutils literal notranslate"><span class="pre">mask</span></code> is True.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.masked_scatter.html#torch.Tensor.masked_scatter" title="torch.Tensor.masked_scatter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.masked_scatter</span></code></a></p></td>
<td><p>Out-of-place version of <a class="reference internal" href="generated/torch.Tensor.masked_scatter_.html#torch.Tensor.masked_scatter_" title="torch.Tensor.masked_scatter_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.masked_scatter_()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.masked_fill_.html#torch.Tensor.masked_fill_" title="torch.Tensor.masked_fill_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.masked_fill_</span></code></a></p></td>
<td><p>Fills elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor with <code class="xref py py-attr docutils literal notranslate"><span class="pre">value</span></code> where <code class="xref py py-attr docutils literal notranslate"><span class="pre">mask</span></code> is True.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.masked_fill.html#torch.Tensor.masked_fill" title="torch.Tensor.masked_fill"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.masked_fill</span></code></a></p></td>
<td><p>Out-of-place version of <a class="reference internal" href="generated/torch.Tensor.masked_fill_.html#torch.Tensor.masked_fill_" title="torch.Tensor.masked_fill_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.masked_fill_()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.masked_select.html#torch.Tensor.masked_select" title="torch.Tensor.masked_select"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.masked_select</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.masked_select.html#torch.masked_select" title="torch.masked_select"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.masked_select()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.matmul.html#torch.Tensor.matmul" title="torch.Tensor.matmul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.matmul</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.matmul.html#torch.matmul" title="torch.matmul"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.matmul()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.matrix_power.html#torch.Tensor.matrix_power" title="torch.Tensor.matrix_power"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.matrix_power</span></code></a></p></td>
<td><p><div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="generated/torch.Tensor.matrix_power.html#torch.Tensor.matrix_power" title="torch.Tensor.matrix_power"><code class="xref py py-meth docutils literal notranslate"><span class="pre">matrix_power()</span></code></a> is deprecated, use <a class="reference internal" href="generated/torch.linalg.matrix_power.html#torch.linalg.matrix_power" title="torch.linalg.matrix_power"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.linalg.matrix_power()</span></code></a> instead.</p>
</div>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.matrix_exp.html#torch.Tensor.matrix_exp" title="torch.Tensor.matrix_exp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.matrix_exp</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.matrix_exp.html#torch.matrix_exp" title="torch.matrix_exp"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.matrix_exp()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.max.html#torch.Tensor.max" title="torch.Tensor.max"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.max</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.max.html#torch.max" title="torch.max"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.max()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.maximum.html#torch.Tensor.maximum" title="torch.Tensor.maximum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.maximum</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.maximum.html#torch.maximum" title="torch.maximum"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.maximum()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.mean.html#torch.Tensor.mean" title="torch.Tensor.mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.mean</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.mean.html#torch.mean" title="torch.mean"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.mean()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.nanmean.html#torch.Tensor.nanmean" title="torch.Tensor.nanmean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.nanmean</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.nanmean.html#torch.nanmean" title="torch.nanmean"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nanmean()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.median.html#torch.Tensor.median" title="torch.Tensor.median"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.median</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.median.html#torch.median" title="torch.median"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.median()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.nanmedian.html#torch.Tensor.nanmedian" title="torch.Tensor.nanmedian"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.nanmedian</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.nanmedian.html#torch.nanmedian" title="torch.nanmedian"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nanmedian()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.min.html#torch.Tensor.min" title="torch.Tensor.min"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.min</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.min.html#torch.min" title="torch.min"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.min()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.minimum.html#torch.Tensor.minimum" title="torch.Tensor.minimum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.minimum</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.minimum.html#torch.minimum" title="torch.minimum"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.minimum()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.mm.html#torch.Tensor.mm" title="torch.Tensor.mm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.mm</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.mm.html#torch.mm" title="torch.mm"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.mm()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.smm.html#torch.Tensor.smm" title="torch.Tensor.smm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.smm</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.smm.html#torch.smm" title="torch.smm"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.smm()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.mode.html#torch.Tensor.mode" title="torch.Tensor.mode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.mode</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.mode.html#torch.mode" title="torch.mode"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.mode()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.movedim.html#torch.Tensor.movedim" title="torch.Tensor.movedim"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.movedim</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.movedim.html#torch.movedim" title="torch.movedim"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.movedim()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.moveaxis.html#torch.Tensor.moveaxis" title="torch.Tensor.moveaxis"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.moveaxis</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.moveaxis.html#torch.moveaxis" title="torch.moveaxis"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.moveaxis()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.msort.html#torch.Tensor.msort" title="torch.Tensor.msort"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.msort</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.msort.html#torch.msort" title="torch.msort"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.msort()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.mul.html#torch.Tensor.mul" title="torch.Tensor.mul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.mul</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.mul.html#torch.mul" title="torch.mul"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.mul()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.mul_.html#torch.Tensor.mul_" title="torch.Tensor.mul_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.mul_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.mul.html#torch.Tensor.mul" title="torch.Tensor.mul"><code class="xref py py-meth docutils literal notranslate"><span class="pre">mul()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.multiply.html#torch.Tensor.multiply" title="torch.Tensor.multiply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.multiply</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.multiply.html#torch.multiply" title="torch.multiply"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.multiply()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.multiply_.html#torch.Tensor.multiply_" title="torch.Tensor.multiply_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.multiply_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.multiply.html#torch.Tensor.multiply" title="torch.Tensor.multiply"><code class="xref py py-meth docutils literal notranslate"><span class="pre">multiply()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.multinomial.html#torch.Tensor.multinomial" title="torch.Tensor.multinomial"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.multinomial</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.multinomial.html#torch.multinomial" title="torch.multinomial"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.multinomial()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.mv.html#torch.Tensor.mv" title="torch.Tensor.mv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.mv</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.mv.html#torch.mv" title="torch.mv"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.mv()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.mvlgamma.html#torch.Tensor.mvlgamma" title="torch.Tensor.mvlgamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.mvlgamma</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.mvlgamma.html#torch.mvlgamma" title="torch.mvlgamma"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.mvlgamma()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.mvlgamma_.html#torch.Tensor.mvlgamma_" title="torch.Tensor.mvlgamma_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.mvlgamma_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.mvlgamma.html#torch.Tensor.mvlgamma" title="torch.Tensor.mvlgamma"><code class="xref py py-meth docutils literal notranslate"><span class="pre">mvlgamma()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.nansum.html#torch.Tensor.nansum" title="torch.Tensor.nansum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.nansum</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.nansum.html#torch.nansum" title="torch.nansum"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nansum()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.narrow.html#torch.Tensor.narrow" title="torch.Tensor.narrow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.narrow</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.narrow.html#torch.narrow" title="torch.narrow"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.narrow()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.narrow_copy.html#torch.Tensor.narrow_copy" title="torch.Tensor.narrow_copy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.narrow_copy</span></code></a></p></td>
<td><p>Same as <a class="reference internal" href="generated/torch.Tensor.narrow.html#torch.Tensor.narrow" title="torch.Tensor.narrow"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Tensor.narrow()</span></code></a> except returning a copy rather than shared storage.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.ndimension.html#torch.Tensor.ndimension" title="torch.Tensor.ndimension"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ndimension</span></code></a></p></td>
<td><p>Alias for <a class="reference internal" href="generated/torch.Tensor.dim.html#torch.Tensor.dim" title="torch.Tensor.dim"><code class="xref py py-meth docutils literal notranslate"><span class="pre">dim()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.nan_to_num.html#torch.Tensor.nan_to_num" title="torch.Tensor.nan_to_num"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.nan_to_num</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.nan_to_num.html#torch.nan_to_num" title="torch.nan_to_num"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nan_to_num()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.nan_to_num_.html#torch.Tensor.nan_to_num_" title="torch.Tensor.nan_to_num_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.nan_to_num_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.nan_to_num.html#torch.Tensor.nan_to_num" title="torch.Tensor.nan_to_num"><code class="xref py py-meth docutils literal notranslate"><span class="pre">nan_to_num()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.ne.html#torch.Tensor.ne" title="torch.Tensor.ne"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ne</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.ne.html#torch.ne" title="torch.ne"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.ne()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.ne_.html#torch.Tensor.ne_" title="torch.Tensor.ne_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ne_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.ne.html#torch.Tensor.ne" title="torch.Tensor.ne"><code class="xref py py-meth docutils literal notranslate"><span class="pre">ne()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.not_equal.html#torch.Tensor.not_equal" title="torch.Tensor.not_equal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.not_equal</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.not_equal.html#torch.not_equal" title="torch.not_equal"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.not_equal()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.not_equal_.html#torch.Tensor.not_equal_" title="torch.Tensor.not_equal_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.not_equal_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.not_equal.html#torch.Tensor.not_equal" title="torch.Tensor.not_equal"><code class="xref py py-meth docutils literal notranslate"><span class="pre">not_equal()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.neg.html#torch.Tensor.neg" title="torch.Tensor.neg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.neg</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.neg.html#torch.neg" title="torch.neg"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.neg()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.neg_.html#torch.Tensor.neg_" title="torch.Tensor.neg_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.neg_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.neg.html#torch.Tensor.neg" title="torch.Tensor.neg"><code class="xref py py-meth docutils literal notranslate"><span class="pre">neg()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.negative.html#torch.Tensor.negative" title="torch.Tensor.negative"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.negative</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.negative.html#torch.negative" title="torch.negative"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.negative()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.negative_.html#torch.Tensor.negative_" title="torch.Tensor.negative_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.negative_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.negative.html#torch.Tensor.negative" title="torch.Tensor.negative"><code class="xref py py-meth docutils literal notranslate"><span class="pre">negative()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.nelement.html#torch.Tensor.nelement" title="torch.Tensor.nelement"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.nelement</span></code></a></p></td>
<td><p>Alias for <a class="reference internal" href="generated/torch.Tensor.numel.html#torch.Tensor.numel" title="torch.Tensor.numel"><code class="xref py py-meth docutils literal notranslate"><span class="pre">numel()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.nextafter.html#torch.Tensor.nextafter" title="torch.Tensor.nextafter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.nextafter</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.nextafter.html#torch.nextafter" title="torch.nextafter"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nextafter()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.nextafter_.html#torch.Tensor.nextafter_" title="torch.Tensor.nextafter_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.nextafter_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.nextafter.html#torch.Tensor.nextafter" title="torch.Tensor.nextafter"><code class="xref py py-meth docutils literal notranslate"><span class="pre">nextafter()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.nonzero.html#torch.Tensor.nonzero" title="torch.Tensor.nonzero"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.nonzero</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.nonzero.html#torch.nonzero" title="torch.nonzero"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nonzero()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.norm.html#torch.Tensor.norm" title="torch.Tensor.norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.norm</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.norm.html#torch.norm" title="torch.norm"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.norm()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.normal_.html#torch.Tensor.normal_" title="torch.Tensor.normal_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.normal_</span></code></a></p></td>
<td><p>Fills <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor with elements samples from the normal distribution parameterized by <a class="reference internal" href="generated/torch.mean.html#torch.mean" title="torch.mean"><code class="xref py py-attr docutils literal notranslate"><span class="pre">mean</span></code></a> and <a class="reference internal" href="generated/torch.std.html#torch.std" title="torch.std"><code class="xref py py-attr docutils literal notranslate"><span class="pre">std</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.numel.html#torch.Tensor.numel" title="torch.Tensor.numel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.numel</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.numel.html#torch.numel" title="torch.numel"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.numel()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.numpy.html#torch.Tensor.numpy" title="torch.Tensor.numpy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.numpy</span></code></a></p></td>
<td><p>Returns <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor as a NumPy <code class="xref py py-class docutils literal notranslate"><span class="pre">ndarray</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.orgqr.html#torch.Tensor.orgqr" title="torch.Tensor.orgqr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.orgqr</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.orgqr.html#torch.orgqr" title="torch.orgqr"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.orgqr()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.ormqr.html#torch.Tensor.ormqr" title="torch.Tensor.ormqr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ormqr</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.ormqr.html#torch.ormqr" title="torch.ormqr"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.ormqr()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.outer.html#torch.Tensor.outer" title="torch.Tensor.outer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.outer</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.outer.html#torch.outer" title="torch.outer"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.outer()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.permute.html#torch.Tensor.permute" title="torch.Tensor.permute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.permute</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.permute.html#torch.permute" title="torch.permute"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.permute()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.pin_memory.html#torch.Tensor.pin_memory" title="torch.Tensor.pin_memory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.pin_memory</span></code></a></p></td>
<td><p>Copies the tensor to pinned memory, if itâ€™s not already pinned.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.pinverse.html#torch.Tensor.pinverse" title="torch.Tensor.pinverse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.pinverse</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.pinverse.html#torch.pinverse" title="torch.pinverse"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.pinverse()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.polygamma.html#torch.Tensor.polygamma" title="torch.Tensor.polygamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.polygamma</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.polygamma.html#torch.polygamma" title="torch.polygamma"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.polygamma()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.polygamma_.html#torch.Tensor.polygamma_" title="torch.Tensor.polygamma_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.polygamma_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.polygamma.html#torch.Tensor.polygamma" title="torch.Tensor.polygamma"><code class="xref py py-meth docutils literal notranslate"><span class="pre">polygamma()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.positive.html#torch.Tensor.positive" title="torch.Tensor.positive"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.positive</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.positive.html#torch.positive" title="torch.positive"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.positive()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.pow.html#torch.Tensor.pow" title="torch.Tensor.pow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.pow</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.pow.html#torch.pow" title="torch.pow"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.pow()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.pow_.html#torch.Tensor.pow_" title="torch.Tensor.pow_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.pow_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.pow.html#torch.Tensor.pow" title="torch.Tensor.pow"><code class="xref py py-meth docutils literal notranslate"><span class="pre">pow()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.prod.html#torch.Tensor.prod" title="torch.Tensor.prod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.prod</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.prod.html#torch.prod" title="torch.prod"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.prod()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.put_.html#torch.Tensor.put_" title="torch.Tensor.put_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.put_</span></code></a></p></td>
<td><p>Copies the elements from <code class="xref py py-attr docutils literal notranslate"><span class="pre">source</span></code> into the positions specified by <code class="xref py py-attr docutils literal notranslate"><span class="pre">index</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.qr.html#torch.Tensor.qr" title="torch.Tensor.qr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.qr</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.qr.html#torch.qr" title="torch.qr"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.qr()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.qscheme.html#torch.Tensor.qscheme" title="torch.Tensor.qscheme"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.qscheme</span></code></a></p></td>
<td><p>Returns the quantization scheme of a given QTensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.quantile.html#torch.Tensor.quantile" title="torch.Tensor.quantile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.quantile</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.quantile.html#torch.quantile" title="torch.quantile"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.quantile()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.nanquantile.html#torch.Tensor.nanquantile" title="torch.Tensor.nanquantile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.nanquantile</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.nanquantile.html#torch.nanquantile" title="torch.nanquantile"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nanquantile()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.q_scale.html#torch.Tensor.q_scale" title="torch.Tensor.q_scale"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.q_scale</span></code></a></p></td>
<td><p>Given a Tensor quantized by linear(affine) quantization, returns the scale of the underlying quantizer().</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.q_zero_point.html#torch.Tensor.q_zero_point" title="torch.Tensor.q_zero_point"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.q_zero_point</span></code></a></p></td>
<td><p>Given a Tensor quantized by linear(affine) quantization, returns the zero_point of the underlying quantizer().</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.q_per_channel_scales.html#torch.Tensor.q_per_channel_scales" title="torch.Tensor.q_per_channel_scales"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.q_per_channel_scales</span></code></a></p></td>
<td><p>Given a Tensor quantized by linear (affine) per-channel quantization, returns a Tensor of scales of the underlying quantizer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.q_per_channel_zero_points.html#torch.Tensor.q_per_channel_zero_points" title="torch.Tensor.q_per_channel_zero_points"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.q_per_channel_zero_points</span></code></a></p></td>
<td><p>Given a Tensor quantized by linear (affine) per-channel quantization, returns a tensor of zero_points of the underlying quantizer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.q_per_channel_axis.html#torch.Tensor.q_per_channel_axis" title="torch.Tensor.q_per_channel_axis"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.q_per_channel_axis</span></code></a></p></td>
<td><p>Given a Tensor quantized by linear (affine) per-channel quantization, returns the index of dimension on which per-channel quantization is applied.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.rad2deg.html#torch.Tensor.rad2deg" title="torch.Tensor.rad2deg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.rad2deg</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.rad2deg.html#torch.rad2deg" title="torch.rad2deg"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.rad2deg()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.random_.html#torch.Tensor.random_" title="torch.Tensor.random_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.random_</span></code></a></p></td>
<td><p>Fills <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor with numbers sampled from the discrete uniform distribution over <code class="docutils literal notranslate"><span class="pre">[from,</span> <span class="pre">to</span> <span class="pre">-</span> <span class="pre">1]</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.ravel.html#torch.Tensor.ravel" title="torch.Tensor.ravel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.ravel</span></code></a></p></td>
<td><p>see <a class="reference internal" href="generated/torch.ravel.html#torch.ravel" title="torch.ravel"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.ravel()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.reciprocal.html#torch.Tensor.reciprocal" title="torch.Tensor.reciprocal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.reciprocal</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.reciprocal.html#torch.reciprocal" title="torch.reciprocal"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.reciprocal()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.reciprocal_.html#torch.Tensor.reciprocal_" title="torch.Tensor.reciprocal_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.reciprocal_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.reciprocal.html#torch.Tensor.reciprocal" title="torch.Tensor.reciprocal"><code class="xref py py-meth docutils literal notranslate"><span class="pre">reciprocal()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.record_stream.html#torch.Tensor.record_stream" title="torch.Tensor.record_stream"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.record_stream</span></code></a></p></td>
<td><p>Ensures that the tensor memory is not reused for another tensor until all current work queued on <code class="xref py py-attr docutils literal notranslate"><span class="pre">stream</span></code> are complete.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.register_hook.html#torch.Tensor.register_hook" title="torch.Tensor.register_hook"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.register_hook</span></code></a></p></td>
<td><p>Registers a backward hook.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.remainder.html#torch.Tensor.remainder" title="torch.Tensor.remainder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.remainder</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.remainder.html#torch.remainder" title="torch.remainder"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.remainder()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.remainder_.html#torch.Tensor.remainder_" title="torch.Tensor.remainder_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.remainder_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.remainder.html#torch.Tensor.remainder" title="torch.Tensor.remainder"><code class="xref py py-meth docutils literal notranslate"><span class="pre">remainder()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.renorm.html#torch.Tensor.renorm" title="torch.Tensor.renorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.renorm</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.renorm.html#torch.renorm" title="torch.renorm"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.renorm()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.renorm_.html#torch.Tensor.renorm_" title="torch.Tensor.renorm_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.renorm_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.renorm.html#torch.Tensor.renorm" title="torch.Tensor.renorm"><code class="xref py py-meth docutils literal notranslate"><span class="pre">renorm()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.repeat.html#torch.Tensor.repeat" title="torch.Tensor.repeat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.repeat</span></code></a></p></td>
<td><p>Repeats this tensor along the specified dimensions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.repeat_interleave.html#torch.Tensor.repeat_interleave" title="torch.Tensor.repeat_interleave"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.repeat_interleave</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.repeat_interleave.html#torch.repeat_interleave" title="torch.repeat_interleave"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.repeat_interleave()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.requires_grad.html#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.requires_grad</span></code></a></p></td>
<td><p>Is <code class="docutils literal notranslate"><span class="pre">True</span></code> if gradients need to be computed for this Tensor, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.requires_grad_.html#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.requires_grad_</span></code></a></p></td>
<td><p>Change if autograd should record operations on this tensor: sets this tensorâ€™s <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attribute in-place.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.reshape.html#torch.Tensor.reshape" title="torch.Tensor.reshape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.reshape</span></code></a></p></td>
<td><p>Returns a tensor with the same data and number of elements as <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> but with the specified shape.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.reshape_as.html#torch.Tensor.reshape_as" title="torch.Tensor.reshape_as"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.reshape_as</span></code></a></p></td>
<td><p>Returns this tensor as the same shape as <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.resize_.html#torch.Tensor.resize_" title="torch.Tensor.resize_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.resize_</span></code></a></p></td>
<td><p>Resizes <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor to the specified size.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.resize_as_.html#torch.Tensor.resize_as_" title="torch.Tensor.resize_as_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.resize_as_</span></code></a></p></td>
<td><p>Resizes the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor to be the same size as the specified <a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code class="xref py py-attr docutils literal notranslate"><span class="pre">tensor</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.retain_grad.html#torch.Tensor.retain_grad" title="torch.Tensor.retain_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.retain_grad</span></code></a></p></td>
<td><p>Enables this Tensor to have their <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad</span></code> populated during <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.retains_grad.html#torch.Tensor.retains_grad" title="torch.Tensor.retains_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.retains_grad</span></code></a></p></td>
<td><p>Is <code class="docutils literal notranslate"><span class="pre">True</span></code> if this Tensor is non-leaf and its <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad</span></code> is enabled to be populated during <code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code>, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.roll.html#torch.Tensor.roll" title="torch.Tensor.roll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.roll</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.roll.html#torch.roll" title="torch.roll"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.roll()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.rot90.html#torch.Tensor.rot90" title="torch.Tensor.rot90"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.rot90</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.rot90.html#torch.rot90" title="torch.rot90"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.rot90()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.round.html#torch.Tensor.round" title="torch.Tensor.round"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.round</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.round.html#torch.round" title="torch.round"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.round()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.round_.html#torch.Tensor.round_" title="torch.Tensor.round_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.round_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.round.html#torch.Tensor.round" title="torch.Tensor.round"><code class="xref py py-meth docutils literal notranslate"><span class="pre">round()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.rsqrt.html#torch.Tensor.rsqrt" title="torch.Tensor.rsqrt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.rsqrt</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.rsqrt.html#torch.rsqrt" title="torch.rsqrt"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.rsqrt()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.rsqrt_.html#torch.Tensor.rsqrt_" title="torch.Tensor.rsqrt_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.rsqrt_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.rsqrt.html#torch.Tensor.rsqrt" title="torch.Tensor.rsqrt"><code class="xref py py-meth docutils literal notranslate"><span class="pre">rsqrt()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.scatter.html#torch.Tensor.scatter" title="torch.Tensor.scatter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.scatter</span></code></a></p></td>
<td><p>Out-of-place version of <a class="reference internal" href="generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.scatter_()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.scatter_</span></code></a></p></td>
<td><p>Writes all values from the tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">src</span></code> into <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> at the indices specified in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">index</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_" title="torch.Tensor.scatter_add_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.scatter_add_</span></code></a></p></td>
<td><p>Adds all values from the tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code> into <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> at the indices specified in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">index</span></code> tensor in a similar fashion as <a class="reference internal" href="generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">scatter_()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.scatter_add.html#torch.Tensor.scatter_add" title="torch.Tensor.scatter_add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.scatter_add</span></code></a></p></td>
<td><p>Out-of-place version of <a class="reference internal" href="generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_" title="torch.Tensor.scatter_add_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.scatter_add_()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.scatter_reduce_.html#torch.Tensor.scatter_reduce_" title="torch.Tensor.scatter_reduce_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.scatter_reduce_</span></code></a></p></td>
<td><p>Reduces all values from the <code class="xref py py-attr docutils literal notranslate"><span class="pre">src</span></code> tensor to the indices specified in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">index</span></code> tensor in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor using the applied reduction defined via the <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> argument (<code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;sum&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;prod&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;amax&quot;</span></code>, <code class="xref py py-obj docutils literal notranslate"><span class="pre">&quot;amin&quot;</span></code>).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.scatter_reduce.html#torch.Tensor.scatter_reduce" title="torch.Tensor.scatter_reduce"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.scatter_reduce</span></code></a></p></td>
<td><p>Out-of-place version of <a class="reference internal" href="generated/torch.Tensor.scatter_reduce_.html#torch.Tensor.scatter_reduce_" title="torch.Tensor.scatter_reduce_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.scatter_reduce_()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.select.html#torch.Tensor.select" title="torch.Tensor.select"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.select</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.select.html#torch.select" title="torch.select"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.select()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.select_scatter.html#torch.Tensor.select_scatter" title="torch.Tensor.select_scatter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.select_scatter</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.select_scatter.html#torch.select_scatter" title="torch.select_scatter"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.select_scatter()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.set_.html#torch.Tensor.set_" title="torch.Tensor.set_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.set_</span></code></a></p></td>
<td><p>Sets the underlying storage, size, and strides.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.share_memory_.html#torch.Tensor.share_memory_" title="torch.Tensor.share_memory_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.share_memory_</span></code></a></p></td>
<td><p>Moves the underlying storage to shared memory.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.short.html#torch.Tensor.short" title="torch.Tensor.short"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.short</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.short()</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">self.to(torch.int16)</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.sigmoid.html#torch.Tensor.sigmoid" title="torch.Tensor.sigmoid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sigmoid</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.sigmoid.html#torch.sigmoid" title="torch.sigmoid"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sigmoid()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.sigmoid_.html#torch.Tensor.sigmoid_" title="torch.Tensor.sigmoid_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sigmoid_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.sigmoid.html#torch.Tensor.sigmoid" title="torch.Tensor.sigmoid"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sigmoid()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.sign.html#torch.Tensor.sign" title="torch.Tensor.sign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sign</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.sign.html#torch.sign" title="torch.sign"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sign()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.sign_.html#torch.Tensor.sign_" title="torch.Tensor.sign_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sign_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.sign.html#torch.Tensor.sign" title="torch.Tensor.sign"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sign()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.signbit.html#torch.Tensor.signbit" title="torch.Tensor.signbit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.signbit</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.signbit.html#torch.signbit" title="torch.signbit"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.signbit()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.sgn.html#torch.Tensor.sgn" title="torch.Tensor.sgn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sgn</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.sgn.html#torch.sgn" title="torch.sgn"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sgn()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.sgn_.html#torch.Tensor.sgn_" title="torch.Tensor.sgn_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sgn_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.sgn.html#torch.Tensor.sgn" title="torch.Tensor.sgn"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sgn()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.sin.html#torch.Tensor.sin" title="torch.Tensor.sin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sin</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.sin.html#torch.sin" title="torch.sin"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sin()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.sin_.html#torch.Tensor.sin_" title="torch.Tensor.sin_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sin_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.sin.html#torch.Tensor.sin" title="torch.Tensor.sin"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sin()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.sinc.html#torch.Tensor.sinc" title="torch.Tensor.sinc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sinc</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.sinc.html#torch.sinc" title="torch.sinc"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sinc()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.sinc_.html#torch.Tensor.sinc_" title="torch.Tensor.sinc_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sinc_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.sinc.html#torch.Tensor.sinc" title="torch.Tensor.sinc"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sinc()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.sinh.html#torch.Tensor.sinh" title="torch.Tensor.sinh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sinh</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.sinh.html#torch.sinh" title="torch.sinh"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sinh()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.sinh_.html#torch.Tensor.sinh_" title="torch.Tensor.sinh_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sinh_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.sinh.html#torch.Tensor.sinh" title="torch.Tensor.sinh"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sinh()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.asinh.html#torch.Tensor.asinh" title="torch.Tensor.asinh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.asinh</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.asinh.html#torch.asinh" title="torch.asinh"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.asinh()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.asinh_.html#torch.Tensor.asinh_" title="torch.Tensor.asinh_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.asinh_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.asinh.html#torch.Tensor.asinh" title="torch.Tensor.asinh"><code class="xref py py-meth docutils literal notranslate"><span class="pre">asinh()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.arcsinh.html#torch.Tensor.arcsinh" title="torch.Tensor.arcsinh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arcsinh</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.arcsinh.html#torch.arcsinh" title="torch.arcsinh"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.arcsinh()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.arcsinh_.html#torch.Tensor.arcsinh_" title="torch.Tensor.arcsinh_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arcsinh_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.arcsinh.html#torch.Tensor.arcsinh" title="torch.Tensor.arcsinh"><code class="xref py py-meth docutils literal notranslate"><span class="pre">arcsinh()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.size.html#torch.Tensor.size" title="torch.Tensor.size"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.size</span></code></a></p></td>
<td><p>Returns the size of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.slogdet.html#torch.Tensor.slogdet" title="torch.Tensor.slogdet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.slogdet</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.slogdet.html#torch.slogdet" title="torch.slogdet"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.slogdet()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.slice_scatter.html#torch.Tensor.slice_scatter" title="torch.Tensor.slice_scatter"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.slice_scatter</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.slice_scatter.html#torch.slice_scatter" title="torch.slice_scatter"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.slice_scatter()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.sort.html#torch.Tensor.sort" title="torch.Tensor.sort"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sort</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.sort.html#torch.sort" title="torch.sort"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sort()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.split.html#torch.Tensor.split" title="torch.Tensor.split"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.split</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.split.html#torch.split" title="torch.split"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.split()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.sparse_mask.html#torch.Tensor.sparse_mask" title="torch.Tensor.sparse_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sparse_mask</span></code></a></p></td>
<td><p>Returns a new <a class="reference internal" href="sparse.html#sparse-docs"><span class="std std-ref">sparse tensor</span></a> with values from a strided tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> filtered by the indices of the sparse tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">mask</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.sparse_dim.html#torch.Tensor.sparse_dim" title="torch.Tensor.sparse_dim"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sparse_dim</span></code></a></p></td>
<td><p>Return the number of sparse dimensions in a <a class="reference internal" href="sparse.html#sparse-docs"><span class="std std-ref">sparse tensor</span></a> <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.sqrt.html#torch.Tensor.sqrt" title="torch.Tensor.sqrt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sqrt</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.sqrt.html#torch.sqrt" title="torch.sqrt"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sqrt()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.sqrt_.html#torch.Tensor.sqrt_" title="torch.Tensor.sqrt_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sqrt_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.sqrt.html#torch.Tensor.sqrt" title="torch.Tensor.sqrt"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sqrt()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.square.html#torch.Tensor.square" title="torch.Tensor.square"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.square</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.square.html#torch.square" title="torch.square"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.square()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.square_.html#torch.Tensor.square_" title="torch.Tensor.square_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.square_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.square.html#torch.Tensor.square" title="torch.Tensor.square"><code class="xref py py-meth docutils literal notranslate"><span class="pre">square()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.squeeze.html#torch.Tensor.squeeze" title="torch.Tensor.squeeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.squeeze</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.squeeze.html#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.squeeze()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.squeeze_.html#torch.Tensor.squeeze_" title="torch.Tensor.squeeze_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.squeeze_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.squeeze.html#torch.Tensor.squeeze" title="torch.Tensor.squeeze"><code class="xref py py-meth docutils literal notranslate"><span class="pre">squeeze()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.std.html#torch.Tensor.std" title="torch.Tensor.std"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.std</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.std.html#torch.std" title="torch.std"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.std()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.stft.html#torch.Tensor.stft" title="torch.Tensor.stft"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.stft</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.stft.html#torch.stft" title="torch.stft"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.stft()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.storage.html#torch.Tensor.storage" title="torch.Tensor.storage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.storage</span></code></a></p></td>
<td><p>Returns the underlying storage.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.storage_offset.html#torch.Tensor.storage_offset" title="torch.Tensor.storage_offset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.storage_offset</span></code></a></p></td>
<td><p>Returns <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensorâ€™s offset in the underlying storage in terms of number of storage elements (not bytes).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.storage_type.html#torch.Tensor.storage_type" title="torch.Tensor.storage_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.storage_type</span></code></a></p></td>
<td><p>Returns the type of the underlying storage.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.stride.html#torch.Tensor.stride" title="torch.Tensor.stride"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.stride</span></code></a></p></td>
<td><p>Returns the stride of <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.sub.html#torch.Tensor.sub" title="torch.Tensor.sub"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sub</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.sub.html#torch.sub" title="torch.sub"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sub()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.sub_.html#torch.Tensor.sub_" title="torch.Tensor.sub_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sub_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.sub.html#torch.Tensor.sub" title="torch.Tensor.sub"><code class="xref py py-meth docutils literal notranslate"><span class="pre">sub()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.subtract.html#torch.Tensor.subtract" title="torch.Tensor.subtract"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.subtract</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.subtract.html#torch.subtract" title="torch.subtract"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.subtract()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.subtract_.html#torch.Tensor.subtract_" title="torch.Tensor.subtract_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.subtract_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.subtract.html#torch.Tensor.subtract" title="torch.Tensor.subtract"><code class="xref py py-meth docutils literal notranslate"><span class="pre">subtract()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.sum.html#torch.Tensor.sum" title="torch.Tensor.sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sum</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.sum.html#torch.sum" title="torch.sum"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.sum()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.sum_to_size.html#torch.Tensor.sum_to_size" title="torch.Tensor.sum_to_size"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.sum_to_size</span></code></a></p></td>
<td><p>Sum <code class="docutils literal notranslate"><span class="pre">this</span></code> tensor to <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.svd.html#torch.Tensor.svd" title="torch.Tensor.svd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.svd</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.svd.html#torch.svd" title="torch.svd"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.svd()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.swapaxes.html#torch.Tensor.swapaxes" title="torch.Tensor.swapaxes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.swapaxes</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.swapaxes.html#torch.swapaxes" title="torch.swapaxes"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.swapaxes()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.swapdims.html#torch.Tensor.swapdims" title="torch.Tensor.swapdims"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.swapdims</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.swapdims.html#torch.swapdims" title="torch.swapdims"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.swapdims()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.symeig.html#torch.Tensor.symeig" title="torch.Tensor.symeig"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.symeig</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.symeig.html#torch.symeig" title="torch.symeig"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.symeig()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.t.html#torch.Tensor.t" title="torch.Tensor.t"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.t</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.t.html#torch.t" title="torch.t"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.t()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.t_.html#torch.Tensor.t_" title="torch.Tensor.t_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.t_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.t.html#torch.Tensor.t" title="torch.Tensor.t"><code class="xref py py-meth docutils literal notranslate"><span class="pre">t()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.tensor_split.html#torch.Tensor.tensor_split" title="torch.Tensor.tensor_split"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.tensor_split</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.tensor_split.html#torch.tensor_split" title="torch.tensor_split"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.tensor_split()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.tile.html#torch.Tensor.tile" title="torch.Tensor.tile"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.tile</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.tile.html#torch.tile" title="torch.tile"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.tile()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.to.html#torch.Tensor.to" title="torch.Tensor.to"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.to</span></code></a></p></td>
<td><p>Performs Tensor dtype and/or device conversion.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.to_mkldnn.html#torch.Tensor.to_mkldnn" title="torch.Tensor.to_mkldnn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.to_mkldnn</span></code></a></p></td>
<td><p>Returns a copy of the tensor in <code class="docutils literal notranslate"><span class="pre">torch.mkldnn</span></code> layout.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.take.html#torch.Tensor.take" title="torch.Tensor.take"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.take</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.take.html#torch.take" title="torch.take"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.take()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.take_along_dim.html#torch.Tensor.take_along_dim" title="torch.Tensor.take_along_dim"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.take_along_dim</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.take_along_dim.html#torch.take_along_dim" title="torch.take_along_dim"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.take_along_dim()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.tan.html#torch.Tensor.tan" title="torch.Tensor.tan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.tan</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.tan.html#torch.tan" title="torch.tan"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.tan()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.tan_.html#torch.Tensor.tan_" title="torch.Tensor.tan_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.tan_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.tan.html#torch.Tensor.tan" title="torch.Tensor.tan"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tan()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.tanh.html#torch.Tensor.tanh" title="torch.Tensor.tanh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.tanh</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.tanh.html#torch.tanh" title="torch.tanh"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.tanh()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.tanh_.html#torch.Tensor.tanh_" title="torch.Tensor.tanh_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.tanh_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.tanh.html#torch.Tensor.tanh" title="torch.Tensor.tanh"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tanh()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.atanh.html#torch.Tensor.atanh" title="torch.Tensor.atanh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.atanh</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.atanh.html#torch.atanh" title="torch.atanh"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.atanh()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.atanh_.html#torch.Tensor.atanh_" title="torch.Tensor.atanh_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.atanh_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.atanh.html#torch.Tensor.atanh" title="torch.Tensor.atanh"><code class="xref py py-meth docutils literal notranslate"><span class="pre">atanh()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.arctanh.html#torch.Tensor.arctanh" title="torch.Tensor.arctanh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arctanh</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.arctanh.html#torch.arctanh" title="torch.arctanh"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.arctanh()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.arctanh_.html#torch.Tensor.arctanh_" title="torch.Tensor.arctanh_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.arctanh_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.arctanh.html#torch.Tensor.arctanh" title="torch.Tensor.arctanh"><code class="xref py py-meth docutils literal notranslate"><span class="pre">arctanh()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.tolist.html#torch.Tensor.tolist" title="torch.Tensor.tolist"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.tolist</span></code></a></p></td>
<td><p>Returns the tensor as a (nested) list.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.topk.html#torch.Tensor.topk" title="torch.Tensor.topk"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.topk</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.topk.html#torch.topk" title="torch.topk"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.topk()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.to_sparse.html#torch.Tensor.to_sparse" title="torch.Tensor.to_sparse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.to_sparse</span></code></a></p></td>
<td><p>Returns a sparse copy of the tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.trace.html#torch.Tensor.trace" title="torch.Tensor.trace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.trace</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.trace.html#torch.trace" title="torch.trace"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.trace()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.transpose.html#torch.Tensor.transpose" title="torch.Tensor.transpose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.transpose</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.transpose.html#torch.transpose" title="torch.transpose"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.transpose()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.transpose_.html#torch.Tensor.transpose_" title="torch.Tensor.transpose_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.transpose_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.transpose.html#torch.Tensor.transpose" title="torch.Tensor.transpose"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transpose()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.triangular_solve.html#torch.Tensor.triangular_solve" title="torch.Tensor.triangular_solve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.triangular_solve</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.triangular_solve.html#torch.triangular_solve" title="torch.triangular_solve"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.triangular_solve()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.tril.html#torch.Tensor.tril" title="torch.Tensor.tril"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.tril</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.tril.html#torch.tril" title="torch.tril"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.tril()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.tril_.html#torch.Tensor.tril_" title="torch.Tensor.tril_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.tril_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.tril.html#torch.Tensor.tril" title="torch.Tensor.tril"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tril()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.triu.html#torch.Tensor.triu" title="torch.Tensor.triu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.triu</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.triu.html#torch.triu" title="torch.triu"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.triu()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.triu_.html#torch.Tensor.triu_" title="torch.Tensor.triu_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.triu_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.triu.html#torch.Tensor.triu" title="torch.Tensor.triu"><code class="xref py py-meth docutils literal notranslate"><span class="pre">triu()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.true_divide.html#torch.Tensor.true_divide" title="torch.Tensor.true_divide"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.true_divide</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.true_divide.html#torch.true_divide" title="torch.true_divide"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.true_divide()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.true_divide_.html#torch.Tensor.true_divide_" title="torch.Tensor.true_divide_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.true_divide_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.true_divide_.html#torch.Tensor.true_divide_" title="torch.Tensor.true_divide_"><code class="xref py py-meth docutils literal notranslate"><span class="pre">true_divide_()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.trunc.html#torch.Tensor.trunc" title="torch.Tensor.trunc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.trunc</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.trunc.html#torch.trunc" title="torch.trunc"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.trunc()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.trunc_.html#torch.Tensor.trunc_" title="torch.Tensor.trunc_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.trunc_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.trunc.html#torch.Tensor.trunc" title="torch.Tensor.trunc"><code class="xref py py-meth docutils literal notranslate"><span class="pre">trunc()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.type.html#torch.Tensor.type" title="torch.Tensor.type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.type</span></code></a></p></td>
<td><p>Returns the type if <cite>dtype</cite> is not provided, else casts this object to the specified type.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.type_as.html#torch.Tensor.type_as" title="torch.Tensor.type_as"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.type_as</span></code></a></p></td>
<td><p>Returns this tensor cast to the type of the given tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.unbind.html#torch.Tensor.unbind" title="torch.Tensor.unbind"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.unbind</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.unbind.html#torch.unbind" title="torch.unbind"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.unbind()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.unfold.html#torch.Tensor.unfold" title="torch.Tensor.unfold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.unfold</span></code></a></p></td>
<td><p>Returns a view of the original tensor which contains all slices of size <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> from <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor in the dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dimension</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.uniform_.html#torch.Tensor.uniform_" title="torch.Tensor.uniform_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.uniform_</span></code></a></p></td>
<td><p>Fills <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor with numbers sampled from the continuous uniform distribution:</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.unique.html#torch.Tensor.unique" title="torch.Tensor.unique"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.unique</span></code></a></p></td>
<td><p>Returns the unique elements of the input tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.unique_consecutive.html#torch.Tensor.unique_consecutive" title="torch.Tensor.unique_consecutive"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.unique_consecutive</span></code></a></p></td>
<td><p>Eliminates all but the first element from every consecutive group of equivalent elements.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.unsqueeze.html#torch.Tensor.unsqueeze" title="torch.Tensor.unsqueeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.unsqueeze</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.unsqueeze.html#torch.unsqueeze" title="torch.unsqueeze"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.unsqueeze()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.unsqueeze_.html#torch.Tensor.unsqueeze_" title="torch.Tensor.unsqueeze_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.unsqueeze_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.unsqueeze.html#torch.Tensor.unsqueeze" title="torch.Tensor.unsqueeze"><code class="xref py py-meth docutils literal notranslate"><span class="pre">unsqueeze()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.values.html#torch.Tensor.values" title="torch.Tensor.values"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.values</span></code></a></p></td>
<td><p>Return the values tensor of a <a class="reference internal" href="sparse.html#sparse-coo-docs"><span class="std std-ref">sparse COO tensor</span></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.var.html#torch.Tensor.var" title="torch.Tensor.var"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.var</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.var.html#torch.var" title="torch.var"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.var()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.vdot.html#torch.Tensor.vdot" title="torch.Tensor.vdot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.vdot</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.vdot.html#torch.vdot" title="torch.vdot"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.vdot()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.view.html#torch.Tensor.view" title="torch.Tensor.view"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.view</span></code></a></p></td>
<td><p>Returns a new tensor with the same data as the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor but of a different <code class="xref py py-attr docutils literal notranslate"><span class="pre">shape</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.view_as.html#torch.Tensor.view_as" title="torch.Tensor.view_as"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.view_as</span></code></a></p></td>
<td><p>View this tensor as the same size as <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.vsplit.html#torch.Tensor.vsplit" title="torch.Tensor.vsplit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.vsplit</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.vsplit.html#torch.vsplit" title="torch.vsplit"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.vsplit()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.where.html#torch.Tensor.where" title="torch.Tensor.where"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.where</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">self.where(condition,</span> <span class="pre">y)</span></code> is equivalent to <code class="docutils literal notranslate"><span class="pre">torch.where(condition,</span> <span class="pre">self,</span> <span class="pre">y)</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.xlogy.html#torch.Tensor.xlogy" title="torch.Tensor.xlogy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.xlogy</span></code></a></p></td>
<td><p>See <a class="reference internal" href="generated/torch.xlogy.html#torch.xlogy" title="torch.xlogy"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.xlogy()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Tensor.xlogy_.html#torch.Tensor.xlogy_" title="torch.Tensor.xlogy_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.xlogy_</span></code></a></p></td>
<td><p>In-place version of <a class="reference internal" href="generated/torch.Tensor.xlogy.html#torch.Tensor.xlogy" title="torch.Tensor.xlogy"><code class="xref py py-meth docutils literal notranslate"><span class="pre">xlogy()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.Tensor.zero_.html#torch.Tensor.zero_" title="torch.Tensor.zero_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Tensor.zero_</span></code></a></p></td>
<td><p>Fills <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor with zeros.</p></td>
</tr>
</tbody>
</table>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="generated/torch.Tensor.new_tensor.html" class="btn btn-neutral float-right" title="torch.Tensor.new_tensor" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="generated/torch.nn.functional.torch.nn.parallel.data_parallel.html" class="btn btn-neutral" title="torch.nn.functional.torch.nn.parallel.data_parallel" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torch.Tensor</a><ul>
<li><a class="reference internal" href="#data-types">Data types</a></li>
<li><a class="reference internal" href="#initializing-and-basic-operations">Initializing and basic operations</a></li>
<li><a class="reference internal" href="#tensor-class-reference">Tensor class reference</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/clipboard.min.js"></script>
         <script src="_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>


 <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>
      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>
        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>
          </div>
        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        <hr size="20" color="white" />
         <div class="privacy-policy">
            <p class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a>&nbsp;&nbsp; | &nbsp;&nbsp; <a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></p>
        </div>
        <hr size="20" color="white" />
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/" style="color:#ee4c2c">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/" style="color:#ee4c2c">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>
  </footer>
  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>