


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Benchmark Utils - torch.utils.benchmark &mdash; PyTorch 1.12 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/benchmark_utils.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
  <link rel="stylesheet" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="torch.utils.bottleneck" href="bottleneck.html" />
    <link rel="prev" title="torch.testing" href="testing.html" />


  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  


  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>1.12 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          


            
            
              
            
            
<p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community/build_ci_governance.html">PyTorch Governance | Build + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/design.html">PyTorch Design Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/governance.html">PyTorch Governance | Mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/persons_of_interest.html">PyTorch Governance | Maintainers</a></li>
</ul>
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/amp_examples.html">CUDA Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">torch::deploy</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">torch.testing</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="config_mod.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Benchmark Utils - torch.utils.benchmark</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/benchmark_utils.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="module-torch.utils.benchmark">
<span id="benchmark-utils-torch-utils-benchmark"></span><h1>Benchmark Utils - torch.utils.benchmark<a class="headerlink" href="#module-torch.utils.benchmark" title="Permalink to this headline">¶</a></h1>
<dl class="py class">
<dt id="torch.utils.benchmark.Timer">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">torch.utils.benchmark.</span></code><code class="sig-name descname"><span class="pre">Timer</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">stmt='pass'</span></em>, <em class="sig-param"><span class="pre">setup='pass'</span></em>, <em class="sig-param"><span class="pre">global_setup=''</span></em>, <em class="sig-param"><span class="pre">timer=&lt;built-in</span> <span class="pre">function</span> <span class="pre">perf_counter&gt;</span></em>, <em class="sig-param"><span class="pre">globals=None</span></em>, <em class="sig-param"><span class="pre">label=None</span></em>, <em class="sig-param"><span class="pre">sub_label=None</span></em>, <em class="sig-param"><span class="pre">description=None</span></em>, <em class="sig-param"><span class="pre">env=None</span></em>, <em class="sig-param"><span class="pre">num_threads=1</span></em>, <em class="sig-param"><span class="pre">language=&lt;Language.PYTHON:</span> <span class="pre">0&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/timer.html#Timer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.Timer" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper class for measuring execution time of PyTorch statements.</p>
<p>For a full tutorial on how to use this class, see:
<a class="reference external" href="https://pytorch.org/tutorials/recipes/recipes/benchmark.html">https://pytorch.org/tutorials/recipes/recipes/benchmark.html</a></p>
<p>The PyTorch Timer is based on <cite>timeit.Timer</cite> (and in fact uses
<cite>timeit.Timer</cite> internally), but with several key differences:</p>
<ol class="arabic simple">
<li><dl class="simple">
<dt>Runtime aware:</dt><dd><p>Timer will perform warmups (important as some elements of PyTorch are
lazily initialized), set threadpool size so that comparisons are
apples-to-apples, and synchronize asynchronous CUDA functions when
necessary.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Focus on replicates:</dt><dd><p>When measuring code, and particularly complex kernels / models,
run-to-run variation is a significant confounding factor. It is
expected that all measurements should include replicates to quantify
noise and allow median computation, which is more robust than mean.
To that effect, this class deviates from the <cite>timeit</cite> API by
conceptually merging <cite>timeit.Timer.repeat</cite> and <cite>timeit.Timer.autorange</cite>.
(Exact algorithms are discussed in method docstrings.) The <cite>timeit</cite>
method is replicated for cases where an adaptive strategy is not
desired.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Optional metadata:</dt><dd><p>When defining a Timer, one can optionally specify <cite>label</cite>, <cite>sub_label</cite>,
<cite>description</cite>, and <cite>env</cite>. (Defined later) These fields are included in
the representation of result object and by the <cite>Compare</cite> class to group
and display results for comparison.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Instruction counts</dt><dd><p>In addition to wall times, Timer can run a statement under Callgrind
and report instructions executed.</p>
</dd>
</dl>
</li>
</ol>
<p>Directly analogous to <cite>timeit.Timer</cite> constructor arguments:</p>
<blockquote>
<div><p><cite>stmt</cite>, <cite>setup</cite>, <cite>timer</cite>, <cite>globals</cite></p>
</div></blockquote>
<p>PyTorch Timer specific constructor arguments:</p>
<blockquote>
<div><p><cite>label</cite>, <cite>sub_label</cite>, <cite>description</cite>, <cite>env</cite>, <cite>num_threads</cite></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>stmt</strong> – Code snippet to be run in a loop and timed.</p></li>
<li><p><strong>setup</strong> – Optional setup code. Used to define variables used in <cite>stmt</cite></p></li>
<li><p><strong>global_setup</strong> – (C++ only)
Code which is placed at the top level of the file for things like
<cite>#include</cite> statements.</p></li>
<li><p><strong>timer</strong> – Callable which returns the current time. If PyTorch was built
without CUDA or there is no GPU present, this defaults to
<cite>timeit.default_timer</cite>; otherwise it will synchronize CUDA before
measuring the time.</p></li>
<li><p><strong>globals</strong> – A dict which defines the global variables when <cite>stmt</cite> is being
executed. This is the other method for providing variables which
<cite>stmt</cite> needs.</p></li>
<li><p><strong>label</strong> – String which summarizes <cite>stmt</cite>. For instance, if <cite>stmt</cite> is
“torch.nn.functional.relu(torch.add(x, 1, out=out))”
one might set label to “ReLU(x + 1)” to improve readability.</p></li>
<li><p><strong>sub_label</strong> – <p>Provide supplemental information to disambiguate measurements
with identical stmt or label. For instance, in our example
above sub_label might be “float” or “int”, so that it is easy
to differentiate:
“ReLU(x + 1): (float)”</p>
<p>”ReLU(x + 1): (int)”
when printing Measurements or summarizing using <cite>Compare</cite>.</p>
</p></li>
<li><p><strong>description</strong> – <p>String to distinguish measurements with identical label and
sub_label. The principal use of <cite>description</cite> is to signal to
<cite>Compare</cite> the columns of data. For instance one might set it
based on the input size  to create a table of the form:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                        <span class="o">|</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span> <span class="o">|</span> <span class="n">n</span><span class="o">=</span><span class="mi">4</span> <span class="o">|</span> <span class="o">...</span>
                        <span class="o">-------------</span> <span class="o">...</span>
<span class="n">ReLU</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span> <span class="p">(</span><span class="nb">float</span><span class="p">)</span>    <span class="o">|</span> <span class="o">...</span> <span class="o">|</span> <span class="o">...</span> <span class="o">|</span> <span class="o">...</span>
<span class="n">ReLU</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span> <span class="p">(</span><span class="nb">int</span><span class="p">)</span>      <span class="o">|</span> <span class="o">...</span> <span class="o">|</span> <span class="o">...</span> <span class="o">|</span> <span class="o">...</span>
</pre></div>
</div>
<p>using <cite>Compare</cite>. It is also included when printing a Measurement.</p>
</p></li>
<li><p><strong>env</strong> – This tag indicates that otherwise identical tasks were run in
different environments, and are therefore not equivilent, for
instance when A/B testing a change to a kernel. <cite>Compare</cite> will
treat Measurements with different <cite>env</cite> specification as distinct
when merging replicate runs.</p></li>
<li><p><strong>num_threads</strong> – The size of the PyTorch threadpool when executing <cite>stmt</cite>. Single
threaded performace is important as both a key inference workload
and a good indicator of intrinsic algorithmic efficiency, so the
default is set to one. This is in contrast to the default PyTorch
threadpool size which tries to utilize all cores.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="torch.utils.benchmark.Timer.blocked_autorange">
<code class="sig-name descname"><span class="pre">blocked_autorange</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">callback</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_run_time</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.2</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/timer.html#Timer.blocked_autorange"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.Timer.blocked_autorange" title="Permalink to this definition">¶</a></dt>
<dd><p>Measure many replicates while keeping timer overhead to a minimum.</p>
<p>At a high level, blocked_autorange executes the following pseudo-code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>`setup`

total_time = 0
while total_time &lt; min_run_time
    start = timer()
    for _ in range(block_size):
        `stmt`
    total_time += (timer() - start)
</pre></div>
</div>
<p>Note the variable <cite>block_size</cite> in the inner loop. The choice of block
size is important to measurement quality, and must balance two
competing objectives:</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>A small block size results in more replicates and generally
better statistics.</p></li>
<li><p>A large block size better amortizes the cost of <cite>timer</cite>
invocation, and results in a less biased measurement. This is
important because CUDA syncronization time is non-trivial
(order single to low double digit microseconds) and would
otherwise bias the measurement.</p></li>
</ol>
</div></blockquote>
<p>blocked_autorange sets block_size by running a warmup period,
increasing block size until timer overhead is less than 0.1% of
the overall computation. This value is then used for the main
measurement loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>Measurement</cite> object that contains measured runtimes and
repetition counts, and can be used to compute statistics.
(mean, median, etc.)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.utils.benchmark.Timer.collect_callgrind">
<code class="sig-name descname"><span class="pre">collect_callgrind</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">number</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">repeats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">collect_baseline</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain_out_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/timer.html#Timer.collect_callgrind"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.Timer.collect_callgrind" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect instruction counts using Callgrind.</p>
<p>Unlike wall times, instruction counts are deterministic
(modulo non-determinism in the program itself and small amounts of
jitter from the Python interpreter.) This makes them ideal for detailed
performance analysis. This method runs <cite>stmt</cite> in a separate process
so that Valgrind can instrument the program. Performance is severely
degraded due to the instrumentation, however this is ameliorated by
the fact that a small number of iterations is generally sufficient to
obtain good measurements.</p>
<p>In order to to use this method <cite>valgrind</cite>, <cite>callgrind_control</cite>, and
<cite>callgrind_annotate</cite> must be installed.</p>
<p>Because there is a process boundary between the caller (this process)
and the <cite>stmt</cite> execution, <cite>globals</cite> cannot contain arbitrary in-memory
data structures. (Unlike timing methods) Instead, globals are
restricted to builtins, <cite>nn.Modules</cite>’s, and TorchScripted functions/modules
to reduce the surprise factor from serialization and subsequent
deserialization. The <cite>GlobalsBridge</cite> class provides more detail on this
subject. Take particular care with nn.Modules: they rely on pickle and
you may need to add an import to <cite>setup</cite> for them to transfer properly.</p>
<p>By default, a profile for an empty statement will be collected and
cached to indicate how many instructions are from the Python loop which
drives <cite>stmt</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A <cite>CallgrindStats</cite> object which provides instruction counts and
some basic facilities for analyzing and manipulating results.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.utils.benchmark.Timer.timeit">
<code class="sig-name descname"><span class="pre">timeit</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">number</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/timer.html#Timer.timeit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.Timer.timeit" title="Permalink to this definition">¶</a></dt>
<dd><p>Mirrors the semantics of timeit.Timer.timeit().</p>
<p>Execute the main statement (<cite>stmt</cite>) <cite>number</cite> times.
<a class="reference external" href="https://docs.python.org/3/library/timeit.html#timeit.Timer.timeit">https://docs.python.org/3/library/timeit.html#timeit.Timer.timeit</a></p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="torch.utils.benchmark.Measurement">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">torch.utils.benchmark.</span></code><code class="sig-name descname"><span class="pre">Measurement</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">number_per_run</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw_times</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_spec</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/common.html#Measurement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.Measurement" title="Permalink to this definition">¶</a></dt>
<dd><p>The result of a Timer measurement.</p>
<p>This class stores one or more measurements of a given statement. It is
serializable and provides several convenience methods
(including a detailed __repr__) for downstream consumers.</p>
<dl class="py method">
<dt id="torch.utils.benchmark.Measurement.merge">
<em class="property"><span class="pre">static</span> </em><code class="sig-name descname"><span class="pre">merge</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">measurements</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/common.html#Measurement.merge"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.Measurement.merge" title="Permalink to this definition">¶</a></dt>
<dd><p>Convenience method for merging replicates.</p>
<p>Merge will extrapolate times to <cite>number_per_run=1</cite> and will not
transfer any metadata. (Since it might differ between replicates)</p>
</dd></dl>

<dl class="py method">
<dt id="torch.utils.benchmark.Measurement.significant_figures">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">significant_figures</span></code><a class="headerlink" href="#torch.utils.benchmark.Measurement.significant_figures" title="Permalink to this definition">¶</a></dt>
<dd><p>Approximate significant figure estimate.</p>
<p>This property is intended to give a convenient way to estimate the
precision of a measurement. It only uses the interquartile region to
estimate statistics to try to mitigate skew from the tails, and
uses a static z value of 1.645 since it is not expected to be used
for small values of <cite>n</cite>, so z can approximate <cite>t</cite>.</p>
<p>The significant figure estimation used in conjunction with the
<cite>trim_sigfig</cite> method to provide a more human interpretable data
summary. __repr__ does not use this method; it simply displays raw
values. Significant figure estimation is intended for <cite>Compare</cite>.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="torch.utils.benchmark.CallgrindStats">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">torch.utils.benchmark.</span></code><code class="sig-name descname"><span class="pre">CallgrindStats</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">task_spec</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">number_per_run</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">built_with_debug_symbols</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baseline_inclusive_stats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baseline_exclusive_stats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stmt_inclusive_stats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stmt_exclusive_stats</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stmt_callgrind_out</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#CallgrindStats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.CallgrindStats" title="Permalink to this definition">¶</a></dt>
<dd><p>Top level container for Callgrind results collected by Timer.</p>
<p>Manipulation is generally done using the FunctionCounts class, which is
obtained by calling <cite>CallgrindStats.stats(…)</cite>. Several convenience
methods are provided as well; the most significant is
<cite>CallgrindStats.as_standardized()</cite>.</p>
<dl class="py method">
<dt id="torch.utils.benchmark.CallgrindStats.as_standardized">
<code class="sig-name descname"><span class="pre">as_standardized</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#CallgrindStats.as_standardized"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.CallgrindStats.as_standardized" title="Permalink to this definition">¶</a></dt>
<dd><p>Strip library names and some prefixes from function strings.</p>
<p>When comparing two different sets of instruction counts, on stumbling
block can be path prefixes. Callgrind includes the full filepath
when reporting a function (as it should). However, this can cause
issues when diffing profiles. If a key component such as Python
or PyTorch was built in separate locations in the two profiles, which
can result in something resembling:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">23234231</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">first_build_dir</span><span class="o">/</span><span class="n">thing</span><span class="o">.</span><span class="n">c</span><span class="p">:</span><span class="n">foo</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
 <span class="mi">9823794</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">first_build_dir</span><span class="o">/</span><span class="n">thing</span><span class="o">.</span><span class="n">c</span><span class="p">:</span><span class="n">bar</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
  <span class="o">...</span>
   <span class="mi">53453</span> <span class="o">.../</span><span class="n">aten</span><span class="o">/</span><span class="n">src</span><span class="o">/</span><span class="n">Aten</span><span class="o">/...</span><span class="p">:</span><span class="n">function_that_actually_changed</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
  <span class="o">...</span>
 <span class="o">-</span><span class="mi">9823794</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">second_build_dir</span><span class="o">/</span><span class="n">thing</span><span class="o">.</span><span class="n">c</span><span class="p">:</span><span class="n">bar</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="o">-</span><span class="mi">23234231</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">second_build_dir</span><span class="o">/</span><span class="n">thing</span><span class="o">.</span><span class="n">c</span><span class="p">:</span><span class="n">foo</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>Stripping prefixes can ameliorate this issue by regularizing the
strings and causing better cancellation of equivilent call sites
when diffing.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.utils.benchmark.CallgrindStats.counts">
<code class="sig-name descname"><span class="pre">counts</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">denoise</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#CallgrindStats.counts"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.CallgrindStats.counts" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the total number of instructions executed.</p>
<p>See <cite>FunctionCounts.denoise()</cite> for an explation of the <cite>denoise</cite> arg.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.utils.benchmark.CallgrindStats.delta">
<code class="sig-name descname"><span class="pre">delta</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inclusive</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#CallgrindStats.delta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.CallgrindStats.delta" title="Permalink to this definition">¶</a></dt>
<dd><p>Diff two sets of counts.</p>
<p>One common reason to collect instruction counts is to determine the
the effect that a particular change will have on the number of instructions
needed to perform some unit of work. If a change increases that number, the
next logical question is “why”. This generally involves looking at what part
if the code increased in instruction count. This function automates that
process so that one can easily diff counts on both an inclusive and
exclusive basis.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.utils.benchmark.CallgrindStats.stats">
<code class="sig-name descname"><span class="pre">stats</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inclusive</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#CallgrindStats.stats"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.CallgrindStats.stats" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns detailed function counts.</p>
<p>Conceptually, the FunctionCounts returned can be thought of as a tuple
of (count, path_and_function_name) tuples.</p>
<p><cite>inclusive</cite> matches the semantics of callgrind. If True, the counts
include instructions executed by children. <cite>inclusive=True</cite> is useful
for identifying hot spots in code; <cite>inclusive=False</cite> is useful for
reducing noise when diffing counts from two different runs. (See
CallgrindStats.delta(…) for more details)</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="torch.utils.benchmark.FunctionCounts">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">torch.utils.benchmark.</span></code><code class="sig-name descname"><span class="pre">FunctionCounts</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inclusive</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truncate_rows</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_linewidth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#FunctionCounts"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.FunctionCounts" title="Permalink to this definition">¶</a></dt>
<dd><p>Container for manipulating Callgrind results.</p>
<dl class="simple">
<dt>It supports:</dt><dd><ol class="arabic simple">
<li><p>Addition and subtraction to combine or diff results.</p></li>
<li><p>Tuple-like indexing.</p></li>
<li><p>A <cite>denoise</cite> function which strips CPython calls which are known to
be non-deterministic and quite noisy.</p></li>
<li><p>Two higher order methods (<cite>filter</cite> and <cite>transform</cite>) for custom
manipulation.</p></li>
</ol>
</dd>
</dl>
<dl class="py method">
<dt id="torch.utils.benchmark.FunctionCounts.denoise">
<code class="sig-name descname"><span class="pre">denoise</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#FunctionCounts.denoise"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.FunctionCounts.denoise" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove known noisy instructions.</p>
<p>Several instructions in the CPython interpreter are rather noisy. These
instructions involve unicode to dictionary lookups which Python uses to
map variable names. FunctionCounts is generally a content agnostic
container, however this is sufficiently important for obtaining
reliable results to warrant an exception.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.utils.benchmark.FunctionCounts.filter">
<code class="sig-name descname"><span class="pre">filter</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filter_fn</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#FunctionCounts.filter"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.FunctionCounts.filter" title="Permalink to this definition">¶</a></dt>
<dd><p>Keep only the elements where <cite>filter_fn</cite> applied to function name returns True.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.utils.benchmark.FunctionCounts.transform">
<code class="sig-name descname"><span class="pre">transform</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">map_fn</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/benchmark/utils/valgrind_wrapper/timer_interface.html#FunctionCounts.transform"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#torch.utils.benchmark.FunctionCounts.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply <cite>map_fn</cite> to all of the function names.</p>
<p>This can be used to regularize function names (e.g. stripping irrelevant
parts of the file path), coalesce entries by mapping multiple functions
to the same name (in which case the counts are added together), etc.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-torch.utils.benchmark.examples"></span><span class="target" id="module-torch.utils.benchmark.op_fuzzers"></span><span class="target" id="module-torch.utils.benchmark.utils"></span><span class="target" id="module-torch.utils.benchmark.utils.valgrind_wrapper"></span></div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="bottleneck.html" class="btn btn-neutral float-right" title="torch.utils.bottleneck" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="testing.html" class="btn btn-neutral" title="torch.testing" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Benchmark Utils - torch.utils.benchmark</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/clipboard.min.js"></script>
         <script src="_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>


 <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>
      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>
        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>
          </div>
        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        <hr size="20" color="white" />
         <div class="privacy-policy">
            <p class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a>&nbsp;&nbsp; | &nbsp;&nbsp; <a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></p>
        </div>
        <hr size="20" color="white" />
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/" style="color:#ee4c2c">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/" style="color:#ee4c2c">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>
  </footer>
  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>