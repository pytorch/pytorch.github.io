


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.jit &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/jit.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master (1.0.0 )
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          

            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.html#torch-nn-functional">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.html#torch-nn-init">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../multiprocessing.html">torch.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ffi.html">torch.utils.ffi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed_deprecated.html">torch.distributed.deprecated</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../legacy.html">torch.legacy</a></li>
</ul>
<p class="caption"><span class="caption-text">torchvision Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torchvision/index.html">torchvision</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">Module code</a> &gt;</li>
        
          <li><a href="../torch.html">torch</a> &gt;</li>
        
      <li>torch.jit</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.jit</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch._C</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="k">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="k">import</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">function</span>
<span class="kn">from</span> <span class="nn">torch.serialization</span> <span class="k">import</span> <span class="n">validate_cuda_device</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="k">import</span> <span class="n">Module</span><span class="p">,</span> <span class="n">ModuleList</span><span class="p">,</span> <span class="n">ParameterList</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">torch.jit.frontend</span> <span class="k">import</span> <span class="n">get_jit_ast</span><span class="p">,</span> <span class="n">get_default_args</span>
<span class="kn">import</span> <span class="nn">torch.backends.cudnn</span> <span class="k">as</span> <span class="nn">cudnn</span>
<span class="kn">import</span> <span class="nn">torch.jit.annotations</span>
<span class="kn">from</span> <span class="nn">torch._six</span> <span class="k">import</span> <span class="n">raise_from</span><span class="p">,</span> <span class="n">with_metaclass</span><span class="p">,</span> <span class="n">get_function_from_type</span><span class="p">,</span> \
    <span class="n">string_classes</span>
<span class="kn">from</span> <span class="nn">.._jit_internal</span> <span class="k">import</span> <span class="n">createResolutionCallback</span><span class="p">,</span> <span class="n">_compiled_weak_fns</span><span class="p">,</span> \
    <span class="n">_weak_script_methods</span><span class="p">,</span> <span class="n">_weak_modules</span><span class="p">,</span> <span class="n">_weak_types</span><span class="p">,</span> <span class="n">COMPILED</span><span class="p">,</span> \
    <span class="n">COMPILATION_PENDING</span><span class="p">,</span> <span class="n">_boolean_dispatched</span>
<span class="kn">from</span> <span class="nn">..nn.modules.utils</span> <span class="k">import</span> <span class="n">_single</span><span class="p">,</span> <span class="n">_pair</span><span class="p">,</span> <span class="n">_triple</span><span class="p">,</span> <span class="n">_quadruple</span><span class="p">,</span> \
    <span class="n">_list_with_default</span>
<span class="kn">import</span> <span class="nn">torch.testing</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="n">namedtuple</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">weakref</span>
<span class="kn">import</span> <span class="nn">types</span>
<span class="kn">import</span> <span class="nn">contextlib</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">pathlib</span>


<span class="k">def</span> <span class="nf">_parse_env</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">default</span><span class="p">,</span> <span class="n">true_message</span><span class="p">,</span> <span class="n">false_message</span><span class="p">):</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">default</span>
    <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;true&#39;</span><span class="p">,</span> <span class="s1">&#39;yes&#39;</span><span class="p">}:</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="n">value</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;0&#39;</span><span class="p">,</span> <span class="s1">&#39;false&#39;</span><span class="p">,</span> <span class="s1">&#39;no&#39;</span><span class="p">}:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="n">value</span> <span class="o">==</span> <span class="s1">&#39;1v&#39;</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">true_message</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="n">value</span> <span class="o">==</span> <span class="s1">&#39;0v&#39;</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">false_message</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unknown setting of </span><span class="si">{}</span><span class="s1">. Try using 0 or 1.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>


<span class="n">_enabled</span> <span class="o">=</span> <span class="n">_parse_env</span><span class="p">(</span><span class="s1">&#39;PYTORCH_JIT&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;&gt; Using PyTorch JIT&quot;</span><span class="p">,</span> <span class="s2">&quot;&gt; PyTorch JIT DISABLED&quot;</span><span class="p">)</span>
<span class="n">_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_flatten</span>
<span class="n">_unflatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_unflatten</span>
<span class="n">_jit_script_compile</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_script_compile</span>
<span class="n">BatchTensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit</span><span class="o">.</span><span class="n">BatchTensor</span>

<span class="n">Future</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Future</span>
<span class="n">_fork</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">fork</span>
<span class="n">_wait</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">wait</span>


<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">scope</span><span class="p">(</span><span class="n">scope_name</span><span class="p">):</span>
    <span class="n">tracing_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_get_tracing_state</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">tracing_state</span><span class="p">:</span>
        <span class="n">tracing_state</span><span class="o">.</span><span class="n">push_scope</span><span class="p">(</span><span class="n">scope_name</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tracing_state</span><span class="p">:</span>
            <span class="n">tracing_state</span><span class="o">.</span><span class="n">pop_scope</span><span class="p">()</span>


<div class="viewcode-block" id="load"><a class="viewcode-back" href="../../jit.html#torch.jit.load">[docs]</a><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load a ``ScriptModule`` previously saved with :func:`save &lt;torch.jit.save&gt;`</span>

<span class="sd">        All previously saved modules, no matter their device, are first loaded onto CPU,</span>
<span class="sd">        and then are moved to the devices they were saved from. If this fails (e.g. because</span>
<span class="sd">        the run time system doesn&#39;t have certain devices), an exception is raised.</span>
<span class="sd">        However, storages can be dynamically remapped to an alternative set of devices</span>
<span class="sd">        using the `map_location` argument. Comparing to :func:`torch.load`, `map_location`</span>
<span class="sd">        in this function is simplified, which only accepts a string (e.g., &#39;cpu&#39;, &#39;cuda:0&#39;),</span>
<span class="sd">        or torch.device (e.g., torch.device(&#39;cpu&#39;))</span>

<span class="sd">        Arguments:</span>
<span class="sd">            f: a file-like object (has to implement read, readline, tell, and seek),</span>
<span class="sd">                or a string containing a file name</span>
<span class="sd">            map_location: can a string (e.g., &#39;cpu&#39;, &#39;cuda:0&#39;), a device (e.g.,</span>
<span class="sd">                torch.device(&#39;cpu&#39;))</span>

<span class="sd">        Returns:</span>
<span class="sd">            A ``ScriptModule`` object.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; torch.jit.load(&#39;scriptmodule.pt&#39;)</span>
<span class="sd">            # Load ScriptModule from io.BytesIO object</span>
<span class="sd">            &gt;&gt;&gt; with open(&#39;scriptmodule.pt&#39;, &#39;rb&#39;) as f:</span>
<span class="sd">                    buffer = io.BytesIO(f.read())</span>
<span class="sd">            # Load all tensors to the original device</span>
<span class="sd">            &gt;&gt;&gt; torch.jit.load(buffer)</span>
<span class="sd">            # Load all tensors onto CPU, using a device</span>
<span class="sd">            &gt;&gt;&gt; torch.jit.load(buffer, map_location=torch.device(&#39;cpu&#39;))</span>
<span class="sd">            # Load all tensors onto CPU, using a string</span>
<span class="sd">            &gt;&gt;&gt; torch.jit.load(buffer, map_location=&#39;cpu&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">ScriptModule</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">module_lookup</span><span class="p">(</span><span class="n">names</span><span class="p">):</span>
        <span class="n">curr</span> <span class="o">=</span> <span class="n">m</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ScriptModule</span><span class="p">())</span>
            <span class="n">curr</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">curr</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">map_location</span><span class="p">,</span> <span class="n">string_classes</span><span class="p">):</span>
        <span class="n">map_location</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">map_location</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="p">(</span><span class="n">map_location</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span>
              <span class="nb">isinstance</span><span class="p">(</span><span class="n">map_location</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;map_location should be either None, string or torch.device, &quot;</span>
                         <span class="s2">&quot;but got type: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">map_location</span><span class="p">)))</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">map_location</span><span class="p">)</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)):</span>
        <span class="n">validate_cuda_device</span><span class="p">(</span><span class="n">map_location</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> \
            <span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">unicode</span><span class="p">))</span> <span class="ow">or</span> \
            <span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">)):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">import_ir_module</span><span class="p">(</span><span class="n">module_lookup</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">map_location</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">import_ir_module_from_buffer</span><span class="p">(</span><span class="n">module_lookup</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">map_location</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">m</span></div>


<span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Saves a ScriptModule to a file.</span>

<span class="sd">        Args:</span>
<span class="sd">            m: a ScriptModule to save</span>
<span class="sd">            f: a file-like object (has to implement write and flush) or a string</span>
<span class="sd">               containing a file name</span>

<span class="sd">        .. warning::</span>
<span class="sd">            If you are using Python 2, torch.save does NOT support StringIO.StringIO</span>
<span class="sd">            as a valid file-like object. This is because the write method should return</span>
<span class="sd">            the number of bytes written; StringIO.write() does not do this.</span>

<span class="sd">            Please use something like io.BytesIO instead.</span>

<span class="sd">        Example:</span>
<span class="sd">            &gt;&gt;&gt; m = torch.jit.ScriptModule()</span>
<span class="sd">            &gt;&gt;&gt; # Save to file</span>
<span class="sd">            &gt;&gt;&gt; torch.jit.save(m, &#39;scriptmodule.pt&#39;)</span>
<span class="sd">            &gt;&gt;&gt; # Save to io.BytesIO buffer</span>
<span class="sd">            &gt;&gt;&gt; buffer = io.BytesIO()</span>
<span class="sd">            &gt;&gt;&gt; torch.jit.save(m, buffer)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> \
            <span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">unicode</span><span class="p">))</span> <span class="ow">or</span> \
            <span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">)):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">save_to_buffer</span><span class="p">()</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_trace_graph</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(),</span> <span class="n">kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trace a function or model, returning a tuple consisting of the both the</span>
<span class="sd">    *trace* of an execution, as well as the original return value.</span>

<span class="sd">    Tracing is guaranteed not to change the semantics of the function/module</span>
<span class="sd">    that is traced.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        f (torch.nn.Module or function): the function or module</span>
<span class="sd">            to be traced.</span>
<span class="sd">        args (tuple or Tensor): the positional arguments to pass to the</span>
<span class="sd">            function/module to be traced.  A non-tuple is assumed to</span>
<span class="sd">            be a single positional argument to be passed to the model.</span>
<span class="sd">        kwargs (dict): the keyword arguments to pass to the function/module</span>
<span class="sd">            to be traced.</span>

<span class="sd">    Example: Trace a cell.</span>

<span class="sd">        &gt;&gt;&gt; trace, out = jit.trace(nn.LSTMCell(), (input, hidden))</span>
<span class="sd">        &gt;&gt;&gt; print(trace)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">args</span><span class="p">,)</span>
    <span class="k">return</span> <span class="n">LegacyTracedModule</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_unique_state_dict</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(</span><span class="n">keep_vars</span><span class="o">=</span><span class="n">keep_vars</span><span class="p">)</span>
    <span class="n">filtered_dict</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)()</span>
    <span class="n">seen_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">id</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">seen_ids</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">seen_ids</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="n">filtered_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
    <span class="k">return</span> <span class="n">filtered_dict</span>


<span class="k">def</span> <span class="nf">_create_interpreter_name_lookup_fn</span><span class="p">(</span><span class="n">frames_up</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_get_interpreter_name_for_var</span><span class="p">(</span><span class="n">var</span><span class="p">):</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">currentframe</span><span class="p">()</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">frames_up</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">f_back</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">f_locals</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">f_locals</span>
        <span class="n">f_globals</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">f_globals</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">f_locals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">var</span> <span class="ow">is</span> <span class="n">v</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">k</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">f_globals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">var</span> <span class="ow">is</span> <span class="n">v</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">k</span>
        <span class="k">return</span> <span class="s1">&#39;&#39;</span>
    <span class="k">return</span> <span class="n">_get_interpreter_name_for_var</span>


<span class="k">class</span> <span class="nc">LegacyTracedModule</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inner</span><span class="p">,</span> <span class="n">force_outplace</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LegacyTracedModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># inner may be a Module, or it may be an arbitrary callable</span>
        <span class="c1"># If it&#39;s a Module, we get its parameters automatically, which lets</span>
        <span class="c1"># us avoid a special casing functions versus modules.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner</span> <span class="o">=</span> <span class="n">inner</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_force_outplace</span> <span class="o">=</span> <span class="n">force_outplace</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">in_vars</span><span class="p">,</span> <span class="n">in_desc</span> <span class="o">=</span> <span class="n">_flatten</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="c1"># NOTE: use full state, because we need it for BatchNorm export</span>
        <span class="c1"># This differs from the compiler path, which doesn&#39;t support it at the moment.</span>
        <span class="n">module_state</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">_unique_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="n">trace</span><span class="p">,</span> <span class="n">all_trace_inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_enter</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">in_vars</span> <span class="o">+</span> <span class="n">module_state</span><span class="p">))</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_set_force_outplace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_force_outplace</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_set_get_unique_name_fn</span><span class="p">(</span><span class="n">_create_interpreter_name_lookup_fn</span><span class="p">())</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">trace_inputs</span> <span class="o">=</span> <span class="n">_unflatten</span><span class="p">(</span><span class="n">all_trace_inputs</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">in_vars</span><span class="p">)],</span> <span class="n">in_desc</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="o">*</span><span class="n">trace_inputs</span><span class="p">)</span>
            <span class="n">out_vars</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_flatten</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_exit</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">out_vars</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_abandon</span><span class="p">()</span>
            <span class="k">raise</span>
        <span class="k">return</span> <span class="n">trace</span><span class="p">,</span> <span class="n">out</span>


<span class="k">def</span> <span class="nf">_clone_inputs</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">clone_input</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">a</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># TODO: figure out one liner to .clone() and set requires_grad</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">v</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">clone_input</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">v</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">function</span><span class="o">.</span><span class="n">_nested_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">),</span>
                                <span class="n">clone_input</span><span class="p">,</span> <span class="n">condition_msg</span><span class="o">=</span><span class="s2">&quot;tensors&quot;</span><span class="p">)(</span><span class="n">args</span><span class="p">)</span>


<span class="c1"># This is purely for developer debugging.  We are not going to advertise it.</span>
<span class="n">_JIT_DUMP</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PYTORCH_JIT_DUMP&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">_JIT_TIME</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PYTORCH_JIT_TIME&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>  <span class="c1"># CUDA-only timing</span>
<span class="n">_JIT_DISABLE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PYTORCH_JIT_DISABLE&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">_JIT_STATS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PYTORCH_JIT_STATS&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_dump_trace</span><span class="p">(</span><span class="n">trace_name</span><span class="p">,</span> <span class="n">pass_name</span><span class="p">,</span> <span class="n">input_key</span><span class="p">,</span> <span class="n">trace</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_JIT_DUMP</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="kn">import</span> <span class="nn">torch.contrib._graph_vis</span> <span class="k">as</span> <span class="nn">graph_vis</span>

    <span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trace_name</span><span class="p">,</span> <span class="n">pass_name</span><span class="p">)</span>
    <span class="c1"># TODO: Also paste out the backtrace when the trace was compiled</span>
    <span class="c1"># (and maybe also when it was run?)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;.ir&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;Input key: </span><span class="si">{}</span><span class="se">\n\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">input_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">trace</span><span class="p">)))</span>
    <span class="n">graph_vis</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">trace</span><span class="o">.</span><span class="n">graph</span><span class="p">(),</span> <span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;.html&quot;</span><span class="p">)</span>


<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">_time</span><span class="p">(</span><span class="n">trace_name</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">_JIT_TIME</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">time</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="k">yield</span>
        <span class="k">return</span>
    <span class="n">stream</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">stream</span><span class="o">.</span><span class="n">record_event</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">stream</span><span class="o">.</span><span class="n">record_event</span><span class="p">(</span><span class="n">end</span><span class="p">)</span>
        <span class="n">end</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> </span><span class="si">{}</span><span class="s2"> time: </span><span class="si">{}</span><span class="s2"> ms&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trace_name</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">start</span><span class="o">.</span><span class="n">elapsed_time</span><span class="p">(</span><span class="n">end</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">verify</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Verify that a JIT compiled model has the same behavior as its uncompiled</span>
<span class="sd">    version along with its backwards pass.  If your model returns multiple</span>
<span class="sd">    outputs, you must also specify a `loss_fn` to produce a loss for which</span>
<span class="sd">    the backwards will be computed.</span>

<span class="sd">    This function has side-effects (e.g., it executes your model / saves and loads</span>
<span class="sd">    parameters), so don&#39;t expect the model to come out exactly the same as what</span>
<span class="sd">    you passed in.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model (compiled torch.nn.Module or function): the module/function to be</span>
<span class="sd">            verified.  The module/function definition MUST have been decorated with</span>
<span class="sd">            `@torch.jit.compile`.</span>
<span class="sd">        args (tuple or Tensor): the positional arguments to pass to the</span>
<span class="sd">            compiled function/module to be verified.  A non-tuple is assumed to</span>
<span class="sd">            be a single positional argument to be passed to the model.</span>
<span class="sd">        loss_fn (function, optional): the loss function to be applied to</span>
<span class="sd">            the output of the model, before backwards is invoked.  By default,</span>
<span class="sd">            we assume that a model returns a single result, and we :func:`torch.sum`</span>
<span class="sd">            before calling backwards; if this is inappropriate, you can pass your</span>
<span class="sd">            own loss function.  Note that if a model returns a tuple of results,</span>
<span class="sd">            these are passed as separate positional arguments to `loss_fn`.</span>
<span class="sd">        devices (iterable of device IDs, optional): the GPU devices which the</span>
<span class="sd">            compiled module will be run on.  This determines the RNG state we</span>
<span class="sd">            must save when running both compiled and uncompiled versions of the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: In principle, we track device information in our trace, so it</span>
    <span class="c1"># should be possible to check if our execution actually obeyed the &#39;devices&#39;</span>
    <span class="c1"># the user provided.</span>

    <span class="c1"># TODO: Consider adding a utility function to torch.jit to test</span>
    <span class="c1"># for this case</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">CompiledFunction</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Cannot verify an uncompiled module.  Add @torch.jit.compile to compile it&quot;</span><span class="p">)</span>
    <span class="n">is_module</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Module</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">args</span><span class="p">,)</span>

    <span class="n">saved_args</span> <span class="o">=</span> <span class="n">_clone_inputs</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">is_module</span><span class="p">:</span>
        <span class="n">saved_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">run_fwd_bwd</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">force_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">assert_compiled</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="k">if</span> <span class="n">is_module</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="n">in_vars</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_flatten</span><span class="p">((</span><span class="n">args</span><span class="p">,</span> <span class="n">params</span><span class="p">))</span>
        <span class="c1"># We use a special API to reset the trace and compile it from scratch.</span>
        <span class="n">compiled_fn</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">if</span> <span class="n">force_trace</span><span class="p">:</span>
            <span class="n">compiled_fn</span><span class="o">.</span><span class="n">clear_cache</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">assert_compiled</span><span class="p">:</span>
            <span class="n">hits</span> <span class="o">=</span> <span class="n">compiled_fn</span><span class="o">.</span><span class="n">hits</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">assert_compiled</span> <span class="ow">and</span> <span class="n">compiled_fn</span><span class="o">.</span><span class="n">hits</span> <span class="o">==</span> <span class="n">hits</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;failed to use the compiled function&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="p">)</span>
        <span class="k">if</span> <span class="n">loss_fn</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s2">&quot;Model returns </span><span class="si">{}</span><span class="s2"> outputs, but default loss function &quot;</span>
                              <span class="s2">&quot;(torch.sum) can only handle a single output&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)))</span>
        <span class="n">out_vars</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_flatten</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">saved_outs</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">out_vars</span><span class="p">]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="o">*</span><span class="n">out</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">([</span><span class="n">loss</span><span class="p">],</span> <span class="n">in_vars</span><span class="p">)</span>
        <span class="c1"># TODO: I&#39;m not sure if the clone here is necessary but it is safer</span>
        <span class="n">saved_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">saved_outs</span><span class="p">,</span> <span class="n">saved_grads</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">fork_rng</span><span class="p">(</span><span class="n">devices</span><span class="p">,</span> <span class="n">_caller</span><span class="o">=</span><span class="s2">&quot;torch.jit.verify&quot;</span><span class="p">):</span>
        <span class="n">uncompiled_outs</span><span class="p">,</span> <span class="n">uncompiled_grads</span> <span class="o">=</span> <span class="n">run_fwd_bwd</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">force_trace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">has_trace_for</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_module</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">saved_state</span><span class="p">)</span>
    <span class="n">compiled_outs</span><span class="p">,</span> <span class="n">compiled_grads</span> <span class="o">=</span> <span class="n">run_fwd_bwd</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">assert_compiled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">_verify_equal</span><span class="p">(</span><span class="n">uncompiled_outs</span><span class="p">,</span> <span class="n">compiled_outs</span><span class="p">)</span>
    <span class="n">_verify_equal</span><span class="p">(</span><span class="n">uncompiled_grads</span><span class="p">,</span> <span class="n">compiled_grads</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_verify_equal</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">1e-6</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;JIT and real computation mismatch&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">indent</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()])</span>


<span class="k">class</span> <span class="nc">TracingCheckError</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_diff_error</span><span class="p">,</span> <span class="n">tensor_compare_error</span><span class="p">,</span> <span class="n">extra_msg</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s1">&#39;Tracing failed sanity checks!</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">if</span> <span class="n">extra_msg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">+=</span> <span class="n">extra_msg</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">if</span> <span class="n">graph_diff_error</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">+=</span> <span class="s1">&#39;ERROR: Graphs differed across invocations!</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">+=</span> <span class="n">indent</span><span class="p">(</span><span class="n">graph_diff_error</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">if</span> <span class="n">tensor_compare_error</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">+=</span> <span class="s1">&#39;ERROR: Tensor-valued Constant nodes differed in value &#39;</span> \
                            <span class="s1">&#39;across invocations. This often indicates that the tracer has&#39;</span> \
                            <span class="s1">&#39; encountered untraceable code.</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">+=</span> <span class="n">indent</span><span class="p">(</span><span class="n">tensor_compare_error</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TracingCheckError</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>


<span class="c1"># Check the traced module against a set of user-provided validation inputs</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">_check_trace</span><span class="p">(</span><span class="n">check_inputs</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">executor_options</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">check_tolerance</span><span class="p">,</span> <span class="n">force_outplace</span><span class="p">):</span>
    <span class="c1"># Note: tracing is independent of optimizations, which consume the trace</span>
    <span class="n">executor_options</span><span class="p">[</span><span class="s1">&#39;optimize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">for</span> <span class="n">inputs</span> <span class="ow">in</span> <span class="n">check_inputs</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,)</span>
        <span class="n">check_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span>
            <span class="n">func</span><span class="p">,</span>
            <span class="n">_clone_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span>
            <span class="n">check_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">_force_outplace</span><span class="o">=</span><span class="n">force_outplace</span><span class="p">,</span>
            <span class="o">**</span><span class="n">executor_options</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">graph_diagnostic_info</span><span class="p">():</span>
            <span class="n">mod_canonicalized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_pass_canonicalize</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_pass_erase_shape_information</span><span class="p">(</span><span class="n">mod_canonicalized</span><span class="p">)</span>
            <span class="n">check_canonicalized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_pass_canonicalize</span><span class="p">(</span><span class="n">check_mod</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_pass_erase_shape_information</span><span class="p">(</span><span class="n">check_canonicalized</span><span class="p">)</span>

            <span class="n">graph_diff_errors</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">mod_canonicalized</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">str</span><span class="p">(</span><span class="n">check_canonicalized</span><span class="p">):</span>
                <span class="kn">import</span> <span class="nn">difflib</span>
                <span class="n">graph_diff</span> <span class="o">=</span> <span class="n">difflib</span><span class="o">.</span><span class="n">ndiff</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">mod_canonicalized</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span>
                                           <span class="nb">str</span><span class="p">(</span><span class="n">check_canonicalized</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">(</span><span class="kc">True</span><span class="p">))</span>
                <span class="n">graph_diff_errors</span> <span class="o">=</span> <span class="s1">&#39;Graph diff:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">graph_diff</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>

                <span class="k">for</span> <span class="n">n_mod</span><span class="p">,</span> <span class="n">n_check</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mod_canonicalized</span><span class="o">.</span><span class="n">nodes</span><span class="p">(),</span> <span class="n">check_canonicalized</span><span class="o">.</span><span class="n">nodes</span><span class="p">()):</span>
                    <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_mod</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_check</span><span class="p">):</span>
                        <span class="n">graph_diff_errors</span> <span class="o">+=</span> <span class="s1">&#39;First diverging operator:</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">node_diff</span> <span class="o">=</span> <span class="n">difflib</span><span class="o">.</span><span class="n">ndiff</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">n_mod</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span>
                                                  <span class="nb">str</span><span class="p">(</span><span class="n">n_check</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">(</span><span class="kc">True</span><span class="p">))</span>
                        <span class="n">source_printout</span> <span class="o">=</span> <span class="s1">&#39;Node diff:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">node_diff</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">mod_stack</span> <span class="o">=</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">getSourceLocation</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">mod_stack</span><span class="p">:</span>
                            <span class="n">source_printout</span> <span class="o">+=</span> <span class="s1">&#39;Trace source location:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="n">mod_stack</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">check_stack</span> <span class="o">=</span> <span class="n">n_check</span><span class="o">.</span><span class="n">getSourceLocation</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">check_stack</span><span class="p">:</span>
                            <span class="n">source_printout</span> <span class="o">+=</span> <span class="s1">&#39;Check source location:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="n">check_stack</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">graph_diff_errors</span> <span class="o">+=</span> <span class="n">source_printout</span>

                        <span class="k">break</span>  <span class="c1"># For now, only print out the first pair of nodes that diverges</span>

            <span class="n">tensor_compare_errors</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="c1"># Check Tensor-valued constant nodes</span>
            <span class="k">for</span> <span class="n">n_mod</span><span class="p">,</span> <span class="n">n_check</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mod_canonicalized</span><span class="o">.</span><span class="n">nodes</span><span class="p">(),</span> <span class="n">check_canonicalized</span><span class="o">.</span><span class="n">nodes</span><span class="p">()):</span>
                <span class="k">if</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">kind</span><span class="p">()</span> <span class="o">!=</span> <span class="n">n_check</span><span class="o">.</span><span class="n">kind</span><span class="p">():</span>
                    <span class="k">break</span>  <span class="c1"># Graphs have already diverged</span>

                <span class="k">if</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">kind</span><span class="p">()</span> <span class="o">==</span> <span class="n">n_check</span><span class="o">.</span><span class="n">kind</span><span class="p">()</span> <span class="ow">and</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">kind</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;prim::Constant&#39;</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">kindOf</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span> <span class="o">!=</span> <span class="s1">&#39;t&#39;</span> <span class="ow">or</span> <span class="n">n_check</span><span class="o">.</span><span class="n">kindOf</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span> <span class="o">!=</span> <span class="s1">&#39;t&#39;</span><span class="p">:</span>
                        <span class="k">continue</span>

                    <span class="n">mod_tensor_val</span> <span class="o">=</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span>
                    <span class="n">check_tensor_val</span> <span class="o">=</span> <span class="n">n_check</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">mod_tensor_val</span><span class="p">,</span> <span class="n">check_tensor_val</span><span class="p">)</span>
                    <span class="k">except</span> <span class="p">(</span><span class="ne">RuntimeError</span><span class="p">,</span> <span class="ne">AssertionError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">tensor_compare_errors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">tensor_compare_errors</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
                        <span class="n">tensor_compare_errors</span> <span class="o">+=</span> <span class="s1">&#39;Node:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">n_mod</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">compare_stack</span> <span class="o">=</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">getSourceLocation</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">compare_stack</span><span class="p">:</span>
                            <span class="n">tensor_compare_errors</span> <span class="o">+=</span> <span class="s1">&#39;Source Location:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="n">compare_stack</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">tensor_compare_errors</span> <span class="o">+=</span> <span class="s1">&#39;Comparison exception: &#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>

                        <span class="k">break</span>  <span class="c1"># For now, only print the first diverging pair</span>

            <span class="k">return</span> <span class="n">graph_diff_errors</span><span class="p">,</span> <span class="n">tensor_compare_errors</span>

        <span class="k">def</span> <span class="nf">wrap_retval</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">x</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>

        <span class="k">def</span> <span class="nf">run_mod_and_filter_tensor_outputs</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">running_what</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">outs</span> <span class="o">=</span> <span class="n">wrap_retval</span><span class="p">(</span><span class="n">mod</span><span class="p">(</span><span class="o">*</span><span class="n">_clone_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)))</span>
                <span class="n">outs</span> <span class="o">=</span> <span class="p">[</span><span class="n">out</span> <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">outs</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)]</span>
                <span class="k">return</span> <span class="n">outs</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">TracingCheckError</span><span class="p">(</span><span class="o">*</span><span class="n">graph_diagnostic_info</span><span class="p">(),</span>
                                        <span class="n">extra_msg</span><span class="o">=</span><span class="s1">&#39;Encountered an exception while running the &#39;</span> <span class="o">+</span> <span class="n">running_what</span> <span class="o">+</span>
                                                  <span class="s1">&#39; with test inputs.</span><span class="se">\n</span><span class="s1">Exception:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)))</span>

        <span class="n">has_warned</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">maybe_warn_nondeterministic</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">has_warned</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="k">return</span>
            <span class="n">has_warned</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">nondeterm_ops</span> <span class="o">=</span> <span class="p">[</span><span class="n">op</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">()</span> <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">isNondeterministic</span><span class="p">()]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nondeterm_ops</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">nondeterministic_ops_warning</span> <span class="o">=</span> <span class="s2">&quot;Trace had nondeterministic nodes. Nodes:</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">nondeterministic_ops_warning</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">indent</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">op</span><span class="p">))</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">nondeterm_ops</span><span class="p">][:</span><span class="mi">20</span><span class="p">])</span>
                <span class="n">nondeterministic_ops_warning</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">This may cause errors in trace checking. To disable trace checking,&quot;</span>\
                                                <span class="s2">&quot; pass check_trace=False to torch.jit.trace()&quot;</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">nondeterministic_ops_warning</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">TracerWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">compare_outputs</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">match_what</span><span class="p">):</span>
            <span class="n">all_ok</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">orig</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">reference</span><span class="p">)):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">orig</span><span class="o">.</span><span class="n">double</span><span class="p">(),</span> <span class="n">ref</span><span class="o">.</span><span class="n">double</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="n">check_tolerance</span><span class="p">,</span>
                                                  <span class="n">atol</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">_get_default_tolerance</span><span class="p">(</span><span class="n">orig</span><span class="p">,</span> <span class="n">ref</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
                <span class="k">except</span> <span class="ne">AssertionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">maybe_warn_nondeterministic</span><span class="p">()</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Output nr &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;. of the traced function does not match &#39;</span>
                                  <span class="s1">&#39;the corresponding output of the &#39;</span> <span class="o">+</span> <span class="n">match_what</span> <span class="o">+</span> <span class="s1">&#39;. Detailed error:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">),</span>
                                  <span class="n">category</span><span class="o">=</span><span class="n">TracerWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
                    <span class="n">all_ok</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">return</span> <span class="n">all_ok</span>

        <span class="n">traced_outs</span> <span class="o">=</span> <span class="n">run_mod_and_filter_tensor_outputs</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="s1">&#39;trace&#39;</span><span class="p">)</span>
        <span class="n">fn_outs</span> <span class="o">=</span> <span class="n">run_mod_and_filter_tensor_outputs</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="s1">&#39;Python function&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">compare_outputs</span><span class="p">(</span><span class="n">traced_outs</span><span class="p">,</span> <span class="n">fn_outs</span><span class="p">,</span> <span class="s1">&#39;Python function&#39;</span><span class="p">):</span>
            <span class="n">check_outs</span> <span class="o">=</span> <span class="n">run_mod_and_filter_tensor_outputs</span><span class="p">(</span><span class="n">check_mod</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="s1">&#39;repeated trace&#39;</span><span class="p">)</span>
            <span class="n">compare_outputs</span><span class="p">(</span><span class="n">traced_outs</span><span class="p">,</span> <span class="n">check_outs</span><span class="p">,</span> <span class="s1">&#39;repeated trace&#39;</span><span class="p">)</span>

        <span class="n">diag_info</span> <span class="o">=</span> <span class="n">graph_diagnostic_info</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">info</span> <span class="ow">in</span> <span class="n">diag_info</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">TracingCheckError</span><span class="p">(</span><span class="o">*</span><span class="n">diag_info</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TracerWarning</span><span class="p">(</span><span class="ne">Warning</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">ignore_lib_warnings</span><span class="p">():</span>
        <span class="c1"># We ignore warnings from all submodules excluding the JIT, because we need them e.g. for _check_trace</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">TracerWarning</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s1">&#39;torch.(?!jit)&#39;</span><span class="p">)</span>


<span class="c1"># We ignore the tracer warnings coming form inside the library, because all our shape</span>
<span class="c1"># checks in nn will trigger them.</span>
<span class="n">TracerWarning</span><span class="o">.</span><span class="n">ignore_lib_warnings</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_warn_use_python</span><span class="p">()</span>


<div class="viewcode-block" id="trace"><a class="viewcode-back" href="../../jit.html#torch.jit.trace">[docs]</a><span class="k">def</span> <span class="nf">trace</span><span class="p">(</span><span class="n">func</span><span class="p">,</span>
          <span class="n">example_inputs</span><span class="p">,</span>
          <span class="n">optimize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">check_trace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">check_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">check_tolerance</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
          <span class="n">_force_outplace</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trace a function and return an executable trace that will be optimized</span>
<span class="sd">    using just-in-time compilation.</span>

<span class="sd">    .. warning::</span>

<span class="sd">        Tracing only correctly records functions and modules which are not data</span>
<span class="sd">        dependent (e.g., have conditionals on data in tensors) and do not have</span>
<span class="sd">        any untracked external dependencies (e.g., perform input/output or</span>
<span class="sd">        access global variables). If you trace such models, you may silently get</span>
<span class="sd">        incorrect results on subsequent invocations of the model. The tracer</span>
<span class="sd">        will try to emit warnings when doing something that may cause an</span>
<span class="sd">        incorrect trace to be produced.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        func (callable or torch.nn.Module):  a python function or torch.nn.Module</span>
<span class="sd">                                             that will be run with example_inputs.</span>
<span class="sd">                                             arguments and returns to func must be Tensors</span>
<span class="sd">                                             or (possibly nested) tuples that</span>
<span class="sd">                                             contain tensors.</span>
<span class="sd">        example_inputs (tuple):  a tuple of example inputs that will be passed to the function</span>
<span class="sd">                                 while tracing. The resulting trace can be run with</span>
<span class="sd">                                 inputs of different types and shapes assuming the traced operations</span>
<span class="sd">                                 support those types and shapes. example_inputs may also be a single</span>
<span class="sd">                                 Tensor in which case it is automatically wrapped in a tuple</span>

<span class="sd">    Keyword arguments:</span>
<span class="sd">        optimize (bool, optional): whether or not to apply optimizations.  Default: ``True``.</span>
<span class="sd">        check_trace (bool, optional): check if the same inputs run through</span>
<span class="sd">                                      traced code produce the same outputs. Default: ``True``. You might want</span>
<span class="sd">                                      to disable this if, for example, your network contains non-</span>
<span class="sd">                                      deterministic ops or if you are sure that the network is correct despite</span>
<span class="sd">                                      a checker failure.</span>

<span class="sd">        check_inputs (list of tuples, optional): A list of tuples of input arguments that should be used</span>
<span class="sd">                                                 to check the trace against what is expected. Each tuple</span>
<span class="sd">                                                 is equivalent to a seet of input arguments that would</span>
<span class="sd">                                                 be specified in ``args``. For best results, pass in a</span>
<span class="sd">                                                 set of checking inputs representative of the space of</span>
<span class="sd">                                                 shapes and types of inputs you expect the network to see.</span>
<span class="sd">                                                 If not specified, the original ``args`` is used for checking</span>
<span class="sd">        check_tolerance (float, optional): Floating-point comparison tolerance to use in the checker procedure.</span>
<span class="sd">                                           This can be used to relax the checker strictness in the event that</span>
<span class="sd">                                           results diverge numerically for a known reason, such as operator fusion.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A ``ScriptModule`` object with a single ``forward()`` method containing the traced code.</span>
<span class="sd">        When func is a ``torch.nn.Module``, the returned ``ScriptModule`` will have the same set of</span>
<span class="sd">        sub-modules and parameters as func.</span>

<span class="sd">    Example:</span>
<span class="sd">       &gt;&gt;&gt; def f(x):</span>
<span class="sd">       ...     return x * 2</span>
<span class="sd">       &gt;&gt;&gt; traced_f = torch.jit.trace(f, torch.rand(1))</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_enabled</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">func</span>
    <span class="n">executor_options</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;optimize&#39;</span><span class="p">:</span> <span class="nb">bool</span><span class="p">(</span><span class="n">optimize</span><span class="p">)}</span>
    <span class="c1"># Special case for common case of passing a single Tensor</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">example_inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">example_inputs</span><span class="p">,)</span>
    <span class="c1"># done primarily so that weird iterables fail here and not pybind11 code</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">example_inputs</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">)</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">TopLevelTracedModule</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="o">**</span><span class="n">executor_options</span><span class="p">)</span>
    <span class="n">var_lookup_fn</span> <span class="o">=</span> <span class="n">_create_interpreter_name_lookup_fn</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">module</span><span class="o">.</span><span class="n">_create_method_from_trace</span><span class="p">(</span><span class="s1">&#39;forward&#39;</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">,</span>
                                     <span class="n">var_lookup_fn</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">)</span>

    <span class="c1"># Check the trace against new traces created from user-specified inputs</span>
    <span class="k">if</span> <span class="n">check_trace</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">check_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_check_trace</span><span class="p">(</span><span class="n">check_inputs</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">executor_options</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">check_tolerance</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_check_trace</span><span class="p">([</span><span class="n">example_inputs</span><span class="p">],</span> <span class="n">func</span><span class="p">,</span> <span class="n">executor_options</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">check_tolerance</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">module</span></div>


<span class="k">class</span> <span class="nc">CompilationUnit</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">_frames_up</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">ScriptModule</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_set_optimized</span><span class="p">(</span><span class="n">optimize</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">lang</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">_frames_up</span><span class="o">=</span><span class="n">_frames_up</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimize</span> <span class="o">=</span> <span class="n">optimize</span>

    <span class="k">def</span> <span class="nf">define</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">rcb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_frames_up</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">rcb</span><span class="p">:</span>
            <span class="n">rcb</span> <span class="o">=</span> <span class="n">createResolutionCallback</span><span class="p">(</span><span class="n">_frames_up</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_define</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">rcb</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_get_method</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_try_get_dispatched_fn</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">_boolean_dispatched</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_try_compile_weak_script</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
    <span class="n">entry</span> <span class="o">=</span> <span class="n">_compiled_weak_fns</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">entry</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">entry</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">COMPILATION_PENDING</span><span class="p">:</span>
        <span class="n">compiled_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">script</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">entry</span><span class="p">[</span><span class="s2">&quot;rcb&quot;</span><span class="p">])</span>
        <span class="k">del</span> <span class="n">entry</span><span class="p">[</span><span class="s2">&quot;rcb&quot;</span><span class="p">]</span>
        <span class="n">_compiled_weak_fns</span><span class="p">[</span><span class="n">fn</span><span class="p">][</span><span class="s2">&quot;compiled_fn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">compiled_fn</span>
        <span class="n">entry</span><span class="p">[</span><span class="s2">&quot;status&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">COMPILED</span>
        <span class="k">return</span> <span class="n">compiled_fn</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">entry</span><span class="p">[</span><span class="s2">&quot;compiled_fn&quot;</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">script</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">_frames_up</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">_rcb</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_enabled</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fn</span>
    <span class="k">if</span> <span class="n">_rcb</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_rcb</span> <span class="o">=</span> <span class="n">createResolutionCallback</span><span class="p">(</span><span class="n">_frames_up</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ast</span> <span class="o">=</span> <span class="n">get_jit_ast</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">is_method</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">mod</span> <span class="o">=</span> <span class="n">ScriptModule</span><span class="p">()</span>
    <span class="n">_jit_script_compile</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">ast</span><span class="p">,</span> <span class="n">_rcb</span><span class="p">,</span> <span class="n">get_default_args</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span>
    <span class="c1"># Forward docstrings</span>
    <span class="n">mod</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="vm">__doc__</span>
    <span class="k">return</span> <span class="n">mod</span>

<span class="n">ScriptMethodStub</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;ScriptMethodStub&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;resolution_callback&#39;</span><span class="p">,</span> <span class="s1">&#39;def_&#39;</span><span class="p">,</span> <span class="s1">&#39;original_method&#39;</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">script_method</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">_rcb</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_enabled</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fn</span>
    <span class="c1"># NOTE: we need to traverse two frames here because the meta-class frame</span>
    <span class="c1"># for ScriptModule will be present, as opposed to invoking @script on a</span>
    <span class="c1"># a function or invoking define() on a CompilationUnit.</span>
    <span class="c1"># The stack will look like:</span>
    <span class="c1">#</span>
    <span class="c1"># 0. createResolutionCallback()</span>
    <span class="c1"># 1. script_method()</span>
    <span class="c1"># 2. ScriptModule metaclass frame</span>
    <span class="c1"># 3. Surrounding scope</span>
    <span class="c1">#</span>
    <span class="c1"># createResolutionCallback internally adds 1 to get us to the scope of this</span>
    <span class="c1"># function (the calling function). Adding 2 gets us to the proper surrounding scope.</span>
    <span class="k">if</span> <span class="n">_rcb</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_rcb</span> <span class="o">=</span> <span class="n">createResolutionCallback</span><span class="p">(</span><span class="n">frames_up</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ast</span> <span class="o">=</span> <span class="n">get_jit_ast</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">is_method</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ScriptMethodStub</span><span class="p">(</span><span class="n">_rcb</span><span class="p">,</span> <span class="n">ast</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_try_get_weak_module</span><span class="p">(</span><span class="n">mod</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the WeakScriptModuleProxy corresponding to mod if it exists</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">Module</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">_weak_modules</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_is_weak_type</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check if a type has been annotated with `weak_module`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">cls</span> <span class="ow">in</span> <span class="n">_weak_types</span>


<span class="k">def</span> <span class="nf">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">_frames_up</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">decorator</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_enabled</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">fn</span>
        <span class="kn">import</span> <span class="nn">torch.jit.batchop</span>
        <span class="n">mod</span> <span class="o">=</span> <span class="n">script</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">optimize</span><span class="p">,</span> <span class="n">_frames_up</span><span class="p">)</span>
        <span class="n">res_graph</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">to_batch_graph</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
        <span class="n">res_mod</span> <span class="o">=</span> <span class="n">ScriptModule</span><span class="p">()</span>
        <span class="n">res_mod</span><span class="o">.</span><span class="n">_create_method_from_graph</span><span class="p">(</span><span class="s1">&#39;forward&#39;</span><span class="p">,</span> <span class="n">res_graph</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">wrapper</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">):</span>
            <span class="n">new_args</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="n">arg</span> <span class="o">=</span> <span class="n">BatchTensor</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">BatchTensor</span><span class="p">):</span>
                    <span class="n">new_args</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">arg</span><span class="o">.</span><span class="n">get_data</span><span class="p">(),</span> <span class="n">arg</span><span class="o">.</span><span class="n">get_mask</span><span class="p">(),</span> <span class="n">arg</span><span class="o">.</span><span class="n">get_dims</span><span class="p">()])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">new_args</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
            <span class="n">res</span> <span class="o">=</span> <span class="n">res_mod</span><span class="p">(</span><span class="o">*</span><span class="n">new_args</span><span class="p">)</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="o">%</span> <span class="mi">3</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="s2">&quot;non-batched-tensor output is not supported yet&quot;</span>
            <span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">BatchTensor</span><span class="p">(</span><span class="o">*</span><span class="n">res</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="mi">3</span><span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">+</span> <span class="mi">3</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">res</span><span class="p">)</span> <span class="o">//</span> <span class="mi">3</span><span class="p">)]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="n">wrapper</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="vm">__doc__</span>
        <span class="k">return</span> <span class="n">wrapper</span>
    <span class="k">return</span> <span class="n">decorator</span>


<span class="c1"># These OrderedDictWrapper classes replace the actual OrderedDicts in</span>
<span class="c1"># module with versions that get/set properties inside of script::Module.</span>
<span class="c1"># This allows us to reuse most of nn.Module while still storing the</span>
<span class="c1"># data in C++.</span>
<span class="c1"># Each OrderedDict needs to support:</span>
<span class="c1">#  x not in view</span>
<span class="c1">#  x in view</span>
<span class="c1">#  view[name] = ...</span>
<span class="c1">#  view.values()</span>
<span class="c1">#  del view[name]</span>
<span class="c1">#  view.items()</span>
<span class="c1">#  view.keys()</span>
<span class="c1">#  len(view)</span>

<span class="k">class</span> <span class="nc">OrderedDictWrapper</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module_ref</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">module</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module_ref</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;_parameters or _modules alive after module is dead&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>

    <span class="k">def</span> <span class="nf">values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>

    <span class="k">def</span> <span class="nf">__delitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot delete methods or parameters of a script module&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>


<span class="k">class</span> <span class="nc">OrderedModuleDict</span><span class="p">(</span><span class="n">OrderedDictWrapper</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OrderedModuleDict</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
        <span class="c1"># contains _both_ script modules and non-script python-only modules</span>

        <span class="c1"># because script modules are subclassed in python and the</span>
        <span class="c1"># C++ script::Module class will not hold references to them,</span>
        <span class="c1"># to ensure that you always get the same python value here</span>
        <span class="c1"># we store it in the python dict as well</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="k">def</span> <span class="nf">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span>

    <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot re-assign modules in a ScriptModule&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ScriptModule</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_register_module</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">OrderedParameterDict</span><span class="p">(</span><span class="n">OrderedDictWrapper</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OrderedParameterDict</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="n">is_buffer</span>
                <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_get_parameters</span><span class="p">()</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">is_buffer</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_register_parameter</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_has_parameter</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_get_parameter</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">OrderedBufferDict</span><span class="p">(</span><span class="n">OrderedDictWrapper</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OrderedBufferDict</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="n">is_buffer</span>
                <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_get_parameters</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">is_buffer</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_register_parameter</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_has_buffer</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_get_parameter</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

<span class="c1"># base types that can be constants</span>
<span class="c1"># in addition, tuples and lists of these base types are also considered constants</span>
<span class="c1"># If you edit this list, then you also need to edit the handlers in</span>
<span class="c1"># ConstantValue in jit/script/init.cpp</span>
<span class="n">_constant_types</span> <span class="o">=</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="n">types</span><span class="o">.</span><span class="n">FunctionType</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_valid_constant</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">_constant_types</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">v</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">_get_valid_constant</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="p">)</span>
    <span class="n">constants</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">typ</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">typ</span> <span class="ow">in</span> <span class="n">_constant_types</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
        <span class="s2">&quot;&#39;</span><span class="si">{}</span><span class="s2">&#39; object for attribute &#39;</span><span class="si">{}</span><span class="s2">&#39; &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span> <span class="o">+</span>
        <span class="s2">&quot;is not a valid constant.</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span>
        <span class="s2">&quot;Valid constants are:</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span>
        <span class="s2">&quot;  1. a nn.ModuleList</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span>
        <span class="s2">&quot;  2. a value of type {{</span><span class="si">{}</span><span class="s2">}}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">constants</span><span class="p">)</span> <span class="o">+</span>
        <span class="s2">&quot;  3. a list or tuple of (2)</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_create_methods_from_stubs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stubs</span><span class="p">):</span>
    <span class="n">defs</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">def_</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">stubs</span><span class="p">]</span>
    <span class="n">rcbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">resolution_callback</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">stubs</span><span class="p">]</span>
    <span class="n">defaults</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_default_args</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">original_method</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">stubs</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_create_methods</span><span class="p">(</span><span class="n">defs</span><span class="p">,</span> <span class="n">rcbs</span><span class="p">,</span> <span class="n">defaults</span><span class="p">)</span>

<span class="c1"># For each user-defined class that subclasses ScriptModule this meta-class,</span>
<span class="c1"># (1) finds all the methods annotated with @script_method</span>
<span class="c1"># in a ScriptModule and removes them from the class attributes, and</span>
<span class="c1"># (2) puts a wrapper around the class&#39;s __init__ method to register</span>
<span class="c1"># all of the script_methods with the module after the original __init__</span>
<span class="c1"># has run. This has to occur after the user-defined __init__ so that</span>
<span class="c1"># submodules and parameters are initialized _before_ the script compiler</span>
<span class="c1"># resolve references to `self.param` or `self.module`.</span>


<span class="k">class</span> <span class="nc">ScriptMeta</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">ScriptModule</span><span class="p">)):</span>
    <span class="c1"># this has to inherit from pybind11&#39;s metaclass otherwise we get</span>
    <span class="c1"># issues because ScriptModule inherits from torch._C.ScriptModule,</span>
    <span class="c1"># a pybind11 type</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">bases</span><span class="p">,</span> <span class="n">attrs</span><span class="p">):</span>
        <span class="c1"># find all the script methods</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_original_methods</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">methods</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">attrs</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ScriptMethodStub</span><span class="p">):</span>
                <span class="nb">delattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
                <span class="n">methods</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">_original_methods</span><span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">original_method</span><span class="o">.</span><span class="vm">__name__</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">original_method</span>
        <span class="c1"># after the user&#39;s __init__ register all the script methods</span>
        <span class="c1"># with the module</span>
        <span class="n">original_init</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s1">&#39;__init__&#39;</span><span class="p">,</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">super_constants</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="nb">super</span><span class="p">(</span><span class="bp">cls</span><span class="p">),</span> <span class="s1">&#39;_constants_set&#39;</span><span class="p">,</span> <span class="nb">set</span><span class="p">())</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_constants_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s1">&#39;__constants__&#39;</span><span class="p">,</span> <span class="p">()))</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">super_constants</span><span class="p">)</span>

        <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">original_init</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">init_then_register</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="c1"># ensure even if the user forgets to call super that</span>
            <span class="c1"># the pybind object is initialized so it will not segfault</span>
            <span class="c1"># run this once, before the most-derived __init__ is called</span>
            <span class="k">if</span> <span class="bp">cls</span> <span class="ow">is</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">ScriptModule</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">original_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">_create_methods_from_stubs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">methods</span><span class="p">)</span>

        <span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span> <span class="o">=</span> <span class="n">init_then_register</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">ScriptMeta</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">bases</span><span class="p">,</span> <span class="n">attrs</span><span class="p">)</span>


<span class="k">if</span> <span class="n">_enabled</span><span class="p">:</span>
<div class="viewcode-block" id="ScriptModule"><a class="viewcode-back" href="../../jit.html#torch.jit.ScriptModule">[docs]</a>    <span class="k">class</span> <span class="nc">ScriptModule</span><span class="p">(</span><span class="n">with_metaclass</span><span class="p">(</span><span class="n">ScriptMeta</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="n">Module</span><span class="p">)):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The core data structure in Torch Script is the ``ScriptModule``. It is an</span>
<span class="sd">        analogue of torch&#39;s nn.Module and represents an entire model as a tree of</span>
<span class="sd">        submodules. Like normal modules, each individual module in a ScriptModule can</span>
<span class="sd">        have submodules, parameters, and methods. In nn.Modules methods are implemented</span>
<span class="sd">        as Python functions, but in ScriptModules methods typically implemented as</span>
<span class="sd">        *Torch Script* functions,  a statically-typed subset of Python that contains all</span>
<span class="sd">        of PyTorch&#39;s built-in Tensor operations. This difference allows your</span>
<span class="sd">        ScriptModules code to run without the need for a Python interpreter.</span>

<span class="sd">        ScriptModules and the Torch Script functions inside of them can be created in</span>
<span class="sd">        two ways:</span>

<span class="sd">        **Tracing:**</span>

<span class="sd">            Using ``torch.jit.trace``, you can take an existing module or python</span>
<span class="sd">            function, provide example inputs, and we run the function, recording the</span>
<span class="sd">            operations performed on all the tensors. We turn the resulting recording</span>
<span class="sd">            into a Torch Script method that is installed as the ``forward`` method of a</span>
<span class="sd">            ScriptModule. This module also contains any parameters that the original</span>
<span class="sd">            module had as well.</span>

<span class="sd">            Example::</span>

<span class="sd">                import torch</span>
<span class="sd">                def foo(x, y):</span>
<span class="sd">                    return 2*x + y</span>
<span class="sd">                traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))</span>

<span class="sd">            .. note::</span>
<span class="sd">                Tracing a *function* will produce a ``ScriptModule`` with a single</span>
<span class="sd">                ``forward`` method that implements that function, and that contains</span>
<span class="sd">                no parameters.</span>

<span class="sd">            Example::</span>

<span class="sd">                import torch</span>
<span class="sd">                import torchvision</span>
<span class="sd">                traced_net = torch.jit.trace(torchvision.models.resnet18(),</span>
<span class="sd">                                             torch.rand(1, 3, 224, 224))</span>

<span class="sd">            .. note::</span>

<span class="sd">                Tracing only records operations done when the given function is run on the given</span>
<span class="sd">                tensors. Therefore, the returned ``ScriptModule`` will always run the same traced</span>
<span class="sd">                graph on any input. This has some important implications when your module is</span>
<span class="sd">                expected to run different sets of operations, depending on the input and/or the</span>
<span class="sd">                module state. For example,</span>

<span class="sd">                    + Tracing will not record any control-flow like if statements or loops. When</span>
<span class="sd">                      this control-flow is constant across your module, this is fine and it often</span>
<span class="sd">                      just inlines configuration decisions. But sometimes the control-flow is</span>
<span class="sd">                      actually part of the model itself. For instance, a beam search in</span>
<span class="sd">                      sequence-to-sequence translation is a loop over the (varying) sequence</span>
<span class="sd">                      length of inputs.</span>

<span class="sd">                    + In the returned ``ScriptModule``, operations that have different behaviors</span>
<span class="sd">                      in ``training`` and ``eval`` modes will always behave as if it is in the</span>
<span class="sd">                      mode it was in during tracing, no matter which mode the ``ScriptModule``</span>
<span class="sd">                      is in.</span>

<span class="sd">                In cases like these, tracing would not be appropriate and scripting is a better</span>
<span class="sd">                choice.</span>

<span class="sd">        **Scripting:**</span>

<span class="sd">            You can write Torch Script code directly using Python syntax. You do this</span>
<span class="sd">            using the ``torch.jit.script`` annotation (for functions) or</span>
<span class="sd">            ``torch.jit.script_method`` annotation (for methods) on subclasses of</span>
<span class="sd">            ScriptModule. With this annotation the body of the annotated function is</span>
<span class="sd">            directly translated into Torch Script. Torch Script itself is a subset of</span>
<span class="sd">            the Python language, so not all features in python work, but we provide</span>
<span class="sd">            enough functionality to compute on tensors and do control-dependent</span>
<span class="sd">            operations.</span>

<span class="sd">            Example::</span>

<span class="sd">                import torch</span>
<span class="sd">                @torch.jit.script</span>
<span class="sd">                def foo(x, y):</span>
<span class="sd">                    if x.max() &gt; y.max():</span>
<span class="sd">                        r = x</span>
<span class="sd">                    else:</span>
<span class="sd">                        r = y</span>
<span class="sd">                    return r</span>

<span class="sd">            .. note::</span>
<span class="sd">                A script *function* annotation will construct a ScriptModule</span>
<span class="sd">                with a single ``forward`` method that implements that function,</span>
<span class="sd">                and that contains no parameters.</span>

<span class="sd">            Example::</span>

<span class="sd">              import torch</span>
<span class="sd">              class MyModule(torch.jit.ScriptModule):</span>
<span class="sd">                  def __init__(self, N, M):</span>
<span class="sd">                      super(MyModule, self).__init__()</span>
<span class="sd">                      self.weight = torch.nn.Parameter(torch.rand(N, M))</span>

<span class="sd">                  @torch.jit.script_method</span>
<span class="sd">                  def forward(self, input):</span>
<span class="sd">                      return self.weight.mv(input)</span>

<span class="sd">            Example::</span>

<span class="sd">                import torch</span>
<span class="sd">                import torch.nn as nn</span>
<span class="sd">                import torch.nn.functional as F</span>
<span class="sd">                from torch.jit import ScriptModule, script_method, trace</span>

<span class="sd">                class MyScriptModule(ScriptModule):</span>
<span class="sd">                    def __init__(self):</span>
<span class="sd">                        super(MyScriptModule, self).__init__()</span>
<span class="sd">                        # trace produces a ScriptModule&#39;s conv1 and conv2</span>
<span class="sd">                        self.conv1 = trace(nn.Conv2d(1, 20, 5), torch.rand(1, 1, 16, 16))</span>
<span class="sd">                        self.conv2 = trace(nn.Conv2d(20, 20, 5), torch.rand(1, 20, 16, 16))</span>

<span class="sd">                    @script_method</span>
<span class="sd">                    def forward(self, input):</span>
<span class="sd">                      input = F.relu(self.conv1(input))</span>
<span class="sd">                      input = F.relu(self.conv2(input))</span>
<span class="sd">                      return input</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="c1"># must be before Module.init since the field is used in __getattr__</span>
            <span class="n">Module</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_optimized</span><span class="p">(</span><span class="n">optimize</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="n">OrderedParameterDict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span> <span class="o">=</span> <span class="n">OrderedBufferDict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span> <span class="o">=</span> <span class="n">OrderedModuleDict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_method</span><span class="p">(</span><span class="n">attr</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">attr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">_original_methods</span><span class="p">:</span>
                    <span class="n">original_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">_original_methods</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span>
                    <span class="n">script_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_method</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">original_method</span><span class="p">)(</span><span class="n">script_method</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_method</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">attr</span> <span class="o">==</span> <span class="s1">&#39;graph&#39;</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_method</span><span class="p">(</span><span class="s1">&#39;forward&#39;</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="s1">&#39;forward&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">graph</span>
            <span class="k">return</span> <span class="n">Module</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">attr</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constants_set</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Module</span><span class="p">)</span> <span class="ow">and</span> <span class="n">_is_weak_type</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">)):</span>
                    <span class="c1"># Compile weak script module</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">_make_strong</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">attr</span> <span class="o">==</span> <span class="s1">&#39;training&#39;</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_buffer</span><span class="p">(</span><span class="s1">&#39;training&#39;</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s1">&#39;training&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_get_parameter</span><span class="p">(</span><span class="s1">&#39;training&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
                        <span class="k">return</span>
                <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;attempting to re-assign constant &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attr</span><span class="p">))</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">ModuleList</span><span class="p">):</span>
                <span class="c1"># special case for list of modules. Modules need to be registered with their</span>
                <span class="c1"># parent module. To do this, we create a ConstModuleList, which is itself a module, that</span>
                <span class="c1"># contains each of these modules as submodules. The ConstModuleList then</span>
                <span class="c1"># is set as an attribute of the parent module.</span>
                <span class="nb">super</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">_ConstModuleList</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">):</span>
                <span class="nb">super</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">_ConstSequential</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">super</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">_get_valid_constant</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>

        <span class="k">def</span> <span class="nf">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">Module</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_method_names</span><span class="p">())</span>

        <span class="k">def</span> <span class="nf">define</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lang</span><span class="p">):</span>
            <span class="c1"># We use frames_up=1 to get to the proper surrounding scope. The stack</span>
            <span class="c1"># will look like:</span>
            <span class="c1"># 0. createResolutionCallback</span>
            <span class="c1"># 1. define()</span>
            <span class="c1"># 2. surrounding scope.</span>
            <span class="c1">#</span>
            <span class="c1"># createResolutionCallback internally adds 1 to get us to our frame, then</span>
            <span class="c1"># we add 1 to get to the proper surrounding scope.</span>
            <span class="n">rcb</span> <span class="o">=</span> <span class="n">createResolutionCallback</span><span class="p">(</span><span class="n">frames_up</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_define</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">rcb</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span></div>

    <span class="k">class</span> <span class="nc">WeakScriptModuleProxy</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">,</span> <span class="n">stubs</span><span class="p">):</span>
            <span class="c1"># Guards behavior of __setattr__ and __getattr__ so ScriptModule</span>
            <span class="c1"># __init__ can run correctly</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s1">&#39;_initialized&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">WeakScriptModuleProxy</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_original&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">original</span><span class="p">)</span>

            <span class="c1"># Copy Parameters / Modules / Buffers</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">original</span><span class="p">):</span>
                <span class="n">item</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">item</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">original</span><span class="o">.</span><span class="n">_parameters</span><span class="p">:</span>
                    <span class="c1"># XXX: treat None value simply as module attributes instead of adding them to the parameter list</span>
                    <span class="c1"># TODO: need to handle this more generally when non-tensor attributes added to module</span>
                    <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">Module</span><span class="p">)</span> <span class="ow">and</span> <span class="n">item</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span><span class="p">):</span>
                    <span class="n">ScriptModule</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">original</span><span class="o">.</span><span class="n">_buffers</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">original</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">original</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>

            <span class="c1"># Copy constants</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_constants_set&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="s2">&quot;__constants__&quot;</span><span class="p">,</span> <span class="p">[]))</span>

            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_initialized&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">_create_methods_from_stubs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stubs</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
            <span class="c1"># Try to get the attribute directly, if that fails, fall back to the</span>
            <span class="c1"># weak module itself</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">ScriptModule</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_initialized&quot;</span><span class="p">]:</span>
                    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_original&quot;</span><span class="p">](),</span> <span class="n">attr</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Only fall back to original once __init__() is done</span>
                    <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Weak module has no attribute &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span>
                                         <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attr</span><span class="p">))</span>

        <span class="k">def</span> <span class="nf">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
            <span class="c1"># Once constructed, no new properties can be set</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_initialized&quot;</span><span class="p">]:</span>
                <span class="c1"># If constructing, don&#39;t fall back to original module</span>
                <span class="k">return</span> <span class="n">ScriptModule</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">ScriptModule</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Cannot set new attribute &#39;</span><span class="si">{}</span><span class="s2">&#39; on &quot;</span>
                                     <span class="s2">&quot;weak script module once it has been &quot;</span>
                                     <span class="s2">&quot;created&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attr</span><span class="p">))</span>

<span class="k">else</span><span class="p">:</span>
    <span class="n">ScriptModule</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span>


<span class="k">def</span> <span class="nf">_get_weak_stubs</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calls script_method for each method on the type of the object passed in and</span>
<span class="sd">    returns the generated ScriptMethodStubs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">stubs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
        <span class="n">func</span> <span class="o">=</span> <span class="n">get_function_from_type</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">_weak_script_methods</span><span class="p">:</span>
            <span class="n">entry</span> <span class="o">=</span> <span class="n">_weak_script_methods</span><span class="p">[</span><span class="n">func</span><span class="p">]</span>
            <span class="n">stub</span> <span class="o">=</span> <span class="n">script_method</span><span class="p">(</span><span class="n">entry</span><span class="p">[</span><span class="s2">&quot;original_method&quot;</span><span class="p">],</span> <span class="n">entry</span><span class="p">[</span><span class="s2">&quot;rcb&quot;</span><span class="p">])</span>
            <span class="n">stubs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">stub</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">stubs</span>


<span class="k">def</span> <span class="nf">_make_strong</span><span class="p">(</span><span class="n">mod</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Converts a weak module into a subclass of ScriptModule</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">_weak_modules</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_weak_modules</span><span class="p">[</span><span class="n">mod</span><span class="p">]</span>

    <span class="n">stubs</span> <span class="o">=</span> <span class="n">_weak_types</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">mod</span><span class="p">))[</span><span class="s2">&quot;method_stubs&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">stubs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Generate stubs and and store on _weak_types in case this type is</span>
        <span class="c1"># used again</span>
        <span class="n">stubs</span> <span class="o">=</span> <span class="n">_get_weak_stubs</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">mod</span><span class="p">))</span>
        <span class="n">_weak_types</span><span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="n">mod</span><span class="p">)][</span><span class="s2">&quot;method_stubs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">stubs</span>

    <span class="c1"># Create proxy with stubs</span>
    <span class="n">proxy</span> <span class="o">=</span> <span class="n">WeakScriptModuleProxy</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">stubs</span><span class="p">)</span>

    <span class="n">_weak_modules</span><span class="p">[</span><span class="n">mod</span><span class="p">]</span> <span class="o">=</span> <span class="n">proxy</span>

    <span class="k">return</span> <span class="n">proxy</span>


<span class="k">def</span> <span class="nf">_get_methods</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">inspect</span>
    <span class="c1"># In Python 3 unbound methods are functions, but in Python 2 they are methods</span>
    <span class="k">return</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getmembers</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">predicate</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isfunction</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="ow">or</span> <span class="n">inspect</span><span class="o">.</span><span class="n">ismethod</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="n">_compiled_methods_whitelist</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;forward&#39;</span><span class="p">,</span> <span class="s1">&#39;register_buffer&#39;</span><span class="p">,</span> <span class="s1">&#39;register_parameter&#39;</span><span class="p">,</span> <span class="s1">&#39;add_module&#39;</span><span class="p">,</span>
    <span class="s1">&#39;_apply&#39;</span><span class="p">,</span> <span class="s1">&#39;apply&#39;</span><span class="p">,</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;float&#39;</span><span class="p">,</span> <span class="s1">&#39;double&#39;</span><span class="p">,</span> <span class="s1">&#39;half&#39;</span><span class="p">,</span>
    <span class="s1">&#39;state_dict&#39;</span><span class="p">,</span> <span class="s1">&#39;load_state_dict&#39;</span><span class="p">,</span> <span class="s1">&#39;_load_from_state_dict&#39;</span><span class="p">,</span>
    <span class="s1">&#39;_named_members&#39;</span><span class="p">,</span> <span class="s1">&#39;parameters&#39;</span><span class="p">,</span> <span class="s1">&#39;named_parameters&#39;</span><span class="p">,</span>
    <span class="s1">&#39;buffers&#39;</span><span class="p">,</span> <span class="s1">&#39;named_buffers&#39;</span><span class="p">,</span> <span class="s1">&#39;children&#39;</span><span class="p">,</span> <span class="s1">&#39;named_children&#39;</span><span class="p">,</span> <span class="s1">&#39;modules&#39;</span><span class="p">,</span>
    <span class="s1">&#39;named_modules&#39;</span><span class="p">,</span> <span class="s1">&#39;zero_grad&#39;</span><span class="p">,</span> <span class="s1">&#39;share_memory&#39;</span><span class="p">,</span> <span class="s1">&#39;_get_name&#39;</span><span class="p">,</span> <span class="s1">&#39;extra_repr&#39;</span><span class="p">,</span>
    <span class="s1">&#39;_slow_forward&#39;</span><span class="p">,</span> <span class="s1">&#39;_tracing_name&#39;</span><span class="p">,</span> <span class="s1">&#39;eval&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">_make_fail</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">fail</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot; is not supported on TracedModules&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fail</span>


<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">_get_methods</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">):</span>
        <span class="k">continue</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ScriptModule</span><span class="o">.</span><span class="vm">__dict__</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_compiled_methods_whitelist</span><span class="p">:</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="n">method</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">_make_fail</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">TracedModule</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">):</span>
    <span class="n">__frozen</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">orig</span><span class="p">,</span> <span class="n">id_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="c1"># XXX: orig can be a nn.Module or a function!</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TracedModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">optimize</span><span class="o">=</span><span class="n">optimize</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">id_set</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">id_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">orig</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="n">orig</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="n">orig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="s1">&#39;TracedModule[&#39;</span> <span class="o">+</span> <span class="nb">type</span><span class="p">(</span><span class="n">orig</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;]&#39;</span>

        <span class="k">def</span> <span class="nf">check_unique</span><span class="p">(</span><span class="n">param</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">id_set</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TracedModules don&#39;t support parameter sharing between modules&quot;</span><span class="p">)</span>
            <span class="n">id_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="n">orig</span><span class="o">.</span><span class="n">training</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">orig</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span>
                <span class="n">check_unique</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">orig</span><span class="o">.</span><span class="n">_buffers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">buf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">buf</span>
                <span class="n">check_unique</span><span class="p">(</span><span class="n">buf</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">orig</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="n">orig</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="n">orig</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Modules that have hooks assigned can&#39;t be compiled&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">submodule</span> <span class="ow">in</span> <span class="n">orig</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">TracedModule</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">id_set</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="n">optimize</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_freeze</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Trace submodules cannot be called.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__frozen</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">_get_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span>

    <span class="k">def</span> <span class="nf">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">__frozen</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">TracedModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot set new properties on a traced module.&quot;</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TopLevelTracedModule</span><span class="p">(</span><span class="n">TracedModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_method</span><span class="p">(</span><span class="s1">&#39;forward&#39;</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_ConstModuleList</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">modules</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_ConstModuleList</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">modules</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">_is_weak_type</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">module</span><span class="p">)):</span>
                <span class="n">module</span> <span class="o">=</span> <span class="n">_make_strong</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">_ConstModuleList</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s1">&#39;index </span><span class="si">{}</span><span class="s1"> is out of range&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">_ConstModuleList</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">()</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">key</span><span class="o">.</span><span class="n">isdigit</span><span class="p">()]</span>
        <span class="k">return</span> <span class="n">keys</span>


<span class="k">class</span> <span class="nc">_ConstSequential</span><span class="p">(</span><span class="n">_ConstModuleList</span><span class="p">):</span>
    <span class="n">__constants__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mods&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mods</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_ConstSequential</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">mods</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="c1"># we define the forward method via self.define rather than</span>
        <span class="c1"># making it a direct class member (with a @script) annotation</span>
        <span class="c1"># because, in optimized runtime environments where only .pyc files</span>
        <span class="c1"># are shipped, we cant retrieve the source code.</span>
        <span class="c1"># TODO: find a workaround for this and remove this hack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        def forward(self, input):</span>
<span class="s2">            for m in self:</span>
<span class="s2">                input = m(input)</span>
<span class="s2">            return input</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="p">)</span>


<span class="n">_builtin_table</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">_modules_containing_builtins</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_nn</span><span class="p">)</span>

<span class="c1"># These functions have been converted to weak script, so don&#39;t add them as</span>
<span class="c1"># builtin aten ops. Instead, they will be compiled from the code in</span>
<span class="c1"># torch.nn.functional when used.</span>


<span class="c1"># TODO: delete _should_skip() and remove torch.nn.functional from builtins list</span>
<span class="c1"># once everything in it has been converted to weak script</span>
<span class="k">def</span> <span class="nf">_should_skip</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">mod</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">func</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">_compiled_weak_fns</span> <span class="ow">or</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">_boolean_dispatched</span>


<span class="k">def</span> <span class="nf">_unwrap_optional</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Unwrapping null optional&quot;</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="c1"># lazily built to ensure the correct initialization order</span>
<span class="k">def</span> <span class="nf">_get_builtin_table</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">_builtin_table</span>
    <span class="k">if</span> <span class="n">_builtin_table</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_builtin_table</span>
    <span class="n">_builtin_table</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">register_all</span><span class="p">(</span><span class="n">mod</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">mod</span><span class="p">):</span>
            <span class="n">v</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">_should_skip</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">v</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::&quot;</span> <span class="o">+</span> <span class="n">name</span>
    <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">_modules_containing_builtins</span><span class="p">:</span>
        <span class="n">register_all</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>

    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::warn&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">_single</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::_single&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">_pair</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::_pair&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">_triple</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::_triple&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">_quadruple</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::_quadruple&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">_list_with_default</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::list_with_default&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">_unwrap_optional</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::_unwrap_optional&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">cudnn</span><span class="o">.</span><span class="n">is_acceptable</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::cudnn_is_acceptable&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_infer_size</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::_infer_size&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">_no_grad_embedding_renorm_</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::_no_grad_embedding_renorm_&quot;</span>

    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::floor&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">interpolate</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::__interpolate&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample_nearest</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::__upsample_nearest&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::__upsample&quot;</span>
    <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample_bilinear</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::__upsample_bilinear&quot;</span>

    <span class="k">return</span> <span class="n">_builtin_table</span>


<span class="k">def</span> <span class="nf">_register_builtin</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
    <span class="n">_get_builtin_table</span><span class="p">()[</span><span class="nb">id</span><span class="p">(</span><span class="n">fn</span><span class="p">)]</span> <span class="o">=</span> <span class="n">op</span>


<span class="k">def</span> <span class="nf">_find_builtin</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_get_builtin_table</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span>


<span class="n">_register_builtin</span><span class="p">(</span><span class="nb">len</span><span class="p">,</span> <span class="s1">&#39;aten::len&#39;</span><span class="p">)</span>
<span class="n">_register_builtin</span><span class="p">(</span><span class="n">_wait</span><span class="p">,</span> <span class="s1">&#39;aten::wait&#39;</span><span class="p">)</span>

<span class="c1"># torch.jit.Error</span>
<span class="n">Error</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">JITException</span>


<span class="k">class</span> <span class="nc">_disable_tracing</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_get_tracing_state</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_set_tracing_state</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_set_tracing_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="kc">None</span>


<span class="c1"># for use in python if using annotate</span>
<span class="k">def</span> <span class="nf">annotate</span><span class="p">(</span><span class="n">the_type</span><span class="p">,</span> <span class="n">the_value</span><span class="p">):</span>
    <span class="c1"># noop in python</span>
    <span class="k">return</span> <span class="n">the_value</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_init</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;JIT initialization failed&quot;</span><span class="p">)</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Torch Contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script type="text/javascript" src="../../_static/jquery.js"></script>
         <script type="text/javascript" src="../../_static/underscore.js"></script>
         <script type="text/javascript" src="../../_static/doctools.js"></script>
         <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.js"></script>
         <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.9.0/dist/contrib/auto-render.min.js"></script>
         <script type="text/javascript" src="../../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-1', 'auto');
  ga('send', 'pageview');

</script>
<img height="1" width="1" style="border-style:none;" alt="" src="http://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://pytorch.org/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>