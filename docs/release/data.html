


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.utils.data &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/data.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="torch.utils.dlpack" href="dlpack.html" />
    <link rel="prev" title="torch.utils.cpp_extension" href="cpp_extension.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master (1.0.0 )
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          

            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html#torch-nn-functional">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html#torch-nn-init">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="multiprocessing.html">torch.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="ffi.html">torch.utils.ffi</a></li>
<li class="toctree-l1"><a class="reference internal" href="hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed_deprecated.html">torch.distributed.deprecated</a></li>
<li class="toctree-l1"><a class="reference internal" href="legacy.html">torch.legacy</a></li>
</ul>
<p class="caption"><span class="caption-text">torchvision Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="torchvision/index.html">torchvision</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>torch.utils.data</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/data.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="module-torch.utils.data">
<span id="torch-utils-data"></span><h1>torch.utils.data<a class="headerlink" href="#module-torch.utils.data" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="torch.utils.data.Dataset">
<em class="property">class </em><code class="descclassname">torch.utils.data.</code><code class="descname">Dataset</code><a class="reference internal" href="_modules/torch/utils/data/dataset.html#Dataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.Dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>An abstract class representing a Dataset.</p>
<p>All other datasets should subclass it. All subclasses should override
<code class="docutils literal notranslate"><span class="pre">__len__</span></code>, that provides the size of the dataset, and <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>,
supporting integer indexing in range from 0 to len(self) exclusive.</p>
</dd></dl>

<dl class="class">
<dt id="torch.utils.data.TensorDataset">
<em class="property">class </em><code class="descclassname">torch.utils.data.</code><code class="descname">TensorDataset</code><span class="sig-paren">(</span><em>*tensors</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/dataset.html#TensorDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.TensorDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataset wrapping tensors.</p>
<p>Each sample will be retrieved by indexing tensors along the first dimension.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>*tensors</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – tensors that have the same size of the first dimension.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.utils.data.ConcatDataset">
<em class="property">class </em><code class="descclassname">torch.utils.data.</code><code class="descname">ConcatDataset</code><span class="sig-paren">(</span><em>datasets</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/dataset.html#ConcatDataset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.ConcatDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataset to concatenate multiple datasets.
Purpose: useful to assemble different existing datasets, possibly
large-scale datasets as the concatenation operation is done in an
on-the-fly manner.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>datasets</strong> (<em>sequence</em>) – List of datasets to be concatenated</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.utils.data.Subset">
<em class="property">class </em><code class="descclassname">torch.utils.data.</code><code class="descname">Subset</code><span class="sig-paren">(</span><em>dataset</em>, <em>indices</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/dataset.html#Subset"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.Subset" title="Permalink to this definition">¶</a></dt>
<dd><p>Subset of a dataset at specified indices.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="#torch.utils.data.Dataset" title="torch.utils.data.Dataset"><em>Dataset</em></a>) – The whole Dataset</li>
<li><strong>indices</strong> (<em>sequence</em>) – Indices in the whole set selected for subset</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.utils.data.DataLoader">
<em class="property">class </em><code class="descclassname">torch.utils.data.</code><code class="descname">DataLoader</code><span class="sig-paren">(</span><em>dataset</em>, <em>batch_size=1</em>, <em>shuffle=False</em>, <em>sampler=None</em>, <em>batch_sampler=None</em>, <em>num_workers=0</em>, <em>collate_fn=&lt;function default_collate&gt;</em>, <em>pin_memory=False</em>, <em>drop_last=False</em>, <em>timeout=0</em>, <em>worker_init_fn=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/dataloader.html#DataLoader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.DataLoader" title="Permalink to this definition">¶</a></dt>
<dd><p>Data loader. Combines a dataset and a sampler, and provides
single- or multi-process iterators over the dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="#torch.utils.data.Dataset" title="torch.utils.data.Dataset"><em>Dataset</em></a>) – dataset from which to load the data.</li>
<li><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – how many samples per batch to load
(default: <code class="docutils literal notranslate"><span class="pre">1</span></code>).</li>
<li><strong>shuffle</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – set to <code class="docutils literal notranslate"><span class="pre">True</span></code> to have the data reshuffled
at every epoch (default: <code class="docutils literal notranslate"><span class="pre">False</span></code>).</li>
<li><strong>sampler</strong> (<a class="reference internal" href="#torch.utils.data.Sampler" title="torch.utils.data.Sampler"><em>Sampler</em></a><em>, </em><em>optional</em>) – defines the strategy to draw samples from
the dataset. If specified, <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> must be False.</li>
<li><strong>batch_sampler</strong> (<a class="reference internal" href="#torch.utils.data.Sampler" title="torch.utils.data.Sampler"><em>Sampler</em></a><em>, </em><em>optional</em>) – like sampler, but returns a batch of
indices at a time. Mutually exclusive with <code class="xref py py-attr docutils literal notranslate"><span class="pre">batch_size</span></code>,
<code class="xref py py-attr docutils literal notranslate"><span class="pre">shuffle</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">sampler</span></code>, and <code class="xref py py-attr docutils literal notranslate"><span class="pre">drop_last</span></code>.</li>
<li><strong>num_workers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – how many subprocesses to use for data
loading. 0 means that the data will be loaded in the main process.
(default: <code class="docutils literal notranslate"><span class="pre">0</span></code>)</li>
<li><strong>collate_fn</strong> (<em>callable</em><em>, </em><em>optional</em>) – merges a list of samples to form a mini-batch.</li>
<li><strong>pin_memory</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the data loader will copy tensors
into CUDA pinned memory before returning them.</li>
<li><strong>drop_last</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – set to <code class="docutils literal notranslate"><span class="pre">True</span></code> to drop the last incomplete batch,
if the dataset size is not divisible by the batch size. If <code class="docutils literal notranslate"><span class="pre">False</span></code> and
the size of dataset is not divisible by the batch size, then the last batch
will be smaller. (default: <code class="docutils literal notranslate"><span class="pre">False</span></code>)</li>
<li><strong>timeout</strong> (<em>numeric</em><em>, </em><em>optional</em>) – if positive, the timeout value for collecting a batch
from workers. Should always be non-negative. (default: <code class="docutils literal notranslate"><span class="pre">0</span></code>)</li>
<li><strong>worker_init_fn</strong> (<em>callable</em><em>, </em><em>optional</em>) – If not <code class="docutils literal notranslate"><span class="pre">None</span></code>, this will be called on each
worker subprocess with the worker id (an int in <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">num_workers</span> <span class="pre">-</span> <span class="pre">1]</span></code>) as
input, after seeding and before data loading. (default: <code class="docutils literal notranslate"><span class="pre">None</span></code>)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">By default, each worker will have its PyTorch seed set to
<code class="docutils literal notranslate"><span class="pre">base_seed</span> <span class="pre">+</span> <span class="pre">worker_id</span></code>, where <code class="docutils literal notranslate"><span class="pre">base_seed</span></code> is a long generated
by main process using its RNG. However, seeds for other libraies
may be duplicated upon initializing workers (w.g., NumPy), causing
each worker to return identical random numbers. (See
<a class="reference internal" href="notes/faq.html#dataloader-workers-random-seed"><span class="std std-ref">My data loader workers return identical random numbers</span></a> section in FAQ.) You may
use <a class="reference internal" href="torch.html#torch.initial_seed" title="torch.initial_seed"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.initial_seed()</span></code></a> to access the PyTorch seed for
each worker in <code class="xref py py-attr docutils literal notranslate"><span class="pre">worker_init_fn</span></code>, and use it to set other
seeds before data loading.</p>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">If <code class="docutils literal notranslate"><span class="pre">spawn</span></code> start method is used, <code class="xref py py-attr docutils literal notranslate"><span class="pre">worker_init_fn</span></code> cannot be an
unpicklable object, e.g., a lambda function.</p>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.utils.data.random_split">
<code class="descclassname">torch.utils.data.</code><code class="descname">random_split</code><span class="sig-paren">(</span><em>dataset</em>, <em>lengths</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/dataset.html#random_split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.random_split" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly split a dataset into non-overlapping new datasets of given lengths.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> (<a class="reference internal" href="#torch.utils.data.Dataset" title="torch.utils.data.Dataset"><em>Dataset</em></a>) – Dataset to be split</li>
<li><strong>lengths</strong> (<em>sequence</em>) – lengths of splits to be produced</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.utils.data.Sampler">
<em class="property">class </em><code class="descclassname">torch.utils.data.</code><code class="descname">Sampler</code><span class="sig-paren">(</span><em>data_source</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/sampler.html#Sampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.Sampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for all Samplers.</p>
<p>Every Sampler subclass has to provide an __iter__ method, providing a way
to iterate over indices of dataset elements, and a __len__ method that
returns the length of the returned iterators.</p>
</dd></dl>

<dl class="class">
<dt id="torch.utils.data.SequentialSampler">
<em class="property">class </em><code class="descclassname">torch.utils.data.</code><code class="descname">SequentialSampler</code><span class="sig-paren">(</span><em>data_source</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/sampler.html#SequentialSampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.SequentialSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples elements sequentially, always in the same order.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>data_source</strong> (<a class="reference internal" href="#torch.utils.data.Dataset" title="torch.utils.data.Dataset"><em>Dataset</em></a>) – dataset to sample from</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.utils.data.RandomSampler">
<em class="property">class </em><code class="descclassname">torch.utils.data.</code><code class="descname">RandomSampler</code><span class="sig-paren">(</span><em>data_source</em>, <em>replacement=False</em>, <em>num_samples=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/sampler.html#RandomSampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.RandomSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples elements randomly. If without replacement, then sample from a shuffled dataset.
If with replacement, then user can specify <code class="docutils literal notranslate"><span class="pre">num_samples</span></code> to draw.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>data_source</strong> (<a class="reference internal" href="#torch.utils.data.Dataset" title="torch.utils.data.Dataset"><em>Dataset</em></a>) – dataset to sample from</li>
<li><strong>num_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – number of samples to draw, default=len(dataset)</li>
<li><strong>replacement</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – samples are drawn with replacement if <code class="docutils literal notranslate"><span class="pre">True</span></code>, default=False</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.utils.data.SubsetRandomSampler">
<em class="property">class </em><code class="descclassname">torch.utils.data.</code><code class="descname">SubsetRandomSampler</code><span class="sig-paren">(</span><em>indices</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/sampler.html#SubsetRandomSampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.SubsetRandomSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples elements randomly from a given list of indices, without replacement.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>indices</strong> (<em>sequence</em>) – a sequence of indices</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.utils.data.WeightedRandomSampler">
<em class="property">class </em><code class="descclassname">torch.utils.data.</code><code class="descname">WeightedRandomSampler</code><span class="sig-paren">(</span><em>weights</em>, <em>num_samples</em>, <em>replacement=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/sampler.html#WeightedRandomSampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.WeightedRandomSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Samples elements from [0,..,len(weights)-1] with given probabilities (weights).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>weights</strong> (<em>sequence</em>) – a sequence of weights, not necessary summing up to one</li>
<li><strong>num_samples</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – number of samples to draw</li>
<li><strong>replacement</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, samples are drawn with replacement.
If not, they are drawn without replacement, which means that when a
sample index is drawn for a row, it cannot be drawn again for that row.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.utils.data.BatchSampler">
<em class="property">class </em><code class="descclassname">torch.utils.data.</code><code class="descname">BatchSampler</code><span class="sig-paren">(</span><em>sampler</em>, <em>batch_size</em>, <em>drop_last</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/sampler.html#BatchSampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.BatchSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Wraps another sampler to yield a mini-batch of indices.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sampler</strong> (<a class="reference internal" href="#torch.utils.data.Sampler" title="torch.utils.data.Sampler"><em>Sampler</em></a>) – Base sampler.</li>
<li><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Size of mini-batch.</li>
<li><strong>drop_last</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the sampler will drop the last batch if
its size would be less than <code class="docutils literal notranslate"><span class="pre">batch_size</span></code></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">BatchSampler</span><span class="p">(</span><span class="n">SequentialSampler</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="go">[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">list</span><span class="p">(</span><span class="n">BatchSampler</span><span class="p">(</span><span class="n">SequentialSampler</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="go">[[0, 1, 2], [3, 4, 5], [6, 7, 8]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="torch.utils.data.distributed.DistributedSampler">
<em class="property">class </em><code class="descclassname">torch.utils.data.distributed.</code><code class="descname">DistributedSampler</code><span class="sig-paren">(</span><em>dataset</em>, <em>num_replicas=None</em>, <em>rank=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/utils/data/distributed.html#DistributedSampler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.utils.data.distributed.DistributedSampler" title="Permalink to this definition">¶</a></dt>
<dd><p>Sampler that restricts data loading to a subset of the dataset.</p>
<p>It is especially useful in conjunction with
<a class="reference internal" href="nn.html#torch.nn.parallel.DistributedDataParallel" title="torch.nn.parallel.DistributedDataParallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.parallel.DistributedDataParallel</span></code></a>. In such case, each
process can pass a DistributedSampler instance as a DataLoader sampler,
and load a subset of the original dataset that is exclusive to it.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Dataset is assumed to be of constant size.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>dataset</strong> – Dataset used for sampling.</li>
<li><strong>num_replicas</strong> (<em>optional</em>) – Number of processes participating in
distributed training.</li>
<li><strong>rank</strong> (<em>optional</em>) – Rank of the current process within num_replicas.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="dlpack.html" class="btn btn-neutral float-right" title="torch.utils.dlpack" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="cpp_extension.html" class="btn btn-neutral" title="torch.utils.cpp_extension" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Torch Contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torch.utils.data</a></li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script type="text/javascript" src="_static/jquery.js"></script>
         <script type="text/javascript" src="_static/underscore.js"></script>
         <script type="text/javascript" src="_static/doctools.js"></script>
         <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.js"></script>
         <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.9.0/dist/contrib/auto-render.min.js"></script>
         <script type="text/javascript" src="_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-1', 'auto');
  ga('send', 'pageview');

</script>
<img height="1" width="1" style="border-style:none;" alt="" src="http://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://pytorch.org/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>