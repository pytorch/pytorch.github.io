


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.jit &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/jit.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  <a href='http://pytorch.org/docs/versions.html'>1.2.0 &#x25BC</a>
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../multiprocessing.html">torch.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../__config__.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">torchvision Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torchvision/index.html">torchvision</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">Module code</a> &gt;</li>
        
          <li><a href="../torch.html">torch</a> &gt;</li>
        
      <li>torch.jit</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.jit</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch._C</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="k">import</span> <span class="n">Variable</span><span class="p">,</span> <span class="n">function</span>
<span class="kn">from</span> <span class="nn">torch.serialization</span> <span class="k">import</span> <span class="n">validate_cuda_device</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="k">import</span> <span class="n">Module</span><span class="p">,</span> <span class="n">ModuleList</span><span class="p">,</span> <span class="n">Parameter</span><span class="p">,</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">torch.jit.frontend</span> <span class="k">import</span> <span class="n">get_jit_class_def</span><span class="p">,</span> <span class="n">get_jit_def</span><span class="p">,</span> <span class="n">get_default_args</span>
<span class="kn">import</span> <span class="nn">torch.backends.cudnn</span> <span class="k">as</span> <span class="nn">cudnn</span>
<span class="kn">import</span> <span class="nn">torch.jit.annotations</span>
<span class="kn">import</span> <span class="nn">torch._jit_internal</span> <span class="k">as</span> <span class="nn">_jit_internal</span>
<span class="kn">from</span> <span class="nn">torch._jit_internal</span> <span class="k">import</span> <span class="n">_qualified_name</span>
<span class="kn">from</span> <span class="nn">torch._six</span> <span class="k">import</span> <span class="n">PY2</span><span class="p">,</span> <span class="n">PY37</span><span class="p">,</span> <span class="n">with_metaclass</span><span class="p">,</span> <span class="n">get_function_from_type</span><span class="p">,</span> \
    <span class="n">string_classes</span>
<span class="kn">from</span> <span class="nn">..nn.modules.utils</span> <span class="k">import</span> <span class="n">_single</span><span class="p">,</span> <span class="n">_pair</span><span class="p">,</span> <span class="n">_triple</span><span class="p">,</span> <span class="n">_quadruple</span><span class="p">,</span> \
    <span class="n">_list_with_default</span>
<span class="kn">import</span> <span class="nn">torch.testing</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">OrderedDict</span><span class="p">,</span> <span class="n">namedtuple</span>
<span class="kn">import</span> <span class="nn">textwrap</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">weakref</span>
<span class="kn">import</span> <span class="nn">types</span>
<span class="kn">import</span> <span class="nn">contextlib</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">pickle</span>

<span class="c1"># These are imported so users can access them from the `torch.jit` module</span>
<span class="kn">from</span> <span class="nn">torch._jit_internal</span> <span class="k">import</span> <span class="n">Final</span>  <span class="c1"># noqa: F401</span>
<span class="kn">from</span> <span class="nn">torch._jit_internal</span> <span class="k">import</span> <span class="n">ignore</span><span class="p">,</span> <span class="n">export</span>  <span class="c1"># noqa: F401</span>

<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">pathlib</span>


<span class="k">def</span> <span class="nf">_parse_env</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">default</span><span class="p">,</span> <span class="n">true_message</span><span class="p">,</span> <span class="n">false_message</span><span class="p">):</span>
    <span class="n">value</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">default</span>
    <span class="k">if</span> <span class="n">value</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;true&#39;</span><span class="p">,</span> <span class="s1">&#39;yes&#39;</span><span class="p">}:</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="n">value</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="p">{</span><span class="s1">&#39;0&#39;</span><span class="p">,</span> <span class="s1">&#39;false&#39;</span><span class="p">,</span> <span class="s1">&#39;no&#39;</span><span class="p">}:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="n">value</span> <span class="o">==</span> <span class="s1">&#39;1v&#39;</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">true_message</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">True</span>
    <span class="k">elif</span> <span class="n">value</span> <span class="o">==</span> <span class="s1">&#39;0v&#39;</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">false_message</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unknown setting of </span><span class="si">{}</span><span class="s1">. Try using 0 or 1.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>


<span class="n">_enabled</span> <span class="o">=</span> <span class="n">_parse_env</span><span class="p">(</span><span class="s1">&#39;PYTORCH_JIT&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;&gt; Using PyTorch JIT&quot;</span><span class="p">,</span> <span class="s2">&quot;&gt; PyTorch JIT DISABLED&quot;</span><span class="p">)</span>
<span class="n">_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_flatten</span>
<span class="n">_unflatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_unflatten</span>
<span class="n">_jit_script_class_compile</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_script_class_compile</span>

<span class="c1"># The Python CompilationUnit. All functions and modules defined in Python will</span>
<span class="c1"># live in here. It&#39;s defined in Python because doing in cpp creates static</span>
<span class="c1"># destruction order issues.</span>
<span class="n">_python_cu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">CompilationUnit</span><span class="p">()</span>

<span class="n">Future</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Future</span>
<span class="n">_fork</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">fork</span>
<span class="n">_wait</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">wait</span>


<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">scope</span><span class="p">(</span><span class="n">scope_name</span><span class="p">):</span>
    <span class="n">tracing_state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_get_tracing_state</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">tracing_state</span><span class="p">:</span>
        <span class="n">tracing_state</span><span class="o">.</span><span class="n">push_scope</span><span class="p">(</span><span class="n">scope_name</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">tracing_state</span><span class="p">:</span>
            <span class="n">tracing_state</span><span class="o">.</span><span class="n">pop_scope</span><span class="p">()</span>

<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">optimized_execution</span><span class="p">(</span><span class="n">should_optimize</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A context manager that controls whether the JIT&#39;s executor will run</span>
<span class="sd">    optimizations before executing a function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">stored_flag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_get_graph_executor_optimize</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_set_graph_executor_optimize</span><span class="p">(</span><span class="n">should_optimize</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_set_graph_executor_optimize</span><span class="p">(</span><span class="n">stored_flag</span><span class="p">)</span>


<span class="n">DEFAULT_EXTRA_FILES_MAP</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">ExtraFilesMap</span><span class="p">()</span>


<div class="viewcode-block" id="load"><a class="viewcode-back" href="../../jit.html#torch.jit.load">[docs]</a><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_extra_files</span><span class="o">=</span><span class="n">DEFAULT_EXTRA_FILES_MAP</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load a ``ScriptModule`` previously saved with :func:`save &lt;torch.jit.save&gt;`</span>

<span class="sd">        All previously saved modules, no matter their device, are first loaded onto CPU,</span>
<span class="sd">        and then are moved to the devices they were saved from. If this fails (e.g. because</span>
<span class="sd">        the run time system doesn&#39;t have certain devices), an exception is raised.</span>
<span class="sd">        However, storages can be dynamically remapped to an alternative set of devices</span>
<span class="sd">        using the `map_location` argument. Comparing to :func:`torch.load`, `map_location`</span>
<span class="sd">        in this function is simplified, which only accepts a string (e.g., &#39;cpu&#39;, &#39;cuda:0&#39;),</span>
<span class="sd">        or torch.device (e.g., torch.device(&#39;cpu&#39;))</span>

<span class="sd">        Arguments:</span>
<span class="sd">            f: a file-like object (has to implement read, readline, tell, and seek),</span>
<span class="sd">                or a string containing a file name</span>
<span class="sd">            map_location: can a string (e.g., &#39;cpu&#39;, &#39;cuda:0&#39;), a device (e.g.,</span>
<span class="sd">                torch.device(&#39;cpu&#39;))</span>
<span class="sd">            _extra_files: map from filename to content. The extra</span>
<span class="sd">                filenames given in the map would be loaded and their content</span>
<span class="sd">                would be stored in the provided map.</span>


<span class="sd">        Returns:</span>
<span class="sd">            A ``ScriptModule`` object.</span>

<span class="sd">        Example: ::</span>

<span class="sd">            torch.jit.load(&#39;scriptmodule.pt&#39;)</span>

<span class="sd">            # Load ScriptModule from io.BytesIO object</span>
<span class="sd">            with open(&#39;scriptmodule.pt&#39;, &#39;rb&#39;) as f:</span>
<span class="sd">                buffer = io.BytesIO(f.read())</span>

<span class="sd">            # Load all tensors to the original device</span>
<span class="sd">            torch.jit.load(buffer)</span>

<span class="sd">            # Load all tensors onto CPU, using a device</span>
<span class="sd">            torch.jit.load(buffer, map_location=torch.device(&#39;cpu&#39;))</span>

<span class="sd">            # Load all tensors onto CPU, using a string</span>
<span class="sd">            torch.jit.load(buffer, map_location=&#39;cpu&#39;)</span>

<span class="sd">            # Load with extra files.</span>
<span class="sd">            files = {&#39;metadata.json&#39; : &#39;&#39;}</span>
<span class="sd">            torch.jit.load(&#39;scriptmodule.pt&#39;, _extra_files = files)</span>
<span class="sd">            print (files[&#39;metadata.json&#39;])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">string_classes</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The provided filename </span><span class="si">{}</span><span class="s2"> does not exist&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">map_location</span><span class="p">,</span> <span class="n">string_classes</span><span class="p">):</span>
        <span class="n">map_location</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">map_location</span><span class="p">)</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="p">(</span><span class="n">map_location</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span>
              <span class="nb">isinstance</span><span class="p">(</span><span class="n">map_location</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;map_location should be either None, string or torch.device, &quot;</span>
                         <span class="s2">&quot;but got type: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">map_location</span><span class="p">)))</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">map_location</span><span class="p">)</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)):</span>
        <span class="n">validate_cuda_device</span><span class="p">(</span><span class="n">map_location</span><span class="p">)</span>

    <span class="n">cu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">CompilationUnit</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> \
            <span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">unicode</span><span class="p">))</span> <span class="ow">or</span> \
            <span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">)):</span>
        <span class="n">cpp_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">import_ir_module</span><span class="p">(</span><span class="n">cu</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">map_location</span><span class="p">,</span> <span class="n">_extra_files</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">cpp_module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">import_ir_module_from_buffer</span><span class="p">(</span><span class="n">cu</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">map_location</span><span class="p">,</span> <span class="n">_extra_files</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">ScriptModule</span><span class="p">(</span><span class="n">_cpp_module</span><span class="o">=</span><span class="n">cpp_module</span><span class="p">)</span></div>


<div class="viewcode-block" id="save"><a class="viewcode-back" href="../../jit.html#torch.jit.save">[docs]</a><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">_extra_files</span><span class="o">=</span><span class="n">DEFAULT_EXTRA_FILES_MAP</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save an offline version of this module for use in a separate process. The saved</span>
<span class="sd">        module serializes all of the methods, submodules, parameters, and attributes of this</span>
<span class="sd">        module. It can be loaded into the C++ API using ``torch::jit::load(filename)`` or into the Python</span>
<span class="sd">        API with :func:`load &lt;torch.jit.load&gt;`.</span>

<span class="sd">        To be able to save a module, it must not make any calls to native Python functions.</span>
<span class="sd">        This means that all submodules must be subclasses of ``torch.jit.ScriptModule`` as well.</span>

<span class="sd">        .. DANGER::</span>
<span class="sd">           All modules, no matter their device, are always loaded onto the CPU during loading.</span>
<span class="sd">           This is different from :func:`load &lt;torch.jit.load&gt;`&#39;s semantics and may change in the future.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            m: a ScriptModule to save</span>
<span class="sd">            f: a file-like object (has to implement write and flush) or a string</span>
<span class="sd">               containing a file name</span>
<span class="sd">            _extra_files: Map from filename to contents which will be stored as part of &#39;f&#39;</span>

<span class="sd">        .. warning::</span>
<span class="sd">            If you are using Python 2, ``torch.save`` does NOT support ``StringIO.StringIO``</span>
<span class="sd">            as a valid file-like object. This is because the write method should return</span>
<span class="sd">            the number of bytes written; ``StringIO.write()`` does not do this.</span>

<span class="sd">            Please use something like ``io.BytesIO`` instead.</span>

<span class="sd">        Example: ::</span>

<span class="sd">            import torch</span>
<span class="sd">            import io</span>


<span class="sd">            class MyModule(torch.nn.Module):</span>
<span class="sd">                def forward(self, x):</span>
<span class="sd">                    return x + 10</span>

<span class="sd">            m = torch.jit.script(MyModule())</span>

<span class="sd">            # Save to file</span>
<span class="sd">            torch.jit.save(m, &#39;scriptmodule.pt&#39;)</span>

<span class="sd">            # Save to io.BytesIO buffer</span>
<span class="sd">            buffer = io.BytesIO()</span>
<span class="sd">            torch.jit.save(m, buffer)</span>

<span class="sd">            # Save with extra files</span>
<span class="sd">            extra_files = torch._C.ExtraFilesMap()</span>
<span class="sd">            extra_files[&#39;foo.txt&#39;] = &#39;bar&#39;</span>
<span class="sd">            torch.jit.save(m, &#39;scriptmodule.pt&#39;, _extra_files=extra_files)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">or</span> \
            <span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">unicode</span><span class="p">))</span> <span class="ow">or</span> \
            <span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">version_info</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">)):</span>
        <span class="n">m</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">_extra_files</span><span class="o">=</span><span class="n">_extra_files</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">save_to_buffer</span><span class="p">(</span><span class="n">_extra_files</span><span class="o">=</span><span class="n">_extra_files</span><span class="p">)</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">get_trace_graph</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(),</span> <span class="n">kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_inputs</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trace a function or model, returning a tuple consisting of the both the</span>
<span class="sd">    *trace* of an execution, as well as the original return value. If return_inputs,</span>
<span class="sd">    also returns the trace inputs as part of the tuple</span>

<span class="sd">    Tracing is guaranteed not to change the semantics of the function/module</span>
<span class="sd">    that is traced.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        f (torch.nn.Module or function): the function or module</span>
<span class="sd">            to be traced.</span>
<span class="sd">        args (tuple or Tensor): the positional arguments to pass to the</span>
<span class="sd">            function/module to be traced.  A non-tuple is assumed to</span>
<span class="sd">            be a single positional argument to be passed to the model.</span>
<span class="sd">        kwargs (dict): the keyword arguments to pass to the function/module</span>
<span class="sd">            to be traced.</span>

<span class="sd">    Example: Trace a cell.</span>

<span class="sd">        &gt;&gt;&gt; trace, out = jit.trace(nn.LSTMCell(), (input, hidden))</span>
<span class="sd">        &gt;&gt;&gt; print(trace)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">args</span><span class="p">,)</span>
    <span class="k">return</span> <span class="n">LegacyTracedModule</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">,</span> <span class="n">return_inputs</span><span class="p">)(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_unique_state_dict</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="c1"># since Parameter.data always creates a new torch.Tensor instance,</span>
    <span class="c1"># id(v) doesn&#39;t work with it. So we always get the Parameter or Buffer</span>
    <span class="c1"># as values, and deduplicate the params using Parameters and Buffers</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(</span><span class="n">keep_vars</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">filtered_dict</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)()</span>
    <span class="n">seen_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">id</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="ow">in</span> <span class="n">seen_ids</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">seen_ids</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">v</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">keep_vars</span><span class="p">:</span>
            <span class="n">filtered_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">filtered_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">data</span>
    <span class="k">return</span> <span class="n">filtered_dict</span>


<span class="k">def</span> <span class="nf">_create_interpreter_name_lookup_fn</span><span class="p">(</span><span class="n">frames_up</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_get_interpreter_name_for_var</span><span class="p">(</span><span class="n">var</span><span class="p">):</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">currentframe</span><span class="p">()</span>
        <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">frames_up</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">frame</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">f_back</span>
            <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">f_locals</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">f_locals</span>
        <span class="n">f_globals</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">f_globals</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">f_locals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">var</span> <span class="ow">is</span> <span class="n">v</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">k</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s1">&#39;self&#39;</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">f_globals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">var</span> <span class="ow">is</span> <span class="n">v</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">k</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="s1">&#39;self&#39;</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
        <span class="k">return</span> <span class="s1">&#39;&#39;</span>
    <span class="k">return</span> <span class="n">_get_interpreter_name_for_var</span>


<span class="k">class</span> <span class="nc">LegacyTracedModule</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inner</span><span class="p">,</span> <span class="n">force_outplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_inputs</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LegacyTracedModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># inner may be a Module, or it may be an arbitrary callable</span>
        <span class="c1"># If it&#39;s a Module, we get its parameters automatically, which lets</span>
        <span class="c1"># us avoid a special casing functions versus modules.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner</span> <span class="o">=</span> <span class="n">inner</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_force_outplace</span> <span class="o">=</span> <span class="n">force_outplace</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_return_inputs</span> <span class="o">=</span> <span class="n">return_inputs</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">in_vars</span><span class="p">,</span> <span class="n">in_desc</span> <span class="o">=</span> <span class="n">_flatten</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
        <span class="c1"># NOTE: use full state, because we need it for BatchNorm export</span>
        <span class="c1"># This differs from the compiler path, which doesn&#39;t support it at the moment.</span>
        <span class="n">module_state</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">_unique_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">keep_vars</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">trace</span><span class="p">,</span> <span class="n">all_trace_inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_enter</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">in_vars</span> <span class="o">+</span> <span class="n">module_state</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_abandon</span><span class="p">()</span>
            <span class="k">raise</span> <span class="n">e</span>
        <span class="n">ret_inputs</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">all_trace_inputs</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_set_force_outplace</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_force_outplace</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_set_get_unique_name_fn</span><span class="p">(</span><span class="n">_create_interpreter_name_lookup_fn</span><span class="p">())</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">trace_inputs</span> <span class="o">=</span> <span class="n">_unflatten</span><span class="p">(</span><span class="n">all_trace_inputs</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">in_vars</span><span class="p">)],</span> <span class="n">in_desc</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner</span><span class="p">(</span><span class="o">*</span><span class="n">trace_inputs</span><span class="p">)</span>
            <span class="n">out_vars</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_flatten</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_exit</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">out_vars</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_abandon</span><span class="p">()</span>
            <span class="k">raise</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_return_inputs</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">trace</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">ret_inputs</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">trace</span><span class="p">,</span> <span class="n">out</span>


<span class="k">def</span> <span class="nf">_clone_inputs</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">clone_input</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">a</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="c1"># TODO: figure out one liner to .clone() and set requires_grad</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">(),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">a</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">a</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">v</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">clone_input</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">v</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">function</span><span class="o">.</span><span class="n">_nested_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">),</span>
                                <span class="n">clone_input</span><span class="p">,</span> <span class="n">condition_msg</span><span class="o">=</span><span class="s2">&quot;tensors&quot;</span><span class="p">)(</span><span class="n">args</span><span class="p">)</span>


<span class="c1"># This is purely for developer debugging.  We are not going to advertise it.</span>
<span class="n">_JIT_DUMP</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PYTORCH_JIT_DUMP&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">_JIT_TIME</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PYTORCH_JIT_TIME&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>  <span class="c1"># CUDA-only timing</span>
<span class="n">_JIT_DISABLE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PYTORCH_JIT_DISABLE&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">_JIT_STATS</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;PYTORCH_JIT_STATS&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_dump_trace</span><span class="p">(</span><span class="n">trace_name</span><span class="p">,</span> <span class="n">pass_name</span><span class="p">,</span> <span class="n">input_key</span><span class="p">,</span> <span class="n">trace</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_JIT_DUMP</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="kn">import</span> <span class="nn">torch.contrib._graph_vis</span> <span class="k">as</span> <span class="nn">graph_vis</span>

    <span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">{}</span><span class="s2">_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trace_name</span><span class="p">,</span> <span class="n">pass_name</span><span class="p">)</span>
    <span class="c1"># TODO: Also paste out the backtrace when the trace was compiled</span>
    <span class="c1"># (and maybe also when it was run?)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;.ir&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;Input key: </span><span class="si">{}</span><span class="se">\n\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">input_key</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">trace</span><span class="p">)))</span>
    <span class="n">graph_vis</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">trace</span><span class="o">.</span><span class="n">graph</span><span class="p">(),</span> <span class="n">filename</span> <span class="o">+</span> <span class="s2">&quot;.html&quot;</span><span class="p">)</span>


<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">_time</span><span class="p">(</span><span class="n">trace_name</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">_JIT_TIME</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">time</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="k">yield</span>
        <span class="k">return</span>
    <span class="n">stream</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">stream</span><span class="o">.</span><span class="n">record_event</span><span class="p">(</span><span class="n">start</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">stream</span><span class="o">.</span><span class="n">record_event</span><span class="p">(</span><span class="n">end</span><span class="p">)</span>
        <span class="n">end</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> </span><span class="si">{}</span><span class="s2"> time: </span><span class="si">{}</span><span class="s2"> ms&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">trace_name</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">start</span><span class="o">.</span><span class="n">elapsed_time</span><span class="p">(</span><span class="n">end</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">verify</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">,</span> <span class="n">devices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Verify that a JIT compiled model has the same behavior as its uncompiled</span>
<span class="sd">    version along with its backwards pass.  If your model returns multiple</span>
<span class="sd">    outputs, you must also specify a `loss_fn` to produce a loss for which</span>
<span class="sd">    the backwards will be computed.</span>

<span class="sd">    This function has side-effects (e.g., it executes your model / saves and loads</span>
<span class="sd">    parameters), so don&#39;t expect the model to come out exactly the same as what</span>
<span class="sd">    you passed in.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        model (compiled torch.nn.Module or function): the module/function to be</span>
<span class="sd">            verified.  The module/function definition MUST have been decorated with</span>
<span class="sd">            `@torch.jit.compile`.</span>
<span class="sd">        args (tuple or Tensor): the positional arguments to pass to the</span>
<span class="sd">            compiled function/module to be verified.  A non-tuple is assumed to</span>
<span class="sd">            be a single positional argument to be passed to the model.</span>
<span class="sd">        loss_fn (function, optional): the loss function to be applied to</span>
<span class="sd">            the output of the model, before backwards is invoked.  By default,</span>
<span class="sd">            we assume that a model returns a single result, and we :func:`torch.sum`</span>
<span class="sd">            before calling backwards; if this is inappropriate, you can pass your</span>
<span class="sd">            own loss function.  Note that if a model returns a tuple of results,</span>
<span class="sd">            these are passed as separate positional arguments to `loss_fn`.</span>
<span class="sd">        devices (iterable of device IDs, optional): the GPU devices which the</span>
<span class="sd">            compiled module will be run on.  This determines the RNG state we</span>
<span class="sd">            must save when running both compiled and uncompiled versions of the model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO: In principle, we track device information in our trace, so it</span>
    <span class="c1"># should be possible to check if our execution actually obeyed the &#39;devices&#39;</span>
    <span class="c1"># the user provided.</span>

    <span class="c1"># TODO: Consider adding a utility function to torch.jit to test</span>
    <span class="c1"># for this case</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">CompiledFunction</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Cannot verify an uncompiled module.  Add @torch.jit.compile to compile it&quot;</span><span class="p">)</span>
    <span class="n">is_module</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Module</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">args</span><span class="p">,)</span>

    <span class="n">saved_args</span> <span class="o">=</span> <span class="n">_clone_inputs</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">is_module</span><span class="p">:</span>
        <span class="n">saved_state</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">run_fwd_bwd</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">force_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">assert_compiled</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span> <span class="k">if</span> <span class="n">is_module</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="n">in_vars</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_flatten</span><span class="p">((</span><span class="n">args</span><span class="p">,</span> <span class="n">params</span><span class="p">))</span>
        <span class="c1"># We use a special API to reset the trace and compile it from scratch.</span>
        <span class="n">compiled_fn</span> <span class="o">=</span> <span class="n">model</span>
        <span class="k">if</span> <span class="n">force_trace</span><span class="p">:</span>
            <span class="n">compiled_fn</span><span class="o">.</span><span class="n">clear_cache</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">assert_compiled</span><span class="p">:</span>
            <span class="n">hits</span> <span class="o">=</span> <span class="n">compiled_fn</span><span class="o">.</span><span class="n">hits</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">assert_compiled</span> <span class="ow">and</span> <span class="n">compiled_fn</span><span class="o">.</span><span class="n">hits</span> <span class="o">==</span> <span class="n">hits</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;failed to use the compiled function&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="p">)</span>
        <span class="k">if</span> <span class="n">loss_fn</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">((</span><span class="s2">&quot;Model returns </span><span class="si">{}</span><span class="s2"> outputs, but default loss function &quot;</span>
                              <span class="s2">&quot;(torch.sum) can only handle a single output&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)))</span>
        <span class="n">out_vars</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_flatten</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="n">saved_outs</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">out_vars</span><span class="p">]</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="o">*</span><span class="n">out</span><span class="p">)</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">([</span><span class="n">loss</span><span class="p">],</span> <span class="n">in_vars</span><span class="p">)</span>
        <span class="c1"># TODO: I&#39;m not sure if the clone here is necessary but it is safer</span>
        <span class="n">saved_grads</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">grads</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">saved_outs</span><span class="p">,</span> <span class="n">saved_grads</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">fork_rng</span><span class="p">(</span><span class="n">devices</span><span class="p">,</span> <span class="n">_caller</span><span class="o">=</span><span class="s2">&quot;torch.jit.verify&quot;</span><span class="p">):</span>
        <span class="n">uncompiled_outs</span><span class="p">,</span> <span class="n">uncompiled_grads</span> <span class="o">=</span> <span class="n">run_fwd_bwd</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">force_trace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">has_trace_for</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">is_module</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">saved_state</span><span class="p">)</span>
    <span class="n">compiled_outs</span><span class="p">,</span> <span class="n">compiled_grads</span> <span class="o">=</span> <span class="n">run_fwd_bwd</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">assert_compiled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">_verify_equal</span><span class="p">(</span><span class="n">uncompiled_outs</span><span class="p">,</span> <span class="n">compiled_outs</span><span class="p">)</span>
    <span class="n">_verify_equal</span><span class="p">(</span><span class="n">uncompiled_grads</span><span class="p">,</span> <span class="n">compiled_grads</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_verify_equal</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">1e-6</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;JIT and real computation mismatch&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">indent</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">splitlines</span><span class="p">()])</span>


<span class="k">class</span> <span class="nc">TracingCheckError</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_diff_error</span><span class="p">,</span> <span class="n">tensor_compare_error</span><span class="p">,</span> <span class="n">extra_msg</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="s1">&#39;Tracing failed sanity checks!</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">if</span> <span class="n">extra_msg</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">+=</span> <span class="n">extra_msg</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">if</span> <span class="n">graph_diff_error</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">+=</span> <span class="s1">&#39;ERROR: Graphs differed across invocations!</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">+=</span> <span class="n">indent</span><span class="p">(</span><span class="n">graph_diff_error</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="k">if</span> <span class="n">tensor_compare_error</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">+=</span> <span class="s1">&#39;ERROR: Tensor-valued Constant nodes differed in value &#39;</span> \
                            <span class="s1">&#39;across invocations. This often indicates that the tracer has&#39;</span> \
                            <span class="s1">&#39; encountered untraceable code.</span><span class="se">\n</span><span class="s1">&#39;</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">message</span> <span class="o">+=</span> <span class="n">indent</span><span class="p">(</span><span class="n">tensor_compare_error</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TracingCheckError</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>


<span class="c1"># Check the traced module against a set of user-provided validation inputs</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">_check_trace</span><span class="p">(</span><span class="n">check_inputs</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">traced_func</span><span class="p">,</span> <span class="n">check_tolerance</span><span class="p">,</span>
                 <span class="n">force_outplace</span><span class="p">,</span> <span class="n">is_trace_module</span><span class="p">,</span> <span class="n">_module_class</span><span class="p">):</span>
    <span class="c1"># Note: tracing is independent of optimizations, which consume the trace</span>
    <span class="k">for</span> <span class="n">inputs</span> <span class="ow">in</span> <span class="n">check_inputs</span><span class="p">:</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,)</span>

        <span class="k">if</span> <span class="n">is_trace_module</span><span class="p">:</span>
            <span class="n">copied_dict</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">copied_dict</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">_clone_inputs</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">check_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace_module</span><span class="p">(</span>
                <span class="n">func</span><span class="o">.</span><span class="vm">__self__</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="s1">&#39;__self__&#39;</span><span class="p">)</span> <span class="k">else</span> <span class="n">func</span><span class="p">,</span>
                <span class="n">copied_dict</span><span class="p">,</span>
                <span class="n">check_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">_force_outplace</span><span class="o">=</span><span class="n">force_outplace</span><span class="p">,</span>
                <span class="n">_module_class</span><span class="o">=</span><span class="n">_module_class</span><span class="p">,</span>
                <span class="n">_compilation_unit</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">CompilationUnit</span><span class="p">(),</span>
            <span class="p">)</span>
            <span class="n">check_mod_func</span> <span class="o">=</span> <span class="n">check_mod</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_get_method</span><span class="p">(</span><span class="n">traced_func</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">traced_func</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)):</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">check_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span>
                <span class="n">func</span><span class="p">,</span>
                <span class="n">_clone_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span>
                <span class="n">check_trace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">_force_outplace</span><span class="o">=</span><span class="n">force_outplace</span><span class="p">,</span>
                <span class="n">_module_class</span><span class="o">=</span><span class="n">_module_class</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">check_mod_func</span> <span class="o">=</span> <span class="n">check_mod</span>

        <span class="k">def</span> <span class="nf">graph_diagnostic_info</span><span class="p">():</span>
            <span class="n">mod_canonicalized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_pass_canonicalize</span><span class="p">(</span><span class="n">traced_func</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_pass_erase_shape_information</span><span class="p">(</span><span class="n">mod_canonicalized</span><span class="p">)</span>
            <span class="n">check_canonicalized</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_pass_canonicalize</span><span class="p">(</span><span class="n">check_mod_func</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_pass_erase_shape_information</span><span class="p">(</span><span class="n">check_canonicalized</span><span class="p">)</span>

            <span class="n">graph_diff_errors</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">mod_canonicalized</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">str</span><span class="p">(</span><span class="n">check_canonicalized</span><span class="p">):</span>
                <span class="kn">import</span> <span class="nn">difflib</span>
                <span class="n">graph_diff</span> <span class="o">=</span> <span class="n">difflib</span><span class="o">.</span><span class="n">ndiff</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">mod_canonicalized</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span>
                                           <span class="nb">str</span><span class="p">(</span><span class="n">check_canonicalized</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">(</span><span class="kc">True</span><span class="p">))</span>
                <span class="n">graph_diff_errors</span> <span class="o">=</span> <span class="s1">&#39;Graph diff:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">graph_diff</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>

                <span class="k">for</span> <span class="n">n_mod</span><span class="p">,</span> <span class="n">n_check</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mod_canonicalized</span><span class="o">.</span><span class="n">nodes</span><span class="p">(),</span> <span class="n">check_canonicalized</span><span class="o">.</span><span class="n">nodes</span><span class="p">()):</span>
                    <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_mod</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_check</span><span class="p">):</span>
                        <span class="n">graph_diff_errors</span> <span class="o">+=</span> <span class="s1">&#39;First diverging operator:</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">node_diff</span> <span class="o">=</span> <span class="n">difflib</span><span class="o">.</span><span class="n">ndiff</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">n_mod</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span>
                                                  <span class="nb">str</span><span class="p">(</span><span class="n">n_check</span><span class="p">)</span><span class="o">.</span><span class="n">splitlines</span><span class="p">(</span><span class="kc">True</span><span class="p">))</span>
                        <span class="n">source_printout</span> <span class="o">=</span> <span class="s1">&#39;Node diff:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">node_diff</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">mod_stack</span> <span class="o">=</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">sourceRange</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">mod_stack</span><span class="p">:</span>
                            <span class="n">source_printout</span> <span class="o">+=</span> <span class="s1">&#39;Trace source location:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="n">mod_stack</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">check_stack</span> <span class="o">=</span> <span class="n">n_check</span><span class="o">.</span><span class="n">sourceRange</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">check_stack</span><span class="p">:</span>
                            <span class="n">source_printout</span> <span class="o">+=</span> <span class="s1">&#39;Check source location:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="n">check_stack</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">graph_diff_errors</span> <span class="o">+=</span> <span class="n">source_printout</span>

                        <span class="k">break</span>  <span class="c1"># For now, only print out the first pair of nodes that diverges</span>

            <span class="n">tensor_compare_errors</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="c1"># Check Tensor-valued constant nodes</span>
            <span class="k">for</span> <span class="n">n_mod</span><span class="p">,</span> <span class="n">n_check</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mod_canonicalized</span><span class="o">.</span><span class="n">nodes</span><span class="p">(),</span> <span class="n">check_canonicalized</span><span class="o">.</span><span class="n">nodes</span><span class="p">()):</span>
                <span class="k">if</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">kind</span><span class="p">()</span> <span class="o">!=</span> <span class="n">n_check</span><span class="o">.</span><span class="n">kind</span><span class="p">():</span>
                    <span class="k">break</span>  <span class="c1"># Graphs have already diverged</span>

                <span class="k">if</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">kind</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;prim::Constant&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="p">(</span><span class="n">n_mod</span><span class="o">.</span><span class="n">mustBeNone</span><span class="p">()</span> <span class="ow">or</span> <span class="n">n_check</span><span class="o">.</span><span class="n">mustBeNone</span><span class="p">()):</span>
                    <span class="k">if</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">kindOf</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span> <span class="o">!=</span> <span class="s1">&#39;t&#39;</span> <span class="ow">or</span> <span class="n">n_check</span><span class="o">.</span><span class="n">kindOf</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span> <span class="o">!=</span> <span class="s1">&#39;t&#39;</span><span class="p">:</span>
                        <span class="k">continue</span>

                    <span class="n">mod_tensor_val</span> <span class="o">=</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span>
                    <span class="n">check_tensor_val</span> <span class="o">=</span> <span class="n">n_check</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">)</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">mod_tensor_val</span><span class="p">,</span> <span class="n">check_tensor_val</span><span class="p">)</span>
                    <span class="k">except</span> <span class="p">(</span><span class="ne">RuntimeError</span><span class="p">,</span> <span class="ne">AssertionError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">tensor_compare_errors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">tensor_compare_errors</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
                        <span class="n">tensor_compare_errors</span> <span class="o">+=</span> <span class="s1">&#39;Node:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">n_mod</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">compare_stack</span> <span class="o">=</span> <span class="n">n_mod</span><span class="o">.</span><span class="n">sourceRange</span><span class="p">()</span>
                        <span class="k">if</span> <span class="n">compare_stack</span><span class="p">:</span>
                            <span class="n">tensor_compare_errors</span> <span class="o">+=</span> <span class="s1">&#39;Source Location:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="n">compare_stack</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
                        <span class="n">tensor_compare_errors</span> <span class="o">+=</span> <span class="s1">&#39;Comparison exception: &#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>

                        <span class="k">break</span>  <span class="c1"># For now, only print the first diverging pair</span>

            <span class="k">return</span> <span class="n">graph_diff_errors</span><span class="p">,</span> <span class="n">tensor_compare_errors</span>

        <span class="k">def</span> <span class="nf">wrap_retval</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">x</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span>

        <span class="k">def</span> <span class="nf">run_mod_and_filter_tensor_outputs</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">running_what</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">outs</span> <span class="o">=</span> <span class="n">wrap_retval</span><span class="p">(</span><span class="n">mod</span><span class="p">(</span><span class="o">*</span><span class="n">_clone_inputs</span><span class="p">(</span><span class="n">inputs</span><span class="p">)))</span>
                <span class="n">outs</span> <span class="o">=</span> <span class="p">[</span><span class="n">out</span> <span class="k">for</span> <span class="n">out</span> <span class="ow">in</span> <span class="n">outs</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)]</span>
                <span class="k">return</span> <span class="n">outs</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="n">TracingCheckError</span><span class="p">(</span><span class="o">*</span><span class="n">graph_diagnostic_info</span><span class="p">(),</span>
                                        <span class="n">extra_msg</span><span class="o">=</span><span class="s1">&#39;Encountered an exception while running the &#39;</span> <span class="o">+</span> <span class="n">running_what</span> <span class="o">+</span>
                                                  <span class="s1">&#39; with test inputs.</span><span class="se">\n</span><span class="s1">Exception:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="n">indent</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)))</span>

        <span class="n">has_warned</span> <span class="o">=</span> <span class="p">[</span><span class="kc">False</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">maybe_warn_nondeterministic</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">has_warned</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
                <span class="k">return</span>
            <span class="n">has_warned</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">nondeterm_ops</span> <span class="o">=</span> <span class="p">[</span><span class="n">op</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">traced_func</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">()</span> <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">isNondeterministic</span><span class="p">()]</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">nondeterm_ops</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">nondeterministic_ops_warning</span> <span class="o">=</span> <span class="s2">&quot;Trace had nondeterministic nodes. &quot;</span>
                <span class="n">nondeterministic_ops_warning</span> <span class="o">+=</span> <span class="s2">&quot;Did you forget call .eval() on your model? Nodes:</span><span class="se">\n</span><span class="s2">&quot;</span>
                <span class="n">nondeterministic_ops_warning</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">indent</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">op</span><span class="p">))</span> <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">nondeterm_ops</span><span class="p">][:</span><span class="mi">20</span><span class="p">])</span>
                <span class="n">nondeterministic_ops_warning</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">This may cause errors in trace checking. To disable trace checking,&quot;</span>\
                                                <span class="s2">&quot; pass check_trace=False to torch.jit.trace()&quot;</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">nondeterministic_ops_warning</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">TracerWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">compare_outputs</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">reference</span><span class="p">,</span> <span class="n">match_what</span><span class="p">):</span>
            <span class="n">all_ok</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">orig</span><span class="p">,</span> <span class="n">ref</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">reference</span><span class="p">)):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">orig</span><span class="o">.</span><span class="n">double</span><span class="p">(),</span> <span class="n">ref</span><span class="o">.</span><span class="n">double</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="n">check_tolerance</span><span class="p">,</span>
                                                  <span class="n">atol</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">_get_default_tolerance</span><span class="p">(</span><span class="n">orig</span><span class="p">,</span> <span class="n">ref</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
                <span class="k">except</span> <span class="ne">AssertionError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">maybe_warn_nondeterministic</span><span class="p">()</span>
                    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Output nr &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;. of the traced function does not match &#39;</span>
                                  <span class="s1">&#39;the corresponding output of the &#39;</span> <span class="o">+</span> <span class="n">match_what</span> <span class="o">+</span> <span class="s1">&#39;. Detailed error:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">),</span>
                                  <span class="n">category</span><span class="o">=</span><span class="n">TracerWarning</span><span class="p">,</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
                    <span class="n">all_ok</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="k">return</span> <span class="n">all_ok</span>

        <span class="n">traced_outs</span> <span class="o">=</span> <span class="n">run_mod_and_filter_tensor_outputs</span><span class="p">(</span><span class="n">traced_func</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="s1">&#39;trace&#39;</span><span class="p">)</span>
        <span class="n">fn_outs</span> <span class="o">=</span> <span class="n">run_mod_and_filter_tensor_outputs</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="s1">&#39;Python function&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">compare_outputs</span><span class="p">(</span><span class="n">traced_outs</span><span class="p">,</span> <span class="n">fn_outs</span><span class="p">,</span> <span class="s1">&#39;Python function&#39;</span><span class="p">):</span>
            <span class="n">check_outs</span> <span class="o">=</span> <span class="n">run_mod_and_filter_tensor_outputs</span><span class="p">(</span><span class="n">check_mod_func</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="s1">&#39;repeated trace&#39;</span><span class="p">)</span>
            <span class="n">compare_outputs</span><span class="p">(</span><span class="n">traced_outs</span><span class="p">,</span> <span class="n">check_outs</span><span class="p">,</span> <span class="s1">&#39;repeated trace&#39;</span><span class="p">)</span>

        <span class="n">diag_info</span> <span class="o">=</span> <span class="n">graph_diagnostic_info</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">info</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">info</span> <span class="ow">in</span> <span class="n">diag_info</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">TracingCheckError</span><span class="p">(</span><span class="o">*</span><span class="n">diag_info</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TracerWarning</span><span class="p">(</span><span class="ne">Warning</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">ignore_lib_warnings</span><span class="p">():</span>
        <span class="c1"># We ignore warnings from all submodules excluding the JIT, because we need them e.g. for _check_trace</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">TracerWarning</span><span class="p">,</span> <span class="n">module</span><span class="o">=</span><span class="s1">&#39;torch.(?!jit)&#39;</span><span class="p">)</span>


<span class="c1"># We ignore the tracer warnings coming form inside the library, because all our shape</span>
<span class="c1"># checks in nn will trigger them.</span>
<span class="n">TracerWarning</span><span class="o">.</span><span class="n">ignore_lib_warnings</span><span class="p">()</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_tracer_warn_use_python</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">make_tuple</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">example_inputs</span><span class="p">,)</span>
    <span class="c1"># done primarily so that weird iterables fail here and not pybind11 code</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">example_inputs</span>


<span class="k">def</span> <span class="nf">make_module</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">_module_class</span><span class="p">,</span> <span class="n">_compilation_unit</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">_module_class</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_module_class</span> <span class="o">=</span> <span class="n">TopLevelTracedModule</span>
    <span class="k">return</span> <span class="n">_module_class</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">_compilation_unit</span><span class="o">=</span><span class="n">_compilation_unit</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">wrap_check_inputs</span><span class="p">(</span><span class="n">check_inputs</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">check_inputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">return</span> <span class="p">[{</span><span class="s1">&#39;forward&#39;</span> <span class="p">:</span> <span class="n">c</span><span class="p">}</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">check_inputs</span><span class="p">]</span>

<div class="viewcode-block" id="trace"><a class="viewcode-back" href="../../jit.html#torch.jit.trace">[docs]</a><span class="k">def</span> <span class="nf">trace</span><span class="p">(</span><span class="n">func</span><span class="p">,</span>
          <span class="n">example_inputs</span><span class="p">,</span>
          <span class="n">optimize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">check_trace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
          <span class="n">check_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">check_tolerance</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
          <span class="n">_force_outplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
          <span class="n">_module_class</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">_compilation_unit</span><span class="o">=</span><span class="n">_python_cu</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trace a function and return an executable ``ScriptModule`` or ``torch.jit._C.Function``</span>
<span class="sd">    that will be optimized using just-in-time compilation.</span>

<span class="sd">    .. warning::</span>

<span class="sd">        Tracing only correctly records functions and modules which are not data</span>
<span class="sd">        dependent (e.g., do not have conditionals on data in tensors) and do not have</span>
<span class="sd">        any untracked external dependencies (e.g., perform input/output or</span>
<span class="sd">        access global variables). If you trace such models, you may silently get</span>
<span class="sd">        incorrect results on subsequent invocations of the model. The tracer</span>
<span class="sd">        will try to emit warnings when doing something that may cause an</span>
<span class="sd">        incorrect trace to be produced.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        func (callable or torch.nn.Module):  a Python function or ``torch.nn.Module``</span>
<span class="sd">                                             that will be run with ``example_inputs``.</span>
<span class="sd">                                             arguments and returns to ``func`` must be tensors</span>
<span class="sd">                                             or (possibly nested) tuples that</span>
<span class="sd">                                             contain tensors.</span>
<span class="sd">        example_inputs (tuple):  a tuple of example inputs that will be passed to the function</span>
<span class="sd">                                 while tracing. The resulting trace can be run with</span>
<span class="sd">                                 inputs of different types and shapes assuming the traced operations</span>
<span class="sd">                                 support those types and shapes. ``example_inputs`` may also be a single</span>
<span class="sd">                                 Tensor in which case it is automatically wrapped in a tuple</span>

<span class="sd">    Keyword arguments:</span>
<span class="sd">        check_trace (bool, optional): check if the same inputs run through</span>
<span class="sd">                                      traced code produce the same outputs. Default: ``True``. You might want</span>
<span class="sd">                                      to disable this if, for example, your network contains non-</span>
<span class="sd">                                      deterministic ops or if you are sure that the network is correct despite</span>
<span class="sd">                                      a checker failure.</span>

<span class="sd">        check_inputs (list of tuples, optional): A list of tuples of input arguments that should be used</span>
<span class="sd">                                                 to check the trace against what is expected. Each tuple</span>
<span class="sd">                                                 is equivalent to a set of input arguments that would</span>
<span class="sd">                                                 be specified in ``example_inputs``. For best results, pass in a</span>
<span class="sd">                                                 set of checking inputs representative of the space of</span>
<span class="sd">                                                 shapes and types of inputs you expect the network to see.</span>
<span class="sd">                                                 If not specified, the original ``example_inputs`` are used for checking</span>
<span class="sd">        check_tolerance (float, optional): Floating-point comparison tolerance to use in the checker procedure.</span>
<span class="sd">                                           This can be used to relax the checker strictness in the event that</span>
<span class="sd">                                           results diverge numerically for a known reason, such as operator fusion.</span>

<span class="sd">    Returns:</span>
<span class="sd">        if ``callable`` is ``nn.Module`` or ``forward()`` of ``nn.Module``, ``trace`` returns</span>
<span class="sd">        a ``ScriptModule`` object with a single ``forward()`` method containing the traced code.</span>
<span class="sd">        The returned ``ScriptModule`` will have the same set of sub-modules and parameters as the</span>
<span class="sd">        original ``nn.Module``.</span>
<span class="sd">        If ``callable`` is a standalone function, ``trace`` returns ``torch.jit._C.Function``</span>

<span class="sd">    Example::</span>

<span class="sd">        class Net(nn.Module):</span>
<span class="sd">            def __init__(self):</span>
<span class="sd">                super(Net, self).__init__()</span>
<span class="sd">                self.conv = nn.Conv2d(1, 1, 3)</span>

<span class="sd">            def forward(self, x):</span>
<span class="sd">                return self.conv(x)</span>

<span class="sd">            def weighted_kernel_sum(self, weight):</span>
<span class="sd">                return weight * self.conv.weight</span>

<span class="sd">        example_weight = torch.rand(1, 1, 3, 3)</span>
<span class="sd">        example_forward_input = torch.rand(1, 1, 3, 3)</span>
<span class="sd">        n = Net()</span>
<span class="sd">        # the following two calls are equivalent</span>
<span class="sd">        module = torch.jit.trace_module(n, example_forward_input)</span>
<span class="sd">        module = torch.jit.trace_module(n.forward, example_forward_input)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_enabled</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">func</span>
    <span class="k">if</span> <span class="n">optimize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;`optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">ScriptModule</span><span class="p">):</span>
        <span class="c1"># it is hard to trace it because the forward method on ScriptModule is already defined, so it</span>
        <span class="c1"># would result in an error.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;The input to trace is already a ScriptModule, tracing it is a no-op. Returning the object as is.&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">func</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">trace_module</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;forward&#39;</span><span class="p">:</span> <span class="n">example_inputs</span><span class="p">},</span> <span class="kc">None</span><span class="p">,</span>
                            <span class="n">check_trace</span><span class="p">,</span> <span class="n">wrap_check_inputs</span><span class="p">(</span><span class="n">check_inputs</span><span class="p">),</span>
                            <span class="n">check_tolerance</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">,</span> <span class="n">_module_class</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="s1">&#39;__self__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="vm">__self__</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="ow">and</span>
            <span class="n">func</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;forward&#39;</span><span class="p">):</span>

        <span class="k">return</span> <span class="n">trace_module</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="vm">__self__</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;forward&#39;</span><span class="p">:</span> <span class="n">example_inputs</span><span class="p">},</span> <span class="kc">None</span><span class="p">,</span>
                            <span class="n">check_trace</span><span class="p">,</span> <span class="n">wrap_check_inputs</span><span class="p">(</span><span class="n">check_inputs</span><span class="p">),</span>
                            <span class="n">check_tolerance</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">,</span> <span class="n">_module_class</span><span class="p">)</span>

    <span class="c1"># Special case for common case of passing a single Tensor</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)):</span>
        <span class="n">example_inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">example_inputs</span><span class="p">,)</span>
    <span class="c1"># done primarily so that weird iterables fail here and not pybind11 code</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
        <span class="n">example_inputs</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">)</span>

    <span class="n">var_lookup_fn</span> <span class="o">=</span> <span class="n">_create_interpreter_name_lookup_fn</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="s1">&#39;__self__&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="vm">__self__</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;trace doesn&#39;t support compiling individual module&#39;s functions.</span><span class="se">\n</span><span class="s2">&quot;</span>
                             <span class="s2">&quot;Please use trace_module&quot;</span><span class="p">)</span>

    <span class="n">name</span> <span class="o">=</span> <span class="n">_qualified_name</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;&lt;lambda&gt;&#39;</span><span class="p">:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;_lambda&#39;</span>  <span class="c1"># make name a valid identifier</span>
    <span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_create_function_from_trace</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">,</span>
                                                  <span class="n">var_lookup_fn</span><span class="p">,</span>
                                                  <span class="n">_force_outplace</span><span class="p">)</span>

    <span class="c1"># Check the trace against new traces created from user-specified inputs</span>
    <span class="k">if</span> <span class="n">check_trace</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">check_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_check_trace</span><span class="p">(</span><span class="n">check_inputs</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">traced</span><span class="p">,</span> <span class="n">check_tolerance</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">_module_class</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_check_trace</span><span class="p">([</span><span class="n">example_inputs</span><span class="p">],</span> <span class="n">func</span><span class="p">,</span> <span class="n">traced</span><span class="p">,</span> <span class="n">check_tolerance</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">_module_class</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">traced</span></div>


<span class="k">def</span> <span class="nf">trace_module</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span>
                 <span class="n">inputs</span><span class="p">,</span>
                 <span class="n">optimize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">check_trace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">check_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">check_tolerance</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span>
                 <span class="n">_force_outplace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">_module_class</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">_compilation_unit</span><span class="o">=</span><span class="n">_python_cu</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trace a module and return an executable ``ScriptModule`` that will be optimized</span>
<span class="sd">    using just-in-time compilation.</span>

<span class="sd">    .. warning::</span>

<span class="sd">        Tracing only correctly records functions and modules which are not data</span>
<span class="sd">        dependent (e.g., do not have conditionals on data in tensors) and do not have</span>
<span class="sd">        any untracked external dependencies (e.g., perform input/output or</span>
<span class="sd">        access global variables). If you trace such models, you may silently get</span>
<span class="sd">        incorrect results on subsequent invocations of the model. The tracer</span>
<span class="sd">        will try to emit warnings when doing something that may cause an</span>
<span class="sd">        incorrect trace to be produced.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        mod (torch.nn.Module):           a ``torch.nn.Module`` containing methods whose names are</span>
<span class="sd">                                         specified in ``example_inputs``. The given methods will be compiled</span>
<span class="sd">                                         as a part of a single `ScriptModule`</span>
<span class="sd">        example_inputs (dict):           a dict containing sample inputs indexed by method names in ``mod``</span>
<span class="sd">                                         The inputs will be passed to methods whose names correspond to inputs&#39;</span>
<span class="sd">                                         keys while tracing.</span>
<span class="sd">                                         ``{ &#39;forward&#39; : example_forward_input, &#39;method2&#39;: example_method2_input}``</span>
<span class="sd">    Keyword arguments:</span>
<span class="sd">        check_trace (bool, optional): check if the same inputs run through</span>
<span class="sd">                                      traced code produce the same outputs. Default: ``True``. You might want</span>
<span class="sd">                                      to disable this if, for example, your network contains non-</span>
<span class="sd">                                      deterministic ops or if you are sure that the network is correct despite</span>
<span class="sd">                                      a checker failure.</span>

<span class="sd">        check_inputs (list of dicts, optional): A list of dicts of input arguments that should be used</span>
<span class="sd">                                                 to check the trace against what is expected. Each tuple</span>
<span class="sd">                                                 is equivalent to a set of input arguments that would</span>
<span class="sd">                                                 be specified in ``example_inputs``. For best results, pass in a</span>
<span class="sd">                                                 set of checking inputs representative of the space of</span>
<span class="sd">                                                 shapes and types of inputs you expect the network to see.</span>
<span class="sd">                                                 If not specified, the original ``example_inputs`` are used for checking</span>
<span class="sd">        check_tolerance (float, optional): Floating-point comparison tolerance to use in the checker procedure.</span>
<span class="sd">                                           This can be used to relax the checker strictness in the event that</span>
<span class="sd">                                           results diverge numerically for a known reason, such as operator fusion.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A ``ScriptModule`` object with a single ``forward()`` method containing the traced code.</span>
<span class="sd">        When ``func`` is a ``torch.nn.Module``, the returned ``ScriptModule`` will have the same set of</span>
<span class="sd">        sub-modules and parameters as ``func``.</span>

<span class="sd">    Example::</span>

<span class="sd">        class Net(nn.Module):</span>
<span class="sd">            def __init__(self):</span>
<span class="sd">                super(Net, self).__init__()</span>
<span class="sd">                self.conv = nn.Conv2d(1, 1, 3)</span>

<span class="sd">            def forward(self, x):</span>
<span class="sd">                return self.conv(x)</span>

<span class="sd">            def weighted_kernel_sum(self, weight):</span>
<span class="sd">                return weight * self.conv.weight</span>

<span class="sd">        example_weight = torch.rand(1, 1, 3, 3)</span>
<span class="sd">        example_forward_input = torch.rand(1, 1, 3, 3)</span>
<span class="sd">        inputs = {&#39;forward&#39; : example_forward_input, &#39;weighted_kernel_sum&#39; : example_weight}</span>
<span class="sd">        n = Net()</span>
<span class="sd">        module = torch.jit.trace_module(n, inputs)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_enabled</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">mod</span>
    <span class="k">if</span> <span class="n">optimize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;`optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead&quot;</span><span class="p">)</span>

    <span class="n">var_lookup_fn</span> <span class="o">=</span> <span class="n">_create_interpreter_name_lookup_fn</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;expected torch.nn.Module as the first argument&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;expected a dictionary of (method_name, input) pairs&quot;</span><span class="p">)</span>

    <span class="n">module</span> <span class="o">=</span> <span class="n">make_module</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">_module_class</span><span class="p">,</span> <span class="n">_compilation_unit</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">method_name</span><span class="p">,</span> <span class="n">example_inputs</span> <span class="ow">in</span> <span class="n">inputs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># this is needed since Module.__call__ sets up some extra tracing</span>
        <span class="n">func</span> <span class="o">=</span> <span class="n">mod</span> <span class="k">if</span> <span class="n">method_name</span> <span class="o">==</span> <span class="s2">&quot;forward&quot;</span> <span class="k">else</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">method_name</span><span class="p">)</span>
        <span class="n">example_inputs</span> <span class="o">=</span> <span class="n">make_tuple</span><span class="p">(</span><span class="n">example_inputs</span><span class="p">)</span>
        <span class="n">module</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_create_method_from_trace</span><span class="p">(</span><span class="n">method_name</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">,</span> <span class="n">var_lookup_fn</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">)</span>
        <span class="n">check_trace_method</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_get_method</span><span class="p">(</span><span class="n">method_name</span><span class="p">)</span>

        <span class="c1"># Check the trace against new traces created from user-specified inputs</span>
        <span class="k">if</span> <span class="n">check_trace</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">check_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_check_trace</span><span class="p">(</span><span class="n">check_inputs</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">check_trace_method</span><span class="p">,</span>
                             <span class="n">check_tolerance</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">_module_class</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">_check_trace</span><span class="p">([</span><span class="n">inputs</span><span class="p">],</span> <span class="n">func</span><span class="p">,</span> <span class="n">check_trace_method</span><span class="p">,</span>
                             <span class="n">check_tolerance</span><span class="p">,</span> <span class="n">_force_outplace</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">_module_class</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">module</span>


<span class="k">class</span> <span class="nc">CompilationUnit</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_frames_up</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">CompilationUnit</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">lang</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">_frames_up</span><span class="o">=</span><span class="n">_frames_up</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">define</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">rcb</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_frames_up</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">rcb</span><span class="p">:</span>
            <span class="n">rcb</span> <span class="o">=</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">createResolutionCallback</span><span class="p">(</span><span class="n">_frames_up</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">rcb</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">find_function</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">r</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;&#39;CompilationUnit&#39; has no attribute &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attr</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="k">def</span> <span class="nf">_import</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">constants</span><span class="p">,</span> <span class="n">op_version_set</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; test import logic for single function, use only for testing &quot;&quot;&quot;</span>
        <span class="n">src</span> <span class="o">=</span> <span class="s2">&quot;op_version_set = </span><span class="si">{}</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">op_version_set</span><span class="p">,</span> <span class="n">src</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_import_functions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">constants</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>


<span class="k">def</span> <span class="nf">_try_get_dispatched_fn</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">boolean_dispatched</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_try_get_overloaded_fn</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">field</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">mod</span><span class="o">.</span><span class="n">_overloads</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">field</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">ScriptModule</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span>


<span class="k">class</span> <span class="nc">ScriptWarning</span><span class="p">(</span><span class="ne">Warning</span><span class="p">):</span>
    <span class="k">pass</span>


<span class="k">def</span> <span class="nf">_create_constant_iterable_module</span><span class="p">(</span><span class="n">module</span><span class="p">):</span>
    <span class="n">modules</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">submodule</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="p">(</span><span class="n">ModuleList</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">)):</span>
            <span class="c1"># Make each item in the module a constant</span>
            <span class="n">modules</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">_create_constant_iterable_module</span><span class="p">(</span><span class="n">submodule</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">modules</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">_convert_to_script_module</span><span class="p">(</span><span class="n">submodule</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_ConstSequential</span><span class="p">(</span><span class="n">Sequential</span><span class="p">(</span><span class="n">modules</span><span class="p">))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">ModuleList</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_ConstModuleList</span><span class="p">(</span><span class="n">modules</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Only nn.ModuleList and nn.Sequential can be made &quot;</span>
                           <span class="s2">&quot;into constant modules, found </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">module</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">_make_strong_submodule</span><span class="p">(</span><span class="n">field</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">parent</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">field</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">parent</span><span class="o">.</span><span class="n">_modules</span><span class="p">:</span>
        <span class="c1"># It&#39;s not a submodule, don&#39;t do anything</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># Convert the module to a ScriptModule</span>
    <span class="n">new_strong_submodule</span> <span class="o">=</span> <span class="n">_convert_to_script_module</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

    <span class="c1"># Install the ScriptModule on the python side</span>
    <span class="n">parent</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">_python_modules</span><span class="p">[</span><span class="n">field</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_strong_submodule</span>

    <span class="k">return</span> <span class="n">new_strong_submodule</span>


<span class="k">def</span> <span class="nf">_try_compile_fn</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">loc</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">is_ignored_fn</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="c1"># Don&#39;t do anything for @ignore&#39;d functions</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="c1"># Since modules are callable pybind recognizes them as functions, but</span>
        <span class="c1"># don&#39;t do anything for them</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isfunction</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">inspect</span><span class="o">.</span><span class="n">ismethod</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;`</span><span class="si">{}</span><span class="s2">` is not a function. Recursive scripting only supports &quot;</span>
                           <span class="s2">&quot;Python functions or methods currently.</span><span class="se">\n</span><span class="s2">&quot;</span>
                           <span class="s2">&quot;Consider manually annotating `</span><span class="si">{}</span><span class="s2">` with @torch.jit.script.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">fn</span><span class="p">))</span>

    <span class="c1"># We don&#39;t have the actual scope where the function was defined, but we can</span>
    <span class="c1"># extract the necessary info from the closed over variables on the function</span>
    <span class="c1"># object</span>
    <span class="n">rcb</span> <span class="o">=</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">createResolutionCallbackFromClosure</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="n">qualified_name</span> <span class="o">=</span> <span class="n">_qualified_name</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_compile_function</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">qualified_name</span><span class="o">=</span><span class="n">qualified_name</span><span class="p">,</span> <span class="n">_frames_up</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">_rcb</span><span class="o">=</span><span class="n">rcb</span><span class="p">)</span>


<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">_disable_emit_hooks</span><span class="p">():</span>
    <span class="n">hooks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_get_emit_hooks</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_set_emit_hooks</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">yield</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_set_emit_hooks</span><span class="p">(</span><span class="n">hooks</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hooks</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_create_method_from_fn</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">is_ignored_fn</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">inspect</span><span class="o">.</span><span class="n">ismethod</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="n">stub</span> <span class="o">=</span> <span class="n">script_method</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">createResolutionCallbackFromClosure</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span>
    <span class="k">with</span> <span class="n">_disable_emit_hooks</span><span class="p">():</span>
        <span class="c1"># We don&#39;t want to call the hooks here since the graph that is calling</span>
        <span class="c1"># this function is not yet complete</span>
        <span class="n">_create_methods_from_stubs</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">stub</span><span class="p">,))</span>
    <span class="k">return</span> <span class="n">stub</span>


<span class="c1"># ScriptClasses must be new-style classes because we construct them using their</span>
<span class="c1"># __new__ method.</span>
<span class="k">def</span> <span class="nf">_is_new_style_class</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s1">&#39;__class__&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="s1">&#39;__dict__&#39;</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s1">&#39;__slots__&#39;</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">whichmodule</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Find the module an object belong to.&quot;&quot;&quot;</span>
    <span class="n">module_name</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s1">&#39;__module__&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="c1"># Protect the iteration by using a list copy of sys.modules against dynamic</span>
    <span class="c1"># modules that trigger imports of other modules upon calls to getattr.</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span> <span class="ow">or</span> <span class="n">module</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">_getattribute</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">is</span> <span class="n">obj</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">module_name</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">pass</span>
    <span class="k">return</span> <span class="s1">&#39;__main__&#39;</span>


<span class="k">def</span> <span class="nf">_compile_and_register_class</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">rcb</span><span class="p">,</span> <span class="n">qualified_name</span><span class="p">):</span>
    <span class="n">ast</span> <span class="o">=</span> <span class="n">get_jit_class_def</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="n">_jit_script_class_compile</span><span class="p">(</span><span class="n">qualified_name</span><span class="p">,</span> <span class="n">ast</span><span class="p">,</span> <span class="n">rcb</span><span class="p">)</span>
    <span class="n">_add_script_class</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">qualified_name</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_compile_function</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">qualified_name</span><span class="p">,</span> <span class="n">_frames_up</span><span class="p">,</span> <span class="n">_rcb</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">ast</span> <span class="o">=</span> <span class="n">get_jit_def</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">_rcb</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">closure_rcb</span> <span class="o">=</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">createResolutionCallbackFromClosure</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
        <span class="n">stack_rcb</span> <span class="o">=</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">createResolutionCallback</span><span class="p">(</span><span class="n">_frames_up</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">_rcb</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
            <span class="c1"># since type comments aren&#39;t captured in the function&#39;s closures,</span>
            <span class="c1"># we still need to try to the rcb based on stack frames if the</span>
            <span class="c1"># closure rcb fails</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">closure_rcb</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">result</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">result</span>
            <span class="k">return</span> <span class="n">stack_rcb</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="n">script_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_script_compile</span><span class="p">(</span><span class="n">qualified_name</span><span class="p">,</span> <span class="n">ast</span><span class="p">,</span> <span class="n">_rcb</span><span class="p">,</span> <span class="n">get_default_args</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span>
    <span class="c1"># Forward docstrings</span>
    <span class="n">script_fn</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="vm">__doc__</span>
    <span class="k">return</span> <span class="n">script_fn</span>


<div class="viewcode-block" id="script"><a class="viewcode-back" href="../../jit.html#torch.jit.script">[docs]</a><span class="k">def</span> <span class="nf">script</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_frames_up</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">_rcb</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Scripting a function or ``nn.Module`` will inspect the source code, compile</span>
<span class="sd">    it as TorchScript code using the TorchScript compiler, and return a ``ScriptModule`` or</span>
<span class="sd">    ``torch._C.Function``.</span>

<span class="sd">    **Scripting a function**</span>
<span class="sd">        The ``@torch.jit.script`` decorator will construct a ``torch._C.Function``.</span>

<span class="sd">        Example (scripting a function)::</span>

<span class="sd">            import torch</span>
<span class="sd">            @torch.jit.script</span>
<span class="sd">            def foo(x, y):</span>
<span class="sd">                if x.max() &gt; y.max():</span>
<span class="sd">                    r = x</span>
<span class="sd">                else:</span>
<span class="sd">                    r = y</span>
<span class="sd">                return r</span>

<span class="sd">    **Scripting an nn.Module**</span>
<span class="sd">        Scripting an ``nn.Module`` by default will compile the ``forward`` method and recursively</span>
<span class="sd">        compile any methods, submodules, and functions called by ``forward``. If a ``nn.Module`` only uses</span>
<span class="sd">        features supported in TorchScript, no changes to the original module code should be necessary.</span>

<span class="sd">        Example (scripting a simple module with a Parameter)::</span>

<span class="sd">            import torch</span>

<span class="sd">            class MyModule(torch.nn.Module):</span>
<span class="sd">                def __init__(self, N, M):</span>
<span class="sd">                    super(MyModule, self).__init__()</span>
<span class="sd">                    # This parameter will be copied to the new ScriptModule</span>
<span class="sd">                    self.weight = torch.nn.Parameter(torch.rand(N, M))</span>

<span class="sd">                    # When this submodule is used, it will be compiled</span>
<span class="sd">                    self.linear = torch.nn.Linear(N, M)</span>

<span class="sd">                def forward(self, input):</span>
<span class="sd">                    output = self.weight.mv(input)</span>

<span class="sd">                    # This calls the `forward` method of the `nn.Linear` module, which will</span>
<span class="sd">                    # cause the `self.linear` submodule to be compiled to a `ScriptModule` here</span>
<span class="sd">                    output = self.linear(output)</span>
<span class="sd">                    return output</span>

<span class="sd">            scripted_module = torch.jit.script(MyModule())</span>

<span class="sd">        Example (scripting a module with traced submodules)::</span>

<span class="sd">            import torch</span>
<span class="sd">            import torch.nn as nn</span>
<span class="sd">            import torch.nn.functional as F</span>

<span class="sd">            class MyModule(nn.Module):</span>
<span class="sd">                def __init__(self):</span>
<span class="sd">                    super(MyModule, self).__init__()</span>
<span class="sd">                    # torch.jit.trace produces a ScriptModule&#39;s conv1 and conv2</span>
<span class="sd">                    self.conv1 = torch.jit.trace(nn.Conv2d(1, 20, 5), torch.rand(1, 1, 16, 16))</span>
<span class="sd">                    self.conv2 = torch.jit.trace(nn.Conv2d(20, 20, 5), torch.rand(1, 20, 16, 16))</span>

<span class="sd">                def forward(self, input):</span>
<span class="sd">                  input = F.relu(self.conv1(input))</span>
<span class="sd">                  input = F.relu(self.conv2(input))</span>
<span class="sd">                  return input</span>

<span class="sd">            scripted_module = torch.jit.script(MyModule())</span>

<span class="sd">        To compile a method other than ``forward`` (and recursively compile anything it calls), add</span>
<span class="sd">        the ``@torch.jit.export`` decorator to the method.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_enabled</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">obj</span>

    <span class="k">if</span> <span class="n">optimize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;`optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead&quot;</span><span class="p">)</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_clear_compilation_stack_DELETEME</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_convert_to_script_module</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>

    <span class="n">qualified_name</span> <span class="o">=</span> <span class="n">_qualified_name</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isclass</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
        <span class="c1"># If this type is a `nn.Module` subclass, they probably meant to pass</span>
        <span class="c1"># an instance instead of a Module</span>
        <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Type &#39;</span><span class="si">{}</span><span class="s2">&#39; cannot be compiled since it inherits&quot;</span>
                               <span class="s2">&quot; from nn.Module,&quot;</span>
                               <span class="s2">&quot; pass an instance instead&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">obj</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_new_style_class</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;TorchScript classes must be new-style classes. &quot;</span>
                               <span class="s2">&quot;Please inherit from &#39;object&#39;&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">_rcb</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_rcb</span> <span class="o">=</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">createResolutionCallback</span><span class="p">(</span><span class="n">_frames_up</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">_compile_and_register_class</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">_rcb</span><span class="p">,</span> <span class="n">qualified_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">obj</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_compile_function</span><span class="p">(</span><span class="n">fn</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span> <span class="n">qualified_name</span><span class="o">=</span><span class="n">qualified_name</span><span class="p">,</span> <span class="n">_frames_up</span><span class="o">=</span><span class="n">_frames_up</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">_rcb</span><span class="o">=</span><span class="n">_rcb</span><span class="p">)</span></div>


<span class="n">ScriptMethodStub</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;ScriptMethodStub&#39;</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;resolution_callback&#39;</span><span class="p">,</span> <span class="s1">&#39;def_&#39;</span><span class="p">,</span> <span class="s1">&#39;original_method&#39;</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">script_method</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">_rcb</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">_enabled</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fn</span>
    <span class="c1"># NOTE: we need to traverse two frames here because the meta-class frame</span>
    <span class="c1"># for ScriptModule will be present, as opposed to invoking @script on a</span>
    <span class="c1"># a function or invoking define() on a CompilationUnit.</span>
    <span class="c1"># The stack will look like:</span>
    <span class="c1">#</span>
    <span class="c1"># 0. createResolutionCallback()</span>
    <span class="c1"># 1. script_method()</span>
    <span class="c1"># 2. ScriptModule metaclass frame</span>
    <span class="c1"># 3. Surrounding scope</span>
    <span class="c1">#</span>
    <span class="c1"># createResolutionCallback internally adds 1 to get us to the scope of this</span>
    <span class="c1"># function (the calling function). Adding 2 gets us to the proper surrounding scope.</span>
    <span class="k">if</span> <span class="n">_rcb</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_rcb</span> <span class="o">=</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">createResolutionCallback</span><span class="p">(</span><span class="n">frames_up</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ast</span> <span class="o">=</span> <span class="n">get_jit_def</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">self_name</span><span class="o">=</span><span class="s2">&quot;ScriptModule&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ScriptMethodStub</span><span class="p">(</span><span class="n">_rcb</span><span class="p">,</span> <span class="n">ast</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>



<span class="c1"># These OrderedDictWrapper classes replace the actual OrderedDicts in</span>
<span class="c1"># module with versions that get/set properties inside of script::Module.</span>
<span class="c1"># This allows us to reuse most of nn.Module while still storing the</span>
<span class="c1"># data in C++.</span>
<span class="c1"># Each OrderedDict needs to support:</span>
<span class="c1">#  x not in view</span>
<span class="c1">#  x in view</span>
<span class="c1">#  view[name] = ...</span>
<span class="c1">#  view.values()</span>
<span class="c1">#  del view[name]</span>
<span class="c1">#  view.items()</span>
<span class="c1">#  view.keys()</span>
<span class="c1">#  len(view)</span>

<span class="k">class</span> <span class="nc">OrderedDictWrapper</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span> <span class="o">=</span> <span class="n">module</span>

    <span class="k">def</span> <span class="nf">keys</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>

    <span class="k">def</span> <span class="nf">values</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">()]</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">__delitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;cannot delete methods or parameters of a script module&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>


<span class="k">class</span> <span class="nc">OrderedModuleDict</span><span class="p">(</span><span class="n">OrderedDictWrapper</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OrderedModuleDict</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
        <span class="c1"># contains _both_ script modules and non-script python-only modules</span>

        <span class="c1"># because script modules are subclassed in python and the</span>
        <span class="c1"># C++ script::Module class will not hold references to them,</span>
        <span class="c1"># to ensure that you always get the same python value here</span>
        <span class="c1"># we store it in the python dict as well</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">r</span>

    <span class="k">def</span> <span class="nf">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span>

    <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot re-assign modules in a ScriptModule, &quot;</span>
                               <span class="s2">&quot;tried to replace existing module &#39;</span><span class="si">{}</span><span class="s2">&#39;: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ScriptModule</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_register_module</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="o">.</span><span class="n">_c</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_python_modules</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">OrderedParameterDict</span><span class="p">(</span><span class="n">OrderedDictWrapper</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OrderedParameterDict</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_get_parameters</span><span class="p">()]</span>

    <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_register_parameter</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_has_parameter</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_get_parameter</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">OrderedBufferDict</span><span class="p">(</span><span class="n">OrderedDictWrapper</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OrderedBufferDict</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">items</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_get_attributes</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_register_buffer</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__contains__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_has_buffer</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_get_buffer</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

<span class="c1"># base types that can be constants</span>
<span class="c1"># in addition, tuples and lists of these base types are also considered constants</span>
<span class="c1"># If you edit this list, then you also need to edit the handlers in</span>
<span class="c1"># ConstantValue in jit/script/init.cpp</span>
<span class="n">_constant_types</span> <span class="o">=</span> <span class="p">(</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="n">types</span><span class="o">.</span><span class="n">FunctionType</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_valid_constant</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">v</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">_constant_types</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">v</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">_get_valid_constant</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">v</span><span class="p">)</span>
    <span class="n">constants</span> <span class="o">=</span> <span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">typ</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">typ</span> <span class="ow">in</span> <span class="n">_constant_types</span><span class="p">)</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">textwrap</span><span class="o">.</span><span class="n">dedent</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        &#39;</span><span class="si">{}</span><span class="s2">&#39; object for attribute &#39;</span><span class="si">{}</span><span class="s2">&#39; is not a valid constant.</span>
<span class="s2">        Valid constants are:</span>
<span class="s2">          1. a nn.ModuleList</span>
<span class="s2">          2. a value of type {{</span><span class="si">{}</span><span class="s2">}}</span>
<span class="s2">          3. a list or tuple of (2)</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">constants</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">_create_methods_from_stubs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stubs</span><span class="p">):</span>
    <span class="n">defs</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">def_</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">stubs</span><span class="p">]</span>
    <span class="n">rcbs</span> <span class="o">=</span> <span class="p">[</span><span class="n">m</span><span class="o">.</span><span class="n">resolution_callback</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">stubs</span><span class="p">]</span>
    <span class="n">defaults</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_default_args</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">original_method</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">stubs</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_create_methods</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">defs</span><span class="p">,</span> <span class="n">rcbs</span><span class="p">,</span> <span class="n">defaults</span><span class="p">)</span>

<span class="c1"># For each user-defined class that subclasses ScriptModule this meta-class,</span>
<span class="c1"># (1) finds all the methods annotated with @script_method</span>
<span class="c1"># in a ScriptModule and removes them from the class attributes, and</span>
<span class="c1"># (2) puts a wrapper around the class&#39;s __init__ method to register</span>
<span class="c1"># all of the script_methods with the module after the original __init__</span>
<span class="c1"># has run. This has to occur after the user-defined __init__ so that</span>
<span class="c1"># submodules and parameters are initialized _before_ the script compiler</span>
<span class="c1"># resolve references to `self.param` or `self.module`.</span>


<span class="k">class</span> <span class="nc">ScriptMeta</span><span class="p">(</span><span class="nb">type</span><span class="p">):</span>
    <span class="c1"># this has to inherit from pybind11&#39;s metaclass otherwise we get</span>
    <span class="c1"># issues because ScriptModule inherits from torch._C.ScriptModule,</span>
    <span class="c1"># a pybind11 type</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">bases</span><span class="p">,</span> <span class="n">attrs</span><span class="p">):</span>
        <span class="c1"># initialize inherited properties</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_methods</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_constants_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s1">&#39;__constants__&#39;</span><span class="p">,</span> <span class="p">()))</span>
        <span class="k">for</span> <span class="n">base</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">bases</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="s1">&#39;_methods&#39;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">_methods</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
            <span class="n">base_constants</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="s1">&#39;_constants_set&#39;</span><span class="p">,</span> <span class="nb">set</span><span class="p">())</span>
            <span class="bp">cls</span><span class="o">.</span><span class="n">_constants_set</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_constants_set</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">base_constants</span><span class="p">)</span>

        <span class="c1"># find all the script methods of the current class</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">attrs</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">ScriptMethodStub</span><span class="p">):</span>
                <span class="nb">delattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">_methods</span><span class="p">[</span><span class="n">v</span><span class="o">.</span><span class="n">original_method</span><span class="o">.</span><span class="vm">__name__</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

        <span class="n">original_init</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s1">&#39;__init__&#39;</span><span class="p">,</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">cls</span><span class="o">.</span><span class="n">_overloads</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="s1">&#39;__overloads__&#39;</span><span class="p">,</span> <span class="p">{}))</span>

        <span class="c1"># after the user&#39;s __init__ register all the script methods</span>
        <span class="c1"># with the module</span>
        <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">original_init</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">init_then_register</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">original_init</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">==</span> <span class="bp">cls</span><span class="p">:</span>
                <span class="c1"># this is the init of the concrete type of self,</span>
                <span class="c1"># we have already resolved all _methods</span>
                <span class="n">methods</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">_methods</span><span class="o">.</span><span class="n">items</span><span class="p">())]</span>
                <span class="n">_create_methods_from_stubs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">methods</span><span class="p">)</span>

        <span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span> <span class="o">=</span> <span class="n">init_then_register</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">ScriptMeta</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">bases</span><span class="p">,</span> <span class="n">attrs</span><span class="p">)</span>


<span class="k">if</span> <span class="n">_enabled</span><span class="p">:</span>

    <span class="c1"># this is a Python &#39;non-data descriptor&#39; that causes the first access</span>
    <span class="c1"># to ScriptModule&#39;s forward to lookup the forward method and stash</span>
    <span class="c1"># it in the objects dict. Due to the standard rules for attribute lookup</span>
    <span class="c1"># subsequent lookups will just directly return the previously looked up method.</span>
    <span class="c1"># This is necessary because nn.Module defines forward as a method. If we</span>
    <span class="c1"># did nothing __getattr__ would not be called. Instead we&#39;d get nn.Module.forward</span>
    <span class="c1"># which always throws an exception.</span>
    <span class="k">class</span> <span class="nc">_CachedForward</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__get__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="bp">cls</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="s1">&#39;forward&#39;</span><span class="p">)</span>

    <span class="k">class</span> <span class="nc">ScriptModule</span><span class="p">(</span><span class="n">with_metaclass</span><span class="p">(</span><span class="n">ScriptMeta</span><span class="p">,</span> <span class="n">Module</span><span class="p">)):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The core data structure in TorchScript is the ``ScriptModule``. It is an</span>
<span class="sd">        analogue of torch&#39;s ``nn.Module`` and represents an entire model as a tree of</span>
<span class="sd">        submodules. Like normal modules, each individual module in a ``ScriptModule`` can</span>
<span class="sd">        have submodules, parameters, and methods. In ``nn.Module``\s methods are implemented</span>
<span class="sd">        as Python functions, but in ``ScriptModule``\s methods are implemented as</span>
<span class="sd">        TorchScript functions,  a statically-typed subset of Python that contains all</span>
<span class="sd">        of PyTorch&#39;s built-in Tensor operations. This difference allows your</span>
<span class="sd">        ScriptModules code to run without the need for a Python interpreter.</span>

<span class="sd">        ``ScriptModule``\s be created in two ways:</span>

<span class="sd">        **Tracing:**</span>

<span class="sd">            Using ``torch.jit.trace`` and ``torch.jit.trace_module``, you can turn an existing module or Python</span>
<span class="sd">            function into a TorchScript ``torch._C.Function`` or ``ScriptModule``. You must provide example inputs,</span>
<span class="sd">            and we run the function, recording the operations performed on all the tensors.</span>
<span class="sd">            * The resulting recording of a standalone function produces ``torch._C.Function``.</span>
<span class="sd">            * The resulting recording of ``forward`` function of ``nn.Module`` or ``nn.Module`` produces ``ScriptModule``.</span>
<span class="sd">            This module also contains any parameters that the original</span>
<span class="sd">            module had as well.</span>

<span class="sd">            Example (tracing a function)::</span>

<span class="sd">                import torch</span>
<span class="sd">                def foo(x, y):</span>
<span class="sd">                    return 2 * x + y</span>
<span class="sd">                traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))</span>

<span class="sd">            .. note::</span>
<span class="sd">                Tracing a standalone function will construct a ``torch._C.Function``</span>
<span class="sd">                Tracing ``nn.Module``s ``forward`` will construct a ``ScriptModule``</span>

<span class="sd">            Example (tracing an existing module)::</span>

<span class="sd">                import torch</span>
<span class="sd">                class Net(nn.Module):</span>
<span class="sd">                    def __init__(self):</span>
<span class="sd">                        super(Net, self).__init__()</span>
<span class="sd">                        self.conv = nn.Conv2d(1, 1, 3)</span>

<span class="sd">                    def forward(self, x):</span>
<span class="sd">                        return self.conv(x)</span>

<span class="sd">                    def weighted_kernel_sum(self, weight):</span>
<span class="sd">                        return weight * self.conv.weight</span>


<span class="sd">                n = Net()</span>
<span class="sd">                example_weight = torch.rand(1, 1, 3, 3)</span>
<span class="sd">                example_forward_input = torch.rand(1, 1, 3, 3)</span>

<span class="sd">                # all three trace calls below are equivalent</span>
<span class="sd">                # and construct `ScriptModule` with a single `forward` method</span>
<span class="sd">                module = torch.jit.trace(n.forward, example_forward_input) # produces ScriptModule with `forward`</span>
<span class="sd">                module = torch.jit.trace(n, example_forward_input) # produces ScriptModule with `forward`</span>
<span class="sd">                module = torch.jit.trace_module(n, inputs) # produces ScriptModule with `forward`</span>

<span class="sd">                inputs = {&#39;forward&#39; : example_forward_input, &#39;weighted_kernel_sum&#39; : example_weight}</span>
<span class="sd">                # trace_module produces `ScriptModule` with two methods:</span>
<span class="sd">                # `forward` and `weighted_kernel_sum`</span>
<span class="sd">                module = torch.jit.trace_module(n, inputs, True, True)</span>

<span class="sd">            .. note::</span>

<span class="sd">                * The first three trace/trace_module calls are equivalent and return ``ScriptModule``</span>
<span class="sd">                with a single ``forward`` method.</span>
<span class="sd">                * The last ``trace_module`` call produces a ``ScriptModule`` with two methods.</span>
<span class="sd">                Tracing only records operations done when the given function is run on the given</span>
<span class="sd">                tensors. Therefore, the returned ``ScriptModule`` will always run the same traced</span>
<span class="sd">                graph on any input. This has some important implications when your module is</span>
<span class="sd">                expected to run different sets of operations, depending on the input and/or the</span>
<span class="sd">                module state. For example,</span>

<span class="sd">                    + Tracing will not record any control-flow like if-statements or loops. When</span>
<span class="sd">                      this control-flow is constant across your module, this is fine and it often</span>
<span class="sd">                      inlines the control-flow decisions. But sometimes the control-flow is</span>
<span class="sd">                      actually part of the model itself. For instance, a recurrent network is</span>
<span class="sd">                      a loop over the (possibly dynamic) length of an input sequence.</span>

<span class="sd">                    + In the returned ``ScriptModule``, operations that have different behaviors</span>
<span class="sd">                      in ``training`` and ``eval`` modes will always behave as if it is in the</span>
<span class="sd">                      mode it was in during tracing, no matter which mode the ``ScriptModule``</span>
<span class="sd">                      is in.</span>

<span class="sd">                In cases like these, tracing would not be appropriate and scripting is a better</span>
<span class="sd">                choice.</span>

<span class="sd">        **Scripting:**</span>

<span class="sd">            You can write TorchScript code directly using Python syntax. You do this</span>
<span class="sd">            using the ``@torch.jit.script`` decorator for functions and modules. You can</span>
<span class="sd">            also call ``torch.jit.script`` directly with the function or module you wish to</span>
<span class="sd">            compile. On functions, the body of the function is compiled to TorchScript. If</span>
<span class="sd">            applied to an ``nn.Module``, by default the ``forward`` method and any methods it</span>
<span class="sd">            calls are compiled, and all buffer and Parameters of the original module are copied</span>
<span class="sd">            to a new ``ScriptModule``. You should not need to construct a ``ScriptModule`` manually.</span>
<span class="sd">            TorchScript itself is a subset of the Python language, so not all</span>
<span class="sd">            features in Python work, but we provide enough functionality to compute on</span>
<span class="sd">            tensors and do control-dependent operations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_qualified_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_compilation_unit</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_cpp_module</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">_qualified_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_qualified_name</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="k">if</span> <span class="n">_compilation_unit</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_compilation_unit</span> <span class="o">=</span> <span class="n">_python_cu</span>
            <span class="k">if</span> <span class="n">optimize</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;`optimize` is deprecated and has no effect. Use `with torch.jit.optimized_execution() instead&quot;</span><span class="p">)</span>

            <span class="c1"># If we were give a _cpp_module, use that one as the backing cpp</span>
            <span class="c1"># module instead of creating a fresh one.</span>
            <span class="k">if</span> <span class="n">_cpp_module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s1">&#39;_c&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_cpp_module</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s1">&#39;_c&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">ScriptModule</span><span class="p">(</span><span class="n">_qualified_name</span><span class="p">,</span> <span class="n">_compilation_unit</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

            <span class="n">Module</span><span class="o">.</span><span class="n">_construct</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="n">Module</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;training&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span> <span class="o">=</span> <span class="n">OrderedParameterDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span> <span class="o">=</span> <span class="n">OrderedBufferDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span> <span class="o">=</span> <span class="n">OrderedModuleDict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="p">)</span>

            <span class="c1"># If we were given a _cpp_module, recursively create Python</span>
            <span class="c1"># ScriptModules that mirror the submodule hierarchy.</span>
            <span class="c1"># This has to go last due to quirks in module initialization.</span>
            <span class="k">if</span> <span class="n">_cpp_module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">cpp_mod</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_get_modules</span><span class="p">():</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ScriptModule</span><span class="p">(</span><span class="n">_cpp_module</span><span class="o">=</span><span class="n">cpp_mod</span><span class="p">))</span>

        <span class="nd">@property</span>
        <span class="k">def</span> <span class="nf">graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="o">.</span><span class="n">graph</span>

        <span class="nd">@property</span>
        <span class="k">def</span> <span class="nf">code</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="o">.</span><span class="n">code</span>

        <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">save_to_buffer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">save_to_buffer</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">get_debug_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">get_debug_state</span><span class="p">()</span>

        <span class="n">forward</span> <span class="o">=</span> <span class="n">_CachedForward</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
            <span class="k">if</span> <span class="s1">&#39;_c&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;ScriptModule has not been initialized, did you forget to call super&#39;s init?&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_has_attribute</span><span class="p">(</span><span class="n">attr</span><span class="p">):</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_get_attribute</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_has_method</span><span class="p">(</span><span class="n">attr</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">attr</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">_methods</span><span class="p">:</span>
                    <span class="n">original_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="n">_methods</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span><span class="o">.</span><span class="n">original_method</span>
                    <span class="n">script_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_get_method</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
                    <span class="n">script_method</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">original_method</span><span class="p">)(</span><span class="n">script_method</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">script_method</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_get_method</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>
                <span class="c1"># cache method so future calls do not go through __getattr__</span>
                <span class="c1"># to improve invocation performance</span>
                <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="n">attr</span><span class="p">]</span> <span class="o">=</span> <span class="n">script_method</span>
                <span class="k">return</span> <span class="n">script_method</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="n">attr</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">attr</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_constants_set</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">attr</span> <span class="o">==</span> <span class="s1">&#39;training&#39;</span><span class="p">:</span>
                    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_has_attribute</span><span class="p">(</span><span class="s1">&#39;training&#39;</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s1">&#39;training&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_set_attribute</span><span class="p">(</span><span class="s1">&#39;training&#39;</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
                        <span class="k">return</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">Attribute</span><span class="p">):</span>
                    <span class="n">the_type</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">annotations</span><span class="o">.</span><span class="n">ann_to_type</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_register_attribute</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">the_type</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
                    <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Could not register attribute &#39;</span><span class="si">{}</span><span class="s2">&#39; of type &#39;</span><span class="si">{}</span><span class="s2">&#39; for a value of type &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span>
                                           <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
                    <span class="k">return</span>
                <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;attempting to re-assign constant &#39;</span><span class="si">{}</span><span class="s2">&#39; in </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>

            <span class="k">def</span> <span class="nf">conv_module_to_const</span><span class="p">(</span><span class="n">module_value</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module_value</span><span class="p">,</span> <span class="p">(</span><span class="n">ModuleList</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">)):</span>
                    <span class="k">return</span> <span class="n">module_value</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">module_value</span><span class="p">)):</span>
                    <span class="n">module_value</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_module_to_const</span><span class="p">(</span><span class="n">module_value</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module_value</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">_ConstSequential</span><span class="p">(</span><span class="n">module_value</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">_ConstModuleList</span><span class="p">(</span><span class="n">module_value</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="p">(</span><span class="n">ModuleList</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">)):</span>
                <span class="c1"># special case for list of modules. Modules need to be registered with their</span>
                <span class="c1"># parent module. To do this, we create a ConstModuleList, which is itself a module, that</span>
                <span class="c1"># contains each of these modules as submodules. The ConstModuleList then</span>
                <span class="c1"># is set as an attribute of the parent module.</span>
                <span class="nb">super</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">conv_module_to_const</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">super</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">_get_valid_constant</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>

        <span class="k">def</span> <span class="nf">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">Module</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_method_names</span><span class="p">())</span>

        <span class="k">def</span> <span class="nf">define</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lang</span><span class="p">):</span>
            <span class="c1"># We use frames_up=1 to get to the proper surrounding scope. The stack</span>
            <span class="c1"># will look like:</span>
            <span class="c1"># 0. createResolutionCallback</span>
            <span class="c1"># 1. define()</span>
            <span class="c1"># 2. surrounding scope.</span>
            <span class="c1">#</span>
            <span class="c1"># createResolutionCallback internally adds 1 to get us to our frame, then</span>
            <span class="c1"># we add 1 to get to the proper surrounding scope.</span>
            <span class="n">rcb</span> <span class="o">=</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">createResolutionCallback</span><span class="p">(</span><span class="n">frames_up</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_define</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lang</span><span class="p">,</span> <span class="n">rcb</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">ScriptModule</span><span class="p">()</span>

            <span class="k">def</span> <span class="nf">module_lookup</span><span class="p">(</span><span class="n">names</span><span class="p">):</span>
                <span class="n">curr</span> <span class="o">=</span> <span class="n">m</span>
                <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                        <span class="nb">setattr</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">ScriptModule</span><span class="p">())</span>
                    <span class="n">curr</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">curr</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">curr</span><span class="o">.</span><span class="n">_c</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_copy_into</span><span class="p">(</span><span class="n">module_lookup</span><span class="p">,</span> <span class="p">{},</span> <span class="p">[])</span>
            <span class="k">return</span> <span class="n">m</span>

        <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">raise</span> <span class="n">pickle</span><span class="o">.</span><span class="n">PickleError</span><span class="p">(</span>
                <span class="s2">&quot;ScriptModules cannot be deepcopied using copy.deepcopy or saved using torch.save. &quot;</span> <span class="o">+</span>
                <span class="s2">&quot;Mixed serialization of script and non-script modules is not supported. &quot;</span> <span class="o">+</span>
                <span class="s2">&quot;For purely script modules use my_script_module.save(&lt;filename&gt;) instead.&quot;</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">graph_for</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="o">.</span><span class="n">graph_for</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">class</span> <span class="nc">WeakScriptModuleProxy</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">):</span>
        <span class="c1"># TODO: [weak script refactor]</span>
        <span class="c1"># WeakScriptModule proxy should be deleted since its functionality is</span>
        <span class="c1"># subsumed by recursive scripting, and the copying code in init moved</span>
        <span class="c1"># to a function to create a ScriptModule from an nn.Module without</span>
        <span class="c1"># making a WeakScriptModuleProxy</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Copies the parameters, buffers, constants, attributes, and submodules</span>
<span class="sd">        of an nn.Module into itself.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original</span><span class="p">,</span> <span class="n">stubs</span><span class="p">):</span>
            <span class="c1"># Guards behavior of __setattr__ and __getattr__ so ScriptModule</span>
            <span class="c1"># __init__ can run correctly</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s1">&#39;_initialized&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">WeakScriptModuleProxy</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">_qualified_name</span><span class="o">=</span><span class="n">_qualified_name</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">original</span><span class="p">)))</span>
            <span class="c1"># Store a weak reference to the original module</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_original&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">weakref</span><span class="o">.</span><span class="n">ref</span><span class="p">(</span><span class="n">original</span><span class="p">)</span>

            <span class="n">constants_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="s2">&quot;__constants__&quot;</span><span class="p">,</span> <span class="p">[]))</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_constants_set&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="s1">&#39;_parameters&#39;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;&#39;</span><span class="si">{}</span><span class="s2">&#39; has not been initialized, did you forget to call &#39;super()&#39;?&quot;</span>
                                   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">original</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>

            <span class="c1"># Copy Parameters and Modules</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">original</span><span class="p">):</span>
                <span class="n">item</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">item</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">original</span><span class="o">.</span><span class="n">_parameters</span><span class="p">:</span>
                    <span class="c1"># XXX: treat None value simply as module attributes instead of adding them to the parameter list</span>
                    <span class="c1"># TODO: need to handle this more generally when non-tensor attributes added to module</span>
                    <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">item</span> <span class="ow">is</span> <span class="bp">self</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="p">(</span><span class="n">Parameter</span><span class="p">,</span> <span class="n">Module</span><span class="p">,</span> <span class="n">Attribute</span><span class="p">)):</span>
                    <span class="n">ScriptModule</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>

            <span class="c1"># Copy buffers</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">original</span><span class="o">.</span><span class="n">_buffers</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">original</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="nb">object</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">original</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>

            <span class="c1"># Constants annotated via `Final[T]` rather than being added to `__constants__`</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">ann</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="s1">&#39;__annotations__&#39;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">_jit_internal</span><span class="o">.</span><span class="n">is_final</span><span class="p">(</span><span class="n">ann</span><span class="p">):</span>
                    <span class="n">constants_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

            <span class="c1"># Copy constants</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_constants_set&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">constants_set</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_constants_set&quot;</span><span class="p">]:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">name</span> <span class="ow">in</span> <span class="n">original</span><span class="o">.</span><span class="n">_parameters</span> <span class="ow">or</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">original</span><span class="o">.</span><span class="n">_buffers</span><span class="p">)</span> <span class="ow">and</span> <span class="n">item</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="c1"># for &#39;None&#39; parameters/buffers, don&#39;t actually add their values if it exists</span>
                        <span class="k">continue</span>
                    <span class="n">ScriptModule</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>

            <span class="c1"># Copy annotations, pull types from `__annotations__` or try to infer</span>
            <span class="c1"># the type if possible</span>
            <span class="n">class_annotations</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="s1">&#39;__annotations__&#39;</span><span class="p">,</span> <span class="p">{})</span>
            <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">original</span><span class="p">):</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;training&quot;</span><span class="p">,</span> <span class="s2">&quot;__dict__&quot;</span><span class="p">):</span>
                    <span class="c1"># TODO: removing this skip should let us remove the code to add training as an</span>
                    <span class="c1"># attribute in python_sugared_value.cpp</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
                    <span class="c1"># Don&#39;t re-copy properties</span>
                    <span class="k">continue</span>
                <span class="n">item</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">class_annotations</span><span class="p">:</span>
                    <span class="n">the_type</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">annotations</span><span class="o">.</span><span class="n">ann_to_type</span><span class="p">(</span><span class="n">class_annotations</span><span class="p">[</span><span class="n">name</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">the_type</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_try_infer_type</span><span class="p">(</span><span class="n">item</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">the_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_c</span><span class="o">.</span><span class="n">_register_attribute</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">the_type</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>

            <span class="c1"># Copy overloads</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_overloads&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">original</span><span class="p">,</span> <span class="s2">&quot;__overloads__&quot;</span><span class="p">,</span> <span class="p">{}))</span>

            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_initialized&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_original_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">original</span><span class="p">)</span>
            <span class="n">_create_methods_from_stubs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stubs</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
            <span class="c1"># Try to get the attribute directly, if that fails, fall back to the</span>
            <span class="c1"># weak module itself</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">ScriptModule</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">AttributeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="c1"># unwrap the original</span>
                <span class="n">original_module</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_original&quot;</span><span class="p">]()</span>
                <span class="k">if</span> <span class="n">original_module</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_initialized&quot;</span><span class="p">]:</span>
                    <span class="c1"># get attr from original if it is still alive</span>
                    <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">original_module</span><span class="p">,</span> <span class="n">attr</span><span class="p">)</span>
                <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_initialized&quot;</span><span class="p">]:</span>
                    <span class="c1"># original module is dead, try looking up the value on the</span>
                    <span class="c1"># original type</span>
                    <span class="n">fn</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_original_type&quot;</span><span class="p">],</span> <span class="n">attr</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isroutine</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
                        <span class="c1"># bind the function to this instance and return it</span>
                        <span class="k">return</span> <span class="n">fn</span><span class="o">.</span><span class="fm">__get__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_original_type&quot;</span><span class="p">])</span>
                <span class="c1"># If it&#39;s not on this module and it wasn&#39;t on the original</span>
                <span class="c1"># module (or the original is dead), throw the exception</span>
                <span class="k">raise</span> <span class="n">e</span>

        <span class="k">def</span> <span class="nf">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
            <span class="c1"># Once constructed, no new properties can be set</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">[</span><span class="s2">&quot;_initialized&quot;</span><span class="p">]:</span>
                <span class="c1"># If constructing, don&#39;t fall back to original module</span>
                <span class="k">return</span> <span class="n">ScriptModule</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">ScriptModule</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s2">&quot;Cannot set new attribute &#39;</span><span class="si">{}</span><span class="s2">&#39; on &quot;</span>
                                     <span class="s2">&quot;weak script module once it has been &quot;</span>
                                     <span class="s2">&quot;created&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">attr</span><span class="p">))</span>

<span class="k">else</span><span class="p">:</span>
<div class="viewcode-block" id="ScriptModule"><a class="viewcode-back" href="../../jit.html#torch.jit.ScriptModule">[docs]</a>    <span class="k">class</span> <span class="nc">ScriptModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span></div>


<span class="k">def</span> <span class="nf">_convert_to_script_module</span><span class="p">(</span><span class="n">mod</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Makes a ScriptModule from an nn.Module. If `_methods` is provided,</span>
<span class="sd">    these methods are treated as @script_methods. If not, it defaults to</span>
<span class="sd">    `(&#39;forward&#39;,)`. Methods accessed in forward are scripted on demand.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">ScriptModule</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">mod</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="p">(</span><span class="n">ModuleList</span><span class="p">,</span> <span class="n">Sequential</span><span class="p">)):</span>
        <span class="c1"># Create constant versions for the iterable modules</span>
        <span class="k">return</span> <span class="n">_create_constant_iterable_module</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>

    <span class="n">methods</span> <span class="o">=</span> <span class="p">()</span>
    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="s1">&#39;forward&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">mod</span><span class="o">.</span><span class="n">forward</span><span class="o">.</span><span class="vm">__func__</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="o">.</span><span class="n">forward</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;No forward method was defined on </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mod</span><span class="p">))</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">is_ignored_fn</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">forward</span><span class="p">):</span>
            <span class="n">methods</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;forward&#39;</span><span class="p">,)</span>
    <span class="n">exported</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">mod</span><span class="p">):</span>
        <span class="n">item</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">item</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">get_torchscript_modifier</span><span class="p">(</span><span class="n">item</span><span class="p">)</span> <span class="ow">is</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">FunctionModifiers</span><span class="o">.</span><span class="n">EXPORT</span><span class="p">:</span>
                <span class="n">exported</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="n">methods</span> <span class="o">=</span> <span class="n">methods</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">exported</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">make_stub</span><span class="p">(</span><span class="n">method</span><span class="p">):</span>
        <span class="n">func</span> <span class="o">=</span> <span class="n">get_function_from_type</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">mod</span><span class="p">),</span> <span class="n">method</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">script_method</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">_jit_internal</span><span class="o">.</span><span class="n">createResolutionCallbackFromClosure</span><span class="p">(</span><span class="n">func</span><span class="p">))</span>

    <span class="n">stubs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">make_stub</span><span class="p">,</span> <span class="n">methods</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">WeakScriptModuleProxy</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">stubs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_methods</span><span class="p">(</span><span class="bp">cls</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">inspect</span>
    <span class="c1"># In Python 3 unbound methods are functions, but in Python 2 they are methods</span>
    <span class="k">return</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getmembers</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">predicate</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isfunction</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="ow">or</span> <span class="n">inspect</span><span class="o">.</span><span class="n">ismethod</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="n">_compiled_methods_whitelist</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;forward&#39;</span><span class="p">,</span> <span class="s1">&#39;register_buffer&#39;</span><span class="p">,</span> <span class="s1">&#39;register_parameter&#39;</span><span class="p">,</span> <span class="s1">&#39;add_module&#39;</span><span class="p">,</span>
    <span class="s1">&#39;_apply&#39;</span><span class="p">,</span> <span class="s1">&#39;apply&#39;</span><span class="p">,</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span> <span class="s1">&#39;cpu&#39;</span><span class="p">,</span> <span class="s1">&#39;to&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">,</span> <span class="s1">&#39;float&#39;</span><span class="p">,</span> <span class="s1">&#39;double&#39;</span><span class="p">,</span> <span class="s1">&#39;half&#39;</span><span class="p">,</span>
    <span class="s1">&#39;state_dict&#39;</span><span class="p">,</span> <span class="s1">&#39;_save_to_state_dict&#39;</span><span class="p">,</span> <span class="s1">&#39;load_state_dict&#39;</span><span class="p">,</span>
    <span class="s1">&#39;_load_from_state_dict&#39;</span><span class="p">,</span> <span class="s1">&#39;_named_members&#39;</span><span class="p">,</span> <span class="s1">&#39;parameters&#39;</span><span class="p">,</span> <span class="s1">&#39;named_parameters&#39;</span><span class="p">,</span>
    <span class="s1">&#39;buffers&#39;</span><span class="p">,</span> <span class="s1">&#39;named_buffers&#39;</span><span class="p">,</span> <span class="s1">&#39;children&#39;</span><span class="p">,</span> <span class="s1">&#39;named_children&#39;</span><span class="p">,</span> <span class="s1">&#39;modules&#39;</span><span class="p">,</span>
    <span class="s1">&#39;named_modules&#39;</span><span class="p">,</span> <span class="s1">&#39;zero_grad&#39;</span><span class="p">,</span> <span class="s1">&#39;share_memory&#39;</span><span class="p">,</span> <span class="s1">&#39;_get_name&#39;</span><span class="p">,</span> <span class="s1">&#39;extra_repr&#39;</span><span class="p">,</span>
    <span class="s1">&#39;_slow_forward&#39;</span><span class="p">,</span> <span class="s1">&#39;_tracing_name&#39;</span><span class="p">,</span> <span class="s1">&#39;eval&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">_make_fail</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">fail</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot; is not supported on ScriptModules&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fail</span>


<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">method</span> <span class="ow">in</span> <span class="n">_get_methods</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">):</span>
        <span class="k">continue</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ScriptModule</span><span class="o">.</span><span class="vm">__dict__</span> <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_compiled_methods_whitelist</span><span class="p">:</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">,</span> <span class="n">method</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">_make_fail</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">TracedModule</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">):</span>
    <span class="n">__frozen</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">orig</span><span class="p">,</span> <span class="n">id_set</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_compilation_unit</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># XXX: orig can be a nn.Module or a function!</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TracedModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">_qualified_name</span><span class="o">=</span><span class="n">_jit_internal</span><span class="o">.</span><span class="n">_qualified_name</span><span class="p">(</span><span class="n">orig</span><span class="o">.</span><span class="vm">__class__</span><span class="p">),</span>
                                           <span class="n">_compilation_unit</span><span class="o">=</span><span class="n">_compilation_unit</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">id_set</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">id_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

        <span class="k">assert</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">orig</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_name</span> <span class="o">=</span> <span class="s1">&#39;TracedModule[&#39;</span> <span class="o">+</span> <span class="nb">type</span><span class="p">(</span><span class="n">orig</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;]&#39;</span>

        <span class="k">def</span> <span class="nf">check_unique</span><span class="p">(</span><span class="n">param</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">id_set</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;TracedModules don&#39;t support parameter sharing between modules&quot;</span><span class="p">)</span>
            <span class="n">id_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training</span> <span class="o">=</span> <span class="n">orig</span><span class="o">.</span><span class="n">training</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">orig</span><span class="o">.</span><span class="n">_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span>
                <span class="n">check_unique</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">orig</span><span class="o">.</span><span class="n">_buffers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">buf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_buffers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">buf</span>
                <span class="n">check_unique</span><span class="p">(</span><span class="n">buf</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">orig</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="n">orig</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="n">orig</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Modules that have hooks assigned can&#39;t be compiled&quot;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">submodule</span> <span class="ow">in</span> <span class="n">orig</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">ScriptModule</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">submodule</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">TracedModule</span><span class="p">(</span><span class="n">submodule</span><span class="p">,</span> <span class="n">id_set</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_freeze</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Trace submodules cannot be called.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__frozen</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">_get_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_name</span>

    <span class="k">def</span> <span class="nf">__setattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">__frozen</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attr</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">TracedModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">(</span><span class="n">attr</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot set new properties on a traced module.&quot;</span><span class="p">)</span>


<span class="k">if</span> <span class="n">_enabled</span><span class="p">:</span>
    <span class="k">class</span> <span class="nc">TopLevelTracedModule</span><span class="p">(</span><span class="n">TracedModule</span><span class="p">):</span>
        <span class="n">forward</span> <span class="o">=</span> <span class="n">_CachedForward</span><span class="p">()</span>


<span class="k">class</span> <span class="nc">_ConstModuleList</span><span class="p">(</span><span class="n">ScriptModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">modules</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_ConstModuleList</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">modules</span><span class="p">,</span> <span class="n">OrderedDict</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">modules</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
                    <span class="n">module</span> <span class="o">=</span> <span class="n">_convert_to_script_module</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">module</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">modules</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
                    <span class="n">module</span> <span class="o">=</span> <span class="n">_convert_to_script_module</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="n">module</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">_ConstModuleList</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">idx</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">IndexError</span><span class="p">(</span><span class="s1">&#39;index </span><span class="si">{}</span><span class="s1"> is out of range&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">idx</span><span class="p">)]</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_modules</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">__dir__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">_ConstModuleList</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">()</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">key</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">key</span><span class="o">.</span><span class="n">isdigit</span><span class="p">()]</span>
        <span class="k">return</span> <span class="n">keys</span>


<span class="k">class</span> <span class="nc">_ConstSequential</span><span class="p">(</span><span class="n">_ConstModuleList</span><span class="p">):</span>
    <span class="n">__constants__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mods&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mods</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">_ConstSequential</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">mods</span><span class="o">.</span><span class="n">_modules</span><span class="p">)</span>

        <span class="c1"># we define the forward method via self.define rather than</span>
        <span class="c1"># making it a direct class member (with a @script) annotation</span>
        <span class="c1"># because, in optimized runtime environments where only .pyc files</span>
        <span class="c1"># are shipped, we cant retrieve the source code.</span>
        <span class="c1"># TODO: find a workaround for this and remove this hack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        def forward(self, input):</span>
<span class="s2">            for m in self:</span>
<span class="s2">                input = m(input)</span>
<span class="s2">            return input</span>
<span class="s2">        &quot;&quot;&quot;</span><span class="p">)</span>


<span class="n">_builtin_table</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">_modules_containing_builtins</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_nn</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_unwrap_optional</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;Unwrapping null optional&quot;</span>
    <span class="k">return</span> <span class="n">x</span>


<span class="c1"># lazily built to ensure the correct initialization order</span>
<span class="k">def</span> <span class="nf">_get_builtin_table</span><span class="p">():</span>
    <span class="k">global</span> <span class="n">_builtin_table</span>
    <span class="k">if</span> <span class="n">_builtin_table</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_builtin_table</span>
    <span class="n">_builtin_table</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">register_all</span><span class="p">(</span><span class="n">mod</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">mod</span><span class="p">):</span>
            <span class="n">v</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
                <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">v</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::&quot;</span> <span class="o">+</span> <span class="n">name</span>
    <span class="k">for</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">_modules_containing_builtins</span><span class="p">:</span>
        <span class="n">register_all</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>

    <span class="n">builtin_ops</span> <span class="o">=</span> <span class="p">[</span>
        <span class="c1"># Pairs of (function, op_name)</span>
        <span class="p">(</span><span class="n">_list_with_default</span><span class="p">,</span> <span class="s2">&quot;aten::list_with_default&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">_pair</span><span class="p">,</span> <span class="s2">&quot;aten::_pair&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">_quadruple</span><span class="p">,</span> <span class="s2">&quot;aten::_quadruple&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">_single</span><span class="p">,</span> <span class="s2">&quot;aten::_single&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">_triple</span><span class="p">,</span> <span class="s2">&quot;aten::_triple&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">_unwrap_optional</span><span class="p">,</span> <span class="s2">&quot;aten::_unwrap_optional&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">_wait</span><span class="p">,</span> <span class="s1">&#39;aten::wait&#39;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">cudnn</span><span class="o">.</span><span class="n">is_acceptable</span><span class="p">,</span> <span class="s2">&quot;aten::cudnn_is_acceptable&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">,</span> <span class="s2">&quot;aten::ceil&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">copysign</span><span class="p">,</span> <span class="s2">&quot;aten::copysign&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">erf</span><span class="p">,</span> <span class="s2">&quot;aten::erf&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">erfc</span><span class="p">,</span> <span class="s2">&quot;aten::erfc&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">,</span> <span class="s2">&quot;aten::exp&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">expm1</span><span class="p">,</span> <span class="s2">&quot;aten::expm1&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">,</span> <span class="s2">&quot;aten::fabs&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">,</span> <span class="s2">&quot;aten::floor&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">gamma</span><span class="p">,</span> <span class="s2">&quot;aten::gamma&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">lgamma</span><span class="p">,</span> <span class="s2">&quot;aten::lgamma&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">,</span> <span class="s2">&quot;aten::log&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log10</span><span class="p">,</span> <span class="s2">&quot;aten::log10&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">log1p</span><span class="p">,</span> <span class="s2">&quot;aten::log1p&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">,</span> <span class="s2">&quot;aten::pow&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">,</span> <span class="s2">&quot;aten::sqrt&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isnan</span><span class="p">,</span> <span class="s2">&quot;aten::isnan&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">asinh</span><span class="p">,</span> <span class="s2">&quot;aten::asinh&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">atanh</span><span class="p">,</span> <span class="s2">&quot;aten::atanh&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">cosh</span><span class="p">,</span> <span class="s2">&quot;aten::cosh&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sinh</span><span class="p">,</span> <span class="s2">&quot;aten::sinh&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span> <span class="s2">&quot;aten::tanh&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">acos</span><span class="p">,</span> <span class="s2">&quot;aten::acos&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">asin</span><span class="p">,</span> <span class="s2">&quot;aten::asin&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">atan</span><span class="p">,</span> <span class="s2">&quot;aten::atan&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">atan2</span><span class="p">,</span> <span class="s2">&quot;aten::atan2&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">,</span> <span class="s2">&quot;aten::cos&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">,</span> <span class="s2">&quot;aten::sin&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">tan</span><span class="p">,</span> <span class="s2">&quot;aten::tan&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">asinh</span><span class="p">,</span> <span class="s2">&quot;aten::asinh&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">atanh</span><span class="p">,</span> <span class="s2">&quot;aten::atanh&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">acosh</span><span class="p">,</span> <span class="s2">&quot;aten::acosh&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sinh</span><span class="p">,</span> <span class="s2">&quot;aten::sinh&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">cosh</span><span class="p">,</span> <span class="s2">&quot;aten::cosh&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span> <span class="s2">&quot;aten::tanh&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">fmod</span><span class="p">,</span> <span class="s2">&quot;aten::fmod&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">modf</span><span class="p">,</span> <span class="s2">&quot;aten::modf&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">factorial</span><span class="p">,</span> <span class="s2">&quot;aten::factorial&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">frexp</span><span class="p">,</span> <span class="s2">&quot;aten::frexp&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isnan</span><span class="p">,</span> <span class="s2">&quot;aten::isnan&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isinf</span><span class="p">,</span> <span class="s2">&quot;aten::isinf&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">degrees</span><span class="p">,</span> <span class="s2">&quot;aten::degrees&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">radians</span><span class="p">,</span> <span class="s2">&quot;aten::radians&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ldexp</span><span class="p">,</span> <span class="s2">&quot;aten::ldexp&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_infer_size</span><span class="p">,</span> <span class="s2">&quot;aten::_infer_size&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">_no_grad_embedding_renorm_</span><span class="p">,</span> <span class="s2">&quot;aten::_no_grad_embedding_renorm_&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">assert_int_or_pair</span><span class="p">,</span> <span class="s2">&quot;aten::_assert_int_or_pair&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">interpolate</span><span class="p">,</span> <span class="s2">&quot;aten::__interpolate&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample_bilinear</span><span class="p">,</span> <span class="s2">&quot;aten::__upsample_bilinear&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample_nearest</span><span class="p">,</span> <span class="s2">&quot;aten::__upsample_nearest&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample</span><span class="p">,</span> <span class="s2">&quot;aten::__upsample&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_no_grad_fill_</span><span class="p">,</span> <span class="s2">&quot;aten::_no_grad_fill_&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_no_grad_normal_</span><span class="p">,</span> <span class="s2">&quot;aten::_no_grad_normal_&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_no_grad_uniform_</span><span class="p">,</span> <span class="s2">&quot;aten::_no_grad_uniform_&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">_no_grad_zero_</span><span class="p">,</span> <span class="s2">&quot;aten::_no_grad_zero_&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_get_tracing_state</span><span class="p">,</span> <span class="s2">&quot;aten::_get_tracing_state&quot;</span><span class="p">),</span>
        <span class="p">(</span><span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">,</span> <span class="s2">&quot;aten::warn&quot;</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="k">for</span> <span class="n">builtin</span><span class="p">,</span> <span class="n">aten_op</span> <span class="ow">in</span> <span class="n">builtin_ops</span><span class="p">:</span>
        <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">builtin</span><span class="p">)]</span> <span class="o">=</span> <span class="n">aten_op</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">PY2</span><span class="p">:</span>
        <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">gcd</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::gcd&quot;</span>
        <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">isfinite</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::isfinite&quot;</span>
    <span class="k">if</span> <span class="n">PY37</span><span class="p">:</span>
        <span class="n">_builtin_table</span><span class="p">[</span><span class="nb">id</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">remainder</span><span class="p">)]</span> <span class="o">=</span> <span class="s2">&quot;aten::mathremainder&quot;</span>

    <span class="k">return</span> <span class="n">_builtin_table</span>


<span class="k">def</span> <span class="nf">_register_builtin</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
    <span class="n">_get_builtin_table</span><span class="p">()[</span><span class="nb">id</span><span class="p">(</span><span class="n">fn</span><span class="p">)]</span> <span class="o">=</span> <span class="n">op</span>


<span class="k">def</span> <span class="nf">_find_builtin</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">_get_builtin_table</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span>

<span class="c1"># qualified_name =&gt; ScriptClass mapping</span>
<span class="n">_script_classes</span> <span class="o">=</span> <span class="p">{}</span>


<span class="k">def</span> <span class="nf">_add_script_class</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="bp">cls</span><span class="o">.</span><span class="n">__torch_script_class__</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">global</span> <span class="n">_script_classes</span>
    <span class="n">_script_classes</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">cls</span>


<span class="k">def</span> <span class="nf">_get_script_class</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">_script_classes</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">_script_classes</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Unknown reference to ScriptClass &#39;</span><span class="si">{}</span><span class="s2">&#39;. &quot;</span>
                           <span class="s2">&quot;Did you forget to import it?&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">_script_classes</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

<span class="c1"># torch.jit.Error</span>
<span class="n">Error</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">JITException</span>

<span class="k">def</span> <span class="nf">_get_named_tuple_properties</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s1">&#39;_fields&#39;</span><span class="p">)</span>
    <span class="n">fields</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">_fields</span><span class="p">)</span>
    <span class="n">annotations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">has_annotations</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="s1">&#39;__annotations__&#39;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">fields</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">has_annotations</span> <span class="ow">and</span> <span class="n">field</span> <span class="ow">in</span> <span class="n">obj</span><span class="o">.</span><span class="vm">__annotations__</span><span class="p">:</span>
            <span class="n">annotations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">annotations</span><span class="o">.</span><span class="n">ann_to_type</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="vm">__annotations__</span><span class="p">[</span><span class="n">field</span><span class="p">]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">annotations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">TensorType</span><span class="o">.</span><span class="n">get</span><span class="p">())</span>
    <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">fields</span><span class="p">,</span> <span class="n">annotations</span>

<span class="k">def</span> <span class="nf">_create_named_tuple</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">unqual_name</span><span class="p">,</span> <span class="n">field_names</span><span class="p">):</span>
    <span class="n">TupleType</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="n">unqual_name</span><span class="p">,</span> <span class="n">field_names</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">TupleType</span><span class="p">(</span><span class="o">*</span><span class="n">t</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">_disable_tracing</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_get_tracing_state</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_set_tracing_state</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_set_tracing_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state</span> <span class="o">=</span> <span class="kc">None</span>


<span class="c1"># for use in python if using annotate</span>
<span class="k">def</span> <span class="nf">annotate</span><span class="p">(</span><span class="n">the_type</span><span class="p">,</span> <span class="n">the_value</span><span class="p">):</span>
    <span class="c1"># noop in python</span>
    <span class="k">return</span> <span class="n">the_value</span>


<span class="n">Attribute</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Attribute&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="s1">&#39;type&#39;</span><span class="p">])</span>

<span class="n">last_executed_optimized_graph</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_last_executed_optimized_graph</span>


<span class="k">def</span> <span class="nf">_graph_for</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="bp">self</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">last_executed_optimized_graph</span><span class="p">()</span>

<span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">ScriptMethod</span><span class="o">.</span><span class="n">graph_for</span> <span class="o">=</span> <span class="n">_graph_for</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Function</span><span class="o">.</span><span class="n">graph_for</span> <span class="o">=</span> <span class="n">_graph_for</span>
<span class="n">Function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">Function</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_jit_init</span><span class="p">():</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;JIT initialization failed&quot;</span><span class="p">)</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script type="text/javascript" src="../../_static/jquery.js"></script>
         <script type="text/javascript" src="../../_static/underscore.js"></script>
         <script type="text/javascript" src="../../_static/doctools.js"></script>
         <script type="text/javascript" src="../../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://pytorch.org/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>