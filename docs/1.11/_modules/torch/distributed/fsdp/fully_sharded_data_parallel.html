


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.distributed.fsdp.fully_sharded_data_parallel &mdash; PyTorch 1.11.0 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/distributed/fsdp/fully_sharded_data_parallel.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />


  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  


  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>1.11.0 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          


            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/amp_examples.html">Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../amp.html">torch.cuda.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../__config__.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
          <li><a href="../../../torch.html">torch</a> &gt;</li>
        
          <li><a href="../../distributed.html">torch.distributed</a> &gt;</li>
        
      <li>torch.distributed.fsdp.fully_sharded_data_parallel</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.distributed.fsdp.fully_sharded_data_parallel</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span><span class="p">,</span> <span class="n">auto</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TYPE_CHECKING</span><span class="p">,</span>
    <span class="n">Any</span><span class="p">,</span>
    <span class="n">Callable</span><span class="p">,</span>
    <span class="n">Dict</span><span class="p">,</span>
    <span class="n">List</span><span class="p">,</span>
    <span class="n">Optional</span><span class="p">,</span>
    <span class="n">Set</span><span class="p">,</span>
    <span class="n">Tuple</span><span class="p">,</span>
    <span class="n">Union</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">from</span> <span class="nn">torch.distributed</span> <span class="kn">import</span> <span class="n">ProcessGroup</span>
<span class="kn">from</span> <span class="nn">torch.distributed.distributed_c10d</span> <span class="kn">import</span> <span class="n">_get_default_group</span>
<span class="kn">from</span> <span class="nn">torch.nn.parameter</span> <span class="kn">import</span> <span class="n">Parameter</span>

<span class="kn">from</span> <span class="nn">.flatten_params_wrapper</span> <span class="kn">import</span> <span class="n">FlattenParamsWrapper</span>
<span class="kn">from</span> <span class="nn">.wrap</span> <span class="kn">import</span> <span class="n">_recursive_wrap</span>

<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_apply_to_tensors</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>  <span class="c1"># noqa: F401</span>


<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">CPUOffload</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    CPU offlaoding config. Currently, only parameter and gradient CPU</span>
<span class="sd">    offload are supported.</span>
<span class="sd">    offload_params: Offloading parameters to CPUs when these parameters are</span>
<span class="sd">                    not used for computation on GPUs. This implicitly enables</span>
<span class="sd">                    gradient offloading to CPUs in order for parameters and</span>
<span class="sd">                    gradients to be on the same device to work with optimizer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">offload_params</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="c1"># TODO: state dict offloading</span>
    <span class="c1"># https://github.com/pytorch/pytorch/issues/67224</span>

<span class="k">class</span> <span class="nc">BackwardPrefetch</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Specify where to prefetch next layer&#39;s full parameters</span>
<span class="sd">    during backward pass.</span>
<span class="sd">    BACKWARD_PRE: prefetch right before current layer&#39;s backward computation</span>
<span class="sd">                  starts, this approach will increase backward communication</span>
<span class="sd">                  and computation overalpping and potentialy improve training</span>
<span class="sd">                  performance, but it may increase the peak memory usage as</span>
<span class="sd">                  the prefetched full parameters will be kept in the GPU memory</span>
<span class="sd">                  until next layer&#39;s backward computation is done.</span>
<span class="sd">    BACKWARD_POST: prefetch right after current layer&#39;s backward computation finishes,</span>
<span class="sd">                   this approach will not increase peak memory as prefetching happens</span>
<span class="sd">                   after current layer&#39;s full parameters are freed.</span>
<span class="sd">                   It could potentially improve backward communication and computation</span>
<span class="sd">                   overlapping as it avoids all_gather and reduce_scatter are blocked</span>
<span class="sd">                   each other in the single NCCL stream. However, based on our experiments,</span>
<span class="sd">                   for some models, the backward post backward hook fire order is not always</span>
<span class="sd">                   the reversed forward computation order, so this</span>
<span class="sd">                   approach may prefetch full parameters for layers ahead of next layer,</span>
<span class="sd">                   this &#39;ahead&#39; all_gather could delay next layer&#39;s all_gather in the</span>
<span class="sd">                   single NCCL stream and cause the next layer&#39;s computation delay. So it may</span>
<span class="sd">                   cause some performance regession for some models.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">BACKWARD_PRE</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="n">BACKWARD_POST</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="c1"># TODO, BACKWARD_PRE_CPU, prefetch full parameters and keep them in the CPU memory</span>

<span class="k">class</span> <span class="nc">TrainingState_</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple enum to indicate what state FSDP is in. Used for asserting</span>
<span class="sd">    to make sure APIs are called in the correct state.</span>
<span class="sd">    ..note::</span>
<span class="sd">        ``BACKWARD_PRE`` and ``BACKWARD_POST`` states are used to ensure we</span>
<span class="sd">        receives backward hooks in the correct order. It is used to catch</span>
<span class="sd">        unexpected order of hooks being called (likely due to our</span>
<span class="sd">        hook registration logic or autograd engine logic changes).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">IDLE</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="n">FORWARD</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="n">BACKWARD_PRE</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>
    <span class="n">BACKWARD_POST</span> <span class="o">=</span> <span class="n">auto</span><span class="p">()</span>


<div class="viewcode-block" id="FullyShardedDataParallel"><a class="viewcode-back" href="../../../../fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel">[docs]</a><span class="k">class</span> <span class="nc">FullyShardedDataParallel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A wrapper for sharding Module parameters across data parallel workers. This</span>
<span class="sd">    is inspired by `Xu et al.`_ as well as the ZeRO Stage 3 from DeepSpeed_.</span>
<span class="sd">    FullyShardedDataParallel is commonly shorten to FSDP.</span>

<span class="sd">    .. _`Xu et al.`: https://arxiv.org/abs/2004.13336</span>
<span class="sd">    .. _DeepSpeed: https://www.deepspeed.ai/</span>

<span class="sd">    Example::</span>

<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; from torch.distributed.fsdp import FullyShardedDataParallel as FSDP</span>
<span class="sd">        &gt;&gt;&gt; torch.cuda.set_device(device_id)</span>
<span class="sd">        &gt;&gt;&gt; sharded_module = FSDP(my_module)</span>
<span class="sd">        &gt;&gt;&gt; optim = torch.optim.Adam(sharded_module.parameters(), lr=0.0001)</span>
<span class="sd">        &gt;&gt;&gt; x = sharded_module(x, y=3, z=torch.Tensor([1]))</span>
<span class="sd">        &gt;&gt;&gt; loss = x.sum()</span>
<span class="sd">        &gt;&gt;&gt; loss.backward()</span>
<span class="sd">        &gt;&gt;&gt; optim.step()</span>

<span class="sd">    .. warning::</span>
<span class="sd">        The optimizer must be initialized *after* the module has been wrapped,</span>
<span class="sd">        since FSDP will shard parameters in-place and this will break any</span>
<span class="sd">        previously initialized optimizers.</span>

<span class="sd">    .. warning:</span>
<span class="sd">        Module should be already placed on the destination device or</span>
<span class="sd">        device is set properly using torch.cuda.set_device(device_id).</span>
<span class="sd">        FSDP will get compute device from module first, if module device</span>
<span class="sd">        is CPU, FSDP will then get compute device from current device.</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module):</span>
<span class="sd">            module to be wrapped with FSDP.</span>
<span class="sd">        process_group (Optional[ProcessGroup]):</span>
<span class="sd">            process group for sharding</span>
<span class="sd">        cpu_offload (Optional [CPUOffload]):</span>
<span class="sd">            CPU offloading config. Currently, only parameter and gradient CPU</span>
<span class="sd">            offload is supported. It can be enabled via passing in</span>
<span class="sd">            ``cpu_offload=CPUOffload(offload_params=True)``. Note that this</span>
<span class="sd">            currently implicitly enables gradient offloading to CPU in order for</span>
<span class="sd">            params and grads to be on same device to work with optimizer. This</span>
<span class="sd">            API is subject to change. Default is ``None`` in which case there</span>
<span class="sd">            will be no offloading.</span>
<span class="sd">        fsdp_auto_wrap_policy: (Optional [callable]):</span>
<span class="sd">            A callable specifying a policy to recursively wrap layers with FSDP.</span>
<span class="sd">            Note that this policy currently will only apply to child modules of</span>
<span class="sd">            the passed in module. The remainder modules are always wrapped in</span>
<span class="sd">            the returned FSDP root instance.</span>
<span class="sd">            ``default_auto_wrap_policy`` written in ``torch.distributed.fsdp.wrap`` is</span>
<span class="sd">            an example of ``fsdp_auto_wrap_policy`` callable, this policy wraps layers</span>
<span class="sd">            with parameter sizes larger than 100M. Users can supply the customized</span>
<span class="sd">            ``fsdp_auto_wrap_policy`` callable that should accept following arguments:</span>
<span class="sd">            ``module: nn.Module``, ``recurse: bool``, ``unwrapped_params: int``,</span>
<span class="sd">            extra customized arguments could be added to the customized</span>
<span class="sd">            ``fsdp_auto_wrap_policy`` callable as well.</span>

<span class="sd">            Example::</span>

<span class="sd">                &gt;&gt;&gt; def custom_auto_wrap_policy(</span>
<span class="sd">                &gt;&gt;&gt;     module: nn.Module,</span>
<span class="sd">                &gt;&gt;&gt;     recurse: bool,</span>
<span class="sd">                &gt;&gt;&gt;     unwrapped_params: int,</span>
<span class="sd">                &gt;&gt;&gt;     # These are customizable for this policy function.</span>
<span class="sd">                &gt;&gt;&gt;     min_num_params: int = int(1e8),</span>
<span class="sd">                &gt;&gt;&gt; ) -&gt; bool:</span>
<span class="sd">                &gt;&gt;&gt;     return unwrapped_params &gt;= min_num_params</span>

<span class="sd">        backward_prefetch: (Optional[BackwardPrefetch]):</span>
<span class="sd">            This is an experimental feature that is subject to change in the</span>
<span class="sd">            the near future. It allows users to enable two different backward_prefetch</span>
<span class="sd">            algorithms to help backward communication and computation overlapping.</span>
<span class="sd">            Pros and cons of each algorithm is explained in the class ``BackwardPrefetch``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">process_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProcessGroup</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">cpu_offload</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CPUOffload</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">fsdp_auto_wrap_policy</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">backward_prefetch</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">BackwardPrefetch</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;torch.distributed.fsdp&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="c1"># if fsdp_auto_wrap_policy is specified, submodules should not be</span>
        <span class="c1"># already wrapped, otherwise we&#39;d attempt to double wrap them resulting</span>
        <span class="c1"># in errors.</span>
        <span class="k">if</span> <span class="n">fsdp_auto_wrap_policy</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_wrapped</span><span class="p">(</span>
                <span class="n">module</span><span class="p">,</span>
                <span class="n">check_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">mod</span><span class="p">:</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">FullyShardedDataParallel</span><span class="p">),</span>
                <span class="n">err_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">mod</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Expected </span><span class="si">{</span><span class="n">mod</span><span class="si">}</span><span class="s2"> to NOT be FullyShardedDataParallel if auto_wrap is enabled.&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">_recursive_wrap</span><span class="p">(</span>
                <span class="n">module</span><span class="p">,</span>
                <span class="n">auto_wrap_policy</span><span class="o">=</span><span class="n">fsdp_auto_wrap_policy</span><span class="p">,</span>
                <span class="n">wrapper_cls</span><span class="o">=</span><span class="n">FullyShardedDataParallel</span><span class="p">,</span>
                <span class="c1"># Note that we have the recursive_wrap skip wrapping for</span>
                <span class="c1"># the outermost (this) module otherwise it will result in a</span>
                <span class="c1"># double-wrap causing issues.</span>
                <span class="n">only_wrap_children</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="c1"># FSDP arguments follow.</span>
                <span class="n">process_group</span><span class="o">=</span><span class="n">process_group</span><span class="p">,</span>
                <span class="n">cpu_offload</span><span class="o">=</span><span class="n">cpu_offload</span><span class="p">,</span>
                <span class="n">backward_prefetch</span><span class="o">=</span><span class="n">backward_prefetch</span><span class="p">,</span>
                <span class="c1"># Note that recursive_wap should not call FSDP with wrapping</span>
                <span class="c1"># enabled, as this recursive call handles all wrapping,</span>
                <span class="c1"># including for nested children.</span>
                <span class="n">fsdp_auto_wrap_policy</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">process_group</span> <span class="o">=</span> <span class="n">process_group</span> <span class="ow">or</span> <span class="n">_get_default_group</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_group</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_group</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="c1"># device for computation, if module is on GPU, use module.device;</span>
        <span class="c1"># if module is on CPU, use current device;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_device</span> <span class="o">=</span> <span class="n">_get_default_cuda_device</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

        <span class="c1"># Free full params and keep shard only after forward</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reshard_after_forward</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># setting two factors to avoid underflow and overflow</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_predivide_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_gradient_predivide_factor</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_postdivide_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_predivide_factor</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">numel_padded_per_param</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cpu_offload</span> <span class="o">=</span> <span class="n">cpu_offload</span> <span class="ow">or</span> <span class="n">CPUOffload</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backward_prefetch</span> <span class="o">=</span> <span class="n">backward_prefetch</span>

        <span class="c1"># Only handle params which are not already sharded. This enables</span>
        <span class="c1"># sharding individual layers of a Module, with an outer wrapper to</span>
        <span class="c1"># shard any leftover parameters.</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="s2">&quot;_is_sharded&quot;</span><span class="p">):</span>
                <span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_wrapped_module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">FlattenParamsWrapper</span><span class="p">(</span>
            <span class="n">module</span><span class="p">,</span> <span class="n">param_list</span><span class="o">=</span><span class="n">params</span>
        <span class="p">)</span>
        <span class="k">del</span> <span class="n">module</span>  <span class="c1"># free original module in case it helps garbage collection</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_wrapped_module</span><span class="o">.</span><span class="n">flat_param</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_wrapped_module</span><span class="o">.</span><span class="n">flat_param</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Shard module parameters in place</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_shard_parameters</span><span class="p">()</span>

        <span class="c1"># Make sure all parameters are sharded.</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s2">&quot;_is_sharded&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;found unsharded parameter: </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2"> ; </span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_lazy_init</span><span class="p">()</span>

        <span class="c1"># Enum to indicate if we&#39;re in the forward/backward pass, idle, etc.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_state</span> <span class="o">=</span> <span class="n">TrainingState_</span><span class="o">.</span><span class="n">IDLE</span>

        <span class="c1"># Flag to guard against preparing gradients multiple times per backward pass.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pre_backward_hook_has_run</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># Used for prefetching all gather full params in post backward hook</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_need_rebuild_full_params</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># If specified, offload parameter shard to CPU.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_offload</span><span class="o">.</span><span class="n">offload_params</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_offload_to_cpu</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">_check_wrapped</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">begin_module</span><span class="p">,</span> <span class="n">check_fn</span><span class="p">,</span> <span class="n">err_fn</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">begin_module</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">check_fn</span><span class="p">(</span><span class="n">mod</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">err_fn</span><span class="p">(</span><span class="n">mod</span><span class="p">))</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">module</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FlattenParamsWrapper</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;make model.module accessible, just like DDP.&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_wrapped_module</span><span class="p">,</span> <span class="n">FlattenParamsWrapper</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_wrapped_module</span>

    <span class="c1"># setting two factors &#39;self.gradient_predivide_factor&#39;</span>
    <span class="c1"># and &#39;self.gradient_postdivide_factor&#39; to avoid underflow and overflow</span>
    <span class="k">def</span> <span class="nf">_get_gradient_predivide_factor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">world_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="n">world_size</span> <span class="o">%</span> <span class="n">factor</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">world_size</span> <span class="o">/</span> <span class="n">factor</span> <span class="o">&gt;</span> <span class="n">factor</span><span class="p">:</span>
            <span class="n">factor</span> <span class="o">*=</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">factor</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_offload_to_cpu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Offloads parameter to CPU from self.compute_device. If the parameter is</span>
<span class="sd">        already on CPU then this is a noop.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cpu_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">cpu_device</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cpu_device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_cast_buffers</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">memo</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Set</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Move all buffers to the given *device*.</span>
<span class="sd">        If *device* is not given, then it will default to</span>
<span class="sd">        ``self.compute_device``. In the</span>
<span class="sd">        case of nested FSDP instances, we will respect the child instance&#39;s</span>
<span class="sd">        ``compute_device`` configuration.</span>
<span class="sd">        Args:</span>
<span class="sd">            device (torch.device, Optional):</span>
<span class="sd">                device to cast buffers to (defaults to compute_device)</span>
<span class="sd">            memo (Set, Optional):</span>
<span class="sd">                set of modules that have already been processed</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">memo</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">memo</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">module</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">self</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">FullyShardedDataParallel</span><span class="p">):</span>
                <span class="c1"># Allow any child FSDP instances to handle their own buffers.</span>
                <span class="n">module</span><span class="o">.</span><span class="n">_cast_buffers</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">memo</span><span class="o">=</span><span class="n">memo</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">module</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">memo</span><span class="p">:</span>
                <span class="n">memo</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">buf</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">continue</span>
                    <span class="n">buf</span> <span class="o">=</span> <span class="n">buf</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_device</span><span class="p">)</span>
                    <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_shard_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        At initialization we wrap a module with full parameters and shard the</span>
<span class="sd">        parameters in-place. Sharding is implemented by viewing each parameter</span>
<span class="sd">        as a 1D Tensor and retaining only a single slice, where the slice size</span>
<span class="sd">        is determined by the number of data parallel workers.</span>
<span class="sd">        After this initial sharding is complete, the user can initialize a</span>
<span class="sd">        ``torch.optim.Optimizer`` in the usual way, i.e.::</span>
<span class="sd">        .. code-block:: python</span>
<span class="sd">            optim = torch.optim.Adam(sharded_module.parameters(), lr=0.0001)</span>
<span class="sd">        The optimizer will see only a single slice of parameters and will thus</span>
<span class="sd">        allocate less memory for optimizer state, avoiding redundancy across</span>
<span class="sd">        data parallel workers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">numel_padded_per_param</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="k">assert</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span>
                <span class="n">p</span><span class="p">,</span> <span class="s2">&quot;_is_sharded&quot;</span>
            <span class="p">),</span> <span class="s2">&quot;Param should have not been sharded yet.&quot;</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">p</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">()</span>
            <span class="p">),</span> <span class="s2">&quot;Autograd does not support operations for integer type.&quot;</span>

            <span class="c1"># Sharding is done only when world_size is larger than 1.</span>
            <span class="n">p</span><span class="o">.</span><span class="n">_is_sharded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">&gt;</span> <span class="mi">1</span>  <span class="c1"># type: ignore[attr-defined]</span>
            <span class="n">p</span><span class="o">.</span><span class="n">_orig_size</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>  <span class="c1"># type: ignore[attr-defined]</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">_is_sharded</span><span class="p">:</span>  <span class="c1"># type: ignore[attr-defined]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">numel_padded_per_param</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">continue</span>

            <span class="c1"># Save the original storage and free it later on.</span>
            <span class="c1"># Since we&#39;re modifying the tensor&#39;s storage directly,</span>
            <span class="c1"># make sure the tensor is the sole occupant of the storage.</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">p</span><span class="o">.</span><span class="n">storage_offset</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="p">),</span> <span class="s2">&quot;The tensor is not the sole occupant of the storage.&quot;</span>
            <span class="n">orig_storage</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span>

            <span class="c1"># Replace p with the relevant shard.</span>
            <span class="n">local_shard</span><span class="p">,</span> <span class="n">num_padded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_shard</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
            <span class="n">p</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">local_shard</span><span class="p">)</span>  <span class="c1"># type: ignore[call-overload]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">numel_padded_per_param</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">num_padded</span><span class="p">)</span>

            <span class="c1"># Free storage that contains the original full data.</span>
            <span class="k">if</span> <span class="n">orig_storage</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">orig_storage</span><span class="o">.</span><span class="n">resize_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">numel_padded_per_param</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
        <span class="p">),</span> <span class="s2">&quot;numel_padded_per_param is not populated correctly.&quot;</span>

    <span class="k">def</span> <span class="nf">_get_shard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Return the local shard of a full tensor.&quot;&quot;&quot;</span>
        <span class="c1"># Shard using torch.chunk to match all-gather/reduce-scatter.</span>
        <span class="n">chunks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span> <span class="o">&lt;</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="c1"># If there are not enough chunks to shard across ranks, create an</span>
            <span class="c1"># empty chunk that will just be padded with zeros to be the</span>
            <span class="c1"># appropriate size.</span>
            <span class="n">chunk</span> <span class="o">=</span> <span class="n">chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">new_empty</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chunk</span> <span class="o">=</span> <span class="n">chunks</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">]</span>
        <span class="c1"># Determine number of padding elements.</span>
        <span class="n">num_to_pad</span> <span class="o">=</span> <span class="n">chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">-</span> <span class="n">chunk</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">num_to_pad</span> <span class="o">&gt;=</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;Chunk&#39;s size should be equal or smaller than </span><span class="se">\</span>
<span class="s2">            the first chunk&#39;s size.&quot;</span>

        <span class="c1"># We always need to clone here, because regardless of padding the</span>
        <span class="c1"># original parameter, of which this chunk is a view of, is deallocated</span>
        <span class="c1"># after _get_shard.</span>
        <span class="n">shard</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">num_to_pad</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">shard</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">shard</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_to_pad</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">shard</span><span class="p">,</span> <span class="n">num_to_pad</span>

    <span class="k">def</span> <span class="fm">__getattr__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward missing attributes to wrapped module.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__getattr__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>  <span class="c1"># defer to nn.Module&#39;s logic</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward indexing calls in case the module is a nn.Sequential.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>  <span class="c1"># type: ignore[operator]</span>

    <span class="k">def</span> <span class="nf">_reset_lazy_init</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reset instance so :func:`_lazy_init` will run on the next forward.</span>
<span class="sd">        Currently this is only called in __init__</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_root</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_my_fsdp_idx_in_graph</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s2">&quot;_local_shard&quot;</span><span class="p">):</span>
                <span class="c1"># reset attributes that are added in _init_param_attributes, as</span>
                <span class="c1"># part of _lazy_init</span>
                <span class="k">del</span> <span class="n">p</span><span class="o">.</span><span class="n">_local_shard</span>  <span class="c1"># type: ignore[attr-defined]</span>

    <span class="k">def</span> <span class="nf">_lazy_init</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Initialization steps that should happen lazily, typically right</span>
<span class="sd">        before the first forward pass.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Initialize param attributes lazily, in case the param&#39;s dtype or</span>
        <span class="c1"># device changes after __init__.</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_param_attributes</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

        <span class="c1"># Initialize _is_root and setup streams. These steps would ideally</span>
        <span class="c1"># happen in __init__, but _is_root can only be determined after the</span>
        <span class="c1"># entire model hierarchy is setup, thus we run it lazily.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_root</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># _is_root means that we are in the outermost module&#39;s forward.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set_is_root</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_setup_streams</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_root</span><span class="p">:</span>
            <span class="c1"># Buffers stay on GPU, and don&#39;t get sharded. Since _cast_buffers</span>
            <span class="c1"># applies recursively, we only call this from the root instance.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_cast_buffers</span><span class="p">()</span>

            <span class="c1"># Don&#39;t free the full params for the outer-most (root) instance,</span>
            <span class="c1"># In most cases, root instance contains params in the last layers</span>
            <span class="c1"># or has no params. In these cases, those params will be needed</span>
            <span class="c1"># immediately after for the backward pass. Note that this only</span>
            <span class="c1"># applies currently when freeing parameters at end of layer&#39;s</span>
            <span class="c1"># forward pass.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">reshard_after_forward</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="c1"># Due to the use of streams, we need to make sure the previous</span>
            <span class="c1"># ``optim.step()`` is done before we all-gather parameters.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_wait_for_previous_optim_step</span><span class="p">()</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_init_param_attributes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="n">Parameter</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        We manage several attributes on each Parameter instance. The first two</span>
<span class="sd">        are set by :func:`_shard_parameters`:</span>
<span class="sd">            ``_is_sharded``: ``True`` if the Parameter is sharded or ``False``</span>
<span class="sd">                if the Parameter is intentionally not sharded (in which case we</span>
<span class="sd">                will all-reduce grads for this param). Currently the only way</span>
<span class="sd">                `_is_sharded = False` is if world_size = 1.</span>
<span class="sd">            ``_orig_size``: the size of the original Parameter (before sharding)</span>
<span class="sd">        A few attributes are set here:</span>
<span class="sd">            ``_local_shard``: a single shard of the parameter. This is needed to</span>
<span class="sd">                recover the shard after rebuilding full parameter in forward</span>
<span class="sd">                and backward.</span>
<span class="sd">            ``_full_param_padded``: the full weight (padded to be evenly</span>
<span class="sd">                divisible by ``world_size``), used for computation in the</span>
<span class="sd">                forward and backward pass. It is initialized with the</span>
<span class="sd">                appropriate size and then has its storage freed. This will be</span>
<span class="sd">                resized in place and only materialized (via all-gather) as needed.</span>
<span class="sd">        Another attribute is set by :func:`_register_post_backward_hooks`:</span>
<span class="sd">            ``_shard_bwd_hook``: it holds the parameter&#39;s AccumulateGrad object</span>
<span class="sd">                and the registered post hook handle.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s2">&quot;_is_sharded&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span>
            <span class="n">p</span><span class="p">,</span> <span class="s2">&quot;_orig_size&quot;</span>
        <span class="p">),</span> <span class="s2">&quot;Parameters should have been sharded during construction.&quot;</span>
        <span class="c1"># If _local_shard has been set in the first lazy init and</span>
        <span class="c1"># current parameter is pointed to _local_shard, no need to</span>
        <span class="c1"># set the _local_shard again.</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s2">&quot;_local_shard&quot;</span><span class="p">):</span>
            <span class="c1"># If CPU offloading, p._local_shard should have been placed on CPU</span>
            <span class="c1"># during its first lazy construction.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_offload</span><span class="o">.</span><span class="n">offload_params</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">_local_shard</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="s2">&quot;cpu&quot;</span>
                <span class="p">),</span> <span class="p">(</span>
                    <span class="s2">&quot;Expected p._local_shard to be on CPU, &quot;</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="sa">f</span><span class="s2">&quot;but it&#39;s on </span><span class="si">{</span><span class="n">p</span><span class="o">.</span><span class="n">_local_shard</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>  <span class="c1"># type: ignore[attr-defined]</span>
                <span class="p">)</span>
            <span class="k">return</span>

        <span class="c1"># A single shard of the parameters. Also makes p._local_shard to be on</span>
        <span class="c1"># CPU if we are CPU offloading, since p.data would be on CPU during</span>
        <span class="c1"># init.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_offload</span><span class="o">.</span><span class="n">offload_params</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span>
                <span class="s2">&quot;cpu&quot;</span>
            <span class="p">),</span> <span class="p">(</span><span class="s2">&quot;Expected param to be on CPU when cpu_offloading is enabled. &quot;</span>
                <span class="s2">&quot;If CPU offloading is enabled correctly, you may be &quot;</span>
                <span class="s2">&quot;accidentally moving the model to CUDA after FSDP initialization.&quot;</span>
                <span class="p">)</span>
        <span class="n">p</span><span class="o">.</span><span class="n">_local_shard</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># type: ignore[attr-defined]</span>
        <span class="c1"># If CPU offloading, pin the memory to enable faster CPU -&gt; GPU device</span>
        <span class="c1"># transfer.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_offload</span><span class="o">.</span><span class="n">offload_params</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">_local_shard</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
            <span class="n">p</span><span class="o">.</span><span class="n">_local_shard</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span>  <span class="c1"># type: ignore[attr-defined]</span>
            <span class="c1"># When offloading parameters, also move the grad shard to CPU during</span>
            <span class="c1"># backward pass. In this case, it&#39;s important to pre-allocate the</span>
            <span class="c1"># CPU grad shard in pinned memory so that we can do a non-blocking</span>
            <span class="c1"># transfer.</span>
            <span class="n">p</span><span class="o">.</span><span class="n">_cpu_grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span>  <span class="c1"># type: ignore[attr-defined]</span>
                <span class="n">p</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
            <span class="p">)</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span>

        <span class="c1"># We also maintain a full-sized parameter of type self.compute_dtype.</span>
        <span class="c1"># We resize the storage to size 0 at init (here) and only materialize</span>
        <span class="c1"># as needed. The storage may contain padding elements so that it is</span>
        <span class="c1"># evenly divisible by world_size, although these padding elements will</span>
        <span class="c1"># be removed before the relevant computation.</span>
        <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">_is_sharded</span><span class="p">:</span>  <span class="c1"># type: ignore[attr-defined]</span>
            <span class="n">p</span><span class="o">.</span><span class="n">_full_param_padded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>  <span class="c1"># type: ignore[attr-defined]</span>
                <span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">compute_device</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">_free_storage</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">_full_param_padded</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>

    <span class="k">def</span> <span class="nf">_set_is_root</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;If ``True``, implies that no other :class:`FullyShardedDataParallel`</span>
<span class="sd">        instance wraps this one. Called once by :func:`_lazy_init`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_root</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="c1"># No FSDP instance wraps this, else _is_root would be set to False.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_root</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="c1"># If final backward callback is never been queued, state should be IDLE.</span>
        <span class="c1"># If final backward callback is queued, the callback should be finished</span>
        <span class="c1"># and the state was reset to be IDLE.</span>
        <span class="c1"># This should be asserted at the beginning of forward pass in the root instance only.</span>
        <span class="c1"># For children instances, if they are checkpointed, state will not be reset to</span>
        <span class="c1"># IDLE after each inner forward/backward.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_assert_state</span><span class="p">(</span><span class="n">TrainingState_</span><span class="o">.</span><span class="n">IDLE</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
            <span class="c1"># `n != &quot;&quot;` excludes self.</span>
            <span class="k">if</span> <span class="n">n</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">FullyShardedDataParallel</span><span class="p">):</span>
                <span class="c1"># We relax the assert for non-root instance, when the nested initialized module is wrapped</span>
                <span class="c1"># again in FSDP later, for example after training to run inference.</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="n">m</span><span class="o">.</span><span class="n">_is_root</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">m</span><span class="o">.</span><span class="n">_is_root</span>
                <span class="p">),</span> <span class="s2">&quot;Non-root instance&#39;s _is_root flag should have not been set yet </span><span class="se">\</span>
<span class="s2">                    or has already been set as False.&quot;</span>
                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">_is_root</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">m</span><span class="o">.</span><span class="n">_is_root</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_setup_streams</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create streams to overlap data transfer and computation.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_root</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="c1"># Stream for all-gathering parameters.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;all_gather&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="p">()</span>
            <span class="c1"># Stream for overlapping grad reduction with the backward pass.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;post_backward&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Stream</span><span class="p">()</span>

        <span class="c1"># We share streams with all children instances, which allows them to</span>
        <span class="c1"># overlap transfers across the forward pass without synchronizing with</span>
        <span class="c1"># the default stream.</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">n</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">FullyShardedDataParallel</span><span class="p">):</span>
                <span class="n">m</span><span class="o">.</span><span class="n">_streams</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_streams</span>
                <span class="n">m</span><span class="o">.</span><span class="n">_fsdp_graph_order</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span>

    <span class="k">def</span> <span class="nf">_wait_for_previous_optim_step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The outer-most :class:`FullyShardedDataParallel` instance (i.e., the root</span>
<span class="sd">        instance) needs to synchronize with the default stream to ensure the</span>
<span class="sd">        previous optimizer step is done.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;all_gather&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">())</span>

    <span class="k">def</span> <span class="nf">_need_prefetch_pre_backward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">backward_prefetch</span> <span class="o">==</span> <span class="n">BackwardPrefetch</span><span class="o">.</span><span class="n">BACKWARD_PRE</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_my_fsdp_idx_in_graph</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_my_fsdp_idx_in_graph</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_my_fsdp_idx_in_graph</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">training_state</span> <span class="o">!=</span> <span class="n">TrainingState_</span><span class="o">.</span><span class="n">BACKWARD_POST</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_need_prefetch_post_backward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">backward_prefetch</span> <span class="o">==</span> <span class="n">BackwardPrefetch</span><span class="o">.</span><span class="n">BACKWARD_POST</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_my_fsdp_idx_in_graph</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_my_fsdp_idx_in_graph</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_my_fsdp_idx_in_graph</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">training_state</span> <span class="o">!=</span> <span class="n">TrainingState_</span><span class="o">.</span><span class="n">BACKWARD_POST</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_my_fsdp_idx_in_graph</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_need_rebuild_full_params</span>
        <span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lazy_init</span><span class="p">()</span>

        <span class="c1"># Start of a forward pass.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_state</span> <span class="o">=</span> <span class="n">TrainingState_</span><span class="o">.</span><span class="n">FORWARD</span>

        <span class="c1"># All-gather full parameters, moving them to compute_device if</span>
        <span class="c1"># necessary.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_rebuild_full_params</span><span class="p">()</span>
        <span class="c1"># Wait for all_gather full parameters to finish before computation</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;all_gather&quot;</span><span class="p">])</span>

        <span class="c1"># Register backward hooks to reshard params and reduce-scatter grads.</span>
        <span class="c1"># These need to be re-registered every forward pass in some cases where grad_fn</span>
        <span class="c1"># is mutated.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_register_post_backward_hooks</span><span class="p">()</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_my_fsdp_idx_in_graph</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshard_after_forward</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_free_full_params</span><span class="p">()</span>
        <span class="c1"># Switch to original local shards of params. We maintain this invariant throughout</span>
        <span class="c1"># the code, i.e., ``p.data == p._local_shard`` after each function. This</span>
        <span class="c1"># also ensures that after the first forward, the optimizer state will be</span>
        <span class="c1"># initialized with the correct dtype and (sharded) size, since optimizer</span>
        <span class="c1"># state is typically initialized lazily in ``optim.step()``.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_param_local_shard</span><span class="p">()</span>

        <span class="c1"># Register pre-backward hooks to all-gather the params for the backward</span>
        <span class="c1"># pass (if output&#39;s grad was needed). This won&#39;t register anything if</span>
        <span class="c1"># we are in eval mode.</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_register_pre_backward_hooks</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>

        <span class="c1"># Done with a forward pass.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_state</span> <span class="o">=</span> <span class="n">TrainingState_</span><span class="o">.</span><span class="n">IDLE</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">def</span> <span class="nf">_register_pre_backward_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Register pre-backward hook to run before the wrapped module&#39;s</span>
<span class="sd">        backward. Hooks should be attached to all outputs from the forward.</span>
<span class="sd">        Returns:</span>
<span class="sd">            outputs: new outputs with hooks registered if they requires gradient.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Reset before each backward pass</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_need_rebuild_full_params</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_grad_enabled</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">outputs</span>  <span class="c1"># don&#39;t register hooks if grad isn&#39;t enabled</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_root</span><span class="p">:</span>
            <span class="c1"># This actually means that only root instance has</span>
            <span class="c1"># _post_backward_callback_queued defined. Accidentally accessing this field</span>
            <span class="c1"># will assert on all other instances, giving us a nice bug checker.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_post_backward_callback_queued</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Reset before each backward pass</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_pre_backward_hook_has_run</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">def</span> <span class="nf">_pre_backward_hook</span><span class="p">(</span><span class="o">*</span><span class="n">unused</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Run ``_pre_backward_hook`` only once per backward pass</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_pre_backward_hook_has_run</span><span class="p">:</span>
                <span class="k">return</span>
            <span class="c1"># try to queue final backward callback only once for root, so</span>
            <span class="c1"># that final backward callback is attached to the outer most</span>
            <span class="c1"># backward graph task and called after all the backward</span>
            <span class="c1"># calls are completed.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_root</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_queue_wait_for_post_backward</span><span class="p">()</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_need_prefetch_pre_backward_hook</span><span class="p">():</span>
                <span class="c1"># Always wait for all_gather before rebuilding full params, just</span>
                <span class="c1"># in case full params have already been prefetched in previous layer&#39;s</span>
                <span class="c1"># pre-backward hook.</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;all_gather&quot;</span><span class="p">])</span>

            <span class="c1"># All-gather full parameters, moving them to compute device if</span>
            <span class="c1"># necessary.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_rebuild_full_params</span><span class="p">()</span>
            <span class="c1"># Wait for all_gather to finish before computation</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;all_gather&quot;</span><span class="p">])</span>

            <span class="c1"># Prefetch next layer&#39;s full params in backward pass,</span>
            <span class="c1"># since it is prefetching, no need to wait for all_gather stream.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_need_prefetch_pre_backward_hook</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_my_fsdp_idx_in_graph</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_rebuild_full_params</span><span class="p">()</span>  <span class="c1"># type: ignore[operator]</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_pre_backward_hook_has_run</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="c1"># Prepare p.grad so that it is in the right shape, device, accumulated values, etc.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_prep_grads_for_backward</span><span class="p">()</span>
            <span class="c1"># Start of a backward pass for the first time in an backward pass.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_assert_state</span><span class="p">([</span><span class="n">TrainingState_</span><span class="o">.</span><span class="n">IDLE</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_state</span> <span class="o">=</span> <span class="n">TrainingState_</span><span class="o">.</span><span class="n">BACKWARD_PRE</span>

        <span class="k">def</span> <span class="nf">_register_hook</span><span class="p">(</span><span class="n">t</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="n">t</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span><span class="n">_pre_backward_hook</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_need_rebuild_full_params</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="n">t</span>

        <span class="c1"># Attach hooks to Tensor outputs.</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">_apply_to_tensors</span><span class="p">(</span><span class="n">_register_hook</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">def</span> <span class="nf">_register_post_backward_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Register backward hooks to reshard params and reduce-scatter grads.</span>
<span class="sd">        This is called during forward pass. The goal is to attach a hook</span>
<span class="sd">        on each of the parameter&#39;s gradient generating function (``grad_acc``</span>
<span class="sd">        below) so that the hook is called *after* all gradients for that</span>
<span class="sd">        param are computed.</span>
<span class="sd">        Goals:</span>
<span class="sd">        1. We want the hook to fire once and only once *after* all gradients</span>
<span class="sd">        are accumulated for a param.</span>
<span class="sd">        2. If it fires more than once, we end up incorrectly shard the grad</span>
<span class="sd">        multiple times. (could lead to dimension too small)</span>
<span class="sd">        3. If it fires once but too early or doesn&#39;t fire, we leave gradients</span>
<span class="sd">        unsharded. (could lead to dimension too large)</span>
<span class="sd">        Due to multiple-pass forward, this function can be called on</span>
<span class="sd">        the same parameter multiple times in a single forward pass. If we register</span>
<span class="sd">        the hook multiple time, we end up getting called multiple times. We</span>
<span class="sd">        could try to get a new hook every time and delete the previous one</span>
<span class="sd">        registered. However, due to *unknown reason* (I have debugged it for</span>
<span class="sd">        a long time!), in mixed precision mode, we get two different ``grad_acc``</span>
<span class="sd">        objects below during different calls of this function (in the same</span>
<span class="sd">        forward pass). If we keep the last one, the hook end up firing too</span>
<span class="sd">        early. In full precision mode, we luckily get the *same* ``grad_acc``</span>
<span class="sd">        object, so deleting and re-registering still ensured the hook fire</span>
<span class="sd">        once after all gradients are generated.</span>
<span class="sd">        Empirically, keep the first hook register per forward pass seems to</span>
<span class="sd">        work the best. We do need to remove the hook at the end of the</span>
<span class="sd">        backward pass. Otherwise, the next forward pass will not register</span>
<span class="sd">        a new hook, which is needed for a new forward pass.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">is_grad_enabled</span><span class="p">():</span>
            <span class="k">return</span>  <span class="c1"># don&#39;t register grad hooks if grad isn&#39;t enabled</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s2">&quot;_shard_bwd_hook&quot;</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="c1"># Register a hook on the first call, empirically, autograd</span>
                <span class="c1"># fires it at the end for this param, which makes sense.</span>
                <span class="n">p_tmp</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>  <span class="c1"># Get a grad_fn on p_tmp.</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="n">p_tmp</span><span class="o">.</span><span class="n">grad_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="p">),</span> <span class="s2">&quot;p_tmp grad_fn should not be None, it is used to access </span><span class="se">\</span>
<span class="s2">                    p&#39;s AccumulateGrad object and register post hook on it.&quot;</span>
                <span class="n">grad_acc</span> <span class="o">=</span> <span class="n">p_tmp</span><span class="o">.</span><span class="n">grad_fn</span><span class="o">.</span><span class="n">next_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span>
                    <span class="mi">0</span>
                <span class="p">]</span>  <span class="c1"># Gets its AccumulateGrad object.</span>
                <span class="n">handle</span> <span class="o">=</span> <span class="n">grad_acc</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span>
                    <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_post_backward_hook</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">p</span><span class="o">.</span><span class="n">_shard_bwd_hook</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad_acc</span><span class="p">,</span> <span class="n">handle</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_post_backward_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="p">:</span> <span class="n">Parameter</span><span class="p">,</span> <span class="o">*</span><span class="n">unused</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        At the start of :func:`_post_backward_hook`, ``param.grad`` contains the</span>
<span class="sd">        full gradient for the local batch. The reduce-scatter op will replace</span>
<span class="sd">        ``param.grad`` with a single shard of the summed gradient across all</span>
<span class="sd">        GPUs. This shard will align with the current GPU rank. For example::</span>
<span class="sd">            before reduce_scatter:</span>
<span class="sd">                param.grad (GPU #0): [1, 2, 3, 4]</span>
<span class="sd">                param.grad (GPU #1): [5, 6, 7, 8]</span>
<span class="sd">            after reduce_scatter:</span>
<span class="sd">                param.grad (GPU #0): [6, 8]    # 1+5, 2+6</span>
<span class="sd">                param.grad (GPU #1): [10, 12]  # 3+7, 4+8</span>
<span class="sd">        The local GPU&#39;s ``optim.step`` is responsible for updating a single</span>
<span class="sd">        shard of params, also corresponding to the current GPU&#39;s rank. This</span>
<span class="sd">        alignment is created by :func:`_shard_parameters`, which ensures that</span>
<span class="sd">        the local optimizer only sees the relevant parameter shard.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># First hook callback will see PRE state. If we have multiple params,</span>
        <span class="c1"># then subsequent hook callbacks will see POST state.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_assert_state</span><span class="p">([</span><span class="n">TrainingState_</span><span class="o">.</span><span class="n">BACKWARD_PRE</span><span class="p">,</span> <span class="n">TrainingState_</span><span class="o">.</span><span class="n">BACKWARD_POST</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_state</span> <span class="o">=</span> <span class="n">TrainingState_</span><span class="o">.</span><span class="n">BACKWARD_POST</span>
        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;FSDP only works with gradients that don&#39;t require gradients&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_free_full_params</span><span class="p">([</span><span class="n">param</span><span class="p">])</span>
        <span class="c1"># Switch to local shard after backward.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_use_param_local_shard</span><span class="p">([</span><span class="n">param</span><span class="p">])</span>

        <span class="c1"># Prefetch previous layer&#39;s full params in backward pass post backward hook,</span>
        <span class="c1"># If next layer&#39;s backward computation is done and full params are freed,</span>
        <span class="c1"># no need to prefetch the full params again.</span>
        <span class="c1"># Only prefetch full params if any of the next layer&#39;s outputs requires grad</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_need_prefetch_post_backward_hook</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_fsdp_graph_order</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_my_fsdp_idx_in_graph</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">_rebuild_full_params</span><span class="p">()</span>  <span class="c1"># type: ignore[operator]</span>
            <span class="c1"># Next layer&#39;s computation will start right after this all_gather,</span>
            <span class="c1"># Wait for all_gather to finish before computation.</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;all_gather&quot;</span><span class="p">])</span>

        <span class="c1"># Wait for all work in the current stream to finish, then start the</span>
        <span class="c1"># reductions in post_backward stream.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;post_backward&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">())</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;post_backward&quot;</span><span class="p">]):</span>
            <span class="n">orig_grad_data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_predivide_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># Average grad by world_size for consistency with PyTorch DDP.</span>
                <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_predivide_factor</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">_is_sharded</span><span class="p">:</span>  <span class="c1"># type: ignore[attr-defined]</span>
                <span class="n">grad_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
                <span class="n">chunks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">grad_flatten</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">world_size</span><span class="p">))</span>
                <span class="n">num_pad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">*</span> <span class="n">chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">-</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
                <span class="n">input_flattened</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">grad_flatten</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_pad</span><span class="p">])</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="n">dist</span><span class="o">.</span><span class="n">_reduce_scatter_base</span><span class="p">(</span>
                    <span class="n">output</span><span class="p">,</span> <span class="n">input_flattened</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">process_group</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_postdivide_factor</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># Average grad by world_size for consistency with PyTorch DDP.</span>
                    <span class="n">output</span><span class="o">.</span><span class="n">div_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gradient_postdivide_factor</span><span class="p">)</span>
                <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">output</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Currently the only way for _is_sharded to be False is if</span>
                <span class="c1"># world_size == 1. This could be relaxed in the future, e.g,</span>
                <span class="c1"># no sharding like PyTorch DDP, in which case grads should be</span>
                <span class="c1"># all-reduced here.</span>
                <span class="k">assert</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span> <span class="o">==</span> <span class="mi">1</span>
                <span class="p">),</span> <span class="s2">&quot;Currently the only way for _is_sharded to be False is </span><span class="se">\</span>
<span class="s2">                    world_size == 1&quot;</span>

            <span class="c1"># Regardless of sharding or not, offload the grad to CPU if we are</span>
            <span class="c1"># offloading params. This is so param and grad reside on same device</span>
            <span class="c1"># which is needed for the optimizer step.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_offload</span><span class="o">.</span><span class="n">offload_params</span><span class="p">:</span>
                <span class="c1"># We specify non_blocking=True</span>
                <span class="c1"># and ensure the appropriate synchronization is done by waiting</span>
                <span class="c1"># streams in _wait_for_post_backward.</span>
                <span class="n">param</span><span class="o">.</span><span class="n">_cpu_grad</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
                <span class="c1"># Don&#39;t let this memory get reused until after the transfer.</span>
                <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">())</span>
                <span class="c1"># Point param.grad.data to CPU grad to offload it. Note that</span>
                <span class="c1"># the transfer is async so it is not necessarily done until we</span>
                <span class="c1"># explicitly synchronize in backward.</span>
                <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">_cpu_grad</span>  <span class="c1"># type: ignore[attr-defined]</span>

            <span class="c1"># After _post_backward_hook returns, orig_grad_data will eventually</span>
            <span class="c1"># go out of scope, at which point it could otherwise be freed for</span>
            <span class="c1"># further reuse by the main stream while the div/reduce_scatter/copy</span>
            <span class="c1"># are underway in the post_backward stream. See:</span>
            <span class="c1"># github.com/NVIDIA/apex/blob/master/apex/parallel/distributed.py</span>
            <span class="n">orig_grad_data</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;post_backward&quot;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_queue_wait_for_post_backward</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Try to queue a `wait_for_post_backward` callback.</span>
<span class="sd">        Only called on root and only queue one callback at the beginning of</span>
<span class="sd">        outer most backward.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_is_root</span>
        <span class="p">),</span> <span class="s2">&quot;_queue_wait_for_post_backward can only be called on root.&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_post_backward_callback_queued</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_assert_state</span><span class="p">([</span><span class="n">TrainingState_</span><span class="o">.</span><span class="n">IDLE</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_post_backward_callback_queued</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">Variable</span><span class="o">.</span><span class="n">_execution_engine</span><span class="o">.</span><span class="n">queue_callback</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_wait_for_post_backward</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_wait_for_post_backward</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Wait for post-backward to finish. Only called on root instance.&quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_root</span><span class="p">,</span> <span class="s2">&quot;_wait_for_post_backward can only be called on root.&quot;</span>
        <span class="c1"># Check if the root module has params and if any of them has</span>
        <span class="c1"># the `requires_grad` field set. If `requires_grad=False` for</span>
        <span class="c1"># all the params, the post_backward hook will not fire and the</span>
        <span class="c1"># state will remain in `TrainingState_.BACKWARD_PRE`.</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">]):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_assert_state</span><span class="p">(</span><span class="n">TrainingState_</span><span class="o">.</span><span class="n">BACKWARD_POST</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_assert_state</span><span class="p">(</span><span class="n">TrainingState_</span><span class="o">.</span><span class="n">BACKWARD_PRE</span><span class="p">)</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span><span class="o">.</span><span class="n">wait_stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;post_backward&quot;</span><span class="p">])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_offload</span><span class="o">.</span><span class="n">offload_params</span><span class="p">:</span>
            <span class="c1"># We need to wait for the non-blocking GPU -&gt;</span>
            <span class="c1"># CPU grad transfers to finish. We need to do this for GPU -&gt; CPU</span>
            <span class="c1"># copies because when grad is on CPU, it won&#39;t wait for any CUDA</span>
            <span class="c1"># stream to finish GPU -&gt; CPU copies unless we explicitly block the</span>
            <span class="c1"># host-side with synchronize().</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>

        <span class="c1"># A backward pass is done, clean up below.</span>

        <span class="k">def</span> <span class="nf">_remove_shard_bwd_hook</span><span class="p">(</span><span class="n">fsdp_module</span><span class="p">:</span> <span class="n">FullyShardedDataParallel</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;Helper used below on all fsdp modules.&quot;&quot;&quot;</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">fsdp_module</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s2">&quot;_shard_bwd_hook&quot;</span><span class="p">):</span>
                        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">_shard_bwd_hook</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span>  <span class="c1"># type: ignore[attr-defined]</span>
                            <span class="n">p</span><span class="o">.</span><span class="n">_shard_bwd_hook</span>  <span class="c1"># type: ignore[attr-defined]</span>
                        <span class="p">),</span> <span class="p">(</span>  <span class="c1"># type: ignore[attr-defined]</span>
                            <span class="s2">&quot;p._shard_bwd_hook fields are not valid.&quot;</span>
                        <span class="p">)</span>
                        <span class="n">p</span><span class="o">.</span><span class="n">_shard_bwd_hook</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">remove</span><span class="p">()</span>  <span class="c1"># type: ignore[attr-defined]</span>
                        <span class="nb">delattr</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="s2">&quot;_shard_bwd_hook&quot;</span><span class="p">)</span>

        <span class="c1"># Update root and nested FSDP&#39;s hooks and flags.</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>  <span class="c1"># includes self</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">FullyShardedDataParallel</span><span class="p">):</span>
                <span class="n">_remove_shard_bwd_hook</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
                <span class="n">m</span><span class="o">.</span><span class="n">_pre_backward_hook_has_run</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
                    <span class="c1"># Check if the module has params and if any of them has</span>
                    <span class="c1"># the `requires_grad` field set. If `requires_grad=False` for</span>
                    <span class="c1"># all the params, the post_backward hook will not fire and the</span>
                    <span class="c1"># state will remain in `TrainingState_.BACKWARD_PRE`.</span>
                    <span class="k">if</span> <span class="nb">any</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">params</span><span class="p">]):</span>
                        <span class="n">m</span><span class="o">.</span><span class="n">_assert_state</span><span class="p">(</span><span class="n">TrainingState_</span><span class="o">.</span><span class="n">BACKWARD_POST</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">m</span><span class="o">.</span><span class="n">_assert_state</span><span class="p">(</span><span class="n">TrainingState_</span><span class="o">.</span><span class="n">BACKWARD_PRE</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># When `m` and its children has no params or has params but</span>
                    <span class="c1"># none with `requires_grad==True`, there are two cases:</span>
                    <span class="c1"># 1. output tensors are `requires_grad==True`. In this case,</span>
                    <span class="c1"># pre-backward hook is still registered, so it is in BACKWARD_PRE state.</span>
                    <span class="c1"># 2. output tensors are `requires_grad==False`. In this case,</span>
                    <span class="c1"># pre-backward hook is not registered, so it is in IDLE state.</span>
                    <span class="n">m</span><span class="o">.</span><span class="n">_assert_state</span><span class="p">([</span><span class="n">TrainingState_</span><span class="o">.</span><span class="n">BACKWARD_PRE</span><span class="p">,</span> <span class="n">TrainingState_</span><span class="o">.</span><span class="n">IDLE</span><span class="p">])</span>
                <span class="n">m</span><span class="o">.</span><span class="n">training_state</span> <span class="o">=</span> <span class="n">TrainingState_</span><span class="o">.</span><span class="n">IDLE</span>

                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">_is_root</span><span class="p">:</span>
                    <span class="c1"># reset this flag for cases like &quot;one forward pass + multiple backward passes&quot;</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_post_backward_callback_queued</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_rebuild_full_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Gather all shards of params.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">update_p_data</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">            Helper function to update p.data pointer.</span>
<span class="sd">            Args:</span>
<span class="sd">                output_tensor (torch.Tensor): this tensor contains the data we just gathered.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">output_tensor</span>
            <span class="c1"># Trim any padding and reshape to match original size.</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span> <span class="n">p</span><span class="o">.</span><span class="n">_orig_size</span><span class="o">.</span><span class="n">numel</span><span class="p">()]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">_orig_size</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">stream</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_streams</span><span class="p">[</span><span class="s2">&quot;all_gather&quot;</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_offload</span><span class="o">.</span><span class="n">offload_params</span><span class="p">:</span>
                    <span class="c1"># Move params to GPU if needed. Note that we don&#39;t use</span>
                    <span class="c1"># self._full_param_padded.device here because the attr is</span>
                    <span class="c1"># not set always, i.e. when world_size=1 and</span>
                    <span class="c1"># p._is_sharded = False. However when it is set, the</span>
                    <span class="c1"># device is always self.compute_device.</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">compute_device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="c1"># e.g., when world_size == 1</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">_is_sharded</span><span class="p">:</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="k">continue</span>
                <span class="c1"># If full param has been rebuilt or has not been freed, no need to call all gather</span>
                <span class="k">elif</span> <span class="p">(</span>
                    <span class="n">p</span><span class="o">.</span><span class="n">_full_param_padded</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">_full_param_padded</span><span class="o">.</span><span class="n">size</span><span class="p">()</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>  <span class="c1"># type: ignore[attr-defined]</span>
                <span class="p">):</span>
                    <span class="n">update_p_data</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">_full_param_padded</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="k">continue</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># If full param has not been rebuilt or has been freed, call all gather</span>
                    <span class="n">p_data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">data</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="n">p_full_size</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">_full_param_padded</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="k">assert</span> <span class="p">(</span>
                        <span class="n">p_full_size</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">==</span> <span class="n">p_data</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">world_size</span>
                    <span class="p">),</span> <span class="s2">&quot;Param full size should be equal to its shard size multiply world_size.&quot;</span>
                    <span class="k">assert</span> <span class="p">(</span>
                        <span class="n">p</span><span class="o">.</span><span class="n">_full_param_padded</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="p">),</span> <span class="s2">&quot;Full param&#39;s storage should have been freed before if all gather is needed.&quot;</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="c1"># Allocate based on full size from all shards.</span>
                    <span class="n">_alloc_storage</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">_full_param_padded</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">p_full_size</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">_full_param_padded</span>  <span class="c1"># type: ignore[attr-defined]</span>

                    <span class="c1"># Fill output_tensor with (p.data for each shard in self.world_size)</span>
                    <span class="n">dist</span><span class="o">.</span><span class="n">_all_gather_base</span><span class="p">(</span>
                        <span class="n">output_tensor</span><span class="p">,</span> <span class="n">p_data</span><span class="p">,</span> <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">process_group</span>
                    <span class="p">)</span>

                    <span class="c1"># Set p.data = output_tensor (with padding trimmed)</span>
                    <span class="n">update_p_data</span><span class="p">(</span><span class="n">output_tensor</span><span class="p">)</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_prep_grads_for_backward</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Make sure p.grad has the correct size/device, otherwise set it to None.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">_orig_size</span>  <span class="c1"># type: ignore[attr-defined]</span>
                <span class="ow">or</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">device</span>
            <span class="p">):</span>
                <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_free_full_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Parameter</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Free up storage for full parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
        <span class="n">current_stream</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="c1"># e.g., world_size == 1</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">_is_sharded</span><span class="p">:</span>  <span class="c1"># type: ignore[attr-defined]</span>
                <span class="k">continue</span>
            <span class="c1"># Don&#39;t let PyTorch reuse this memory until all work in the current</span>
            <span class="c1"># stream is complete.</span>
            <span class="n">p</span><span class="o">.</span><span class="n">_full_param_padded</span><span class="o">.</span><span class="n">record_stream</span><span class="p">(</span><span class="n">current_stream</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>
            <span class="c1"># There may be external references to the Tensor Storage that we</span>
            <span class="c1"># can&#39;t modify, such as references that are created by</span>
            <span class="c1"># ctx.save_for_backward in the forward pass. Thus when we</span>
            <span class="c1"># unshard parameters, we should reuse the original Tensor</span>
            <span class="c1"># Storage object and unshard it in-place. For now, just resize</span>
            <span class="c1"># the Storage to 0 to save memory.</span>
            <span class="n">_free_storage</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">_full_param_padded</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>

    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span> <span class="nf">_use_param_local_shard</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Parameter</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Use local shard for a list of params. Also implicitly offloads</span>
<span class="sd">        parameters back to CPU if we are CPU offloading.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">params</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cpu_offload</span><span class="o">.</span><span class="n">offload_params</span><span class="p">:</span>
                <span class="c1"># Ensure local_shard resides in CPU if we are offloading params.</span>
                <span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">_local_shard</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span>  <span class="c1"># type: ignore[attr-defined]</span>
                    <span class="s2">&quot;cpu&quot;</span>
                <span class="p">),</span> <span class="p">(</span>
                    <span class="s2">&quot;Expected p._local_shard to be on CPU&quot;</span>
                <span class="p">)</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">_local_shard</span>  <span class="c1"># type: ignore[attr-defined]</span>

    <span class="k">def</span> <span class="nf">_assert_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TrainingState_</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">TrainingState_</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Assert we are in the given state.&quot;&quot;&quot;</span>
        <span class="c1"># Since assert can be turned off and this error checking</span>
        <span class="c1"># is really important, we use explicit error checking</span>
        <span class="c1"># and raise a ValueError if needed.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">TrainingState_</span><span class="p">):</span>
            <span class="n">state</span> <span class="o">=</span> <span class="p">[</span><span class="n">state</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_state</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;expected to be in states </span><span class="si">{</span><span class="n">state</span><span class="si">}</span><span class="s2"> but current state &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">training_state</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="c1"># In case we are failing in the context of autograd hook, asserting</span>
            <span class="c1"># may not generate useful msg. So, let&#39;s print it to be sure.</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Asserting FSDP instance is: </span><span class="si">{</span><span class="bp">self</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ERROR: </span><span class="si">{</span><span class="n">msg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">traceback</span><span class="o">.</span><span class="n">print_stack</span><span class="p">()</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_get_default_cuda_device</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Try to infer CUDA device from module parameters.&quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">compute_device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
        <span class="k">if</span> <span class="n">compute_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">compute_device</span>
    <span class="c1"># e.g., if module does not have parameters, it will throw StopIteration,</span>
    <span class="c1"># in this case, instead of raising exception, return cuda device.</span>
    <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="c1"># Fall back to current CUDA device</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_free_storage</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Free underlying storage of a Tensor.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Since we&#39;re modifying the Tensor&#39;s Storage directly, make sure the Tensor</span>
        <span class="c1"># is the sole occupant of the Storage.</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">data</span><span class="o">.</span><span class="n">storage_offset</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;The tensor is not the sole occupant of the storage.&quot;</span>
        <span class="n">data</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span><span class="o">.</span><span class="n">resize_</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># type: ignore[attr-defined]</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">_alloc_storage</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Allocate storage for a tensor.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">data</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="n">size</span><span class="o">.</span><span class="n">numel</span><span class="p">():</span>  <span class="c1"># no need to reallocate</span>
        <span class="k">return</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">data</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="p">),</span> <span class="s2">&quot;Then tensor storage should have been resized to be 0.&quot;</span>
    <span class="n">data</span><span class="o">.</span><span class="n">storage</span><span class="p">()</span><span class="o">.</span><span class="n">resize_</span><span class="p">(</span><span class="n">size</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>  <span class="c1"># type: ignore[attr-defined]</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/clipboard.min.js"></script>
         <script src="../../../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>