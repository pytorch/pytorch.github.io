


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.onnx &mdash; PyTorch 1.11.0 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/onnx.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />


  <!-- Google Analytics -->
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-117752657-2');
    </script>
  
  <!-- End Google Analytics -->
  


  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>1.11.0 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          


            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notes/amp_examples.html">Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../amp.html">torch.cuda.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../__config__.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">Module code</a> &gt;</li>
        
          <li><a href="../torch.html">torch</a> &gt;</li>
        
      <li>torch.onnx</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.onnx</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">torch._C</span> <span class="k">as</span> <span class="nn">_C</span>

<span class="n">TensorProtoDataType</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">_onnx</span><span class="o">.</span><span class="n">TensorProtoDataType</span>
<span class="n">OperatorExportTypes</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">_onnx</span><span class="o">.</span><span class="n">OperatorExportTypes</span>
<span class="n">TrainingMode</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">_onnx</span><span class="o">.</span><span class="n">TrainingMode</span>
<span class="n">PYTORCH_ONNX_CAFFE2_BUNDLE</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">_onnx</span><span class="o">.</span><span class="n">PYTORCH_ONNX_CAFFE2_BUNDLE</span>

<span class="n">ONNX_ARCHIVE_MODEL_PROTO_NAME</span> <span class="o">=</span> <span class="s2">&quot;__MODEL_PROTO&quot;</span>

<span class="n">producer_name</span> <span class="o">=</span> <span class="s2">&quot;pytorch&quot;</span>
<span class="n">producer_version</span> <span class="o">=</span> <span class="n">_C</span><span class="o">.</span><span class="n">_onnx</span><span class="o">.</span><span class="n">PRODUCER_VERSION</span>

<span class="k">class</span> <span class="nc">ExportTypes</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;&quot;Specifies how the ONNX model is stored.&quot;&quot;&quot;</span>

    <span class="n">PROTOBUF_FILE</span> <span class="o">=</span> <span class="s2">&quot;Saves model in the specified protobuf file.&quot;</span>
    <span class="n">ZIP_ARCHIVE</span> <span class="o">=</span> <span class="s2">&quot;Saves model in the specified ZIP file (uncompressed).&quot;</span>
    <span class="n">COMPRESSED_ZIP_ARCHIVE</span> <span class="o">=</span> <span class="s2">&quot;Saves model in the specified ZIP file (compressed).&quot;</span>
    <span class="n">DIRECTORY</span> <span class="o">=</span> <span class="s2">&quot;Saves model in the specified folder.&quot;</span>


<span class="k">class</span> <span class="nc">CheckerError</span><span class="p">(</span><span class="ne">Exception</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Raised when ONNX checker detects an invalid model.&quot;&quot;&quot;</span>

    <span class="k">pass</span>


<span class="k">def</span> <span class="nf">_export</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">_export</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<div class="viewcode-block" id="export"><a class="viewcode-back" href="../../onnx.html#torch.onnx.export">[docs]</a><span class="k">def</span> <span class="nf">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">export_params</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">TrainingMode</span><span class="o">.</span><span class="n">EVAL</span><span class="p">,</span>
           <span class="n">input_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">operator_export_type</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
           <span class="n">opset_version</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">do_constant_folding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dynamic_axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
           <span class="n">keep_initializers_as_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">custom_opsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
           <span class="n">export_modules_as_functions</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Exports a model into ONNX format. If ``model`` is not a</span>
<span class="sd">    :class:`torch.jit.ScriptModule` nor a :class:`torch.jit.ScriptFunction`, this runs</span>
<span class="sd">    ``model`` once in order to convert it to a TorchScript graph to be exported</span>
<span class="sd">    (the equivalent of :func:`torch.jit.trace`). Thus this has the same limited support</span>
<span class="sd">    for dynamic control flow as :func:`torch.jit.trace`.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (torch.nn.Module, torch.jit.ScriptModule or torch.jit.ScriptFunction):</span>
<span class="sd">            the model to be exported.</span>
<span class="sd">        args (tuple or torch.Tensor):</span>

<span class="sd">            args can be structured either as:</span>

<span class="sd">            1. ONLY A TUPLE OF ARGUMENTS::</span>

<span class="sd">                args = (x, y, z)</span>

<span class="sd">            The tuple should contain model inputs such that ``model(*args)`` is a valid</span>
<span class="sd">            invocation of the model. Any non-Tensor arguments will be hard-coded into the</span>
<span class="sd">            exported model; any Tensor arguments will become inputs of the exported model,</span>
<span class="sd">            in the order they occur in the tuple.</span>

<span class="sd">            2. A TENSOR::</span>

<span class="sd">                args = torch.Tensor([1])</span>

<span class="sd">            This is equivalent to a 1-ary tuple of that Tensor.</span>

<span class="sd">            3. A TUPLE OF ARGUMENTS ENDING WITH A DICTIONARY OF NAMED ARGUMENTS::</span>

<span class="sd">                args = (x,</span>
<span class="sd">                        {&#39;y&#39;: input_y,</span>
<span class="sd">                         &#39;z&#39;: input_z})</span>

<span class="sd">            All but the last element of the tuple will be passed as non-keyword arguments,</span>
<span class="sd">            and named arguments will be set from the last element. If a named argument is</span>
<span class="sd">            not present in the dictionary, it is assigned the default value, or None if a</span>
<span class="sd">            default value is not provided.</span>

<span class="sd">            .. note::</span>
<span class="sd">                If a dictionary is the last element of the args tuple, it will be</span>
<span class="sd">                interpreted as containing named arguments. In order to pass a dict as the</span>
<span class="sd">                last non-keyword arg, provide an empty dict as the last element of the args</span>
<span class="sd">                tuple. For example, instead of::</span>

<span class="sd">                    torch.onnx.export(</span>
<span class="sd">                        model,</span>
<span class="sd">                        (x,</span>
<span class="sd">                         # WRONG: will be interpreted as named arguments</span>
<span class="sd">                         {y: z}),</span>
<span class="sd">                        &quot;test.onnx.pb&quot;)</span>

<span class="sd">                Write::</span>

<span class="sd">                    torch.onnx.export(</span>
<span class="sd">                        model,</span>
<span class="sd">                        (x,</span>
<span class="sd">                         {y: z},</span>
<span class="sd">                         {}),</span>
<span class="sd">                        &quot;test.onnx.pb&quot;)</span>

<span class="sd">        f: a file-like object (such that ``f.fileno()`` returns a file descriptor)</span>
<span class="sd">            or a string containing a file name.  A binary protocol buffer will be written</span>
<span class="sd">            to this file.</span>
<span class="sd">        export_params (bool, default True): if True, all parameters will</span>
<span class="sd">            be exported. Set this to False if you want to export an untrained model.</span>
<span class="sd">            In this case, the exported model will first take all of its parameters</span>
<span class="sd">            as arguments, with the ordering as specified by ``model.state_dict().values()``</span>
<span class="sd">        verbose (bool, default False): if True, prints a description of the</span>
<span class="sd">            model being exported to stdout. In addition, the final ONNX graph will include the</span>
<span class="sd">            field ``doc_string``` from the exported model which mentions the source code locations</span>
<span class="sd">            for ``model``.</span>
<span class="sd">        training (enum, default TrainingMode.EVAL):</span>
<span class="sd">            * ``TrainingMode.EVAL``: export the model in inference mode.</span>
<span class="sd">            * ``TrainingMode.PRESERVE``: export the model in inference mode if model.training is</span>
<span class="sd">              False and in training mode if model.training is True.</span>
<span class="sd">            * ``TrainingMode.TRAINING``: export the model in training mode. Disables optimizations</span>
<span class="sd">              which might interfere with training.</span>
<span class="sd">        input_names (list of str, default empty list): names to assign to the</span>
<span class="sd">            input nodes of the graph, in order.</span>
<span class="sd">        output_names (list of str, default empty list): names to assign to the</span>
<span class="sd">            output nodes of the graph, in order.</span>
<span class="sd">        operator_export_type (enum, default None):</span>

<span class="sd">            None usually means ``OperatorExportTypes.ONNX``.</span>
<span class="sd">            However if PyTorch was built with ``-DPYTORCH_ONNX_CAFFE2_BUNDLE``, None means</span>
<span class="sd">            ``OperatorExportTypes.ONNX_ATEN_FALLBACK``.</span>

<span class="sd">            * ``OperatorExportTypes.ONNX``: Export all ops as regular ONNX ops</span>
<span class="sd">              (in the default opset domain).</span>
<span class="sd">            * ``OperatorExportTypes.ONNX_FALLTHROUGH``: Try to convert all ops</span>
<span class="sd">              to standard ONNX ops in the default opset domain. If unable to do so</span>
<span class="sd">              (e.g. because support has not been added to convert a particular torch op to ONNX),</span>
<span class="sd">              fall back to exporting the op into a custom opset domain without conversion. Applies</span>
<span class="sd">              to `custom ops &lt;https://pytorch.org/tutorials/advanced/torch_script_custom_ops.html&gt;`_</span>
<span class="sd">              as well as ATen ops. For the exported model to be usable, the runtime must support</span>
<span class="sd">              these non-standard ops.</span>
<span class="sd">            * ``OperatorExportTypes.ONNX_ATEN``: All ATen ops (in the TorchScript namespace &quot;aten&quot;)</span>
<span class="sd">              are exported as ATen ops (in opset domain &quot;org.pytorch.aten&quot;).</span>
<span class="sd">              `ATen &lt;https://pytorch.org/cppdocs/#aten&gt;`_ is PyTorch&#39;s built-in tensor library, so</span>
<span class="sd">              this instructs the runtime to use PyTorch&#39;s implementation of these ops.</span>

<span class="sd">              .. warning::</span>

<span class="sd">                Models exported this way are probably runnable only by Caffe2.</span>

<span class="sd">              This may be useful if the numeric differences in implementations of operators are</span>
<span class="sd">              causing large differences in behavior between PyTorch and Caffe2 (which is more</span>
<span class="sd">              common on untrained models).</span>

<span class="sd">            * ``OperatorExportTypes.ONNX_ATEN_FALLBACK``: Try to export each ATen op</span>
<span class="sd">              (in the TorchScript namespace &quot;aten&quot;) as a regular ONNX op. If we are unable to do so</span>
<span class="sd">              (e.g. because support has not been added to convert a particular torch op to ONNX),</span>
<span class="sd">              fall back to exporting an ATen op. See documentation on OperatorExportTypes.ONNX_ATEN for</span>
<span class="sd">              context.</span>
<span class="sd">              For example::</span>

<span class="sd">                graph(%0 : Float):</span>
<span class="sd">                  %3 : int = prim::Constant[value=0]()</span>
<span class="sd">                  # conversion unsupported</span>
<span class="sd">                  %4 : Float = aten::triu(%0, %3)</span>
<span class="sd">                  # conversion supported</span>
<span class="sd">                  %5 : Float = aten::mul(%4, %0)</span>
<span class="sd">                  return (%5)</span>

<span class="sd">              Assuming ``aten::triu`` is not supported in ONNX, this will be exported as::</span>

<span class="sd">                graph(%0 : Float):</span>
<span class="sd">                  %1 : Long() = onnx::Constant[value={0}]()</span>
<span class="sd">                  # not converted</span>
<span class="sd">                  %2 : Float = aten::ATen[operator=&quot;triu&quot;](%0, %1)</span>
<span class="sd">                  # converted</span>
<span class="sd">                  %3 : Float = onnx::Mul(%2, %0)</span>
<span class="sd">                  return (%3)</span>

<span class="sd">              If PyTorch was built with Caffe2 (i.e. with ``BUILD_CAFFE2=1``), then</span>
<span class="sd">              Caffe2-specific behavior will be enabled, including special support</span>
<span class="sd">              for ops are produced by the modules described in</span>
<span class="sd">              `Quantization &lt;https://pytorch.org/docs/stable/quantization.html&gt;`_.</span>

<span class="sd">              .. warning::</span>

<span class="sd">                Models exported this way are probably runnable only by Caffe2.</span>

<span class="sd">        opset_version (int, default 9): The version of the</span>
<span class="sd">            `default (ai.onnx) opset &lt;https://github.com/onnx/onnx/blob/master/docs/Operators.md&gt;`_</span>
<span class="sd">            to target. Must be &gt;= 7 and &lt;= 15.</span>
<span class="sd">        do_constant_folding (bool, default True): Apply the constant-folding optimization.</span>
<span class="sd">            Constant-folding will replace some of the ops that have all constant inputs</span>
<span class="sd">            with pre-computed constant nodes.</span>
<span class="sd">        dynamic_axes (dict&lt;string, dict&lt;int, string&gt;&gt; or dict&lt;string, list(int)&gt;, default empty dict):</span>

<span class="sd">            By default the exported model will have the shapes of all input and output tensors</span>
<span class="sd">            set to exactly match those given in ``args``. To specify axes of tensors as</span>
<span class="sd">            dynamic (i.e. known only at run-time), set ``dynamic_axes`` to a dict with schema:</span>

<span class="sd">            * KEY (str): an input or output name. Each name must also be provided in ``input_names`` or</span>
<span class="sd">              ``output_names``.</span>
<span class="sd">            * VALUE (dict or list): If a dict, keys are axis indices and values are axis names. If a</span>
<span class="sd">              list, each element is an axis index.</span>

<span class="sd">            For example::</span>

<span class="sd">                class SumModule(torch.nn.Module):</span>
<span class="sd">                    def forward(self, x):</span>
<span class="sd">                        return torch.sum(x, dim=1)</span>

<span class="sd">                torch.onnx.export(SumModule(), (torch.ones(2, 2),), &quot;onnx.pb&quot;,</span>
<span class="sd">                                  input_names=[&quot;x&quot;], output_names=[&quot;sum&quot;])</span>

<span class="sd">            Produces::</span>

<span class="sd">                input {</span>
<span class="sd">                  name: &quot;x&quot;</span>
<span class="sd">                  ...</span>
<span class="sd">                      shape {</span>
<span class="sd">                        dim {</span>
<span class="sd">                          dim_value: 2  # axis 0</span>
<span class="sd">                        }</span>
<span class="sd">                        dim {</span>
<span class="sd">                          dim_value: 2  # axis 1</span>
<span class="sd">                ...</span>
<span class="sd">                output {</span>
<span class="sd">                  name: &quot;sum&quot;</span>
<span class="sd">                  ...</span>
<span class="sd">                      shape {</span>
<span class="sd">                        dim {</span>
<span class="sd">                          dim_value: 2  # axis 0</span>
<span class="sd">                ...</span>

<span class="sd">            While::</span>

<span class="sd">                torch.onnx.export(SumModule(), (torch.ones(2, 2),), &quot;onnx.pb&quot;,</span>
<span class="sd">                                  input_names=[&quot;x&quot;], output_names=[&quot;sum&quot;],</span>
<span class="sd">                                  dynamic_axes={</span>
<span class="sd">                                      # dict value: manually named axes</span>
<span class="sd">                                      &quot;x&quot;: {0: &quot;my_custom_axis_name&quot;},</span>
<span class="sd">                                      # list value: automatic names</span>
<span class="sd">                                      &quot;sum&quot;: [0],</span>
<span class="sd">                                  })</span>

<span class="sd">            Produces::</span>

<span class="sd">                input {</span>
<span class="sd">                  name: &quot;x&quot;</span>
<span class="sd">                  ...</span>
<span class="sd">                      shape {</span>
<span class="sd">                        dim {</span>
<span class="sd">                          dim_param: &quot;my_custom_axis_name&quot;  # axis 0</span>
<span class="sd">                        }</span>
<span class="sd">                        dim {</span>
<span class="sd">                          dim_value: 2  # axis 1</span>
<span class="sd">                ...</span>
<span class="sd">                output {</span>
<span class="sd">                  name: &quot;sum&quot;</span>
<span class="sd">                  ...</span>
<span class="sd">                      shape {</span>
<span class="sd">                        dim {</span>
<span class="sd">                          dim_param: &quot;sum_dynamic_axes_1&quot;  # axis 0</span>
<span class="sd">                ...</span>

<span class="sd">        keep_initializers_as_inputs (bool, default None): If True, all the</span>
<span class="sd">            initializers (typically corresponding to parameters) in the</span>
<span class="sd">            exported graph will also be added as inputs to the graph. If False,</span>
<span class="sd">            then initializers are not added as inputs to the graph, and only</span>
<span class="sd">            the non-parameter inputs are added as inputs.</span>
<span class="sd">            This may allow for better optimizations (e.g. constant folding) by</span>
<span class="sd">            backends/runtimes.</span>

<span class="sd">            If ``opset_version &lt; 9``, initializers MUST be part of graph</span>
<span class="sd">            inputs and this argument will be ignored and the behavior will be</span>
<span class="sd">            equivalent to setting this argument to True.</span>

<span class="sd">            If None, then the behavior is chosen automatically as follows:</span>

<span class="sd">            * If ``operator_export_type=OperatorExportTypes.ONNX``, the behavior is equivalent</span>
<span class="sd">              to setting this argument to False.</span>
<span class="sd">            * Else, the behavior is equivalent to setting this argument to True.</span>

<span class="sd">        custom_opsets (dict&lt;str, int&gt;, default empty dict): A dict with schema:</span>

<span class="sd">            * KEY (str): opset domain name</span>
<span class="sd">            * VALUE (int): opset version</span>

<span class="sd">            If a custom opset is referenced by ``model`` but not mentioned in this dictionary,</span>
<span class="sd">            the opset version is set to 1. Only custom opset domain name and version should be</span>
<span class="sd">            indicated through this argument.</span>

<span class="sd">        export_modules_as_functions (bool or set of type of nn.Module, default False): Flag to enable</span>
<span class="sd">            exporting all ``nn.Module`` forward calls as local functions in ONNX. Or a set to indicate the</span>
<span class="sd">            particular types of modules to export as local functions in ONNX.</span>
<span class="sd">            This feature requires ``opset_version`` &gt;= 15, otherwise the export will fail. This is because</span>
<span class="sd">            ``opset_version`` &lt; 15 implies IR version &lt; 8, which means no local function support.</span>

<span class="sd">            * ``False``(default): export ``nn.Module`` forward calls as fine grained nodes.</span>
<span class="sd">            * ``True``: export all ``nn.Module`` forward calls as local function nodes.</span>
<span class="sd">            * Set of type of nn.Module: export ``nn.Module`` forward calls as local function nodes,</span>
<span class="sd">              only if the type of the ``nn.Module`` is found in the set.</span>

<span class="sd">    Raises:</span>
<span class="sd">      CheckerError: If the ONNX checker detects an invalid ONNX graph. Will still export the</span>
<span class="sd">        model to the file ``f`` even if this is raised.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">export_params</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span>
                        <span class="n">input_names</span><span class="p">,</span> <span class="n">output_names</span><span class="p">,</span> <span class="n">operator_export_type</span><span class="p">,</span> <span class="n">opset_version</span><span class="p">,</span>
                        <span class="n">do_constant_folding</span><span class="p">,</span> <span class="n">dynamic_axes</span><span class="p">,</span>
                        <span class="n">keep_initializers_as_inputs</span><span class="p">,</span> <span class="n">custom_opsets</span><span class="p">,</span>
                        <span class="n">export_modules_as_functions</span><span class="p">)</span></div>


<div class="viewcode-block" id="export_to_pretty_string"><a class="viewcode-back" href="../../onnx.html#torch.onnx.export_to_pretty_string">[docs]</a><span class="k">def</span> <span class="nf">export_to_pretty_string</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Similar to :func:`export`, but returns a text representation of the ONNX</span>
<span class="sd">    model. Only differences in args listed below. All other args are the same</span>
<span class="sd">    as :func:`export`.</span>

<span class="sd">    Args:</span>
<span class="sd">      add_node_names (bool, default True): Whether or not to set</span>
<span class="sd">          NodeProto.name. This makes no difference unless</span>
<span class="sd">          ``google_printer=True``.</span>
<span class="sd">      google_printer (bool, default False): If False, will return a custom,</span>
<span class="sd">          compact representation of the model. If True will return the</span>
<span class="sd">          protobuf&#39;s `Message::DebugString()`, which is more verbose.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A UTF-8 str containing a human-readable representation of the ONNX model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">export_to_pretty_string</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>

<span class="k">def</span> <span class="nf">_optimize_trace</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">operator_export_type</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">_optimize_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">operator_export_type</span><span class="p">)</span>


<div class="viewcode-block" id="select_model_mode_for_export"><a class="viewcode-back" href="../../onnx.html#torch.onnx.select_model_mode_for_export">[docs]</a><span class="k">def</span> <span class="nf">select_model_mode_for_export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A context manager to temporarily set the training mode of ``model``</span>
<span class="sd">    to ``mode``, resetting it when we exit the with-block.  A no-op if</span>
<span class="sd">    mode is None.</span>

<span class="sd">    Args:</span>
<span class="sd">      model: Same type and meaning as ``model`` arg to :func:`export`.</span>
<span class="sd">      mode: Same type and meaning as ``training`` arg to :func:`export`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">select_model_mode_for_export</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_run_symbolic_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">_run_symbolic_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_run_symbolic_method</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">_run_symbolic_method</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<div class="viewcode-block" id="is_in_onnx_export"><a class="viewcode-back" href="../../onnx.html#torch.onnx.is_in_onnx_export">[docs]</a><span class="k">def</span> <span class="nf">is_in_onnx_export</span><span class="p">():</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns True iff :func:`export` is running in the current thread</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="k">return</span> <span class="n">utils</span><span class="o">.</span><span class="n">is_in_onnx_export</span><span class="p">()</span></div>


<div class="viewcode-block" id="register_custom_op_symbolic"><a class="viewcode-back" href="../../onnx.html#torch.onnx.register_custom_op_symbolic">[docs]</a><span class="k">def</span> <span class="nf">register_custom_op_symbolic</span><span class="p">(</span><span class="n">symbolic_name</span><span class="p">,</span> <span class="n">symbolic_fn</span><span class="p">,</span> <span class="n">opset_version</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Registers ``symbolic_fn`` to handle ``symbolic_name``. See</span>
<span class="sd">    &quot;Custom Operators&quot; in the module documentation for an example usage.</span>

<span class="sd">    Args:</span>
<span class="sd">      symbolic_name (str): The name of the custom operator in &quot;&lt;domain&gt;::&lt;op&gt;&quot;</span>
<span class="sd">        format.</span>
<span class="sd">      symbolic_fn (Callable): A function that takes in the ONNX graph and</span>
<span class="sd">        the input arguments to the current operator, and returns new</span>
<span class="sd">        operator nodes to add to the graph.</span>
<span class="sd">      opset_version (int): The ONNX opset version in which to register.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="n">utils</span><span class="o">.</span><span class="n">register_custom_op_symbolic</span><span class="p">(</span><span class="n">symbolic_name</span><span class="p">,</span> <span class="n">symbolic_fn</span><span class="p">,</span> <span class="n">opset_version</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">unregister_custom_op_symbolic</span><span class="p">(</span><span class="n">symbolic_name</span><span class="p">,</span> <span class="n">opset_version</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Unregisters ``symbolic_name``. See</span>
<span class="sd">    &quot;Custom Operators&quot; in the module documentation for an example usage.</span>

<span class="sd">    Args:</span>
<span class="sd">      symbolic_name (str): The name of the custom operator in &quot;&lt;domain&gt;::&lt;op&gt;&quot;</span>
<span class="sd">        format.</span>
<span class="sd">      opset_version (int): The ONNX opset version in which to unregister.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="kn">from</span> <span class="nn">torch.onnx</span> <span class="kn">import</span> <span class="n">utils</span>
    <span class="n">utils</span><span class="o">.</span><span class="n">unregister_custom_op_symbolic</span><span class="p">(</span><span class="n">symbolic_name</span><span class="p">,</span> <span class="n">opset_version</span><span class="p">)</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/clipboard.min.js"></script>
         <script src="../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>