


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.utils.tensorboard.writer &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/utils/tensorboard/writer.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  <a href='http://pytorch.org/docs/versions.html'>1.1.0 &#x25BC</a>
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html#torch-nn-functional">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html#torch-nn-init">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../multiprocessing.html">torch.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensorboard.html">torch.utils.tensorboard (experimental)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../__config__.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed_deprecated.html">torch.distributed.deprecated</a></li>
</ul>
<p class="caption"><span class="caption-text">torchvision Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torchvision/index.html">torchvision</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
          <li><a href="../../../torch.html">torch</a> &gt;</li>
        
      <li>torch.utils.tensorboard.writer</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.utils.tensorboard.writer</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Provides an API for writing protocol buffers to event files to be</span>
<span class="sd">consumed by TensorBoard for visualization.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">six</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">from</span> <span class="nn">tensorboard.compat.proto.event_pb2</span> <span class="k">import</span> <span class="n">SessionLog</span>
<span class="kn">from</span> <span class="nn">tensorboard.compat.proto.event_pb2</span> <span class="k">import</span> <span class="n">Event</span>
<span class="kn">from</span> <span class="nn">tensorboard.compat.proto</span> <span class="k">import</span> <span class="n">event_pb2</span>
<span class="kn">from</span> <span class="nn">tensorboard.summary.writer.event_file_writer</span> <span class="k">import</span> <span class="n">EventFileWriter</span>

<span class="kn">from</span> <span class="nn">._convert_np</span> <span class="k">import</span> <span class="n">make_np</span>
<span class="kn">from</span> <span class="nn">._embedding</span> <span class="k">import</span> <span class="n">make_mat</span><span class="p">,</span> <span class="n">make_sprite</span><span class="p">,</span> <span class="n">make_tsv</span><span class="p">,</span> <span class="n">append_pbtxt</span>
<span class="kn">from</span> <span class="nn">._onnx_graph</span> <span class="k">import</span> <span class="n">load_onnx_graph</span>
<span class="kn">from</span> <span class="nn">._pytorch_graph</span> <span class="k">import</span> <span class="n">graph</span>
<span class="kn">from</span> <span class="nn">._utils</span> <span class="k">import</span> <span class="n">figure_to_image</span>
<span class="kn">from</span> <span class="nn">.summary</span> <span class="k">import</span> <span class="p">(</span>
    <span class="n">scalar</span><span class="p">,</span> <span class="n">histogram</span><span class="p">,</span> <span class="n">histogram_raw</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">audio</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span>
    <span class="n">pr_curve</span><span class="p">,</span> <span class="n">pr_curve_raw</span><span class="p">,</span> <span class="n">video</span><span class="p">,</span> <span class="n">custom_scalars</span><span class="p">,</span> <span class="n">image_boxes</span>
<span class="p">)</span>


<span class="k">class</span> <span class="nc">FileWriter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Writes protocol buffers to event files to be consumed by TensorBoard.</span>

<span class="sd">    The `FileWriter` class provides a mechanism to create an event file in a</span>
<span class="sd">    given directory and add summaries and events to it. The class updates the</span>
<span class="sd">    file contents asynchronously. This allows a training program to call methods</span>
<span class="sd">    to add data to the file directly from the training loop, without slowing down</span>
<span class="sd">    training.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">logdir</span><span class="p">,</span>
                 <span class="n">max_queue</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                 <span class="n">flush_secs</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span>
                 <span class="n">filename_suffix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates a `FileWriter` and an event file.</span>
<span class="sd">        On construction the writer creates a new event file in `logdir`.</span>
<span class="sd">        The other arguments to the constructor control the asynchronous writes to</span>
<span class="sd">        the event file.</span>

<span class="sd">        Args:</span>
<span class="sd">          logdir: A string. Directory where event file will be written.</span>
<span class="sd">          max_queue: Integer. Size of the queue for pending events and</span>
<span class="sd">            summaries before one of the &#39;add&#39; calls forces a flush to disk.</span>
<span class="sd">          flush_secs: Number. How often, in seconds, to flush the</span>
<span class="sd">            pending events and summaries to disk.</span>
<span class="sd">          filename_suffix: A string. Suffix added to all event filenames.</span>
<span class="sd">            More details on event filename construction in</span>
<span class="sd">            tensorboard.summary.writer.event_file_writer.EventFileWriter.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Sometimes PosixPath is passed in and we need to coerce it to</span>
        <span class="c1"># a string in all cases</span>
        <span class="c1"># TODO: See if we can remove this in the future if we are</span>
        <span class="c1"># actually the ones passing in a PosixPath</span>
        <span class="n">logdir</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">logdir</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">event_writer</span> <span class="o">=</span> <span class="n">EventFileWriter</span><span class="p">(</span>
            <span class="n">logdir</span><span class="p">,</span> <span class="n">max_queue</span><span class="p">,</span> <span class="n">flush_secs</span><span class="p">,</span> <span class="n">filename_suffix</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_logdir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the directory where event file will be written.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">event_writer</span><span class="o">.</span><span class="n">get_logdir</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">add_event</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds an event to the event file.</span>
<span class="sd">        Args:</span>
<span class="sd">          event: An `Event` protocol buffer.</span>
<span class="sd">          step: Number. Optional global step value for training process</span>
<span class="sd">            to record with the event.</span>
<span class="sd">          walltime: float. Optional walltime to override the default (current)</span>
<span class="sd">            walltime (from time.time()) seconds after epoch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">event</span><span class="o">.</span><span class="n">wall_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="k">if</span> <span class="n">walltime</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">walltime</span>
        <span class="k">if</span> <span class="n">step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Make sure step is converted from numpy or other formats</span>
            <span class="c1"># since protobuf might not convert depending on version</span>
            <span class="n">event</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">event_writer</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="n">event</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">summary</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds a `Summary` protocol buffer to the event file.</span>
<span class="sd">        This method wraps the provided summary in an `Event` protocol buffer</span>
<span class="sd">        and adds it to the event file.</span>

<span class="sd">        Args:</span>
<span class="sd">          summary: A `Summary` protocol buffer.</span>
<span class="sd">          global_step: Number. Optional global step value for training process</span>
<span class="sd">            to record with the summary.</span>
<span class="sd">          walltime: float. Optional walltime to override the default (current)</span>
<span class="sd">            walltime (from time.time()) seconds after epoch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">event</span> <span class="o">=</span> <span class="n">event_pb2</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">summary</span><span class="o">=</span><span class="n">summary</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph_profile</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds a `Graph` and step stats protocol buffer to the event file.</span>

<span class="sd">        Args:</span>
<span class="sd">          graph_profile: A `Graph` and step stats protocol buffer.</span>
<span class="sd">          walltime: float. Optional walltime to override the default (current)</span>
<span class="sd">            walltime (from time.time()) seconds after epoch</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">graph</span> <span class="o">=</span> <span class="n">graph_profile</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">stepstats</span> <span class="o">=</span> <span class="n">graph_profile</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">event</span> <span class="o">=</span> <span class="n">event_pb2</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">graph_def</span><span class="o">=</span><span class="n">graph</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span>

        <span class="n">trm</span> <span class="o">=</span> <span class="n">event_pb2</span><span class="o">.</span><span class="n">TaggedRunMetadata</span><span class="p">(</span>
            <span class="n">tag</span><span class="o">=</span><span class="s1">&#39;step1&#39;</span><span class="p">,</span> <span class="n">run_metadata</span><span class="o">=</span><span class="n">stepstats</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
        <span class="n">event</span> <span class="o">=</span> <span class="n">event_pb2</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">tagged_run_metadata</span><span class="o">=</span><span class="n">trm</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_onnx_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds a `Graph` protocol buffer to the event file.</span>

<span class="sd">        Args:</span>
<span class="sd">          graph: A `Graph` protocol buffer.</span>
<span class="sd">          walltime: float. Optional walltime to override the default (current)</span>
<span class="sd">            _get_file_writerfrom time.time())</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">event</span> <span class="o">=</span> <span class="n">event_pb2</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">graph_def</span><span class="o">=</span><span class="n">graph</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">flush</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Flushes the event file to disk.</span>
<span class="sd">        Call this method to make sure that all pending events have been written to</span>
<span class="sd">        disk.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">event_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Flushes the event file to disk and close the file.</span>
<span class="sd">        Call this method when you do not need the summary writer anymore.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">event_writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">reopen</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Reopens the EventFileWriter.</span>
<span class="sd">        Can be called after `close()` to add more events in the same directory.</span>
<span class="sd">        The events will go into a new events file.</span>
<span class="sd">        Does nothing if the EventFileWriter was not closed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">event_writer</span><span class="o">.</span><span class="n">reopen</span><span class="p">()</span>


<div class="viewcode-block" id="SummaryWriter"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter">[docs]</a><span class="k">class</span> <span class="nc">SummaryWriter</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Writes entries directly to event files in the log_dir to be</span>
<span class="sd">    consumed by TensorBoard.</span>

<span class="sd">    The `SummaryWriter` class provides a high-level API to create an event file</span>
<span class="sd">    in a given directory and add summaries and events to it. The class updates the</span>
<span class="sd">    file contents asynchronously. This allows a training program to call methods</span>
<span class="sd">    to add data to the file directly from the training loop, without slowing down</span>
<span class="sd">    training.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">comment</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates a `SummaryWriter` that will write out events and summaries</span>
<span class="sd">        to the event file.</span>

<span class="sd">        Args:</span>
<span class="sd">            log_dir (string): save location, default is: runs/**CURRENT_DATETIME_HOSTNAME**, which changes after each</span>
<span class="sd">              run. Use hierarchical folder structure to compare between runs easily. e.g. pass in</span>
<span class="sd">              &#39;runs/exp1&#39;, &#39;runs/exp2&#39;, etc. for each new experiment to compare across. Defaults</span>
<span class="sd">              to ``./runs/``.</span>
<span class="sd">            comment (string): comment that appends to the default ``log_dir``. If ``log_dir`` is assigned,</span>
<span class="sd">              this argument will no effect.</span>
<span class="sd">            purge_step (int):</span>
<span class="sd">              When logging crashes at step :math:`T+X` and restarts at step :math:`T`, any events</span>
<span class="sd">              whose global_step larger or equal to :math:`T` will be purged and hidden from TensorBoard.</span>
<span class="sd">              Note that the resumed experiment and crashed experiment should have the same ``log_dir``.</span>
<span class="sd">            filename_suffix (string):</span>
<span class="sd">              Every event file&#39;s name is suffixed with suffix. Example: ``SummaryWriter(filename_suffix=&#39;.123&#39;)``</span>
<span class="sd">              More details on event filename construction in</span>
<span class="sd">              tensorboard.summary.writer.event_file_writer.EventFileWriter.</span>
<span class="sd">            kwargs: extra keyword arguments for FileWriter (e.g. &#39;flush_secs&#39;</span>
<span class="sd">              controls how often to flush pending events). For more arguments</span>
<span class="sd">              please refer to docs for &#39;tf.summary.FileWriter&#39;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">log_dir</span><span class="p">:</span>
            <span class="kn">import</span> <span class="nn">socket</span>
            <span class="kn">from</span> <span class="nn">datetime</span> <span class="k">import</span> <span class="n">datetime</span>
            <span class="n">current_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%b</span><span class="si">%d</span><span class="s1">_%H-%M-%S&#39;</span><span class="p">)</span>
            <span class="n">log_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
                <span class="s1">&#39;runs&#39;</span><span class="p">,</span> <span class="n">current_time</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="n">socket</span><span class="o">.</span><span class="n">gethostname</span><span class="p">()</span> <span class="o">+</span> <span class="n">comment</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">log_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>

        <span class="c1"># Initialize the file writers, but they can be cleared out on close</span>
        <span class="c1"># and recreated later as needed.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">file_writer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_writers</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span>

        <span class="c1"># Create default bins for histograms, see generate_testdata.py in tensorflow/tensorboard</span>
        <span class="n">v</span> <span class="o">=</span> <span class="mf">1E-12</span>
        <span class="n">buckets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">neg_buckets</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">while</span> <span class="n">v</span> <span class="o">&lt;</span> <span class="mf">1E20</span><span class="p">:</span>
            <span class="n">buckets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
            <span class="n">neg_buckets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">v</span><span class="p">)</span>
            <span class="n">v</span> <span class="o">*=</span> <span class="mf">1.1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_bins</span> <span class="o">=</span> <span class="n">neg_buckets</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">buckets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalar_dict</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">_append_to_scalar_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">scalar_value</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span>
                               <span class="n">timestamp</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This adds an entry to the self.scalar_dict datastructure with format</span>
<span class="sd">        {writer_id : [[timestamp, step, value], ...], ...}.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">tag</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">scalar_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scalar_dict</span><span class="p">[</span><span class="n">tag</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalar_dict</span><span class="p">[</span><span class="n">tag</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">[</span><span class="n">timestamp</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">make_np</span><span class="p">(</span><span class="n">scalar_value</span><span class="p">))])</span>

    <span class="k">def</span> <span class="nf">_check_caffe2_blob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Caffe2 users have the option of passing a string representing the name of</span>
<span class="sd">        a blob in the workspace instead of passing the actual Tensor/array containing</span>
<span class="sd">        the numeric values. Thus, we need to check if we received a string as input</span>
<span class="sd">        instead of an actual Tensor/array, and if so, we need to fetch the Blob</span>
<span class="sd">        from the workspace corresponding to that name. Fetching can be done with the</span>
<span class="sd">        following:</span>

<span class="sd">        from caffe2.python import workspace (if not already imported)</span>
<span class="sd">        workspace.FetchBlob(blob_name)</span>
<span class="sd">        workspace.FetchBlobs([blob_name1, blob_name2, ...])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_file_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the default FileWriter instance. Recreates it if closed.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_writers</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">file_writer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="s1">&#39;purge_step&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">most_recent_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;purge_step&#39;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">file_writer</span> <span class="o">=</span> <span class="n">FileWriter</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">file_writer</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span>
                    <span class="n">Event</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="n">most_recent_step</span><span class="p">,</span> <span class="n">file_version</span><span class="o">=</span><span class="s1">&#39;brain.Event:2&#39;</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">file_writer</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span>
                    <span class="n">Event</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="n">most_recent_step</span><span class="p">,</span> <span class="n">session_log</span><span class="o">=</span><span class="n">SessionLog</span><span class="p">(</span><span class="n">status</span><span class="o">=</span><span class="n">SessionLog</span><span class="o">.</span><span class="n">START</span><span class="p">)))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">file_writer</span> <span class="o">=</span> <span class="n">FileWriter</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">all_writers</span> <span class="o">=</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">file_writer</span><span class="o">.</span><span class="n">get_logdir</span><span class="p">():</span> <span class="bp">self</span><span class="o">.</span><span class="n">file_writer</span><span class="p">}</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">file_writer</span>

<div class="viewcode-block" id="SummaryWriter.add_scalar"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar">[docs]</a>    <span class="k">def</span> <span class="nf">add_scalar</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">scalar_value</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add scalar data to summary.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            scalar_value (float or string/blobname): Value to save</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              with seconds after epoch of event</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_caffe2_blob</span><span class="p">(</span><span class="n">scalar_value</span><span class="p">):</span>
            <span class="n">scalar_value</span> <span class="o">=</span> <span class="n">workspace</span><span class="o">.</span><span class="n">FetchBlob</span><span class="p">(</span><span class="n">scalar_value</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span>
            <span class="n">scalar</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">scalar_value</span><span class="p">),</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">add_scalars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">main_tag</span><span class="p">,</span> <span class="n">tag_scalar_dict</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds many scalar data to summary.</span>

<span class="sd">        Note that this function also keeps logged scalars in memory. In extreme case it explodes your RAM.</span>

<span class="sd">        Args:</span>
<span class="sd">            main_tag (string): The parent name for the tags</span>
<span class="sd">            tag_scalar_dict (dict): Key-value pair storing the tag and corresponding values</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>

<span class="sd">        Examples::</span>

<span class="sd">            writer.add_scalars(&#39;run_14h&#39;, {&#39;xsinx&#39;:i*np.sin(i/r),</span>
<span class="sd">                                           &#39;xcosx&#39;:i*np.cos(i/r),</span>
<span class="sd">                                           &#39;arctanx&#39;: numsteps*np.arctan(i/r)}, i)</span>
<span class="sd">            # This call adds three values to the same scalar plot with the tag</span>
<span class="sd">            # &#39;run_14h&#39; in TensorBoard&#39;s scalar section.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">walltime</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="k">if</span> <span class="n">walltime</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">walltime</span>
        <span class="n">fw_logdir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">get_logdir</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">tag</span><span class="p">,</span> <span class="n">scalar_value</span> <span class="ow">in</span> <span class="n">tag_scalar_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">fw_tag</span> <span class="o">=</span> <span class="n">fw_logdir</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">main_tag</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">tag</span>
            <span class="k">if</span> <span class="n">fw_tag</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_writers</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">fw</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_writers</span><span class="p">[</span><span class="n">fw_tag</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">fw</span> <span class="o">=</span> <span class="n">FileWriter</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="n">fw_tag</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">all_writers</span><span class="p">[</span><span class="n">fw_tag</span><span class="p">]</span> <span class="o">=</span> <span class="n">fw</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_caffe2_blob</span><span class="p">(</span><span class="n">scalar_value</span><span class="p">):</span>
                <span class="n">scalar_value</span> <span class="o">=</span> <span class="n">workspace</span><span class="o">.</span><span class="n">FetchBlob</span><span class="p">(</span><span class="n">scalar_value</span><span class="p">)</span>
            <span class="n">fw</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">scalar</span><span class="p">(</span><span class="n">main_tag</span><span class="p">,</span> <span class="n">scalar_value</span><span class="p">),</span>
                           <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_append_to_scalar_dict</span><span class="p">(</span>
                <span class="n">fw_tag</span><span class="p">,</span> <span class="n">scalar_value</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">export_scalars_to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Exports to the given path an ASCII file containing all the scalars written</span>
<span class="sd">        so far by this instance, with the following format:</span>
<span class="sd">        {writer_id : [[timestamp, step, value], ...], ...}</span>

<span class="sd">        The scalars saved by ``add_scalars()`` will be flushed after export.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scalar_dict</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scalar_dict</span> <span class="o">=</span> <span class="p">{}</span>

<div class="viewcode-block" id="SummaryWriter.add_histogram"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_histogram">[docs]</a>    <span class="k">def</span> <span class="nf">add_histogram</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="s1">&#39;tensorflow&#39;</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_bins</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add histogram to summary.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            values (torch.Tensor, numpy.array, or string/blobname): Values to build histogram</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            bins (string): one of {&#39;tensorflow&#39;,&#39;auto&#39;, &#39;fd&#39;, ...}, this determines how the bins are made. You can find</span>
<span class="sd">              other options in: https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_caffe2_blob</span><span class="p">(</span><span class="n">values</span><span class="p">):</span>
            <span class="n">values</span> <span class="o">=</span> <span class="n">workspace</span><span class="o">.</span><span class="n">FetchBlob</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">six</span><span class="o">.</span><span class="n">string_types</span><span class="p">)</span> <span class="ow">and</span> <span class="n">bins</span> <span class="o">==</span> <span class="s1">&#39;tensorflow&#39;</span><span class="p">:</span>
            <span class="n">bins</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">default_bins</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span>
            <span class="n">histogram</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">max_bins</span><span class="o">=</span><span class="n">max_bins</span><span class="p">),</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">add_histogram_raw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="nb">sum</span><span class="p">,</span> <span class="n">sum_squares</span><span class="p">,</span>
                          <span class="n">bucket_limits</span><span class="p">,</span> <span class="n">bucket_counts</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                          <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds histogram with raw data.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            min (float or int): Min value</span>
<span class="sd">            max (float or int): Max value</span>
<span class="sd">            num (int): Number of values</span>
<span class="sd">            sum (float or int): Sum of all values</span>
<span class="sd">            sum_squares (float or int): Sum of squares for all values</span>
<span class="sd">            bucket_limits (torch.Tensor, numpy.array): Upper value per bucket</span>
<span class="sd">            bucket_counts (torch.Tensor, numpy.array): Number of values per bucket</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>
<span class="sd">            see: https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/histogram/README.md</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span>
            <span class="n">histogram_raw</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span>
                          <span class="nb">min</span><span class="p">,</span>
                          <span class="nb">max</span><span class="p">,</span>
                          <span class="n">num</span><span class="p">,</span>
                          <span class="nb">sum</span><span class="p">,</span>
                          <span class="n">sum_squares</span><span class="p">,</span>
                          <span class="n">bucket_limits</span><span class="p">,</span>
                          <span class="n">bucket_counts</span><span class="p">),</span>
            <span class="n">global_step</span><span class="p">,</span>
            <span class="n">walltime</span><span class="p">)</span>

<div class="viewcode-block" id="SummaryWriter.add_image"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_image">[docs]</a>    <span class="k">def</span> <span class="nf">add_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">img_tensor</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dataformats</span><span class="o">=</span><span class="s1">&#39;CHW&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add image data to summary.</span>

<span class="sd">        Note that this requires the ``pillow`` package.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            img_tensor (torch.Tensor, numpy.array, or string/blobname): Image data</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>
<span class="sd">        Shape:</span>
<span class="sd">            img_tensor: Default is :math:`(3, H, W)`. You can use ``torchvision.utils.make_grid()`` to</span>
<span class="sd">            convert a batch of tensor into 3xHxW format or call ``add_images`` and let us do the job.</span>
<span class="sd">            Tensor with :math:`(1, H, W)`, :math:`(H, W)`, :math:`(H, W, 3)` is also suitible as long as</span>
<span class="sd">            corresponding ``dataformats`` argument is passed. e.g. CHW, HWC, HW.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_caffe2_blob</span><span class="p">(</span><span class="n">img_tensor</span><span class="p">):</span>
            <span class="n">img_tensor</span> <span class="o">=</span> <span class="n">workspace</span><span class="o">.</span><span class="n">FetchBlob</span><span class="p">(</span><span class="n">img_tensor</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span>
            <span class="n">image</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">img_tensor</span><span class="p">,</span> <span class="n">dataformats</span><span class="o">=</span><span class="n">dataformats</span><span class="p">),</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">add_images</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">img_tensor</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dataformats</span><span class="o">=</span><span class="s1">&#39;NCHW&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add batched image data to summary.</span>

<span class="sd">        Note that this requires the ``pillow`` package.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            img_tensor (torch.Tensor, numpy.array, or string/blobname): Image data</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>
<span class="sd">        Shape:</span>
<span class="sd">            img_tensor: Default is :math:`(N, 3, H, W)`. If ``dataformats`` is specified, other shape will be</span>
<span class="sd">            accepted. e.g. NCHW or NHWC.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_caffe2_blob</span><span class="p">(</span><span class="n">img_tensor</span><span class="p">):</span>
            <span class="n">img_tensor</span> <span class="o">=</span> <span class="n">workspace</span><span class="o">.</span><span class="n">FetchBlob</span><span class="p">(</span><span class="n">img_tensor</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span>
            <span class="n">image</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">img_tensor</span><span class="p">,</span> <span class="n">dataformats</span><span class="o">=</span><span class="n">dataformats</span><span class="p">),</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_image_with_boxes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">img_tensor</span><span class="p">,</span> <span class="n">box_tensor</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                             <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dataformats</span><span class="o">=</span><span class="s1">&#39;CHW&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add image and draw bounding boxes on the image.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            img_tensor (torch.Tensor, numpy.array, or string/blobname): Image data</span>
<span class="sd">            box_tensor (torch.Tensor, numpy.array, or string/blobname): Box data (for detected objects)</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>
<span class="sd">        Shape:</span>
<span class="sd">            img_tensor: Default is :math:`(3, H, W)`. It can be specified with ``dataformat`` agrument.</span>
<span class="sd">            e.g. CHW or HWC</span>

<span class="sd">            box_tensor: (torch.Tensor, numpy.array, or string/blobname): NX4,  where N is the number of</span>
<span class="sd">            boxes and each 4 elememts in a row represents (xmin, ymin, xmax, ymax).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_caffe2_blob</span><span class="p">(</span><span class="n">img_tensor</span><span class="p">):</span>
            <span class="n">img_tensor</span> <span class="o">=</span> <span class="n">workspace</span><span class="o">.</span><span class="n">FetchBlob</span><span class="p">(</span><span class="n">img_tensor</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_caffe2_blob</span><span class="p">(</span><span class="n">box_tensor</span><span class="p">):</span>
            <span class="n">box_tensor</span> <span class="o">=</span> <span class="n">workspace</span><span class="o">.</span><span class="n">FetchBlob</span><span class="p">(</span><span class="n">box_tensor</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">image_boxes</span><span class="p">(</span>
            <span class="n">tag</span><span class="p">,</span> <span class="n">img_tensor</span><span class="p">,</span> <span class="n">box_tensor</span><span class="p">,</span> <span class="n">dataformats</span><span class="o">=</span><span class="n">dataformats</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span>

<div class="viewcode-block" id="SummaryWriter.add_figure"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_figure">[docs]</a>    <span class="k">def</span> <span class="nf">add_figure</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">figure</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">close</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Render matplotlib figure into an image and add it to summary.</span>

<span class="sd">        Note that this requires the ``matplotlib`` package.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            figure (matplotlib.pyplot.figure) or list of figures: figure or a list of figures</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            close (bool): Flag to automatically close the figure</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">figure</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">figure_to_image</span><span class="p">(</span><span class="n">figure</span><span class="p">,</span> <span class="n">close</span><span class="p">),</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">,</span> <span class="n">dataformats</span><span class="o">=</span><span class="s1">&#39;NCHW&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_image</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">figure_to_image</span><span class="p">(</span><span class="n">figure</span><span class="p">,</span> <span class="n">close</span><span class="p">),</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">,</span> <span class="n">dataformats</span><span class="o">=</span><span class="s1">&#39;CHW&#39;</span><span class="p">)</span></div>

<div class="viewcode-block" id="SummaryWriter.add_video"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_video">[docs]</a>    <span class="k">def</span> <span class="nf">add_video</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">vid_tensor</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add video data to summary.</span>

<span class="sd">        Note that this requires the ``moviepy`` package.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            vid_tensor (torch.Tensor): Video data</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            fps (float or int): Frames per second</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>
<span class="sd">        Shape:</span>
<span class="sd">            vid_tensor: :math:`(N, T, C, H, W)`. The values should lie in [0, 255] for type `uint8` or [0, 1] for type `float`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span>
            <span class="n">video</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">vid_tensor</span><span class="p">,</span> <span class="n">fps</span><span class="p">),</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span></div>

<div class="viewcode-block" id="SummaryWriter.add_audio"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_audio">[docs]</a>    <span class="k">def</span> <span class="nf">add_audio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">snd_tensor</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="mi">44100</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add audio data to summary.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            snd_tensor (torch.Tensor): Sound data</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            sample_rate (int): sample rate in Hz</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>
<span class="sd">        Shape:</span>
<span class="sd">            snd_tensor: :math:`(1, L)`. The values should lie between [-1, 1].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_caffe2_blob</span><span class="p">(</span><span class="n">snd_tensor</span><span class="p">):</span>
            <span class="n">snd_tensor</span> <span class="o">=</span> <span class="n">workspace</span><span class="o">.</span><span class="n">FetchBlob</span><span class="p">(</span><span class="n">snd_tensor</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span>
            <span class="n">audio</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">snd_tensor</span><span class="p">,</span> <span class="n">sample_rate</span><span class="o">=</span><span class="n">sample_rate</span><span class="p">),</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span></div>

<div class="viewcode-block" id="SummaryWriter.add_text"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_text">[docs]</a>    <span class="k">def</span> <span class="nf">add_text</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">text_string</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add text data to summary.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            text_string (string): String to save</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>
<span class="sd">        Examples::</span>

<span class="sd">            writer.add_text(&#39;lstm&#39;, &#39;This is an lstm&#39;, 0)</span>
<span class="sd">            writer.add_text(&#39;rnn&#39;, &#39;This is an rnn&#39;, 10)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span>
            <span class="n">text</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">text_string</span><span class="p">),</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">add_onnx_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prototxt</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_onnx_graph</span><span class="p">(</span><span class="n">load_onnx_graph</span><span class="p">(</span><span class="n">prototxt</span><span class="p">))</span>

<div class="viewcode-block" id="SummaryWriter.add_graph"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_graph">[docs]</a>    <span class="k">def</span> <span class="nf">add_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">input_to_model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="c1"># prohibit second call?</span>
        <span class="c1"># no, let tensorboard handle it and show its warning message.</span>
        <span class="sd">&quot;&quot;&quot;Add graph data to summary.</span>

<span class="sd">        Args:</span>
<span class="sd">            model (torch.nn.Module): model to draw.</span>
<span class="sd">            input_to_model (torch.Tensor or list of torch.Tensor): a variable or a tuple of</span>
<span class="sd">                variables to be fed.</span>
<span class="sd">            verbose (bool): Whether to print graph structure in console.</span>
<span class="sd">            omit_useless_nodes (bool): Default to ``true``, which eliminates unused nodes.</span>
<span class="sd">            operator_export_type (string): One of: ``&quot;ONNX&quot;``, ``&quot;RAW&quot;``. This determines</span>
<span class="sd">                the optimization level of the graph. If error happens during exporting</span>
<span class="sd">                the graph, use ``&quot;RAW&quot;`` may help.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;forward&#39;</span><span class="p">):</span>
            <span class="c1"># A valid PyTorch model should have a &#39;forward&#39; method</span>
            <span class="kn">import</span> <span class="nn">torch</span>
            <span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
            <span class="k">if</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s2">&quot;0.3.1&quot;</span><span class="p">):</span>
                <span class="k">pass</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s2">&quot;0.3.0&quot;</span><span class="p">):</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;You are using PyTorch==0.3.0, use add_onnx_graph()&#39;</span><span class="p">)</span>
                    <span class="k">return</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Variable</span><span class="p">,</span> <span class="s1">&#39;grad_fn&#39;</span><span class="p">):</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;add_graph() only supports PyTorch v0.2.&#39;</span><span class="p">)</span>
                    <span class="k">return</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_graph</span><span class="p">(</span><span class="n">graph</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">input_to_model</span><span class="p">,</span> <span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Caffe2 models do not have the &#39;forward&#39; method</span>
            <span class="kn">from</span> <span class="nn">caffe2.proto</span> <span class="k">import</span> <span class="n">caffe2_pb2</span>
            <span class="kn">from</span> <span class="nn">caffe2.python</span> <span class="k">import</span> <span class="n">core</span>
            <span class="kn">from</span> <span class="nn">._caffe2_graph</span> <span class="k">import</span> <span class="p">(</span>
                <span class="n">model_to_graph_def</span><span class="p">,</span> <span class="n">nets_to_graph_def</span><span class="p">,</span> <span class="n">protos_to_graph_def</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">core</span><span class="o">.</span><span class="n">Net</span><span class="p">):</span>
                    <span class="n">current_graph</span> <span class="o">=</span> <span class="n">nets_to_graph_def</span><span class="p">(</span>
                        <span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">caffe2_pb2</span><span class="o">.</span><span class="n">NetDef</span><span class="p">):</span>
                    <span class="n">current_graph</span> <span class="o">=</span> <span class="n">protos_to_graph_def</span><span class="p">(</span>
                        <span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Handles cnn.CNNModelHelper, model_helper.ModelHelper</span>
                <span class="n">current_graph</span> <span class="o">=</span> <span class="n">model_to_graph_def</span><span class="p">(</span>
                    <span class="n">model</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">event</span> <span class="o">=</span> <span class="n">event_pb2</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span>
                <span class="n">graph_def</span><span class="o">=</span><span class="n">current_graph</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="n">event</span><span class="p">)</span></div>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_encode</span><span class="p">(</span><span class="n">rawstr</span><span class="p">):</span>
        <span class="c1"># I&#39;d use urllib but, I&#39;m unsure about the differences from python3 to python2, etc.</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="n">rawstr</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="n">retval</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;%&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%%%02x</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;%&quot;</span><span class="p">)))</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="n">retval</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%%%02x</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)))</span>
        <span class="n">retval</span> <span class="o">=</span> <span class="n">retval</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;</span><span class="si">%%%02x</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">ord</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\\</span><span class="s2">&quot;</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">retval</span>

<div class="viewcode-block" id="SummaryWriter.add_embedding"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_embedding">[docs]</a>    <span class="k">def</span> <span class="nf">add_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">label_img</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tag</span><span class="o">=</span><span class="s1">&#39;default&#39;</span><span class="p">,</span> <span class="n">metadata_header</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add embedding projector data to summary.</span>

<span class="sd">        Args:</span>
<span class="sd">            mat (torch.Tensor or numpy.array): A matrix which each row is the feature vector of the data point</span>
<span class="sd">            metadata (list): A list of labels, each element will be convert to string</span>
<span class="sd">            label_img (torch.Tensor): Images correspond to each data point</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            tag (string): Name for the embedding</span>
<span class="sd">        Shape:</span>
<span class="sd">            mat: :math:`(N, D)`, where N is number of data and D is feature dimension</span>

<span class="sd">            label_img: :math:`(N, C, H, W)`</span>

<span class="sd">        Examples::</span>

<span class="sd">            import keyword</span>
<span class="sd">            import torch</span>
<span class="sd">            meta = []</span>
<span class="sd">            while len(meta)&lt;100:</span>
<span class="sd">                meta = meta+keyword.kwlist # get some strings</span>
<span class="sd">            meta = meta[:100]</span>

<span class="sd">            for i, v in enumerate(meta):</span>
<span class="sd">                meta[i] = v+str(i)</span>

<span class="sd">            label_img = torch.rand(100, 3, 10, 32)</span>
<span class="sd">            for i in range(100):</span>
<span class="sd">                label_img[i]*=i/100.0</span>

<span class="sd">            writer.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)</span>
<span class="sd">            writer.add_embedding(torch.randn(100, 5), label_img=label_img)</span>
<span class="sd">            writer.add_embedding(torch.randn(100, 5), metadata=meta)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mat</span> <span class="o">=</span> <span class="n">make_np</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">global_step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">global_step</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="c1"># clear pbtxt?</span>
        <span class="c1"># Maybe we should encode the tag so slashes don&#39;t trip us up?</span>
        <span class="c1"># I don&#39;t think this will mess us up, but better safe than sorry.</span>
        <span class="n">subdir</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="si">%s</span><span class="s2">/</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">global_step</span><span class="p">)</span><span class="o">.</span><span class="n">zfill</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_encode</span><span class="p">(</span><span class="n">tag</span><span class="p">))</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">get_logdir</span><span class="p">(),</span> <span class="n">subdir</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">OSError</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="s1">&#39;warning: Embedding dir exists, did you set global_step for add_embedding()?&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span>
                <span class="n">metadata</span><span class="p">),</span> <span class="s1">&#39;#labels should equal with #data points&#39;</span>
            <span class="n">make_tsv</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">save_path</span><span class="p">,</span> <span class="n">metadata_header</span><span class="o">=</span><span class="n">metadata_header</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">label_img</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">mat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">label_img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;#images should equal with #data points&#39;</span>
            <span class="n">make_sprite</span><span class="p">(</span><span class="n">label_img</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">mat</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;mat should be 2D, where mat.size(0) is the number of data points&#39;</span>
        <span class="n">make_mat</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
        <span class="c1"># new funcion to append to the config file a new embedding</span>
        <span class="n">append_pbtxt</span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span> <span class="n">label_img</span><span class="p">,</span>
                     <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">get_logdir</span><span class="p">(),</span> <span class="n">subdir</span><span class="p">,</span> <span class="n">global_step</span><span class="p">,</span> <span class="n">tag</span><span class="p">)</span></div>

<div class="viewcode-block" id="SummaryWriter.add_pr_curve"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve">[docs]</a>    <span class="k">def</span> <span class="nf">add_pr_curve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">num_thresholds</span><span class="o">=</span><span class="mi">127</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds precision recall curve.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            labels (torch.Tensor, numpy.array, or string/blobname): Ground truth data. Binary label for each element.</span>
<span class="sd">            predictions (torch.Tensor, numpy.array, or string/blobname):</span>
<span class="sd">            The probability that an element be classified as true. Value should in [0, 1]</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            num_thresholds (int): Number of thresholds used to draw the curve.</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">make_np</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="n">make_np</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span>
            <span class="n">pr_curve</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">num_thresholds</span><span class="p">,</span> <span class="n">weights</span><span class="p">),</span>
            <span class="n">global_step</span><span class="p">,</span> <span class="n">walltime</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">add_pr_curve_raw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">true_positive_counts</span><span class="p">,</span>
                         <span class="n">false_positive_counts</span><span class="p">,</span>
                         <span class="n">true_negative_counts</span><span class="p">,</span>
                         <span class="n">false_negative_counts</span><span class="p">,</span>
                         <span class="n">precision</span><span class="p">,</span>
                         <span class="n">recall</span><span class="p">,</span>
                         <span class="n">global_step</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">num_thresholds</span><span class="o">=</span><span class="mi">127</span><span class="p">,</span>
                         <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">walltime</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds precision recall curve with raw data.</span>

<span class="sd">        Args:</span>
<span class="sd">            tag (string): Data identifier</span>
<span class="sd">            true_positive_counts (torch.Tensor, numpy.array, or string/blobname): true positive counts</span>
<span class="sd">            false_positive_counts (torch.Tensor, numpy.array, or string/blobname): false positive counts</span>
<span class="sd">            true_negative_counts (torch.Tensor, numpy.array, or string/blobname): true negative counts</span>
<span class="sd">            false_negative_counts (torch.Tensor, numpy.array, or string/blobname): false negative counts</span>
<span class="sd">            precision (torch.Tensor, numpy.array, or string/blobname): precision</span>
<span class="sd">            recall (torch.Tensor, numpy.array, or string/blobname): recall</span>
<span class="sd">            global_step (int): Global step value to record</span>
<span class="sd">            num_thresholds (int): Number of thresholds used to draw the curve.</span>
<span class="sd">            walltime (float): Optional override default walltime (time.time())</span>
<span class="sd">              seconds after epoch of event</span>
<span class="sd">            see: https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/README.md</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span>
            <span class="n">pr_curve_raw</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span>
                         <span class="n">true_positive_counts</span><span class="p">,</span>
                         <span class="n">false_positive_counts</span><span class="p">,</span>
                         <span class="n">true_negative_counts</span><span class="p">,</span>
                         <span class="n">false_negative_counts</span><span class="p">,</span>
                         <span class="n">precision</span><span class="p">,</span>
                         <span class="n">recall</span><span class="p">,</span>
                         <span class="n">num_thresholds</span><span class="p">,</span>
                         <span class="n">weights</span><span class="p">),</span>
            <span class="n">global_step</span><span class="p">,</span>
            <span class="n">walltime</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_custom_scalars_multilinechart</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tags</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="s1">&#39;default&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;untitled&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Shorthand for creating multilinechart. Similar to ``add_custom_scalars()``, but the only necessary argument</span>
<span class="sd">        is *tags*.</span>

<span class="sd">        Args:</span>
<span class="sd">            tags (list): list of tags that have been used in ``add_scalar()``</span>

<span class="sd">        Examples::</span>

<span class="sd">            writer.add_custom_scalars_multilinechart([&#39;twse/0050&#39;, &#39;twse/2330&#39;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">layout</span> <span class="o">=</span> <span class="p">{</span><span class="n">category</span><span class="p">:</span> <span class="p">{</span><span class="n">title</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Multiline&#39;</span><span class="p">,</span> <span class="n">tags</span><span class="p">]}}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">custom_scalars</span><span class="p">(</span><span class="n">layout</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">add_custom_scalars_marginchart</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tags</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="s1">&#39;default&#39;</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;untitled&#39;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Shorthand for creating marginchart. Similar to ``add_custom_scalars()``, but the only necessary argument</span>
<span class="sd">        is *tags*, which should have exactly 3 elements.</span>

<span class="sd">        Args:</span>
<span class="sd">            tags (list): list of tags that have been used in ``add_scalar()``</span>

<span class="sd">        Examples::</span>

<span class="sd">            writer.add_custom_scalars_marginchart([&#39;twse/0050&#39;, &#39;twse/2330&#39;, &#39;twse/2006&#39;])</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tags</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
        <span class="n">layout</span> <span class="o">=</span> <span class="p">{</span><span class="n">category</span><span class="p">:</span> <span class="p">{</span><span class="n">title</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;Margin&#39;</span><span class="p">,</span> <span class="n">tags</span><span class="p">]}}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">custom_scalars</span><span class="p">(</span><span class="n">layout</span><span class="p">))</span>

<div class="viewcode-block" id="SummaryWriter.add_custom_scalars"><a class="viewcode-back" href="../../../../tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars">[docs]</a>    <span class="k">def</span> <span class="nf">add_custom_scalars</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layout</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Create special chart by collecting charts tags in &#39;scalars&#39;. Note that this function can only be called once</span>
<span class="sd">        for each SummaryWriter() object. Because it only provides metadata to tensorboard, the function can be called</span>
<span class="sd">        before or after the training loop.</span>

<span class="sd">        Args:</span>
<span class="sd">            layout (dict): {categoryName: *charts*}, where *charts* is also a dictionary</span>
<span class="sd">              {chartName: *ListOfProperties*}. The first element in *ListOfProperties* is the chart&#39;s type</span>
<span class="sd">              (one of **Multiline** or **Margin**) and the second element should be a list containing the tags</span>
<span class="sd">              you have used in add_scalar function, which will be collected into the new chart.</span>

<span class="sd">        Examples::</span>

<span class="sd">            layout = {&#39;Taiwan&#39;:{&#39;twse&#39;:[&#39;Multiline&#39;,[&#39;twse/0050&#39;, &#39;twse/2330&#39;]]},</span>
<span class="sd">                         &#39;USA&#39;:{ &#39;dow&#39;:[&#39;Margin&#39;,   [&#39;dow/aaa&#39;, &#39;dow/bbb&#39;, &#39;dow/ccc&#39;]],</span>
<span class="sd">                              &#39;nasdaq&#39;:[&#39;Margin&#39;,   [&#39;nasdaq/aaa&#39;, &#39;nasdaq/bbb&#39;, &#39;nasdaq/ccc&#39;]]}}</span>

<span class="sd">            writer.add_custom_scalars(layout)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_writer</span><span class="p">()</span><span class="o">.</span><span class="n">add_summary</span><span class="p">(</span><span class="n">custom_scalars</span><span class="p">(</span><span class="n">layout</span><span class="p">))</span></div>

    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_writers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span>  <span class="c1"># ignore double close</span>
        <span class="k">for</span> <span class="n">writer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_writers</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
            <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">file_writer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_writers</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script type="text/javascript" src="../../../../_static/jquery.js"></script>
         <script type="text/javascript" src="../../../../_static/underscore.js"></script>
         <script type="text/javascript" src="../../../../_static/doctools.js"></script>
         <script type="text/javascript" src="../../../../_static/language_data.js"></script>
         <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js"></script>
         <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js"></script>
         <script type="text/javascript" src="../../../../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://pytorch.org/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>