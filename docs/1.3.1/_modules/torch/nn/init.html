


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.nn.init &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/nn/init.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <div class="ecosystem-dropdown">
              <a id="dropdownMenuButton" data-toggle="ecosystem-dropdown">
                Ecosystem
              </a>
              <div class="ecosystem-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/hub"">
                  <span class=dropdown-title>Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class=dropdown-title>Tools & Libraries</span>
                  <p>Explore the ecosystem of tools and libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <div class="resources-dropdown">
              <a id="resourcesDropdownButton" data-toggle="resources-dropdown">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/resources"">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class=dropdown-title>About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  <a href='http://pytorch.org/docs/versions.html'>1.3.1 &#x25BC</a>
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/windows.html">Windows FAQ</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../__config__.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">torchvision Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../torchvision/index.html">torchvision</a></li>
</ul>
<p class="caption"><span class="caption-text">torchaudio Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
</ul>
<p class="caption"><span class="caption-text">torchtext Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
</ul>
<p class="caption"><span class="caption-text">Other Languages</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/cppdocs/">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../packages.html">Javadoc</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
          <li><a href="../../torch.html">torch</a> &gt;</li>
        
      <li>torch.nn.init</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.nn.init</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>

<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="c1"># These no_grad_* functions are necessary as wrappers around the parts of these</span>
<span class="c1"># functions that use `with torch.no_grad()`. The JIT doesn&#39;t support context</span>
<span class="c1"># managers, so these need to be implemented as builtins. Using these wrappers</span>
<span class="c1"># lets us keep those builtins small and re-usable.</span>
<span class="k">def</span> <span class="nf">_no_grad_uniform_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_no_grad_normal_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_no_grad_fill_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_no_grad_zero_</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>


<div class="viewcode-block" id="calculate_gain"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.calculate_gain">[docs]</a><span class="k">def</span> <span class="nf">calculate_gain</span><span class="p">(</span><span class="n">nonlinearity</span><span class="p">,</span> <span class="n">param</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Return the recommended gain value for the given nonlinearity function.</span>
<span class="sd">    The values are as follows:</span>

<span class="sd">    ================= ====================================================</span>
<span class="sd">    nonlinearity      gain</span>
<span class="sd">    ================= ====================================================</span>
<span class="sd">    Linear / Identity :math:`1`</span>
<span class="sd">    Conv{1,2,3}D      :math:`1`</span>
<span class="sd">    Sigmoid           :math:`1`</span>
<span class="sd">    Tanh              :math:`\frac{5}{3}`</span>
<span class="sd">    ReLU              :math:`\sqrt{2}`</span>
<span class="sd">    Leaky Relu        :math:`\sqrt{\frac{2}{1 + \text{negative\_slope}^2}}`</span>
<span class="sd">    ================= ====================================================</span>

<span class="sd">    Args:</span>
<span class="sd">        nonlinearity: the non-linear function (`nn.functional` name)</span>
<span class="sd">        param: optional parameter for the non-linear function</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; gain = nn.init.calculate_gain(&#39;leaky_relu&#39;, 0.2)  # leaky_relu with negative_slope=0.2</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">linear_fns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;conv1d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv2d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv3d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_transpose1d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_transpose2d&#39;</span><span class="p">,</span> <span class="s1">&#39;conv_transpose3d&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">nonlinearity</span> <span class="ow">in</span> <span class="n">linear_fns</span> <span class="ow">or</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;tanh&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">5.0</span> <span class="o">/</span> <span class="mi">3</span>
    <span class="k">elif</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;relu&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">nonlinearity</span> <span class="o">==</span> <span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">param</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">negative_slope</span> <span class="o">=</span> <span class="mf">0.01</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="nb">float</span><span class="p">):</span>
            <span class="c1"># True/False are instances of int, hence check above</span>
            <span class="n">negative_slope</span> <span class="o">=</span> <span class="n">param</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;negative_slope </span><span class="si">{}</span><span class="s2"> not a valid number&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">param</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">negative_slope</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported nonlinearity </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">nonlinearity</span><span class="p">))</span></div>


<div class="viewcode-block" id="uniform_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.uniform_">[docs]</a><span class="k">def</span> <span class="nf">uniform_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
    <span class="c1"># type: (Tensor, float, float) -&gt; Tensor</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the input Tensor with values drawn from the uniform</span>
<span class="sd">    distribution :math:`\mathcal{U}(a, b)`.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: an n-dimensional `torch.Tensor`</span>
<span class="sd">        a: the lower bound of the uniform distribution</span>
<span class="sd">        b: the upper bound of the uniform distribution</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.uniform_(w)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_no_grad_uniform_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span></div>


<div class="viewcode-block" id="normal_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.normal_">[docs]</a><span class="k">def</span> <span class="nf">normal_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
    <span class="c1"># type: (Tensor, float, float) -&gt; Tensor</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the input Tensor with values drawn from the normal</span>
<span class="sd">    distribution :math:`\mathcal{N}(\text{mean}, \text{std}^2)`.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: an n-dimensional `torch.Tensor`</span>
<span class="sd">        mean: the mean of the normal distribution</span>
<span class="sd">        std: the standard deviation of the normal distribution</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.normal_(w)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_no_grad_normal_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span></div>


<div class="viewcode-block" id="constant_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.constant_">[docs]</a><span class="k">def</span> <span class="nf">constant_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">val</span><span class="p">):</span>
    <span class="c1"># type: (Tensor, float) -&gt; Tensor</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the input Tensor with the value :math:`\text{val}`.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: an n-dimensional `torch.Tensor`</span>
<span class="sd">        val: the value to fill the tensor with</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.constant_(w, 0.3)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_no_grad_fill_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span></div>


<div class="viewcode-block" id="ones_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.ones_">[docs]</a><span class="k">def</span> <span class="nf">ones_</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="c1"># type: (Tensor) -&gt; Tensor</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the input Tensor with the scalar value `1`.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: an n-dimensional `torch.Tensor`</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.ones_(w)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_no_grad_fill_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span></div>


<div class="viewcode-block" id="zeros_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.zeros_">[docs]</a><span class="k">def</span> <span class="nf">zeros_</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="c1"># type: (Tensor) -&gt; Tensor</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the input Tensor with the scalar value `0`.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: an n-dimensional `torch.Tensor`</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.zeros_(w)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_no_grad_zero_</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span></div>


<div class="viewcode-block" id="eye_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.eye_">[docs]</a><span class="k">def</span> <span class="nf">eye_</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the 2-dimensional input `Tensor` with the identity</span>
<span class="sd">    matrix. Preserves the identity of the inputs in `Linear` layers, where as</span>
<span class="sd">    many inputs are preserved as possible.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: a 2-dimensional `torch.Tensor`</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.eye_(w)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only tensors with 2 dimensions are supported&quot;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="o">*</span><span class="n">tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">tensor</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensor</span></div>


<div class="viewcode-block" id="dirac_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.dirac_">[docs]</a><span class="k">def</span> <span class="nf">dirac_</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the {3, 4, 5}-dimensional input `Tensor` with the Dirac</span>
<span class="sd">    delta function. Preserves the identity of the inputs in `Convolutional`</span>
<span class="sd">    layers, where as many input channels are preserved as possible.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: a {3, 4, 5}-dimensional `torch.Tensor`</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 16, 5, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.dirac_(w)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dimensions</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">dimensions</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only tensors with 3, 4, or 5 dimensions are supported&quot;</span><span class="p">)</span>

    <span class="n">sizes</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
    <span class="n">min_dim</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">tensor</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">min_dim</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">dimensions</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># Temporal convolution</span>
                <span class="n">tensor</span><span class="p">[</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">elif</span> <span class="n">dimensions</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>  <span class="c1"># Spatial convolution</span>
                <span class="n">tensor</span><span class="p">[</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># Volumetric convolution</span>
                <span class="n">tensor</span><span class="p">[</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">tensor</span></div>


<span class="k">def</span> <span class="nf">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="n">dimensions</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">dimensions</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Fan in and fan out can not be computed for tensor with fewer than 2 dimensions&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dimensions</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Linear</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">fan_out</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">num_input_fmaps</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">num_output_fmaps</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">receptive_field_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">receptive_field_size</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">num_input_fmaps</span> <span class="o">*</span> <span class="n">receptive_field_size</span>
        <span class="n">fan_out</span> <span class="o">=</span> <span class="n">num_output_fmaps</span> <span class="o">*</span> <span class="n">receptive_field_size</span>

    <span class="k">return</span> <span class="n">fan_in</span><span class="p">,</span> <span class="n">fan_out</span>


<div class="viewcode-block" id="xavier_uniform_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.xavier_uniform_">[docs]</a><span class="k">def</span> <span class="nf">xavier_uniform_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
    <span class="c1"># type: (Tensor, float) -&gt; Tensor</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the input `Tensor` with values according to the method</span>
<span class="sd">    described in `Understanding the difficulty of training deep feedforward</span>
<span class="sd">    neural networks` - Glorot, X. &amp; Bengio, Y. (2010), using a uniform</span>
<span class="sd">    distribution. The resulting tensor will have values sampled from</span>
<span class="sd">    :math:`\mathcal{U}(-a, a)` where</span>

<span class="sd">    .. math::</span>
<span class="sd">        a = \text{gain} \times \sqrt{\frac{6}{\text{fan\_in} + \text{fan\_out}}}</span>

<span class="sd">    Also known as Glorot initialization.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: an n-dimensional `torch.Tensor`</span>
<span class="sd">        gain: an optional scaling factor</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain(&#39;relu&#39;))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fan_in</span><span class="p">,</span> <span class="n">fan_out</span> <span class="o">=</span> <span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">gain</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">fan_in</span> <span class="o">+</span> <span class="n">fan_out</span><span class="p">))</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span>  <span class="c1"># Calculate uniform bounds from standard deviation</span>

    <span class="k">return</span> <span class="n">_no_grad_uniform_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="o">-</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span></div>


<div class="viewcode-block" id="xavier_normal_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.xavier_normal_">[docs]</a><span class="k">def</span> <span class="nf">xavier_normal_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.</span><span class="p">):</span>
    <span class="c1"># type: (Tensor, float) -&gt; Tensor</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the input `Tensor` with values according to the method</span>
<span class="sd">    described in `Understanding the difficulty of training deep feedforward</span>
<span class="sd">    neural networks` - Glorot, X. &amp; Bengio, Y. (2010), using a normal</span>
<span class="sd">    distribution. The resulting tensor will have values sampled from</span>
<span class="sd">    :math:`\mathcal{N}(0, \text{std}^2)` where</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{std} = \text{gain} \times \sqrt{\frac{2}{\text{fan\_in} + \text{fan\_out}}}</span>

<span class="sd">    Also known as Glorot initialization.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: an n-dimensional `torch.Tensor`</span>
<span class="sd">        gain: an optional scaling factor</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.xavier_normal_(w)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fan_in</span><span class="p">,</span> <span class="n">fan_out</span> <span class="o">=</span> <span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">gain</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">fan_in</span> <span class="o">+</span> <span class="n">fan_out</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">_no_grad_normal_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_calculate_correct_fan</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">valid_modes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;fan_in&#39;</span><span class="p">,</span> <span class="s1">&#39;fan_out&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_modes</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Mode </span><span class="si">{}</span><span class="s2"> not supported, please use one of </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">valid_modes</span><span class="p">))</span>

    <span class="n">fan_in</span><span class="p">,</span> <span class="n">fan_out</span> <span class="o">=</span> <span class="n">_calculate_fan_in_and_fan_out</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fan_in</span> <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;fan_in&#39;</span> <span class="k">else</span> <span class="n">fan_out</span>


<div class="viewcode-block" id="kaiming_uniform_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.kaiming_uniform_">[docs]</a><span class="k">def</span> <span class="nf">kaiming_uniform_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_in&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;leaky_relu&#39;</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the input `Tensor` with values according to the method</span>
<span class="sd">    described in `Delving deep into rectifiers: Surpassing human-level</span>
<span class="sd">    performance on ImageNet classification` - He, K. et al. (2015), using a</span>
<span class="sd">    uniform distribution. The resulting tensor will have values sampled from</span>
<span class="sd">    :math:`\mathcal{U}(-\text{bound}, \text{bound})` where</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{bound} = \sqrt{\frac{6}{(1 + a^2) \times \text{fan\_in}}}</span>

<span class="sd">    Also known as He initialization.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: an n-dimensional `torch.Tensor`</span>
<span class="sd">        a: the negative slope of the rectifier used after this layer (0 for ReLU</span>
<span class="sd">            by default)</span>
<span class="sd">        mode: either ``&#39;fan_in&#39;`` (default) or ``&#39;fan_out&#39;``. Choosing ``&#39;fan_in&#39;``</span>
<span class="sd">            preserves the magnitude of the variance of the weights in the</span>
<span class="sd">            forward pass. Choosing ``&#39;fan_out&#39;`` preserves the magnitudes in the</span>
<span class="sd">            backwards pass.</span>
<span class="sd">        nonlinearity: the non-linear function (`nn.functional` name),</span>
<span class="sd">            recommended to use only with ``&#39;relu&#39;`` or ``&#39;leaky_relu&#39;`` (default).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.kaiming_uniform_(w, mode=&#39;fan_in&#39;, nonlinearity=&#39;relu&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fan</span> <span class="o">=</span> <span class="n">_calculate_correct_fan</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
    <span class="n">gain</span> <span class="o">=</span> <span class="n">calculate_gain</span><span class="p">(</span><span class="n">nonlinearity</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">gain</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan</span><span class="p">)</span>
    <span class="n">bound</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">3.0</span><span class="p">)</span> <span class="o">*</span> <span class="n">std</span>  <span class="c1"># Calculate uniform bounds from standard deviation</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">bound</span><span class="p">,</span> <span class="n">bound</span><span class="p">)</span></div>


<div class="viewcode-block" id="kaiming_normal_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.kaiming_normal_">[docs]</a><span class="k">def</span> <span class="nf">kaiming_normal_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_in&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;leaky_relu&#39;</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the input `Tensor` with values according to the method</span>
<span class="sd">    described in `Delving deep into rectifiers: Surpassing human-level</span>
<span class="sd">    performance on ImageNet classification` - He, K. et al. (2015), using a</span>
<span class="sd">    normal distribution. The resulting tensor will have values sampled from</span>
<span class="sd">    :math:`\mathcal{N}(0, \text{std}^2)` where</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{std} = \sqrt{\frac{2}{(1 + a^2) \times \text{fan\_in}}}</span>

<span class="sd">    Also known as He initialization.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: an n-dimensional `torch.Tensor`</span>
<span class="sd">        a: the negative slope of the rectifier used after this layer (0 for ReLU</span>
<span class="sd">            by default)</span>
<span class="sd">        mode: either ``&#39;fan_in&#39;`` (default) or ``&#39;fan_out&#39;``. Choosing ``&#39;fan_in&#39;``</span>
<span class="sd">            preserves the magnitude of the variance of the weights in the</span>
<span class="sd">            forward pass. Choosing ``&#39;fan_out&#39;`` preserves the magnitudes in the</span>
<span class="sd">            backwards pass.</span>
<span class="sd">        nonlinearity: the non-linear function (`nn.functional` name),</span>
<span class="sd">            recommended to use only with ``&#39;relu&#39;`` or ``&#39;leaky_relu&#39;`` (default).</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.kaiming_normal_(w, mode=&#39;fan_out&#39;, nonlinearity=&#39;relu&#39;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fan</span> <span class="o">=</span> <span class="n">_calculate_correct_fan</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
    <span class="n">gain</span> <span class="o">=</span> <span class="n">calculate_gain</span><span class="p">(</span><span class="n">nonlinearity</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">gain</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">fan</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">return</span> <span class="n">tensor</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span></div>


<div class="viewcode-block" id="orthogonal_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.orthogonal_">[docs]</a><span class="k">def</span> <span class="nf">orthogonal_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the input `Tensor` with a (semi) orthogonal matrix, as</span>
<span class="sd">    described in `Exact solutions to the nonlinear dynamics of learning in deep</span>
<span class="sd">    linear neural networks` - Saxe, A. et al. (2013). The input tensor must have</span>
<span class="sd">    at least 2 dimensions, and for tensors with more than 2 dimensions the</span>
<span class="sd">    trailing dimensions are flattened.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: an n-dimensional `torch.Tensor`, where :math:`n \geq 2`</span>
<span class="sd">        gain: optional scaling factor</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.orthogonal_(w)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only tensors with 2 or more dimensions are supported&quot;</span><span class="p">)</span>

    <span class="n">rows</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">//</span> <span class="n">rows</span>
    <span class="n">flattened</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">)</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">rows</span> <span class="o">&lt;</span> <span class="n">cols</span><span class="p">:</span>
        <span class="n">flattened</span><span class="o">.</span><span class="n">t_</span><span class="p">()</span>

    <span class="c1"># Compute the qr factorization</span>
    <span class="n">q</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">flattened</span><span class="p">)</span>
    <span class="c1"># Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">ph</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">sign</span><span class="p">()</span>
    <span class="n">q</span> <span class="o">*=</span> <span class="n">ph</span>

    <span class="k">if</span> <span class="n">rows</span> <span class="o">&lt;</span> <span class="n">cols</span><span class="p">:</span>
        <span class="n">q</span><span class="o">.</span><span class="n">t_</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">tensor</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">q</span><span class="p">)</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
        <span class="n">tensor</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">gain</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tensor</span></div>


<div class="viewcode-block" id="sparse_"><a class="viewcode-back" href="../../../nn.init.html#torch.nn.init.sparse_">[docs]</a><span class="k">def</span> <span class="nf">sparse_</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fills the 2D input `Tensor` as a sparse matrix, where the</span>
<span class="sd">    non-zero elements will be drawn from the normal distribution</span>
<span class="sd">    :math:`\mathcal{N}(0, 0.01)`, as described in `Deep learning via</span>
<span class="sd">    Hessian-free optimization` - Martens, J. (2010).</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: an n-dimensional `torch.Tensor`</span>
<span class="sd">        sparsity: The fraction of elements in each column to be set to zero</span>
<span class="sd">        std: the standard deviation of the normal distribution used to generate</span>
<span class="sd">            the non-zero values</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; w = torch.empty(3, 5)</span>
<span class="sd">        &gt;&gt;&gt; nn.init.sparse_(w, sparsity=0.1)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">tensor</span><span class="o">.</span><span class="n">ndimension</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Only tensors with 2 dimensions are supported&quot;</span><span class="p">)</span>

    <span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">num_zeros</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">sparsity</span> <span class="o">*</span> <span class="n">rows</span><span class="p">))</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">tensor</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">col_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">cols</span><span class="p">):</span>
            <span class="n">row_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">rows</span><span class="p">)</span>
            <span class="n">zero_indices</span> <span class="o">=</span> <span class="n">row_indices</span><span class="p">[:</span><span class="n">num_zeros</span><span class="p">]</span>
            <span class="n">tensor</span><span class="p">[</span><span class="n">zero_indices</span><span class="p">,</span> <span class="n">col_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">tensor</span></div>


<span class="c1"># for backward compatibility</span>
<span class="k">def</span> <span class="nf">_make_deprecate</span><span class="p">(</span><span class="n">meth</span><span class="p">):</span>
    <span class="n">new_name</span> <span class="o">=</span> <span class="n">meth</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="n">old_name</span> <span class="o">=</span> <span class="n">new_name</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">deprecated_init</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;nn.init.</span><span class="si">{}</span><span class="s2"> is now deprecated in favor of nn.init.</span><span class="si">{}</span><span class="s2">.&quot;</span>
                      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">old_name</span><span class="p">,</span> <span class="n">new_name</span><span class="p">),</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">meth</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">deprecated_init</span><span class="o">.</span><span class="vm">__doc__</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    </span><span class="si">{old_name}</span><span class="s2">(...)</span>

<span class="s2">    .. warning::</span>
<span class="s2">        This method is now deprecated in favor of :func:`torch.nn.init.</span><span class="si">{new_name}</span><span class="s2">`.</span>

<span class="s2">    See :func:`~torch.nn.init.</span><span class="si">{new_name}</span><span class="s2">` for details.&quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">old_name</span><span class="o">=</span><span class="n">old_name</span><span class="p">,</span> <span class="n">new_name</span><span class="o">=</span><span class="n">new_name</span><span class="p">)</span>
    <span class="n">deprecated_init</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">=</span> <span class="n">old_name</span>
    <span class="k">return</span> <span class="n">deprecated_init</span>


<span class="n">uniform</span> <span class="o">=</span> <span class="n">_make_deprecate</span><span class="p">(</span><span class="n">uniform_</span><span class="p">)</span>
<span class="n">normal</span> <span class="o">=</span> <span class="n">_make_deprecate</span><span class="p">(</span><span class="n">normal_</span><span class="p">)</span>
<span class="n">constant</span> <span class="o">=</span> <span class="n">_make_deprecate</span><span class="p">(</span><span class="n">constant_</span><span class="p">)</span>
<span class="n">eye</span> <span class="o">=</span> <span class="n">_make_deprecate</span><span class="p">(</span><span class="n">eye_</span><span class="p">)</span>
<span class="n">dirac</span> <span class="o">=</span> <span class="n">_make_deprecate</span><span class="p">(</span><span class="n">dirac_</span><span class="p">)</span>
<span class="n">xavier_uniform</span> <span class="o">=</span> <span class="n">_make_deprecate</span><span class="p">(</span><span class="n">xavier_uniform_</span><span class="p">)</span>
<span class="n">xavier_normal</span> <span class="o">=</span> <span class="n">_make_deprecate</span><span class="p">(</span><span class="n">xavier_normal_</span><span class="p">)</span>
<span class="n">kaiming_uniform</span> <span class="o">=</span> <span class="n">_make_deprecate</span><span class="p">(</span><span class="n">kaiming_uniform_</span><span class="p">)</span>
<span class="n">kaiming_normal</span> <span class="o">=</span> <span class="n">_make_deprecate</span><span class="p">(</span><span class="n">kaiming_normal_</span><span class="p">)</span>
<span class="n">orthogonal</span> <span class="o">=</span> <span class="n">_make_deprecate</span><span class="p">(</span><span class="n">orthogonal_</span><span class="p">)</span>
<span class="n">sparse</span> <span class="o">=</span> <span class="n">_make_deprecate</span><span class="p">(</span><span class="n">sparse_</span><span class="p">)</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script type="text/javascript" src="../../../_static/jquery.js"></script>
         <script type="text/javascript" src="../../../_static/underscore.js"></script>
         <script type="text/javascript" src="../../../_static/doctools.js"></script>
         <script type="text/javascript" src="../../../_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://pytorch.org/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>