


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.overrides &mdash; PyTorch main documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/overrides.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sphinx-dropdown.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/panels-bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

<!--
  Search engines should not index the main version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>main (2.1.0a0+git707d265 ) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          

<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/_modules/torch/overrides.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../community/build_ci_governance.html">PyTorch Governance | Build + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/design.html">PyTorch Design Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/governance.html">PyTorch Governance | Mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/persons_of_interest.html">PyTorch Governance | Maintainers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notes/amp_examples.html">CUDA Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/extending.func.html">Extending torch.func with autograd.Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">torch.compile</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../compile/index.html">torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/get-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/troubleshooting.html">PyTorch 2.0 Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/technical-overview.html">Technical Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/guards-overview.html">Guards Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/custom-backends.html">Custom Backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/fine_grained_apis.html">TorchDynamo APIs to control fine-grained tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/profiling_torch_compile.html">Profiling to understand torch.compile performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/inductor_profiling.html">TorchInductor GPU Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/deep-dive.html">TorchDynamo Deeper Dive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/cudagraph_trees.html">CUDAGraph Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/performance-dashboard.html">PyTorch 2.0 Performance Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/torchfunc-and-torchcompile.html">torch.func interaction with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ir.html">IRs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/dynamic-shapes.html">Dynamic shapes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/fake-tensor.html">Fake tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logging.html">torch._logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compile/transformations.html">Writing Graph Transformations on ATen IR</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../export.html">torch._export.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../onnx_diagnostics.html">torch.onnx diagnostics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logging.html">torch._logging</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">Module code</a> &gt;</li>
        
          <li><a href="../torch.html">torch</a> &gt;</li>
        
      <li>torch.overrides</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.overrides</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Python implementation of ``__torch_function__``</span>

<span class="sd">While most of the torch API and handling for ``__torch_function__`` happens</span>
<span class="sd">at the C++ level, some of the torch API is written in Python so we need</span>
<span class="sd">python-level handling for ``__torch_function__`` overrides as well. The main</span>
<span class="sd">developer-facing functionality in this file are handle_torch_function and</span>
<span class="sd">has_torch_function. See torch/functional.py and test/test_overrides.py</span>
<span class="sd">for usage examples.</span>

<span class="sd">Note</span>
<span class="sd">----</span>
<span class="sd">heavily inspired by NumPy&#39;s ``__array_function__`` (see:</span>
<span class="sd">https://github.com/pytorch/pytorch/issues/24015 and</span>
<span class="sd">https://www.numpy.org/neps/nep-0018-array-function-protocol.html</span>
<span class="sd">)</span>

<span class="sd">If changing this file in a way that can affect ``__torch_function__`` overhead,</span>
<span class="sd">please report the benchmarks in ``benchmarks/overrides_benchmark``. See the</span>
<span class="sd">instructions in the ``README.md`` in that directory.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">__future__</span>  <span class="c1"># noqa: F404</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">types</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">import</span> <span class="nn">contextlib</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch._C</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_has_torch_function</span><span class="p">,</span> <span class="n">_has_torch_function_unary</span><span class="p">,</span>
    <span class="n">_has_torch_function_variadic</span><span class="p">,</span> <span class="n">_add_docstr</span><span class="p">,</span>
    <span class="n">_push_on_torch_function_stack</span><span class="p">,</span> <span class="n">_pop_torch_function_stack</span><span class="p">,</span> <span class="n">_get_function_stack_at</span><span class="p">,</span> <span class="n">_len_torch_function_stack</span><span class="p">,</span>
    <span class="n">_is_torch_function_mode_enabled</span><span class="p">)</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;get_ignored_functions&quot;</span><span class="p">,</span>
    <span class="s2">&quot;get_overridable_functions&quot;</span><span class="p">,</span>
    <span class="s2">&quot;get_testing_overrides&quot;</span><span class="p">,</span>
    <span class="s2">&quot;handle_torch_function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;has_torch_function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;resolve_name&quot;</span><span class="p">,</span>
    <span class="s2">&quot;is_tensor_like&quot;</span><span class="p">,</span>
    <span class="s2">&quot;is_tensor_method_or_property&quot;</span><span class="p">,</span>
    <span class="s2">&quot;wrap_torch_function&quot;</span><span class="p">,</span>
    <span class="s2">&quot;enable_reentrant_dispatch&quot;</span><span class="p">,</span>
    <span class="s2">&quot;get_buffer&quot;</span><span class="p">,</span>
<span class="p">]</span>

<div class="viewcode-block" id="get_ignored_functions"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.get_ignored_functions">[docs]</a><span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_ignored_functions</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">Callable</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return public functions that cannot be overridden by ``__torch_function__``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Set[Callable]</span>
<span class="sd">        A tuple of functions that are publicly available in the torch API but cannot</span>
<span class="sd">        be overridden with ``__torch_function__``. Mostly this is because none of the</span>
<span class="sd">        arguments of these functions are tensors or tensor-likes.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; torch.Tensor.as_subclass in torch.overrides.get_ignored_functions()</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; torch.add in torch.overrides.get_ignored_functions()</span>
<span class="sd">    False</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">typename</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_storage</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_default_tensor_type</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_default_device</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_rng_state</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_rng_state</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fork</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_num_interop_threads</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_num_threads</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">init_num_threads</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">import_ir_module</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">import_ir_module_from_buffer</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_anomaly_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_anomaly_check_nan_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_grad_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">merge_type_from_type_comment</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">parse_ir</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">parse_schema</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">parse_type_comment</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_anomaly_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_flush_denormal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_num_interop_threads</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_num_threads</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">wait</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_device</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">default_generator</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_cuda</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_cudnn</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_lapack</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">finfo</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_mkl</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_mps</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_mkldnn</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">has_openmp</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">iinfo</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">memory_format</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">qscheme</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">enable_grad</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_inference_mode_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">layout</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">align_tensors</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">as_strided</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bartlett_window</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">blackman_window</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">can_cast</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_affine_grid_generator</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_batch_norm</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_convolution</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_convolution_transpose</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_convolution_relu</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_convolution_add_relu</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_grid_sampler</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cudnn_is_acceptable</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">empty_permuted</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">empty_strided</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">empty_quantized</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fftfreq</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfftfreq</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">from_file</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fill</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hamming_window</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hann_window</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">kaiser_window</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mkldnn_adaptive_avg_pool2d</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mkldnn_convolution</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mkldnn_max_pool2d</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mkldnn_max_pool3d</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mkldnn_linear_backward_weights</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mkldnn_rnn_layer</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">promote_types</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">range</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">result_type</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">scalar_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_compressed_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_csr_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_csc_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_bsr_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sparse_bsc_tensor</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sym_float</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sym_int</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sym_max</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sym_min</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sym_not</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sym_constrain_range</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tril_indices</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">vander</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_jit_internal</span><span class="o">.</span><span class="n">boolean_dispatch</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">assert_int_or_pair</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample_bilinear</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">upsample_nearest</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">has_torch_function</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">has_torch_function_unary</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">has_torch_function_variadic</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">handle_torch_function</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hardsigmoid</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">_canonical_mask</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">_none_or_dtype</span><span class="p">,</span>
        <span class="c1"># Doesn&#39;t actually take or return tensor arguments</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">calculate_gain</span><span class="p">,</span>
        <span class="c1"># These are deprecated; don&#39;t test them</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">eye</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">dirac</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">orthogonal</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">sparse</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nested</span><span class="o">.</span><span class="n">to_padded_tensor</span><span class="p">,</span>
        <span class="n">has_torch_function</span><span class="p">,</span>
        <span class="n">handle_torch_function</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_autocast_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clear_autocast_cache</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_cpu_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_autocast_cpu_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_xla_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_autocast_xla_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_ipu_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_autocast_ipu_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_cpu_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_autocast_cpu_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_ipu_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_autocast_ipu_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_autocast_gpu_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_gpu_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_autocast_xla_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_xla_dtype</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">autocast_increment_nesting</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">autocast_decrement_nesting</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_autocast_cache_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_autocast_cache_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hardswish</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_vulkan_available</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">are_deterministic_algorithms_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">use_deterministic_algorithms</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_deterministic_algorithms_warn_only_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_deterministic_debug_mode</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_deterministic_debug_mode</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_float32_matmul_precision</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">get_float32_matmul_precision</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unify_type_list</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_warn_always_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_warn_always</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">vitals_enabled</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">set_vital</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">read_vitals</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">vmap</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">asarray</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_functional_sym_constrain_range</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_make_dep_token</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__delitem__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__dir__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__init__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__iter__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__init_subclass__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__delattr__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__setattr__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__torch_function__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__torch_dispatch__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__new__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__subclasshook__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__hash__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">as_subclass</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">eig</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">lstsq</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">reinforce</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_tensor</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_empty</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_empty_strided</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_ones</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">new_full</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_make_subclass</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">solve</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">symeig</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">unflatten</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse_coo</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse_csr</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse_csc</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse_bsr</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse_bsc</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_to_sparse</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_to_sparse_csr</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_to_sparse_csc</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_to_sparse_bsr</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_to_sparse_bsc</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_typed_storage</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_reduce_ex_internal</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_fix_weakref</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_view_func</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_make_wrapper_subclass</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_python_dispatch</span><span class="o">.</span><span class="fm">__get__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_has_symbolic_sizes_strides</span><span class="o">.</span><span class="fm">__get__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_conj</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_conj_physical</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_neg_view</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_is_zerotensor</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_is_all_true</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_is_any_true</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_addmm_activation</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_padded_tensor</span><span class="p">,</span>
    <span class="p">}</span></div>


<span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_default_nowrap_functions</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">Callable</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return public functions that do not wrap in a subclass when invoked by</span>
<span class="sd">    the default ``Tensor.__torch_function__`` that preserves subclasses.  Typically,</span>
<span class="sd">    these functions represent field accesses (i.e., retrieving a Tensor that</span>
<span class="sd">    is stored somewhere on the Tensor) as opposed to computation.  Users of</span>
<span class="sd">    these functions expect object identity to be preserved over multiple accesses</span>
<span class="sd">    (e.g., ``a.grad is a.grad``) which cannot be upheld if we&#39;re wrapping on</span>
<span class="sd">    the fly every time (furthermore, the tensor stored here might already be</span>
<span class="sd">    the subclass, in which case wrapping really ought not to happen).</span>

<span class="sd">    Not ALL property accessors have this property; for example ``Tensor.T`` actually</span>
<span class="sd">    just creates a new transposed tensor on the fly, and so we SHOULD interpose on</span>
<span class="sd">    these calls (you need to check the implementation of the function to see if</span>
<span class="sd">    this is the case or not).  Additionally, if a property accessor doesn&#39;t return a Tensor,</span>
<span class="sd">    it doesn&#39;t have to be on this list (though it is harmless if it is).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_base</span><span class="o">.</span><span class="fm">__get__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">,</span>
    <span class="p">}</span>


<div class="viewcode-block" id="get_testing_overrides"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.get_testing_overrides">[docs]</a><span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">get_testing_overrides</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Return a dict containing dummy overrides for all overridable functions</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Dict[Callable, Callable]</span>
<span class="sd">        A dictionary that maps overridable functions in the PyTorch API to</span>
<span class="sd">        lambda functions that have the same signature as the real function</span>
<span class="sd">        and unconditionally return -1. These lambda functions are useful</span>
<span class="sd">        for testing API coverage for a type that defines ``__torch_function__``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import inspect</span>
<span class="sd">    &gt;&gt;&gt; my_add = torch.overrides.get_testing_overrides()[torch.add]</span>
<span class="sd">    &gt;&gt;&gt; inspect.signature(my_add)</span>
<span class="sd">    &lt;Signature (input, other, out=None)&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Every function in the PyTorchAPI that can be overriden needs an entry</span>
    <span class="c1"># in this dict.</span>
    <span class="c1">#</span>
    <span class="c1"># Optimally we would use inspect to get the function signature and define</span>
    <span class="c1"># the lambda function procedurally but that is blocked by generating</span>
    <span class="c1"># function signatures for native kernels that can be consumed by inspect.</span>
    <span class="c1"># See Issue #28233.</span>
    <span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="n">ret</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">absolute</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">adaptive_avg_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">adaptive_max_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">output_size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">acos</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">adjoint</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arccos</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">acosh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arccosh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addbmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addcdiv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addcmul</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">tensor1</span><span class="p">,</span> <span class="n">tensor2</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addmv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">addr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">affine_grid_generator</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">theta</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">all</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">trol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">equal_nan</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">alpha_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">amax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">amin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">aminmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">angle</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">any</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">argmin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">argsort</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">asin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_assert_async</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">msg</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arcsin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">asinh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arcsinh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atan</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arctan</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atan2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arctan2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atanh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">arctanh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">atleast_3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">avg_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">baddbmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_backward_elemt</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">grad_out</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">sum_dy</span><span class="p">,</span> <span class="n">sum_dy_xmu</span><span class="p">,</span> <span class="n">count_tensor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_backward_reduce</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">grad_out</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">input_g</span><span class="p">,</span> <span class="n">weight_g</span><span class="p">,</span> <span class="n">bias_g</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_elemt</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_gather_stats</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">count</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_gather_stats_with_counts</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">invstd</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">count</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_stats</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">batch_norm_update_stats</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">momentum</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bilinear</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                 <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">pos_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bincount</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">binomial</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">count</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_and</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_not</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_or</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_xor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_left_shift</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bitwise_right_shift</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">block_diag</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_tensors</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">bucketize</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">,</span> <span class="n">out_int32</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cartesian_prod</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># alias for torch.cat</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">concatenate</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># alias for torch.concatenate</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cdist</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">compute_mode</span><span class="o">=</span><span class="s1">&#39;use_mm_for_euclid_dist_if_necessary&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ceil</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">celu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">chain_matmul</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">matrices</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">channel_shuffle</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">groups</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cholesky</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky_ex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">check_errors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cholesky_inverse</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cholesky_solve</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">choose_qparams_optimized</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">numel</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="n">ratio</span><span class="p">,</span> <span class="n">bit_width</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">chunk</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">chunks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">min</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clamp_max</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">column_stack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cov</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">correction</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">fweights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">aweights</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">combinations</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">with_replacement</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">complex</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">real</span><span class="p">,</span> <span class="n">imag</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">copysign</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">polar</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">abs</span><span class="p">,</span> <span class="n">ang</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cond</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conj</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conj_physical</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">resolve_conj</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">resolve_neg</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">constant_pad_nd</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">convolution</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">transposed</span><span class="p">,</span> <span class="n">output_adding</span><span class="p">,</span> <span class="n">groups</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv_tbc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv_transpose1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv_transpose2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">conv_transpose3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cosine_embedding_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cosh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cosine_similarity</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cross</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cross</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span>
                         <span class="n">zero_infinity</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cummax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cummin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cumulative_trapezoid</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logcumsumexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">deg2rad</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dequantize</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">det</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># alias for torch.det  # type: ignore[attr-defined]</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">detach</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diagflat</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diff</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">prepend</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diagonal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diagonal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diagonal_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">as_strided_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">storage_offset</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">digamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">divide</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rounding_mode</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dsmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hsmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dsplit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices_or_sections</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">dstack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">UPLO</span><span class="o">=</span><span class="s2">&quot;L&quot;</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">UPLO</span><span class="o">=</span><span class="s2">&quot;L&quot;</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">equation</span><span class="p">,</span> <span class="o">*</span><span class="n">operands</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">embedding</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                          <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">embedding_bag</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                              <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">per_sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">erf</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">erfc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">erfinv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">exp2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">expm1</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fake_quantize_per_channel_affine</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fake_quantize_per_tensor_affine</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fused_moving_avg_obs_fake_quant</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">observer_on</span><span class="p">,</span> <span class="n">fake_quant_on</span><span class="p">,</span> <span class="n">averaging_const</span><span class="p">,</span> <span class="n">running_min</span><span class="p">,</span>
                                                <span class="n">running_max</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">quant_min</span><span class="p">,</span> <span class="n">quant_max</span><span class="p">,</span> <span class="n">ch_axis</span><span class="p">,</span>
                                                <span class="n">per_row_fake_quant</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">symmetric_quant</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_linear_fp16_weight</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">packed_weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_linear_fp16_weight_fp32_activation</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">packed_weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_linear_int8_weight</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">packed</span><span class="p">,</span> <span class="n">col_offsets</span><span class="p">,</span> <span class="n">weight_scale</span><span class="p">,</span> <span class="n">weight_zero_point</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_linear_int8_weight_fp32_activation</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">packed</span><span class="p">,</span> <span class="n">col_offsets</span><span class="p">,</span> <span class="n">weight_scale</span><span class="p">,</span>
                                                          <span class="n">weight_zero_point</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_linear_quantize_weight</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_pack_gemm_matrix_fp16</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fbgemm_pack_quantized_matrix</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">feature_alpha_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">feature_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">irfft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">hfft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ihfft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">hfft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ihfft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">hfftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ihfftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">irfftn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">rfft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">irfft2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fftshift</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifftshift</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fix</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dims</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fliplr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">flipud</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">frobenius_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">floor_divide</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">float_power</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fmod</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">frac</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">frexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">fill_value</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_functional_assert_async</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">msg</span><span class="p">,</span> <span class="n">dep_token</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lu_unpack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">LU_data</span><span class="p">,</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="n">unpack_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unpack_pivots</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sparse_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gcd</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ge</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">geqrf</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">i0</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">inner</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">outer</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ger</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">vec2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># alias for torch.outer</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gradient</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">spacing</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">edge_order</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">grid_sampler</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">grid_sampler_2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">grid_sampler_3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">interpolation_mode</span><span class="p">,</span> <span class="n">padding_mode</span><span class="p">,</span> <span class="n">align_corners</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">group_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">num_groups</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gru</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gru_cell</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_hh</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">gt</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">greater</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hardshrink</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">heaviside</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hinge_embedding_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">histc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">histogram</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">histogramdd</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">householder_product</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">tau</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hspmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hsplit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices_or_sections</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">hypot</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">igamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">igammac</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">imag</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_add</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_put</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">accumulate</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_fill</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">index_reduce</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">include_input</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isfinite</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isin</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">e</span><span class="p">,</span> <span class="n">te</span><span class="p">,</span> <span class="n">assume_unique</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">invert</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isreal</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isposinf</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isneginf</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">instance_norm</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">use_input_stats</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span>
                              <span class="n">cudnn_enabled</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">int_repr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv_ex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">check_errors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_complex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_conj</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_neg</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_distributed</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_inference</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_floating_point</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_nonzero</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_same_size</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">is_signed</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">equal_nan</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">istft</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n_fft</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                      <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">onesided</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_complex</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">kl_div</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">log_target</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">kron</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">kthvalue</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">ldl_factor_ex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">check_errors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">ldl_factor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">ldl_solve</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">LD</span><span class="p">,</span> <span class="n">pivots</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">esp</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">cudnn_enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lcm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ldexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">le</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">less_equal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lerp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lgamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lobpcg</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">iK</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">largest</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">tracker</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ortho_iparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ortho_fparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ortho_bparams</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log10</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log1p</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logaddexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logaddexp2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logdet</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">xlogy</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logical_and</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logical_not</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logical_or</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logical_xor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lstm</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">data</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lstm_cell</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_hh</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lt</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">less</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lu</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">A</span><span class="p">,</span> <span class="n">pivot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">get_infos</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">lu_solve</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">b</span><span class="p">,</span> <span class="n">LU_data</span><span class="p">,</span> <span class="n">LU_pivots</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">margin_ranking_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># type: ignore[attr-defined]  # noqa: B950</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">masked_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">source</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">pivot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu_factor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">pivot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu_factor_ex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">pivot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">check_errors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu_solve</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">LU</span><span class="p">,</span> <span class="n">pivots</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">adjoint</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matmul</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># alias for torch.matmul</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_power</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">multi_dot</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">matrix_exp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_exp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">maximum</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">max_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">max_pool3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">max_pool1d_with_indices</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                        <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nanmean</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">median</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nanmedian</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">:</span> <span class="k">lambda</span> <span class="o">*</span><span class="n">tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">minimum</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">fmin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_batch_norm</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span>
                                  <span class="n">exponential_average_factor</span><span class="p">,</span> <span class="n">epsilon</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_convolution</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_convolution_add_relu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_convolution_relu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_convolution_transpose</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">output_padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span>
                                             <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span> <span class="n">deterministic</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_depthwise_convolution</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">padding</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">dilation</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">benchmark</span><span class="p">,</span>
                                             <span class="n">deterministic</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">miopen_rnn</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weight_stride0</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">,</span>
                           <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">,</span> <span class="n">dropout_state</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mode</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">movedim</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">destination</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">destination</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">msort</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">multiply</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">vec</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">mvlgamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">narrow</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">nan</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">posinf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">neginf</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_batch_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_native_batch_norm_legit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">train</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_layer_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_group_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">HxW</span><span class="p">,</span> <span class="n">group</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">native_channel_shuffle</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">groups</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">not_equal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">negative</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nextafter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_avg_pool2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_avg_pool3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool1d_with_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool2d_with_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">adaptive_max_pool3d_with_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">affine_grid</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">theta</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">alpha_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                         <span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">divisor_override</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">avg_pool3d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                         <span class="n">count_include_pad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">divisor_override</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                         <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">bilinear</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                   <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                               <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">pos_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">celu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cosine_embedding_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                    <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span>
                                            <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="n">label_smoothing</span><span class="o">=</span><span class="mf">0.0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">ctc_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">log_probs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">,</span> <span class="n">blank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                       <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">zero_infinity</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">dropout3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">elu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">embedding</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
                                        <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">embedding_bag</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">offsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">norm_type</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                            <span class="n">scale_grad_by_freq</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">per_sample_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                            <span class="n">include_last_offset</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">feature_alpha_dropout</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fold</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fractional_max_pool2d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_ratio</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                    <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">_random_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fractional_max_pool2d_with_indices</span><span class="p">:</span> <span class="p">(</span>
            <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_ratio</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">_random_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fractional_max_pool3d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_ratio</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                    <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">_random_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fractional_max_pool3d_with_indices</span><span class="p">:</span> <span class="p">(</span>
            <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_ratio</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">_random_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gaussian_nll_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gelu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">approximate</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">glu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">grid_sample</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">grid</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">group_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">num_groups</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">gumbel_softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">logits</span><span class="p">,</span> <span class="n">tau</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hard</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hardshrink</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hardtanh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">min_val</span><span class="o">=-</span><span class="mf">1.</span><span class="p">,</span> <span class="n">max_val</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hinge_embedding_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                   <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">instance_norm</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">running_mean</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">running_var</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                            <span class="n">use_input_stats</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">interpolate</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                          <span class="n">recompute_scale_factor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">antialias</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">kl_div</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">log_target</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">l1_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">negative_slope</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">local_response_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mf">1.0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">logsigmoid</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">lp_pool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">norm_type</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">lp_pool2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">norm_type</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">margin_ranking_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                  <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool1d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                         <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool1d_with_indices</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                      <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                         <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool2d_with_indices</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                      <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool3d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                         <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_pool3d_with_indices</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                      <span class="n">return_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_unpool1d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_unpool2d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">max_unpool3d</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">multi_head_attention_forward</span><span class="p">:</span> <span class="p">(</span>
            <span class="k">lambda</span> <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">embed_dim_to_check</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">in_proj_weight</span><span class="p">,</span> <span class="n">in_proj_bias</span><span class="p">,</span> <span class="n">bias_k</span><span class="p">,</span> <span class="n">bias_v</span><span class="p">,</span>
            <span class="n">add_zero_attn</span><span class="p">,</span> <span class="n">dropout_p</span><span class="p">,</span> <span class="n">out_proj_weight</span><span class="p">,</span> <span class="n">out_proj_bias</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">key_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">need_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_separate_proj_weight</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">q_proj_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">k_proj_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">v_proj_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">static_k</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">static_v</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">average_attn_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">is_causal</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">multi_margin_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">multilabel_margin_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                     <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">multilabel_soft_margin_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                                          <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">nll_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=-</span><span class="mi">100</span><span class="p">,</span>
                                       <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">normalize</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">one_hot</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pairwise_distance</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">poisson_nll_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">log_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">full</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                               <span class="n">eps</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">prelu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu6</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">rrelu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">0.125</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">0.3333333333333333</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">selu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">silu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">mish</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">scaled_dot_product_attention</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">attn_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dropout_p</span><span class="o">=</span><span class="mf">0.0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">smooth_l1_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">1.</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">huber_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">1.</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">soft_margin_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_stacklevel</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softplus</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">20</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softshrink</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mf">0.5</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softsign</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">tanhshrink</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">triplet_margin_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span>
                                                  <span class="n">swap</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">triplet_margin_with_distance_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span>
                                                                <span class="n">distance_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                                                                <span class="n">swap</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">unfold</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">val</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_uniform_</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_in&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;leaky_relu&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">as_tuple</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nonzero_static</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">argwhere</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="s1">&#39;fro&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">vector_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="s1">&#39;fro&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">norm_except_dim</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">,</span> <span class="nb">pow</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nuclear_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="s1">&#39;fro&#39;</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">orgqr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">tau</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ormqr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">input3</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transpose</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pairwise_distance</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">permute</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pca_lowrank</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pdist</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pinverse</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="mf">1e-15</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="mf">1e-15</span><span class="p">,</span> <span class="n">hermitian</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pixel_shuffle</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">upscale_factor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pixel_unshuffle</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">downscale_factor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">poisson</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">poisson_nll_loss</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">log_input</span><span class="p">,</span> <span class="n">full</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">reduction</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">polygamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">positive</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">prelu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">exponent</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">put</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">accumulate</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">q_per_channel_axis</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">q_per_channel_scales</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">q_per_channel_zero_points</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">q_scale</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">q_zero_point</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">qr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">some</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;reduced&#39;</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nanquantile</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantize_per_channel</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">scales</span><span class="p">,</span> <span class="n">zero_points</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantize_per_tensor</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="n">zero_point</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantize_per_tensor_dynamic</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">reduce_range</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_batch_norm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">output_scale</span><span class="p">,</span> <span class="n">output_zero_point</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_gru_cell</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span>
                                   <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_lstm_cell</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span>
                                    <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_max_pool1d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,),</span>
                                     <span class="n">dilation</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_max_pool2d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                                     <span class="n">dilation</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_max_pool3d</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
                                     <span class="n">dilation</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_rnn_relu_cell</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span>
                                        <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">quantized_rnn_tanh_cell</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="p">,</span> <span class="n">b_hh</span><span class="p">,</span> <span class="n">packed_ih</span><span class="p">,</span> <span class="n">packed_hh</span><span class="p">,</span> <span class="n">col_offsets_ih</span><span class="p">,</span>
                                        <span class="n">col_offsets_hh</span><span class="p">,</span> <span class="n">scale_ih</span><span class="p">,</span> <span class="n">scale_hh</span><span class="p">,</span> <span class="n">zero_point_ih</span><span class="p">,</span> <span class="n">zero_point_hh</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rad2deg</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rand_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randint_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">high</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">strided</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ravel</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">real</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">vdot</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">vecdot</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">view_as_real</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">view_as_complex</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">reciprocal</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">remainder</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">renorm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">maxnorm</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rnn_relu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rnn_relu_cell</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_hh</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rnn_tanh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">has_biases</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">bidirectional</span><span class="p">,</span> <span class="n">batch_first</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rnn_tanh_cell</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">hx</span><span class="p">,</span> <span class="n">w_ih</span><span class="p">,</span> <span class="n">w_hh</span><span class="p">,</span> <span class="n">b_ih</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_hh</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">roll</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">shifts</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rot90</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">row_stack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># alias for torch.vstack</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_rowwise_prune</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">weight</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">compressed_indices_dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rrelu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="mf">1.</span> <span class="o">/</span> <span class="mi">8</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">1.</span> <span class="o">/</span> <span class="mi">3</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">rsub</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">saddmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">scatter_add</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">scatter_reduce</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">reduce</span><span class="p">,</span> <span class="n">include_self</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">sorted_sequence</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out_int32</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_segment_reduce</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">data</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="n">lengths</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">offsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">unsafe</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">select</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">select_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">slice_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">selu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">signbit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sgn</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sinc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sinh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">slogdet</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">slogdet</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">smm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">spmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_ex</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">check_errors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">stable</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">split_size_or_sections</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">split_with_sizes</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">split_size_or_sections</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">square</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sspaddmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">std_mean</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">stft</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n_fft</span><span class="p">,</span> <span class="n">hop_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">win_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">pad_mode</span><span class="o">=</span><span class="s1">&#39;reflect&#39;</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">onesided</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_complex</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sub</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">subtract</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nansum</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">some</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">svd_lowrank</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">niter</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svdvals</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">swapaxes</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">swapdims</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">axis0</span><span class="p">,</span> <span class="n">axis1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">airy_ai</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">bessel_j0</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">bessel_j1</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">bessel_y0</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">bessel_y1</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">chebyshev_polynomial_t</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">chebyshev_polynomial_u</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">chebyshev_polynomial_v</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">chebyshev_polynomial_w</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">digamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">entr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erf</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfcx</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">erfinv</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">exp2</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">expit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">expm1</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">gammainc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">gammaincc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">gammaln</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">hermite_polynomial_h</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">hermite_polynomial_he</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">i0</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">i0e</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">i1</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">i1e</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">laguerre_polynomial_l</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">legendre_polynomial_p</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">log1p</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">log_ndtr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">logit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">logsumexp</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">modified_bessel_i0</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">modified_bessel_i1</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">modified_bessel_k0</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">modified_bessel_k1</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">multigammaln</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">ndtr</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">ndtri</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">polygamma</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">psi</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">round</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">scaled_modified_bessel_k0</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">scaled_modified_bessel_k1</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">shifted_chebyshev_polynomial_t</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">shifted_chebyshev_polynomial_u</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">shifted_chebyshev_polynomial_v</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">shifted_chebyshev_polynomial_w</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">sinc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">spherical_bessel_j0</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">xlog1py</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">xlogy</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">zeta</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">t</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">take</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">take_along_dim</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tan</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">tensorinv</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">ind</span><span class="o">=</span><span class="mi">2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">tensorsolve</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensordot</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensor_split</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices_or_sections</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">threshold</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tile</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dims</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">trace</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">trapz</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">trapezoid</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">triangular_solve</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transpose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">unitriangular</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve_triangular</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="n">left</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">unitriangular</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">triplet_margin_loss</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">,</span> <span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">swap</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

                                    <span class="n">size_average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">true_divide</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">trunc</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unbind</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unflatten</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">sizes</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="nb">sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unique_consecutive</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unsafe_chunk</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">chunks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unsafe_split</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">split_size_or_sections</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unsafe_split_with_sizes</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">split_size_or_sections</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">vander</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">var_mean</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">vsplit</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">indices_or_sections</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">condition</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">:</span> <span class="k">lambda</span> <span class="nb">input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_fw_primal_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">level</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_make_dual_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">primal</span><span class="p">,</span> <span class="n">tangent</span><span class="p">,</span> <span class="n">level</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">view_as_real_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">view_as_complex_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_conj_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_neg_view_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">as_strided_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="n">storage_offset</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_sparse_broadcast_to_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">diagonal_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">expand_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">implicit</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">narrow_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">permute_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_reshape_alias_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">select_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">detach_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">slice_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">split_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">split_size</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">split_with_sizes_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">split_sizes</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">squeeze_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">t_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">transpose_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim0</span><span class="p">,</span> <span class="n">dim1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">_values_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">values_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">crow_indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">col_indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">ccol_indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">row_indices_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unbind_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">view_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">unfold_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">alias_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__floordiv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rfloordiv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__ifloordiv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__truediv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rtruediv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__itruediv__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__lshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rlshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__ilshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rrshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__irshift__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__and__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__or__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__xor__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__float__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__complex__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__array__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__bool__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__contains__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__neg__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__invert__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__mod__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__rmod__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__imod__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__array_wrap__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">array</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__deepcopy__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memo</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__int__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__long__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__index__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__len__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__format__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">format_spec</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__reduce_ex__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">proto</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__reversed__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">tensor_contents</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="fm">__setitem__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">d</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">H</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">mT</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">mH</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_backward_hooks</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_base</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_cdata</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_grad_fn</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">grad_fn</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_version</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_autocast_to_reduced_precision</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">cuda_enabled</span><span class="p">,</span> <span class="n">cpu_enabled</span><span class="p">,</span> <span class="n">cuda_dtype</span><span class="p">,</span> <span class="n">cpu_dtype</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_autocast_to_full_precision</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">cuda_enabled</span><span class="p">,</span> <span class="n">cpu_enabled</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_cuda</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_cpu</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_xla</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_xpu</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_ipu</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_leaf</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">retains_grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_meta</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_mps</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_nested</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_ort</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_mkldnn</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_quantized</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_sparse</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_sparse_csr</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_vulkan</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">itemsize</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">layout</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">names</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">nbytes</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">ndim</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">output_nr</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">requires_grad</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">volatile</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">real</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">imag</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__cuda_array_interface__</span><span class="o">.</span><span class="fm">__get__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">type</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_dimI</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_dimV</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_is_view</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_nnz</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">crow_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">col_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">ccol_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">row_indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_update_names</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">inplace</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_values</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">adjoint</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">align_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">align_to</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">ellipsis_idx</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">apply_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">callable</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">as_strided</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">as_strided_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">stride</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">backward</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">gradient</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">bool</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">byte</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">char</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">cauchy_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">median</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">coalesce</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_coalesced_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">coalesced</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">contiguous</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">contiguous_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">copy_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">cpu</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">xpu</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">ipu</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">data_ptr</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">dense_dim</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">diagonal_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">dim</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">double</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">cdouble</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">element_size</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">expand</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">expand_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">exponential_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">lambd</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">fill_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">fill_diagonal_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">float</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">cfloat</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">geometric_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">get_device</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">half</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">chalf</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">has_names</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">indices</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">int</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_coalesced</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_contiguous</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_inference</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_pinned</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_set_to</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">is_shared</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">item</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">log_normal_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">long</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">map_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">callable</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">map2_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">callable</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">mm</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">mat2</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">narrow_copy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">length</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">ndimension</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">nelement</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_nested_tensor_size</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_nested_tensor_storage_offsets</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_nested_tensor_strides</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">normal_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">numpy</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">permute</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">put_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">accumulate</span><span class="o">=</span><span class="kc">False</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">qscheme</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">random_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">from_</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">record_stream</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">stream</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">refine_names</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">names</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">register_hook</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">rename</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">repeat</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">reshape_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">resize</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">resize_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">resize_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">resize_as_sparse_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">retain_grad</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">set_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">storage_offset</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">select_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">share_memory_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">short</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">size</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">slice_scatter</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sparse_dim</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sparse_mask</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_sparse_mask_projection</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sparse_resize_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size1</span><span class="p">,</span> <span class="n">size2</span><span class="p">,</span> <span class="n">dense_dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sparse_resize_and_clear_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size1</span><span class="p">,</span> <span class="n">size2</span><span class="p">,</span> <span class="n">dense_dim</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sspaddmm</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">storage</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">untyped_storage</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">storage_offset</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">storage_type</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">sum_to_size</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">tile</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">reps</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">preserve_format</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_dense</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">masked_grad</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">_to_dense</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">masked_grad</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">tolist</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">to_mkldnn</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">type_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">unfold</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">uniform_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">from_</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">to</span><span class="o">=</span><span class="mi">1</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">values</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">view</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">view_as</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">zero_</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__dlpack__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">Tensor</span><span class="o">.</span><span class="n">__dlpack_device__</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">:</span> <span class="k">lambda</span> <span class="bp">self</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">cond</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">driver</span><span class="o">=</span><span class="kc">None</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">ret2</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">ignored</span> <span class="o">=</span> <span class="n">get_ignored_functions</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">ret</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Generate methods like __add__ and add_ by default from add</span>
        <span class="n">names</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>  <span class="c1"># Default method</span>
            <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;_&quot;</span><span class="p">,</span>  <span class="c1"># Inplace variant</span>
            <span class="s2">&quot;__&quot;</span> <span class="o">+</span> <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span><span class="p">,</span>  <span class="c1"># Dunder method</span>
            <span class="s2">&quot;__i&quot;</span> <span class="o">+</span> <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span><span class="p">,</span>  <span class="c1"># Inplace dunder method</span>
            <span class="s2">&quot;__r&quot;</span> <span class="o">+</span> <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span><span class="p">,</span>  <span class="c1"># Reverse dunder method</span>
        <span class="p">]</span>

        <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;bitwise_&quot;</span><span class="p">):</span>
            <span class="c1"># bitwise_&lt;op&gt; have dunder methods of the form __&lt;op&gt;__</span>
            <span class="c1"># And so on.</span>
            <span class="n">subname</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="vm">__name__</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;bitwise_&quot;</span><span class="p">):]</span>
            <span class="n">names</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
                <span class="s2">&quot;__&quot;</span> <span class="o">+</span> <span class="n">subname</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span><span class="p">,</span>
                <span class="s2">&quot;__i&quot;</span> <span class="o">+</span> <span class="n">subname</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span><span class="p">,</span>
                <span class="s2">&quot;__r&quot;</span> <span class="o">+</span> <span class="n">subname</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span>
            <span class="p">])</span>

        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">names</span><span class="p">:</span>
            <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">func</span><span class="p">)</span> <span class="ow">and</span> <span class="n">func</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ret</span> <span class="ow">and</span> <span class="n">func</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">ignored</span><span class="p">:</span>
                <span class="n">ret2</span><span class="p">[</span><span class="n">func</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>

    <span class="n">ret</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">ret2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ret</span></div>

<div class="viewcode-block" id="wrap_torch_function"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.wrap_torch_function">[docs]</a><span class="k">def</span> <span class="nf">wrap_torch_function</span><span class="p">(</span><span class="n">dispatcher</span><span class="p">:</span> <span class="n">Callable</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wraps a given function with ``__torch_function__`` -related functionality.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    dispatcher: Callable</span>
<span class="sd">        A callable that returns an iterable of Tensor-likes passed into the function.</span>

<span class="sd">    Note</span>
<span class="sd">    ----</span>
<span class="sd">    This decorator may reduce the performance of your code. Generally, it&#39;s enough to express</span>
<span class="sd">    your code as a series of functions that, themselves, support __torch_function__. If you</span>
<span class="sd">    find yourself in the rare situation where this is not the case, e.g. if you&#39;re wrapping a</span>
<span class="sd">    low-level library and you also need it to work for Tensor-likes, then this function is available.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; def dispatcher(a): # Must have the same signature as func</span>
<span class="sd">    ...     return (a,)</span>
<span class="sd">    &gt;&gt;&gt; @torch.overrides.wrap_torch_function(dispatcher)</span>
<span class="sd">    &gt;&gt;&gt; def func(a): # This will make func dispatchable by __torch_function__</span>
<span class="sd">    ...     return a + 0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">inner</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
        <span class="nd">@functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">wrapped</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">relevant_args</span> <span class="o">=</span> <span class="n">dispatcher</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">has_torch_function</span><span class="p">(</span><span class="n">relevant_args</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">handle_torch_function</span><span class="p">(</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">relevant_args</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">wrapped</span>

    <span class="k">return</span> <span class="n">inner</span></div>

<span class="k">def</span> <span class="nf">_get_overloaded_args</span><span class="p">(</span><span class="n">relevant_args</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Returns a list of arguments on which to call __torch_function__.</span>

<span class="sd">    Checks arguments in relevant_args for __torch_function__ implementations,</span>
<span class="sd">    storing references to the arguments and their types in overloaded_args and</span>
<span class="sd">    overloaded_types in order of calling precedence. Only distinct types are</span>
<span class="sd">    considered. If a type is a subclass of another type it will have higher</span>
<span class="sd">    precedence, otherwise the precedence order is the same as the order of</span>
<span class="sd">    arguments in relevant_args, that is, from left-to-right in the argument list.</span>

<span class="sd">    The precedence-determining algorithm implemented in this function is</span>
<span class="sd">    described in `NEP-0018`_.</span>

<span class="sd">    See torch::append_overloaded_arg for the equivalent function in the C++</span>
<span class="sd">    implementation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    relevant_args : iterable of array-like</span>
<span class="sd">        Iterable of array-like arguments to check for __torch_function__</span>
<span class="sd">        methods.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    overloaded_args : list</span>
<span class="sd">        Arguments from relevant_args on which to call __torch_function__</span>
<span class="sd">        methods, in the order in which they should be called.</span>

<span class="sd">    .. _NEP-0018:</span>
<span class="sd">       https://numpy.org/neps/nep-0018-array-function-protocol.html</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># If torch function is not enabled, there are no overloaded types</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_is_torch_function_enabled</span><span class="p">():</span>
        <span class="k">return</span> <span class="p">[]</span>
    <span class="c1"># Runtime is O(num_arguments * num_unique_types)</span>
    <span class="n">overloaded_types</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Type</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">overloaded_args</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">relevant_args</span><span class="p">:</span>
        <span class="n">arg_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
        <span class="c1"># We only collect arguments if they have a unique type, which ensures</span>
        <span class="c1"># reasonable performance even with a long list of possibly overloaded</span>
        <span class="c1"># arguments.</span>
        <span class="c1">#</span>
        <span class="c1"># NB: Important to exclude _disabled_torch_function_impl, otherwise</span>
        <span class="c1"># https://github.com/pytorch/pytorch/issues/64687</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">arg_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">overloaded_types</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">arg_type</span><span class="p">,</span> <span class="s1">&#39;__torch_function__&#39;</span><span class="p">)</span> <span class="ow">and</span>
                <span class="n">arg_type</span><span class="o">.</span><span class="n">__torch_function__</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_disabled_torch_function_impl</span><span class="p">):</span>
            <span class="c1"># Create lists explicitly for the first type (usually the only one</span>
            <span class="c1"># done) to avoid setting up the iterator for overloaded_args.</span>
            <span class="k">if</span> <span class="n">overloaded_types</span><span class="p">:</span>
                <span class="n">overloaded_types</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">arg_type</span><span class="p">)</span>
                <span class="c1"># By default, insert argument at the end, but if it is</span>
                <span class="c1"># subclass of another argument, insert it before that argument.</span>
                <span class="c1"># This ensures &quot;subclasses before superclasses&quot;.</span>
                <span class="n">index</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">overloaded_args</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">old_arg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">overloaded_args</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">arg_type</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">old_arg</span><span class="p">)):</span>
                        <span class="n">index</span> <span class="o">=</span> <span class="n">i</span>
                        <span class="k">break</span>
                <span class="n">overloaded_args</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">arg</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">overloaded_types</span> <span class="o">=</span> <span class="p">{</span><span class="n">arg_type</span><span class="p">}</span>
                <span class="n">overloaded_args</span> <span class="o">=</span> <span class="p">[</span><span class="n">arg</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">overloaded_args</span>


<div class="viewcode-block" id="handle_torch_function"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.handle_torch_function">[docs]</a><span class="k">def</span> <span class="nf">handle_torch_function</span><span class="p">(</span>
        <span class="n">public_api</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">relevant_args</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Implement a function with checks for ``__torch_function__`` overrides.</span>

<span class="sd">    See torch::autograd::handle_torch_function for the equivalent of this</span>
<span class="sd">    function in the C++ implementation.</span>

<span class="sd">    Arguments</span>
<span class="sd">    ---------</span>
<span class="sd">    public_api : function</span>
<span class="sd">        Function exposed by the public torch API originally called like</span>
<span class="sd">        ``public_api(*args, **kwargs)`` on which arguments are now being</span>
<span class="sd">        checked.</span>
<span class="sd">    relevant_args : iterable</span>
<span class="sd">        Iterable of arguments to check for __torch_function__ methods.</span>
<span class="sd">    args : tuple</span>
<span class="sd">        Arbitrary positional arguments originally passed into ``public_api``.</span>
<span class="sd">    kwargs : tuple</span>
<span class="sd">        Arbitrary keyword arguments originally passed into ``public_api``.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    object</span>
<span class="sd">        Result from calling ``implementation`` or an ``__torch_function__``</span>
<span class="sd">        method, as appropriate.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    TypeError : if no implementation is found.</span>

<span class="sd">    Example</span>
<span class="sd">    -------</span>
<span class="sd">    &gt;&gt;&gt; def func(a):</span>
<span class="sd">    ...     if has_torch_function_unary(a):</span>
<span class="sd">    ...         return handle_torch_function(func, (a,), a)</span>
<span class="sd">    ...     return a + 0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check for __torch_function__ methods.</span>
    <span class="n">overloaded_args</span> <span class="o">=</span> <span class="n">_get_overloaded_args</span><span class="p">(</span><span class="n">relevant_args</span><span class="p">)</span>
    <span class="c1"># overloaded_args already have unique types.</span>
    <span class="n">types</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">type</span><span class="p">,</span> <span class="n">overloaded_args</span><span class="p">))</span>

    <span class="c1"># Check for __torch_function__ mode.</span>
    <span class="k">if</span> <span class="n">_is_torch_function_mode_enabled</span><span class="p">():</span>
        <span class="c1"># if we&#39;re here, the mode must be set to a TorchFunctionStackMode</span>
        <span class="c1"># this unsets it and calls directly into TorchFunctionStackMode&#39;s torch function</span>
        <span class="k">with</span> <span class="n">_pop_mode_temporarily</span><span class="p">()</span> <span class="k">as</span> <span class="n">mode</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">__torch_function__</span><span class="p">(</span><span class="n">public_api</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">NotImplemented</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span>

    <span class="c1"># Call overrides</span>
    <span class="k">for</span> <span class="n">overloaded_arg</span> <span class="ow">in</span> <span class="n">overloaded_args</span><span class="p">:</span>
        <span class="c1"># This call needs to become a classmethod call in the future.</span>
        <span class="c1"># See https://github.com/pytorch/pytorch/issues/63767</span>
        <span class="n">torch_func_method</span> <span class="o">=</span> <span class="n">overloaded_arg</span><span class="o">.</span><span class="n">__torch_function__</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch_func_method</span><span class="p">,</span> <span class="s2">&quot;__self__&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch_func_method</span><span class="o">.</span><span class="vm">__self__</span> <span class="ow">is</span> <span class="n">overloaded_arg</span> <span class="ow">and</span> \
                <span class="n">torch_func_method</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_disabled_torch_function_impl</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Defining your `__torch_function__ as a plain method is deprecated and &quot;</span>
                          <span class="s2">&quot;will be an error in future, please define it as a classmethod.&quot;</span><span class="p">,</span>
                          <span class="ne">DeprecationWarning</span><span class="p">)</span>

        <span class="c1"># Use `public_api` instead of `implementation` so __torch_function__</span>
        <span class="c1"># implementations can do equality/identity comparisons.</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">torch_func_method</span><span class="p">(</span><span class="n">public_api</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">NotImplemented</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">result</span>

    <span class="n">func_name</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{}</span><span class="s1">.</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">public_api</span><span class="o">.</span><span class="vm">__module__</span><span class="p">,</span> <span class="n">public_api</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;no implementation found for &#39;</span><span class="si">{}</span><span class="s2">&#39; on types that implement &quot;</span>
        <span class="s1">&#39;__torch_function__: </span><span class="si">{}</span><span class="s1">&#39;</span>
    <span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">func_name</span><span class="p">,</span> <span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">overloaded_args</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">_is_torch_function_mode_enabled</span><span class="p">():</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; nor in mode </span><span class="si">{</span><span class="n">_get_current_function_mode</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span></div>

<span class="n">has_torch_function</span> <span class="o">=</span> <span class="n">_add_docstr</span><span class="p">(</span>
    <span class="n">_has_torch_function</span><span class="p">,</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Check for __torch_function__ implementations in the elements of an iterable</span>
<span class="sd">    or if a __torch_function__ mode is enabled.  Considers exact ``Tensor`` s</span>
<span class="sd">    and ``Parameter`` s non-dispatchable.  Use this to guard a call to</span>
<span class="sd">    :func:`handle_torch_function`; don&#39;t use it to test if something</span>
<span class="sd">    is Tensor-like, use :func:`is_tensor_like` instead.</span>
<span class="sd">    Arguments</span>
<span class="sd">    ---------</span>
<span class="sd">    relevant_args : iterable</span>
<span class="sd">        Iterable or arguments to check for __torch_function__ methods.</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    bool</span>
<span class="sd">        True if any of the elements of relevant_args have __torch_function__</span>
<span class="sd">        implementations, False otherwise.</span>
<span class="sd">    See Also</span>
<span class="sd">    ________</span>
<span class="sd">    torch.is_tensor_like</span>
<span class="sd">        Checks if something is a Tensor-like, including an exact ``Tensor``.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<span class="p">)</span>

<span class="n">has_torch_function_unary</span> <span class="o">=</span> <span class="n">_add_docstr</span><span class="p">(</span>
    <span class="n">_has_torch_function_unary</span><span class="p">,</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Special case of `has_torch_function` for single inputs.</span>
<span class="sd">    Instead of:</span>
<span class="sd">      `has_torch_function((t,))`</span>
<span class="sd">    call:</span>
<span class="sd">      `has_torch_function_unary(t)`</span>
<span class="sd">    which skips unnecessary packing and unpacking work.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<span class="p">)</span>

<span class="n">has_torch_function_variadic</span> <span class="o">=</span> <span class="n">_add_docstr</span><span class="p">(</span>
    <span class="n">_has_torch_function_variadic</span><span class="p">,</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Special case of `has_torch_function` that skips tuple creation.</span>

<span class="sd">    This uses the METH_FASTCALL protocol introduced in Python 3.7</span>

<span class="sd">    Instead of:</span>
<span class="sd">      `has_torch_function((a, b))`</span>
<span class="sd">    call:</span>
<span class="sd">      `has_torch_function_variadic(a, b)`</span>
<span class="sd">    which skips unnecessary packing and unpacking work.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<span class="p">)</span>

<span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_get_overridable_functions</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]],</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]:</span>
    <span class="n">overridable_funcs</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">tested_namespaces</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">__all__</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;torch.functional&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">functional</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">__all__</span><span class="p">),</span>
        <span class="p">(</span><span class="s2">&quot;torch.nn.functional&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch.nn.init&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch.Tensor&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch.linalg&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch.fft&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">fft</span><span class="p">)),</span>
        <span class="p">(</span><span class="s2">&quot;torch.special&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="p">,</span> <span class="nb">dir</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">special</span><span class="p">)),</span>
    <span class="p">]</span>
    <span class="k">for</span> <span class="n">namespace_str</span><span class="p">,</span> <span class="n">namespace</span><span class="p">,</span> <span class="n">ns_funcs</span> <span class="ow">in</span> <span class="n">tested_namespaces</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">func_name</span> <span class="ow">in</span> <span class="n">ns_funcs</span><span class="p">:</span>
            <span class="n">ignore</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="c1"># ignore private functions or functions that are deleted in torch.__init__</span>
            <span class="k">if</span> <span class="n">namespace</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">func_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;__&#39;</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="k">elif</span> <span class="n">func_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">):</span>
                    <span class="n">ignore</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="n">func_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">):</span>
                    <span class="n">ignore</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="ow">not</span> <span class="n">func_name</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">islower</span><span class="p">():</span>
                    <span class="n">ignore</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">elif</span> <span class="n">func_name</span> <span class="o">==</span> <span class="s1">&#39;unique_dim&#39;</span><span class="p">:</span>
                    <span class="k">continue</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">namespace</span><span class="p">,</span> <span class="n">func_name</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="nb">object</span><span class="p">,</span> <span class="n">func_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="n">func</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="n">func_name</span> <span class="o">==</span> <span class="s1">&#39;__weakref__&#39;</span><span class="p">:</span>
                    <span class="k">continue</span>
            <span class="n">func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">namespace</span><span class="p">,</span> <span class="n">func_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">namespace</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="nb">object</span><span class="p">,</span> <span class="n">func_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="o">==</span> <span class="n">func</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="c1"># ignore re-exported modules</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="o">.</span><span class="n">ModuleType</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="c1"># ignore __future__ imports</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">__future__</span><span class="o">.</span><span class="n">_Feature</span><span class="p">):</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">func</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="s2">&quot;__get__&quot;</span><span class="p">):</span>
                <span class="n">index</span><span class="p">[</span><span class="n">func</span><span class="o">.</span><span class="fm">__get__</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">namespace_str</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s2">.__get__&quot;</span>
                <span class="n">index</span><span class="p">[</span><span class="n">func</span><span class="o">.</span><span class="fm">__set__</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">namespace_str</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s2">.__set__&quot;</span>
                <span class="k">if</span> <span class="n">ignore</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">if</span> <span class="n">func</span><span class="o">.</span><span class="fm">__get__</span> <span class="ow">in</span> <span class="n">get_ignored_functions</span><span class="p">():</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">.</span><span class="si">{}</span><span class="s2"> is in the tuple returned by torch._overrides.get_ignored_functions &quot;</span>
                           <span class="s2">&quot;but still has an explicit override&quot;</span><span class="p">)</span>
                    <span class="k">assert</span> <span class="n">func</span><span class="o">.</span><span class="fm">__get__</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">get_testing_overrides</span><span class="p">(),</span> <span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">namespace</span><span class="p">,</span> <span class="n">func</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
                    <span class="k">continue</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">overridable_funcs</span><span class="p">[</span><span class="n">func</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="fm">__get__</span><span class="p">)</span>
                    <span class="k">continue</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
                <span class="k">continue</span>

            <span class="n">index</span><span class="p">[</span><span class="n">func</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">namespace_str</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">func_name</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="k">if</span> <span class="n">ignore</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># cannot be overriden by __torch_function__</span>
            <span class="k">if</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">get_ignored_functions</span><span class="p">():</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">.</span><span class="si">{}</span><span class="s2"> is in the tuple returned by torch._overrides.get_ignored_functions &quot;</span>
                       <span class="s2">&quot;but still has an explicit override&quot;</span><span class="p">)</span>
                <span class="k">assert</span> <span class="n">func</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">get_testing_overrides</span><span class="p">(),</span> <span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">namespace</span><span class="p">,</span> <span class="n">func</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="n">overridable_funcs</span><span class="p">[</span><span class="n">namespace</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">overridable_funcs</span><span class="p">,</span> <span class="n">index</span>

<div class="viewcode-block" id="get_overridable_functions"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.get_overridable_functions">[docs]</a><span class="k">def</span> <span class="nf">get_overridable_functions</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]:</span>
    <span class="sd">&quot;&quot;&quot;List functions that are overridable via __torch_function__</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Dict[Any, List[Callable]]</span>
<span class="sd">        A dictionary that maps namespaces that contain overridable functions</span>
<span class="sd">        to functions in that namespace that can be overridden.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_get_overridable_functions</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="resolve_name"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.resolve_name">[docs]</a><span class="k">def</span> <span class="nf">resolve_name</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get a human readable string name for a function passed to</span>
<span class="sd">    __torch_function__</span>

<span class="sd">    Arguments</span>
<span class="sd">    ---------</span>
<span class="sd">    f : Callable</span>
<span class="sd">        Function to resolve the name of.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    str</span>
<span class="sd">        Name of the function; if eval&#39;ed it should give back the input</span>
<span class="sd">        function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">OpOverload</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">OpOverloadPacket</span><span class="p">)):</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">_get_overridable_functions</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">f</span><span class="p">)</span></div>

<span class="nd">@functools</span><span class="o">.</span><span class="n">lru_cache</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_get_tensor_methods</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Set</span><span class="p">[</span><span class="n">Callable</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot; Returns a set of the overridable methods on ``torch.Tensor`` &quot;&quot;&quot;</span>
    <span class="n">overridable_funcs</span> <span class="o">=</span> <span class="n">get_overridable_functions</span><span class="p">()</span>
    <span class="n">methods</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">overridable_funcs</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">methods</span>

<div class="viewcode-block" id="is_tensor_method_or_property"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.is_tensor_method_or_property">[docs]</a><span class="k">def</span> <span class="nf">is_tensor_method_or_property</span><span class="p">(</span><span class="n">func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns True if the function passed in is a handler for a</span>
<span class="sd">    method or property belonging to ``torch.Tensor``, as passed</span>
<span class="sd">    into ``__torch_function__``.</span>

<span class="sd">    .. note::</span>
<span class="sd">       For properties, their ``__get__`` method must be passed in.</span>

<span class="sd">    This may be needed, in particular, for the following reasons:</span>

<span class="sd">    1. Methods/properties sometimes don&#39;t contain a `__module__` slot.</span>
<span class="sd">    2. They require that the first passed-in argument is an instance</span>
<span class="sd">       of ``torch.Tensor``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_method_or_property(torch.Tensor.add)</span>
<span class="sd">    True</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_method_or_property(torch.add)</span>
<span class="sd">    False</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">func</span> <span class="ow">in</span> <span class="n">_get_tensor_methods</span><span class="p">()</span> <span class="ow">or</span> <span class="n">func</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__get__&quot;</span></div>

<div class="viewcode-block" id="is_tensor_like"><a class="viewcode-back" href="../../torch.overrides.html#torch.overrides.is_tensor_like">[docs]</a><span class="k">def</span> <span class="nf">is_tensor_like</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns ``True`` if the passed-in input is a Tensor-like.</span>

<span class="sd">    Currently, this occurs whenever there&#39;s a ``__torch_function__``</span>
<span class="sd">    attribute on the type of the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    A subclass of tensor is generally a Tensor-like.</span>

<span class="sd">    &gt;&gt;&gt; class SubTensor(torch.Tensor): ...</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_like(SubTensor([0]))</span>
<span class="sd">    True</span>

<span class="sd">    Built-in or user types aren&#39;t usually Tensor-like.</span>

<span class="sd">    &gt;&gt;&gt; is_tensor_like(6)</span>
<span class="sd">    False</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_like(None)</span>
<span class="sd">    False</span>
<span class="sd">    &gt;&gt;&gt; class NotATensor: ...</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_like(NotATensor())</span>
<span class="sd">    False</span>

<span class="sd">    But, they can be made Tensor-like by implementing __torch_function__.</span>

<span class="sd">    &gt;&gt;&gt; class TensorLike:</span>
<span class="sd">    ...     @classmethod</span>
<span class="sd">    ...     def __torch_function__(cls, func, types, args, kwargs):</span>
<span class="sd">    ...         return -1</span>
<span class="sd">    &gt;&gt;&gt; is_tensor_like(TensorLike())</span>
<span class="sd">    True</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">type</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">inp</span><span class="p">),</span> <span class="s2">&quot;__torch_function__&quot;</span><span class="p">)</span></div>

<span class="k">class</span> <span class="nc">TorchFunctionMode</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A ``TorchFunctionMode`` allows you to override the meaning of all</span>
<span class="sd">    ``__torch_function__`` overrideable functions within a dynamic scope,</span>
<span class="sd">    without having to actually create a tensor subclass or manually</span>
<span class="sd">    monkey-patch functions in the PyTorch API.  Some common situations</span>
<span class="sd">    where you should use a mode:</span>

<span class="sd">        * You want to override the meaning of factory functions, or other</span>
<span class="sd">          functions that do not otherwise take a tensor as an argument</span>
<span class="sd">          (these cannot be overridden with tensor subclasses).</span>

<span class="sd">        * You want to override the behavior of all functions without needing</span>
<span class="sd">          to wrap your inputs in tensor subclasses; e.g., if you are just</span>
<span class="sd">          interested in logging intermediate computations.</span>

<span class="sd">        * You want to control the order of execution of various tensor</span>
<span class="sd">          subclasses explicitly, rather than implicitly via the return of</span>
<span class="sd">          ``NotImplemented``.</span>

<span class="sd">    Independent subclasses of :class:`TorchFunctionMode` are compositional:</span>
<span class="sd">    modes can be pushed onto a stack using ``with MyMode():``.</span>
<span class="sd">    When you call functions in the PyTorch API inside your</span>
<span class="sd">    ``__torch_function__`` implementation, by default, they will forward on to</span>
<span class="sd">    the next mode on the mode stack.  If you want recursively call back into</span>
<span class="sd">    your current ``__torch_function__`` implementation, either explicitly</span>
<span class="sd">    invoke ``self.__torch_function__(...)``, or use the context manager</span>
<span class="sd">    ``enable_torch_function_mode(self, replace=self.inner)`` to make PyTorch</span>
<span class="sd">    API self-referential (beware of infinite loops, in this case!)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inner</span><span class="p">:</span> <span class="s2">&quot;TorchFunctionMode&quot;</span>

    <span class="c1"># Force metaclass to generate constructor at the base of the hierarchy</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">__torch_function__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(),</span> <span class="n">kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">_push_mode</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">):</span>
        <span class="n">_pop_mode</span><span class="p">()</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">push</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;`Mode.push()` is no longer necessary and can be replaced with just `with Mode()`&quot;</span><span class="p">)</span>
        <span class="n">instance</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">instance</span>


<span class="k">def</span> <span class="nf">_get_current_function_mode</span><span class="p">():</span>
    <span class="n">stack_len</span> <span class="o">=</span> <span class="n">_len_torch_function_stack</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">_get_function_stack_at</span><span class="p">(</span><span class="n">stack_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">stack_len</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span>


<span class="k">def</span> <span class="nf">_get_current_function_mode_stack</span><span class="p">():</span>
    <span class="n">stack_len</span> <span class="o">=</span> <span class="n">_len_torch_function_stack</span><span class="p">()</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">_get_function_stack_at</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">stack_len</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">_push_mode</span><span class="p">(</span><span class="n">mode</span><span class="p">):</span>
    <span class="n">_push_on_torch_function_stack</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_pop_mode</span><span class="p">():</span>
    <span class="n">old</span> <span class="o">=</span> <span class="n">_pop_torch_function_stack</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">old</span>


<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">_pop_mode_temporarily</span><span class="p">():</span>
    <span class="n">old</span> <span class="o">=</span> <span class="n">_pop_mode</span><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">old</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">_push_mode</span><span class="p">(</span><span class="n">old</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">BaseTorchFunctionMode</span><span class="p">(</span><span class="n">TorchFunctionMode</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__torch_function__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(),</span> <span class="n">kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="nd">@contextlib</span><span class="o">.</span><span class="n">contextmanager</span>
<span class="k">def</span> <span class="nf">enable_reentrant_dispatch</span><span class="p">():</span>
    <span class="c1"># NB: this can&#39;t simply be</span>
    <span class="c1"># `enable_reentrant_dispatch = torch._C._RestorePythonTLSSnapshot`</span>
    <span class="c1"># because:</span>
    <span class="c1"># 1. torch._C._RestorePythonTLSSnapshot is unavailable when this file</span>
    <span class="c1">#    initially gets imported. Probably an import order thing.</span>
    <span class="c1"># 2. enable_reentrant_dispatch is technically public API; assigning</span>
    <span class="c1">#    it the object would change the __module__ to look private.</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_RestorePythonTLSSnapshot</span><span class="p">():</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">yield</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="k">pass</span>

<span class="k">def</span> <span class="nf">get_buffer</span><span class="p">(</span><span class="n">tensor_subclass</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">prefix</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">ctypes</span>
    <span class="k">assert</span> <span class="n">prefix</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;stride&quot;</span><span class="p">,</span> <span class="s2">&quot;size&quot;</span><span class="p">,</span> <span class="s2">&quot;sym_size&quot;</span><span class="p">}</span>
    <span class="n">buffer_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;_</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_buffer&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tensor_subclass</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">):</span>
        <span class="n">SizeType</span> <span class="o">=</span> <span class="n">ctypes</span><span class="o">.</span><span class="n">c_longlong</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">tensor_subclass</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">,</span> <span class="n">SizeType</span><span class="p">(</span><span class="o">*</span><span class="n">data</span><span class="p">))</span>
    <span class="n">ptr</span> <span class="o">=</span> <span class="n">ctypes</span><span class="o">.</span><span class="n">addressof</span><span class="p">(</span><span class="nb">getattr</span><span class="p">(</span><span class="n">tensor_subclass</span><span class="p">,</span> <span class="n">buffer_name</span><span class="p">))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/sphinx_highlight.js"></script>
         <script src="../../_static/clipboard.min.js"></script>
         <script src="../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>