


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.profiler.profiler &mdash; PyTorch main documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/profiler/profiler.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sphinx-dropdown.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/panels-bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />

<!--
  Search engines should not index the main version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>main (2.1.0a0+git707d265 ) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          

<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/_modules/torch/profiler/profiler.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../community/build_ci_governance.html">PyTorch Governance | Build + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community/design.html">PyTorch Design Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community/governance.html">PyTorch Governance | Mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../community/persons_of_interest.html">PyTorch Governance | Maintainers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/amp_examples.html">CUDA Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/extending.func.html">Extending torch.func with autograd.Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">torch.compile</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/index.html">torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/get-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/troubleshooting.html">PyTorch 2.0 Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/technical-overview.html">Technical Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/guards-overview.html">Guards Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/custom-backends.html">Custom Backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/fine_grained_apis.html">TorchDynamo APIs to control fine-grained tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/profiling_torch_compile.html">Profiling to understand torch.compile performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/inductor_profiling.html">TorchInductor GPU Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/deep-dive.html">TorchDynamo Deeper Dive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/cudagraph_trees.html">CUDAGraph Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/performance-dashboard.html">PyTorch 2.0 Performance Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/torchfunc-and-torchcompile.html">torch.func interaction with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ir.html">IRs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/dynamic-shapes.html">Dynamic shapes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/fake-tensor.html">Fake tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">torch._logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compile/transformations.html">Writing Graph Transformations on ATen IR</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../export.html">torch._export.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx_diagnostics.html">torch.onnx diagnostics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logging.html">torch._logging</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../index.html">Module code</a> &gt;</li>
        
          <li><a href="../../torch.html">torch</a> &gt;</li>
        
      <li>torch.profiler.profiler</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.profiler.profiler</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">gzip</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">warn</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.autograd.profiler</span> <span class="k">as</span> <span class="nn">prof</span>
<span class="kn">from</span> <span class="nn">torch._C._profiler</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_add_execution_trace_observer</span><span class="p">,</span>
    <span class="n">_disable_execution_trace_observer</span><span class="p">,</span>
    <span class="n">_enable_execution_trace_observer</span><span class="p">,</span>
    <span class="n">_ExperimentalConfig</span><span class="p">,</span>
    <span class="n">_remove_execution_trace_observer</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">kineto_available</span><span class="p">,</span> <span class="n">ProfilerActivity</span>
<span class="kn">from</span> <span class="nn">torch.profiler._memory_profiler</span> <span class="kn">import</span> <span class="n">MemoryProfile</span><span class="p">,</span> <span class="n">MemoryProfileTimeline</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;supported_activities&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ProfilerAction&quot;</span><span class="p">,</span>
    <span class="s2">&quot;schedule&quot;</span><span class="p">,</span>
    <span class="s2">&quot;tensorboard_trace_handler&quot;</span><span class="p">,</span>
    <span class="s2">&quot;profile&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ExecutionTraceObserver&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">PROFILER_STEP_NAME</span> <span class="o">=</span> <span class="s2">&quot;ProfilerStep&quot;</span>

<span class="k">def</span> <span class="nf">supported_activities</span><span class="p">():</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a set of supported profiler tracing activities.</span>

<span class="sd">    Note: profiler uses CUPTI library to trace on-device CUDA kernels.</span>
<span class="sd">    In case when CUDA is enabled but CUPTI is not available, passing</span>
<span class="sd">    ``ProfilerActivity.CUDA`` to profiler results in using the legacy CUDA</span>
<span class="sd">    profiling code (same as in the legacy ``torch.autograd.profiler``).</span>
<span class="sd">    This, in turn, results in including CUDA time in the profiler table output,</span>
<span class="sd">    but not in the JSON trace.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">_supported_activities</span><span class="p">()</span>


<div class="viewcode-block" id="_KinetoProfile"><a class="viewcode-back" href="../../../profiler.html#torch.profiler._KinetoProfile">[docs]</a><span class="k">class</span> <span class="nc">_KinetoProfile</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Low-level profiler wrap the autograd profile</span>

<span class="sd">    Args:</span>
<span class="sd">        activities (iterable): list of activity groups (CPU, CUDA) to use in profiling, supported values:</span>
<span class="sd">            ``torch.profiler.ProfilerActivity.CPU``, ``torch.profiler.ProfilerActivity.CUDA``.</span>
<span class="sd">            Default value: ProfilerActivity.CPU and (when available) ProfilerActivity.CUDA.</span>
<span class="sd">        record_shapes (bool): save information about operator&#39;s input shapes.</span>
<span class="sd">        profile_memory (bool): track tensor memory allocation/deallocation.</span>
<span class="sd">        with_stack (bool): record source information (file and line number) for the ops.</span>
<span class="sd">        with_flops (bool): use formula to estimate the FLOPS of specific operators</span>
<span class="sd">            (matrix multiplication and 2D convolution).</span>
<span class="sd">        with_modules (bool): record module hierarchy (including function names)</span>
<span class="sd">            corresponding to the callstack of the op. e.g. If module A&#39;s forward call&#39;s</span>
<span class="sd">            module B&#39;s forward which contains an aten::add op,</span>
<span class="sd">            then aten::add&#39;s module hierarchy is A.B</span>
<span class="sd">            Note that this support exist, at the moment, only for TorchScript models</span>
<span class="sd">            and not eager mode models.</span>

<span class="sd">        experimental_config (_ExperimentalConfig) : A set of experimental options</span>
<span class="sd">            used by profiler libraries like Kineto. Note, backward compatibility is not guaranteed.</span>

<span class="sd">    .. note::</span>
<span class="sd">        This API is experimental and subject to change in the future.</span>

<span class="sd">        Enabling shape and stack tracing results in additional overhead.</span>
<span class="sd">        When record_shapes=True is specified, profiler will temporarily hold references to the tensors;</span>
<span class="sd">        that may further prevent certain optimizations that depend on the reference count and introduce</span>
<span class="sd">        extra tensor copies.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="o">*</span><span class="p">,</span>
            <span class="n">activities</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">ProfilerActivity</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">record_shapes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">profile_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">with_stack</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">with_flops</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">with_modules</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">experimental_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ExperimentalConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activities</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">activities</span><span class="p">)</span> <span class="k">if</span> <span class="n">activities</span> <span class="k">else</span> <span class="n">supported_activities</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">record_shapes</span> <span class="o">=</span> <span class="n">record_shapes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">with_flops</span> <span class="o">=</span> <span class="n">with_flops</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profile_memory</span> <span class="o">=</span> <span class="n">profile_memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">with_stack</span> <span class="o">=</span> <span class="n">with_stack</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">with_modules</span> <span class="o">=</span> <span class="n">with_modules</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experimental_config</span> <span class="o">=</span> <span class="n">experimental_config</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">prof</span><span class="o">.</span><span class="n">profile</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mem_tl</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">MemoryProfileTimeline</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_trace</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_trace</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">stop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop_trace</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">prepare_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span> <span class="o">=</span> <span class="n">prof</span><span class="o">.</span><span class="n">profile</span><span class="p">(</span>
            <span class="n">use_cuda</span><span class="o">=</span><span class="p">(</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">activities</span><span class="p">),</span>
            <span class="n">use_cpu</span><span class="o">=</span><span class="p">(</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CPU</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">activities</span><span class="p">),</span>
            <span class="n">use_mtia</span><span class="o">=</span><span class="p">(</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">MTIA</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">activities</span><span class="p">),</span>
            <span class="n">record_shapes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">record_shapes</span><span class="p">,</span>
            <span class="n">with_flops</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">with_flops</span><span class="p">,</span>
            <span class="n">profile_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">profile_memory</span><span class="p">,</span>
            <span class="n">with_stack</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">with_stack</span><span class="p">,</span>
            <span class="n">with_modules</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">with_modules</span><span class="p">,</span>
            <span class="n">use_kineto</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">experimental_config</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">experimental_config</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">_prepare_trace</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">start_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">_start_trace</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">profile_memory</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_metadata_json</span><span class="p">(</span><span class="s2">&quot;profile_memory&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_stack</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_metadata_json</span><span class="p">(</span><span class="s2">&quot;with_stack&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">record_shapes</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_metadata_json</span><span class="p">(</span><span class="s2">&quot;record_shapes&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_modules</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_metadata_json</span><span class="p">(</span><span class="s2">&quot;with_modules&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_flops</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_metadata_json</span><span class="p">(</span><span class="s2">&quot;with_flops&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">kineto_available</span><span class="p">():</span>
            <span class="n">dist_info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_distributed_info</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">dist_info</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_metadata_json</span><span class="p">(</span><span class="s2">&quot;distributedInfo&quot;</span><span class="p">,</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">dist_info</span><span class="p">))</span>

            <span class="c1"># FIXME: CUPTI Lazy Re-init and CUDA Graph crashes with CUDA 11.</span>
            <span class="n">is_cuda11_or_lower</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span>
                <span class="ow">and</span> <span class="p">([</span><span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)]</span> <span class="o">&lt;</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">is_cuda11_or_lower</span>
                <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">torch</span><span class="p">,</span> <span class="s1">&#39;_inductor&#39;</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="kn">import</span> <span class="nn">torch._inductor.config</span> <span class="k">as</span> <span class="nn">inductor_config</span>
                <span class="k">if</span> <span class="n">inductor_config</span><span class="o">.</span><span class="n">triton</span><span class="o">.</span><span class="n">cudagraphs</span><span class="p">:</span>
                    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;DISABLE_CUPTI_LAZY_REINIT&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">add_metadata_json</span><span class="p">(</span><span class="s2">&quot;DISABLE_CUPTI_LAZY_REINIT&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">stop_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<div class="viewcode-block" id="_KinetoProfile.export_chrome_trace"><a class="viewcode-back" href="../../../profiler.html#torch.profiler._KinetoProfile.export_chrome_trace">[docs]</a>    <span class="k">def</span> <span class="nf">export_chrome_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Exports the collected trace in Chrome JSON format.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span>
        <span class="k">if</span> <span class="n">path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.gz&#39;</span><span class="p">):</span>
            <span class="n">fp</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">NamedTemporaryFile</span><span class="p">(</span><span class="s1">&#39;w+t&#39;</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s1">&#39;.json&#39;</span><span class="p">,</span> <span class="n">delete</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">fp</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="n">retvalue</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">export_chrome_trace</span><span class="p">(</span><span class="n">fp</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fp</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="k">as</span> <span class="n">fin</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;wt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fout</span><span class="p">:</span>
                    <span class="n">fout</span><span class="o">.</span><span class="n">writelines</span><span class="p">(</span><span class="n">fin</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">fp</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">retvalue</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">export_chrome_trace</span><span class="p">(</span><span class="n">path</span><span class="p">)</span></div>

<div class="viewcode-block" id="_KinetoProfile.export_stacks"><a class="viewcode-back" href="../../../profiler.html#torch.profiler._KinetoProfile.export_stacks">[docs]</a>    <span class="k">def</span> <span class="nf">export_stacks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">metric</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;self_cpu_time_total&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save stack traces in a file in a format suitable for visualization.</span>

<span class="sd">        Args:</span>
<span class="sd">            path (str): save stacks file to this location;</span>
<span class="sd">            metric (str): metric to use: &quot;self_cpu_time_total&quot; or &quot;self_cuda_time_total&quot;</span>

<span class="sd">        .. note::</span>
<span class="sd">            Example of using FlameGraph tool:</span>

<span class="sd">            - git clone https://github.com/brendangregg/FlameGraph</span>
<span class="sd">            - cd FlameGraph</span>
<span class="sd">            - ./flamegraph.pl --title &quot;CPU time&quot; --countname &quot;us.&quot; profiler.stacks &gt; perf_viz.svg</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">export_stacks</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">metric</span><span class="p">)</span></div>

<div class="viewcode-block" id="_KinetoProfile.key_averages"><a class="viewcode-back" href="../../../profiler.html#torch.profiler._KinetoProfile.key_averages">[docs]</a>    <span class="k">def</span> <span class="nf">key_averages</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">group_by_input_shape</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">group_by_stack_n</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Averages events, grouping them by operator name and (optionally) input shapes and</span>
<span class="sd">        stack.</span>

<span class="sd">        .. note::</span>
<span class="sd">            To use shape/stack functionality make sure to set record_shapes/with_stack</span>
<span class="sd">            when creating profiler context manager.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">key_averages</span><span class="p">(</span><span class="n">group_by_input_shape</span><span class="p">,</span> <span class="n">group_by_stack_n</span><span class="p">)</span></div>

<div class="viewcode-block" id="_KinetoProfile.events"><a class="viewcode-back" href="../../../profiler.html#torch.profiler._KinetoProfile.events">[docs]</a>    <span class="k">def</span> <span class="nf">events</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the list of unaggregated profiler events,</span>
<span class="sd">        to be used in the trace callback or after the profiling is finished</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">function_events</span></div>

<div class="viewcode-block" id="_KinetoProfile.add_metadata"><a class="viewcode-back" href="../../../profiler.html#torch.profiler._KinetoProfile.add_metadata">[docs]</a>    <span class="k">def</span> <span class="nf">add_metadata</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds a user defined metadata with a string key and a string value</span>
<span class="sd">        into the trace file</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">wrapped_value</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">value</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;&quot;&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\\</span><span class="s1">&quot;&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">_add_metadata_json</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">wrapped_value</span><span class="p">)</span></div>

<div class="viewcode-block" id="_KinetoProfile.add_metadata_json"><a class="viewcode-back" href="../../../profiler.html#torch.profiler._KinetoProfile.add_metadata_json">[docs]</a>    <span class="k">def</span> <span class="nf">add_metadata_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds a user defined metadata with a string key and a valid json value</span>
<span class="sd">        into the trace file</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">_add_metadata_json</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_get_distributed_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">dist</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">dist</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;backend&quot;</span><span class="p">:</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_backend</span><span class="p">(),</span>
            <span class="s2">&quot;rank&quot;</span><span class="p">:</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">(),</span>
            <span class="s2">&quot;world_size&quot;</span><span class="p">:</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">_memory_profile</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">MemoryProfile</span><span class="p">:</span>
        <span class="n">required</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;record_shapes&quot;</span><span class="p">,</span> <span class="s2">&quot;profile_memory&quot;</span><span class="p">,</span> <span class="s2">&quot;with_stack&quot;</span><span class="p">)</span>
        <span class="n">missing</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">=True&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">required</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span>
        <span class="k">if</span> <span class="n">missing</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">missing</span><span class="p">)</span><span class="si">}</span><span class="s2"> required for memory profiling.&quot;</span><span class="p">)</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">kineto_results</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">MemoryProfile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">kineto_results</span><span class="p">)</span>

<div class="viewcode-block" id="_KinetoProfile.export_memory_timeline"><a class="viewcode-back" href="../../../profiler.html#torch.profiler._KinetoProfile.export_memory_timeline">[docs]</a>    <span class="k">def</span> <span class="nf">export_memory_timeline</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Extract the memory information from the memory profile collected</span>
<span class="sd">        tree for a given device, and export a timeline plot consisting of</span>
<span class="sd">        [times, [sizes by category]], where times are timestamps and sizes</span>
<span class="sd">        are memory usage for each category. The memory timeline plot will</span>
<span class="sd">        be saved a JSON (by default) or gzipped JSON.</span>

<span class="sd">        Input: (path of file, device)</span>
<span class="sd">        Output: File written as JSON or gzipped JSON</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Default to device 0, if unset. Fallback on cpu.</span>
        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>

        <span class="c1"># Construct the memory timeline plot data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mem_tl</span> <span class="o">=</span> <span class="n">MemoryProfileTimeline</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_memory_profile</span><span class="p">())</span>

        <span class="c1"># Depending on the file suffix, save the data as json.gz or json.</span>
        <span class="c1"># For html, we can embed the image into an HTML file.</span>
        <span class="k">if</span> <span class="n">path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.html&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mem_tl</span><span class="o">.</span><span class="n">export_memory_timeline_html</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.gz&#39;</span><span class="p">):</span>
            <span class="n">fp</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">NamedTemporaryFile</span><span class="p">(</span><span class="s1">&#39;w+t&#39;</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s1">&#39;.json&#39;</span><span class="p">,</span> <span class="n">delete</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">fp</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mem_tl</span><span class="o">.</span><span class="n">export_memory_timeline</span><span class="p">(</span><span class="n">fp</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fp</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="k">as</span> <span class="n">fin</span><span class="p">:</span>
                <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;wt&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fout</span><span class="p">:</span>
                    <span class="n">fout</span><span class="o">.</span><span class="n">writelines</span><span class="p">(</span><span class="n">fin</span><span class="p">)</span>
            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">fp</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mem_tl</span><span class="o">.</span><span class="n">export_memory_timeline</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ProfilerAction"><a class="viewcode-back" href="../../../profiler.html#torch.profiler.ProfilerAction">[docs]</a><span class="k">class</span> <span class="nc">ProfilerAction</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Profiler actions that can be taken at the specified intervals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">NONE</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">WARMUP</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">RECORD</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">RECORD_AND_SAVE</span> <span class="o">=</span> <span class="mi">3</span></div>


<div class="viewcode-block" id="schedule"><a class="viewcode-back" href="../../../profiler.html#torch.profiler.schedule">[docs]</a><span class="k">def</span> <span class="nf">schedule</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">wait</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">warmup</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">active</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">repeat</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">skip_first</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a callable that can be used as profiler ``schedule`` argument. The profiler will skip</span>
<span class="sd">    the first ``skip_first`` steps, then wait for ``wait`` steps, then do the warmup for the next ``warmup`` steps,</span>
<span class="sd">    then do the active recording for the next ``active`` steps and then repeat the cycle starting with ``wait`` steps.</span>
<span class="sd">    The optional number of cycles is specified with the ``repeat`` parameter, the zero value means that</span>
<span class="sd">    the cycles will continue until the profiling is finished.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">schedule_fn</span><span class="p">(</span><span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ProfilerAction</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">step</span> <span class="o">&gt;=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="n">skip_first</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">step</span> <span class="o">-=</span> <span class="n">skip_first</span>
        <span class="n">num_steps</span> <span class="o">=</span> <span class="n">wait</span> <span class="o">+</span> <span class="n">warmup</span> <span class="o">+</span> <span class="n">active</span>
        <span class="k">if</span> <span class="n">repeat</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">step</span> <span class="o">/</span> <span class="n">num_steps</span> <span class="o">&gt;=</span> <span class="n">repeat</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span>
        <span class="n">mod_step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">%</span> <span class="n">num_steps</span>
        <span class="k">if</span> <span class="n">mod_step</span> <span class="o">&lt;</span> <span class="n">wait</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span>
        <span class="k">elif</span> <span class="n">mod_step</span> <span class="o">&lt;</span> <span class="n">wait</span> <span class="o">+</span> <span class="n">warmup</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">WARMUP</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD</span> <span class="k">if</span> <span class="n">mod_step</span> <span class="o">&lt;</span> <span class="n">num_steps</span> <span class="o">-</span> <span class="mi">1</span> \
                <span class="k">else</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD_AND_SAVE</span>
    <span class="k">assert</span> <span class="n">wait</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">warmup</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">active</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> \
           <span class="n">repeat</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">skip_first</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Invalid profiler schedule arguments&quot;</span>
    <span class="k">if</span> <span class="n">warmup</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Profiler won&#39;t be using warmup, this can skew profiler results&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">schedule_fn</span></div>


<span class="k">def</span> <span class="nf">_default_schedule_fn</span><span class="p">(</span><span class="n">_</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ProfilerAction</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Default profiler behavior - immediately starts recording the events,</span>
<span class="sd">    keeps doing it on every profiler step.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD</span>


<div class="viewcode-block" id="tensorboard_trace_handler"><a class="viewcode-back" href="../../../profiler.html#torch.profiler.tensorboard_trace_handler">[docs]</a><span class="k">def</span> <span class="nf">tensorboard_trace_handler</span><span class="p">(</span><span class="n">dir_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">worker_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">use_gzip</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Outputs tracing files to directory of ``dir_name``, then that directory can be</span>
<span class="sd">    directly delivered to tensorboard as logdir.</span>
<span class="sd">    ``worker_name`` should be unique for each worker in distributed scenario,</span>
<span class="sd">    it will be set to &#39;[hostname]_[pid]&#39; by default.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="kn">import</span> <span class="nn">socket</span>
    <span class="kn">import</span> <span class="nn">time</span>

    <span class="k">def</span> <span class="nf">handler_fn</span><span class="p">(</span><span class="n">prof</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">nonlocal</span> <span class="n">worker_name</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Can&#39;t create directory: &quot;</span> <span class="o">+</span> <span class="n">dir_name</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">worker_name</span><span class="p">:</span>
            <span class="n">worker_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">socket</span><span class="o">.</span><span class="n">gethostname</span><span class="p">()</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">getpid</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="c1"># Use nanosecond here to avoid naming clash when exporting the trace</span>
        <span class="n">file_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">worker_name</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">time</span><span class="o">.</span><span class="n">time_ns</span><span class="p">()</span><span class="si">}</span><span class="s2">.pt.trace.json&quot;</span>
        <span class="k">if</span> <span class="n">use_gzip</span><span class="p">:</span>
            <span class="n">file_name</span> <span class="o">=</span> <span class="n">file_name</span> <span class="o">+</span> <span class="s1">&#39;.gz&#39;</span>
        <span class="n">prof</span><span class="o">.</span><span class="n">export_chrome_trace</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">file_name</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">handler_fn</span></div>


<div class="viewcode-block" id="profile"><a class="viewcode-back" href="../../../profiler.html#torch.profiler.profile">[docs]</a><span class="k">class</span> <span class="nc">profile</span><span class="p">(</span><span class="n">_KinetoProfile</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Profiler context manager.</span>

<span class="sd">    Args:</span>
<span class="sd">        activities (iterable): list of activity groups (CPU, CUDA) to use in profiling, supported values:</span>
<span class="sd">            ``torch.profiler.ProfilerActivity.CPU``, ``torch.profiler.ProfilerActivity.CUDA``.</span>
<span class="sd">            Default value: ProfilerActivity.CPU and (when available) ProfilerActivity.CUDA.</span>
<span class="sd">        schedule (Callable): callable that takes step (int) as a single parameter and returns</span>
<span class="sd">            ``ProfilerAction`` value that specifies the profiler action to perform at each step.</span>
<span class="sd">        on_trace_ready (Callable): callable that is called at each step when ``schedule``</span>
<span class="sd">            returns ``ProfilerAction.RECORD_AND_SAVE`` during the profiling.</span>
<span class="sd">        record_shapes (bool): save information about operator&#39;s input shapes.</span>
<span class="sd">        profile_memory (bool): track tensor memory allocation/deallocation.</span>
<span class="sd">        with_stack (bool): record source information (file and line number) for the ops.</span>
<span class="sd">        with_flops (bool): use formula to estimate the FLOPs (floating point operations) of specific operators</span>
<span class="sd">            (matrix multiplication and 2D convolution).</span>
<span class="sd">        with_modules (bool): record module hierarchy (including function names)</span>
<span class="sd">            corresponding to the callstack of the op. e.g. If module A&#39;s forward call&#39;s</span>
<span class="sd">            module B&#39;s forward which contains an aten::add op,</span>
<span class="sd">            then aten::add&#39;s module hierarchy is A.B</span>
<span class="sd">            Note that this support exist, at the moment, only for TorchScript models</span>
<span class="sd">            and not eager mode models.</span>
<span class="sd">        experimental_config (_ExperimentalConfig) : A set of experimental options</span>
<span class="sd">            used for Kineto library features. Note, backward compatibility is not guaranteed.</span>

<span class="sd">        use_cuda (bool):</span>
<span class="sd">            .. deprecated:: 1.8.1</span>
<span class="sd">                use ``activities`` instead.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Use :func:`~torch.profiler.schedule` to generate the callable schedule.</span>
<span class="sd">        Non-default schedules are useful when profiling long training jobs</span>
<span class="sd">        and allow the user to obtain multiple traces at the different iterations</span>
<span class="sd">        of the training process.</span>
<span class="sd">        The default schedule simply records all the events continuously for the</span>
<span class="sd">        duration of the context manager.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Use :func:`~torch.profiler.tensorboard_trace_handler` to generate result files for TensorBoard:</span>

<span class="sd">        ``on_trace_ready=torch.profiler.tensorboard_trace_handler(dir_name)``</span>

<span class="sd">        After profiling, result files can be found in the specified directory. Use the command:</span>

<span class="sd">        ``tensorboard --logdir dir_name``</span>

<span class="sd">        to see the results in TensorBoard.</span>
<span class="sd">        For more information, see</span>
<span class="sd">        `PyTorch Profiler TensorBoard Plugin &lt;https://github.com/pytorch/kineto/tree/master/tb_plugin&gt;`__</span>

<span class="sd">    .. note::</span>
<span class="sd">        Enabling shape and stack tracing results in additional overhead.</span>
<span class="sd">        When record_shapes=True is specified, profiler will temporarily hold references to the tensors;</span>
<span class="sd">        that may further prevent certain optimizations that depend on the reference count and introduce</span>
<span class="sd">        extra tensor copies.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        with torch.profiler.profile(</span>
<span class="sd">            activities=[</span>
<span class="sd">                torch.profiler.ProfilerActivity.CPU,</span>
<span class="sd">                torch.profiler.ProfilerActivity.CUDA,</span>
<span class="sd">            ]</span>
<span class="sd">        ) as p:</span>
<span class="sd">            code_to_profile()</span>
<span class="sd">        print(p.key_averages().table(</span>
<span class="sd">            sort_by=&quot;self_cuda_time_total&quot;, row_limit=-1))</span>

<span class="sd">    Using the profiler&#39;s ``schedule``, ``on_trace_ready`` and ``step`` functions:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        # Non-default profiler schedule allows user to turn profiler on and off</span>
<span class="sd">        # on different iterations of the training loop;</span>
<span class="sd">        # trace_handler is called every time a new trace becomes available</span>
<span class="sd">        def trace_handler(prof):</span>
<span class="sd">            print(prof.key_averages().table(</span>
<span class="sd">                sort_by=&quot;self_cuda_time_total&quot;, row_limit=-1))</span>
<span class="sd">            # prof.export_chrome_trace(&quot;/tmp/test_trace_&quot; + str(prof.step_num) + &quot;.json&quot;)</span>

<span class="sd">        with torch.profiler.profile(</span>
<span class="sd">            activities=[</span>
<span class="sd">                torch.profiler.ProfilerActivity.CPU,</span>
<span class="sd">                torch.profiler.ProfilerActivity.CUDA,</span>
<span class="sd">            ],</span>

<span class="sd">            # In this example with wait=1, warmup=1, active=2, repeat=1,</span>
<span class="sd">            # profiler will skip the first step/iteration,</span>
<span class="sd">            # start warming up on the second, record</span>
<span class="sd">            # the third and the forth iterations,</span>
<span class="sd">            # after which the trace will become available</span>
<span class="sd">            # and on_trace_ready (when set) is called;</span>
<span class="sd">            # the cycle repeats starting with the next step</span>

<span class="sd">            schedule=torch.profiler.schedule(</span>
<span class="sd">                wait=1,</span>
<span class="sd">                warmup=1,</span>
<span class="sd">                active=2,</span>
<span class="sd">                repeat=1),</span>
<span class="sd">            on_trace_ready=trace_handler</span>
<span class="sd">            # on_trace_ready=torch.profiler.tensorboard_trace_handler(&#39;./log&#39;)</span>
<span class="sd">            # used when outputting for tensorboard</span>
<span class="sd">            ) as p:</span>
<span class="sd">                for iter in range(N):</span>
<span class="sd">                    code_iteration_to_profile(iter)</span>
<span class="sd">                    # send a signal to the profiler that the next iteration has started</span>
<span class="sd">                    p.step()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="o">*</span><span class="p">,</span>
            <span class="n">activities</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Iterable</span><span class="p">[</span><span class="n">ProfilerActivity</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">schedule</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">],</span> <span class="n">ProfilerAction</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">on_trace_ready</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">record_shapes</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">profile_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">with_stack</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">with_flops</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">with_modules</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">experimental_config</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_ExperimentalConfig</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="c1"># deprecated:</span>
            <span class="n">use_cuda</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>

        <span class="n">activities_set</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">activities</span><span class="p">)</span> <span class="k">if</span> <span class="n">activities</span> <span class="k">else</span> <span class="n">supported_activities</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">use_cuda</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warn</span><span class="p">(</span><span class="s2">&quot;use_cuda is deprecated, use activities argument instead&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">use_cuda</span><span class="p">:</span>
                <span class="n">activities_set</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span> <span class="ow">in</span> <span class="n">activities_set</span><span class="p">:</span>
                <span class="n">activities_set</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">ProfilerActivity</span><span class="o">.</span><span class="n">CUDA</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">activities_set</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;No valid profiler activities found&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">activities</span><span class="o">=</span><span class="n">activities</span><span class="p">,</span>
            <span class="n">record_shapes</span><span class="o">=</span><span class="n">record_shapes</span><span class="p">,</span>
            <span class="n">profile_memory</span><span class="o">=</span><span class="n">profile_memory</span><span class="p">,</span>
            <span class="n">with_stack</span><span class="o">=</span><span class="n">with_stack</span><span class="p">,</span>
            <span class="n">with_flops</span><span class="o">=</span><span class="n">with_flops</span><span class="p">,</span>
            <span class="n">with_modules</span><span class="o">=</span><span class="n">with_modules</span><span class="p">,</span>
            <span class="n">experimental_config</span><span class="o">=</span><span class="n">experimental_config</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">schedule</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span> <span class="o">=</span> <span class="n">schedule</span>
            <span class="c1"># add step markers into the trace and table view</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">record_steps</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span> <span class="o">=</span> <span class="n">_default_schedule_fn</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">record_steps</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">on_trace_ready</span> <span class="o">=</span> <span class="n">on_trace_ready</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_num</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_num</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_rec_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">prof</span><span class="o">.</span><span class="n">record_function</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">action_map</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">ProfilerAction</span><span class="p">,</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ProfilerAction</span><span class="p">]],</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c1"># key is (prev_action, current_action), value is action list corresponding to the state pair.</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span><span class="p">):</span> <span class="p">[],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">WARMUP</span><span class="p">):</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prepare_trace</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD</span><span class="p">):</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prepare_trace</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_trace</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD_AND_SAVE</span><span class="p">):</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">prepare_trace</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_trace</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">WARMUP</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span><span class="p">):</span> <span class="p">[</span>
                <span class="n">partial</span><span class="p">(</span><span class="n">warn</span><span class="p">,</span> <span class="s2">&quot;Incorrect schedule: WARMUP followed by NONE&quot;</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start_trace</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stop_trace</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">WARMUP</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">WARMUP</span><span class="p">):</span> <span class="p">[],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">WARMUP</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD</span><span class="p">):</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">start_trace</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">WARMUP</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD_AND_SAVE</span><span class="p">):</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">start_trace</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span><span class="p">):</span> <span class="p">[</span>
                <span class="n">partial</span><span class="p">(</span><span class="n">warn</span><span class="p">,</span> <span class="s2">&quot;Incorrect schedule: RECORD followed by NONE&quot;</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stop_trace</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">WARMUP</span><span class="p">):</span> <span class="p">[</span>
                <span class="n">partial</span><span class="p">(</span><span class="n">warn</span><span class="p">,</span> <span class="s2">&quot;Incorrect schedule: RECORD followed by WARMUP&quot;</span><span class="p">),</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stop_trace</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD</span><span class="p">):</span> <span class="p">[],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD_AND_SAVE</span><span class="p">):</span> <span class="p">[],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD_AND_SAVE</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span><span class="p">):</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stop_trace</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trace_ready</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD_AND_SAVE</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">WARMUP</span><span class="p">):</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stop_trace</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trace_ready</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_trace</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD_AND_SAVE</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD</span><span class="p">):</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stop_trace</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_trace_ready</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">prepare_trace</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start_trace</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD_AND_SAVE</span><span class="p">,</span> <span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD_AND_SAVE</span><span class="p">):</span> <span class="p">[</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">stop_trace</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_trace_ready</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">prepare_trace</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">start_trace</span><span class="p">],</span>
            <span class="c1"># used for exit action</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">WARMUP</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">start_trace</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_trace</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stop_trace</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trace_ready</span><span class="p">],</span>
            <span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">RECORD_AND_SAVE</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">stop_trace</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trace_ready</span><span class="p">]</span>
        <span class="p">}</span>
        <span class="c1"># Start tracking increments to profiler step, this will be used</span>
        <span class="c1"># by Kineto</span>
        <span class="n">prof</span><span class="o">.</span><span class="n">KinetoStepTracker</span><span class="o">.</span><span class="n">init_step_count</span><span class="p">(</span><span class="n">PROFILER_STEP_NAME</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">prof</span><span class="o">.</span><span class="n">_enable_dynamo_cache_lookup_profiler</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exc_type</span><span class="p">,</span> <span class="n">exc_val</span><span class="p">,</span> <span class="n">exc_tb</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
        <span class="n">prof</span><span class="o">.</span><span class="n">_enable_dynamo_cache_lookup_profiler</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">prof</span><span class="o">.</span><span class="n">KinetoStepTracker</span><span class="o">.</span><span class="n">erase_step_count</span><span class="p">(</span><span class="n">PROFILER_STEP_NAME</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_transit_action</span><span class="p">(</span><span class="n">ProfilerAction</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_action</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">record_steps</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step_rec_fn</span> <span class="o">=</span> <span class="n">prof</span><span class="o">.</span><span class="n">record_function</span><span class="p">(</span><span class="s2">&quot;ProfilerStep#&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_num</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step_rec_fn</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">stop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">record_steps</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_rec_fn</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step_rec_fn</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_transit_action</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_action</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<div class="viewcode-block" id="profile.step"><a class="viewcode-back" href="../../../profiler.html#torch.profiler.profile.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Signals the profiler that the next profiling step has started.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">record_steps</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_rec_fn</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step_rec_fn</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">prev_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_action</span>
        <span class="n">cur_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">step_num</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">step_num</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">current_action</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">step_num</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_transit_action</span><span class="p">(</span><span class="n">prev_action</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_action</span><span class="p">)</span>
        <span class="n">prof</span><span class="o">.</span><span class="n">KinetoStepTracker</span><span class="o">.</span><span class="n">increment_step</span><span class="p">(</span><span class="n">PROFILER_STEP_NAME</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">record_steps</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step_rec_fn</span> <span class="o">=</span> <span class="n">prof</span><span class="o">.</span><span class="n">record_function</span><span class="p">(</span><span class="s2">&quot;ProfilerStep#&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cur_step</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step_rec_fn</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span></div>

    <span class="k">def</span> <span class="nf">_trace_ready</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">on_trace_ready</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">on_trace_ready</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_transit_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prev_action</span><span class="p">,</span> <span class="n">current_action</span><span class="p">):</span>
        <span class="n">action_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_map</span><span class="o">.</span><span class="n">get</span><span class="p">((</span><span class="n">prev_action</span><span class="p">,</span> <span class="n">current_action</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">action_list</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">action_list</span><span class="p">:</span>
                <span class="n">action</span><span class="p">()</span></div>



<span class="k">class</span> <span class="nc">ExecutionTraceObserver</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Execution Trace Observer</span>

<span class="sd">    Each process can have a single ExecutionTraceObserver instance. The observer</span>
<span class="sd">    can be added to record function callbacks via calling register_callback()</span>
<span class="sd">    explicitly. Without calling unregister_callback(), repeated calls to</span>
<span class="sd">    register_callback() will not add additional observers to record function</span>
<span class="sd">    callbacks. Once an ExecutionTraceObserver is created, the start() and stop()</span>
<span class="sd">    methods control when the event data is recorded.</span>

<span class="sd">    Deleting or calling unregister_callback() will remove the observer from the</span>
<span class="sd">    record function callbacks, finalize the output file, and will stop</span>
<span class="sd">    incurring any overheads.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initializes the default states.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_registered</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_execution_trace_running</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calls unregister_callback() to make sure to finalize outputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unregister_callback</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">register_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_file_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Adds ET observer to record function callbacks. The the data will be</span>
<span class="sd">        written to output_file_path.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_registered</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_file_path</span> <span class="o">=</span> <span class="n">output_file_path</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_registered</span> <span class="o">=</span> <span class="n">_add_execution_trace_observer</span><span class="p">(</span><span class="n">output_file_path</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">unregister_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Removes ET observer from record function callbacks.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_registered</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
            <span class="n">_remove_execution_trace_observer</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_registered</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">is_registered</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns True if the execution trace observer is registered, otherwise False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_registered</span>

    <span class="k">def</span> <span class="nf">is_running</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns True if the observer is running, otherwise False.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execution_trace_running</span>

    <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Starts to capture.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_registered</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execution_trace_running</span><span class="p">:</span>
            <span class="n">_enable_execution_trace_observer</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_execution_trace_running</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">stop</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Stops to capture.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_execution_trace_running</span><span class="p">:</span>
            <span class="n">_disable_execution_trace_observer</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_execution_trace_running</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">get_output_file_path</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the output file name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_registered</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_file_path</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;A callback to the ET profiler needs to be registered &quot;</span>
                <span class="s2">&quot;first before getting the output file path&quot;</span>
            <span class="p">)</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
         <script src="../../../_static/jquery.js"></script>
         <script src="../../../_static/underscore.js"></script>
         <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../_static/doctools.js"></script>
         <script src="../../../_static/sphinx_highlight.js"></script>
         <script src="../../../_static/clipboard.min.js"></script>
         <script src="../../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>