


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.ao.ns._numeric_suite_fx &mdash; PyTorch main documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/ao/ns/_numeric_suite_fx.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sphinx-dropdown.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/panels-bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />

<!--
  Search engines should not index the main version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>main (2.1.0a0+git707d265 ) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          

<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/_modules/torch/ao/ns/_numeric_suite_fx.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/build_ci_governance.html">PyTorch Governance | Build + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/design.html">PyTorch Design Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/governance.html">PyTorch Governance | Mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/persons_of_interest.html">PyTorch Governance | Maintainers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/amp_examples.html">CUDA Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.func.html">Extending torch.func with autograd.Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">torch.compile</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/index.html">torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/get-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/troubleshooting.html">PyTorch 2.0 Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/technical-overview.html">Technical Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/guards-overview.html">Guards Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/custom-backends.html">Custom Backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/fine_grained_apis.html">TorchDynamo APIs to control fine-grained tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/profiling_torch_compile.html">Profiling to understand torch.compile performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/inductor_profiling.html">TorchInductor GPU Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/deep-dive.html">TorchDynamo Deeper Dive</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/cudagraph_trees.html">CUDAGraph Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/performance-dashboard.html">PyTorch 2.0 Performance Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/torchfunc-and-torchcompile.html">torch.func interaction with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ir.html">IRs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/dynamic-shapes.html">Dynamic shapes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/fake-tensor.html">Fake tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../logging.html">torch._logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compile/transformations.html">Writing Graph Transformations on ATen IR</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../export.html">torch._export.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx_diagnostics.html">torch.onnx diagnostics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../logging.html">torch._logging</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
          <li><a href="../../../torch.html">torch</a> &gt;</li>
        
      <li>torch.ao.ns._numeric_suite_fx</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.ao.ns._numeric_suite_fx</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This module contains tooling to compare weights and activations</span>
<span class="sd">across models. Example usage::</span>

<span class="sd">    import copy</span>
<span class="sd">    import torch</span>
<span class="sd">    import torch.ao.quantization.quantize_fx as quantize_fx</span>
<span class="sd">    import torch.ao.ns._numeric_suite_fx as ns</span>

<span class="sd">    m = torch.nn.Sequential(torch.nn.Conv2d(1, 1, 1)).eval()</span>
<span class="sd">    mp = quantize_fx.prepare_fx(m, {&#39;&#39;: torch.ao.quantization.default_qconfig})</span>
<span class="sd">    # We convert a copy because we need the original prepared model</span>
<span class="sd">    # to be available for comparisons, and `quantize_fx.convert_fx` is inplace.</span>
<span class="sd">    mq = quantize_fx.convert_fx(copy.deepcopy(mp))</span>

<span class="sd">    #</span>
<span class="sd">    # Comparing weights</span>
<span class="sd">    #</span>

<span class="sd">    # extract weight pairs</span>
<span class="sd">    weight_comparison = ns.extract_weights(&#39;a&#39;, mp, &#39;b&#39;, mq)</span>

<span class="sd">    # add SQNR for each comparison, inplace</span>
<span class="sd">    ns.extend_logger_results_with_comparison(</span>
<span class="sd">        weight_comparison, &#39;a&#39;, &#39;b&#39;, torch.ao.ns.fx.utils.compute_sqnr,</span>
<span class="sd">        &#39;sqnr&#39;)</span>

<span class="sd">    # weight_comparison contains the weights from `mp` and `mq` stored</span>
<span class="sd">    # in pairs, and can be used for further analysis.</span>


<span class="sd">    #</span>
<span class="sd">    # Comparing activations, with error propagation</span>
<span class="sd">    #</span>

<span class="sd">    # add loggers</span>
<span class="sd">    mp_ns, mq_ns = ns.add_loggers(</span>
<span class="sd">        &#39;a&#39;, copy.deepcopy(mp),</span>
<span class="sd">        &#39;b&#39;, copy.deepcopy(mq),</span>
<span class="sd">        ns.OutputLogger)</span>

<span class="sd">    # send an example datum to capture intermediate activations</span>
<span class="sd">    datum = torch.randn(1, 1, 1, 1)</span>
<span class="sd">    mp_ns(datum)</span>
<span class="sd">    mq_ns(datum)</span>

<span class="sd">    # extract intermediate activations</span>
<span class="sd">    act_comparison = ns.extract_logger_info(</span>
<span class="sd">        mp_ns, mq_ns, ns.OutputLogger, &#39;b&#39;)</span>

<span class="sd">    # add SQNR for each comparison, inplace</span>
<span class="sd">    ns.extend_logger_results_with_comparison(</span>
<span class="sd">        act_comparison, &#39;a&#39;, &#39;b&#39;, torch.ao.ns.fx.utils.compute_sqnr,</span>
<span class="sd">        &#39;sqnr&#39;)</span>

<span class="sd">    # act_comparison contains the activations from `mp_ns` and `mq_ns` stored</span>
<span class="sd">    # in pairs, and can be used for further analysis.</span>

<span class="sd">    #</span>
<span class="sd">    # Comparing activations, without error propagation</span>
<span class="sd">    #</span>

<span class="sd">    # create shadow model</span>
<span class="sd">    mp_shadows_mq = ns.add_shadow_loggers(</span>
<span class="sd">        &#39;a&#39;, copy.deepcopy(mp),</span>
<span class="sd">        &#39;b&#39;, copy.deepcopy(mq),</span>
<span class="sd">        ns.OutputLogger)</span>

<span class="sd">    # send an example datum to capture intermediate activations</span>
<span class="sd">    datum = torch.randn(1, 1, 1, 1)</span>
<span class="sd">    mp_shadows_mq(datum)</span>

<span class="sd">    # extract intermediate activations</span>
<span class="sd">    shadow_act_comparison = ns.extract_shadow_logger_info(</span>
<span class="sd">        mp_shadows_mq, ns.OutputLogger, &#39;b&#39;)</span>

<span class="sd">    # add SQNR for each comparison, inplace</span>
<span class="sd">    ns.extend_logger_results_with_comparison(</span>
<span class="sd">        shadow_act_comparison, &#39;a&#39;, &#39;b&#39;, torch.ao.ns.fx.utils.compute_sqnr,</span>
<span class="sd">        &#39;sqnr&#39;)</span>

<span class="sd">    # shadow_act_comparison contains the activations from `mp_ns` and `mq_ns` stored</span>
<span class="sd">    # in pairs, and can be used for further analysis.</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">collections</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.ao.quantization.quantize_fx</span> <span class="k">as</span> <span class="nn">quantize_fx</span>
<span class="kn">from</span> <span class="nn">torch.fx</span> <span class="kn">import</span> <span class="n">GraphModule</span>
<span class="kn">from</span> <span class="nn">torch.fx.graph</span> <span class="kn">import</span> <span class="n">Node</span>
<span class="kn">from</span> <span class="nn">torch.ao.ns.fx.mappings</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_base_name_to_sets_of_related_ops</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torch.ao.ns.fx.graph_matcher</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_matching_subgraph_pairs</span><span class="p">,</span>
    <span class="n">get_type_a_related_to_b</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">.fx.weight_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">extract_weight_from_node</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">.fx.graph_passes</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">add_loggers_to_model</span><span class="p">,</span>
    <span class="n">create_a_shadows_b</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">.fx.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">rekey_logger_info_on_node_name_of_model</span><span class="p">,</span>
    <span class="n">maybe_add_missing_fqns</span><span class="p">,</span>
    <span class="n">get_target_type_str</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">.fx.ns_types</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">NSSingleResultValuesType</span><span class="p">,</span>
    <span class="n">NSResultsType</span><span class="p">,</span>
    <span class="n">NSNodeTargetType</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torch.ao.quantization.backend_config.utils</span> <span class="kn">import</span> <span class="n">get_fusion_pattern_to_root_node_getter</span>
<span class="kn">from</span> <span class="nn">torch.ao.quantization.backend_config</span> <span class="kn">import</span> <span class="n">BackendConfig</span>
<span class="kn">from</span> <span class="nn">torch.ao.quantization.fx.match_utils</span> <span class="kn">import</span> <span class="n">_find_matches</span>
<span class="kn">from</span> <span class="nn">torch.ao.quantization.fx.graph_module</span> <span class="kn">import</span> <span class="n">_get_observed_graph_module_attr</span>
<span class="kn">from</span> <span class="nn">torch.ao.quantization.fx.qconfig_mapping_utils</span> <span class="kn">import</span> <span class="n">_generate_node_name_to_qconfig</span>
<span class="kn">from</span> <span class="nn">torch.ao.quantization.fx.quantize_handler</span> <span class="kn">import</span> <span class="n">_get_pattern_to_quantize_handlers</span>
<span class="kn">from</span> <span class="nn">torch.ao.quantization.qconfig</span> <span class="kn">import</span> <span class="n">QConfigAny</span>
<span class="kn">from</span> <span class="nn">torch.ao.quantization</span> <span class="kn">import</span> <span class="n">QConfigMapping</span>
<span class="kn">from</span> <span class="nn">torch.ao.ns.fx.n_shadows_utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OutputProp</span><span class="p">,</span>
    <span class="n">_get_dedup_subgraphs</span><span class="p">,</span>
    <span class="n">SHADOW_WRAPPER_NODE_NAME_PREFIX</span><span class="p">,</span>
    <span class="n">group_results_by_subgraph</span><span class="p">,</span>
    <span class="n">create_results_comparison</span><span class="p">,</span>
    <span class="n">print_n_shadows_summary</span><span class="p">,</span>
    <span class="n">create_n_transformed_and_logged_copies_of_subgraph</span><span class="p">,</span>
    <span class="n">create_add_loggers_graph</span><span class="p">,</span>
    <span class="n">extract_weight_comparison</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">torch.ao.ns.fx.qconfig_multi_mapping</span> <span class="kn">import</span> <span class="n">QConfigMultiMapping</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Type</span>

<span class="n">RNNReturnType</span> <span class="o">=</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span>

<div class="viewcode-block" id="OutputLogger"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputLogger">[docs]</a><span class="k">class</span> <span class="nc">OutputLogger</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for capturing intermediate values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">stats</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
    <span class="n">stats_rnn</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">RNNReturnType</span><span class="p">]</span>

    <span class="c1"># Mark as impure so that calls to it will not be removed during DCE.</span>
    <span class="n">_is_impure</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">ref_node_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">prev_node_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">ref_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">prev_node_target_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">ref_node_target_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">results_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">index_within_arg</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">index_of_arg</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">fqn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">qconfig_str</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stats</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stats_rnn</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">RNNReturnType</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># name of the node which was responsible for adding this logger</span>
        <span class="c1"># Note:</span>
        <span class="c1"># - if we are logging node outputs, this is the same as prev_node_name</span>
        <span class="c1"># - if we are logging node inputs, this is the name of the node</span>
        <span class="c1">#   whose input this logger is logging.</span>
        <span class="c1">#</span>
        <span class="c1"># example, where logger1 is logging input of op1 and logger2 is logging</span>
        <span class="c1">#    the output of op1:</span>
        <span class="c1">#</span>
        <span class="c1">#  x1 -&gt; logger1 -&gt; op1 -&gt; logger2 -&gt; x2</span>
        <span class="c1">#</span>
        <span class="c1"># in this example,</span>
        <span class="c1">#   - logger1&#39;s prev_node_name is x1 and ref_node_name is op1</span>
        <span class="c1">#   - logger2&#39;s prev_node_name is op1 and ref_node_name is op1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_node_name</span> <span class="o">=</span> <span class="n">ref_node_name</span>
        <span class="c1"># name of the node whose output this Logger is capturing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_node_name</span> <span class="o">=</span> <span class="n">prev_node_name</span>

        <span class="c1"># name of the model from which the node originated from</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
        <span class="c1"># reference name, used to match loggers from separate models</span>
        <span class="c1"># to each other</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_name</span> <span class="o">=</span> <span class="n">ref_name</span>
        <span class="c1"># type of the target of the node whose output this logger is logging</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prev_node_target_type</span> <span class="o">=</span> <span class="n">prev_node_target_type</span>
        <span class="c1"># type of the target of the node which was responsible for adding this</span>
        <span class="c1"># logger</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ref_node_target_type</span> <span class="o">=</span> <span class="n">ref_node_target_type</span>
        <span class="c1"># what kind of values are inside of stats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">results_type</span> <span class="o">=</span> <span class="n">results_type</span>
        <span class="c1"># index of this node within the arg of the input/output node</span>
        <span class="c1"># for example, in cat([x1, x2, x3], dim=0), x2 would have index_within_arg == 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_within_arg</span> <span class="o">=</span> <span class="n">index_within_arg</span>
        <span class="c1"># index of this node within the args of the input/output node</span>
        <span class="c1"># for example, in add(x1, x2), x2 would have index_of_arg == 1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_of_arg</span> <span class="o">=</span> <span class="n">index_of_arg</span>
        <span class="c1"># fully qualified name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fqn</span> <span class="o">=</span> <span class="n">fqn</span>
        <span class="c1"># if loggers are added before prepare_fx, but we do not want</span>
        <span class="c1"># collect results of calibration, only results after convert_fx</span>
        <span class="c1"># so, we add a flag to control whether this logger collects data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="c1"># string representation of qconfig</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qconfig_str</span> <span class="o">=</span> <span class="n">qconfig_str</span>
        <span class="c1"># this can be turned off to reduce memory usage during calibration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_activations</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Note: cannot annotate the type of x because TorchScript does not support</span>
    <span class="c1">#   the Union type.</span>
<div class="viewcode-block" id="OutputLogger.forward"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputLogger.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># blank docblock to make autodoc happy</span>
        <span class="c1"># TODO(future PR): consider designing this better, as the difference</span>
        <span class="c1"># between these two flags is subtle and not obvious.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_activations</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="c1"># TODO(future PR): consider refactoring this to better reuse the parent</span>
        <span class="c1"># class</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">new_res</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stats_rnn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_res</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">clean_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="c1"># skip nn.Module keys</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">k</span> <span class="o">!=</span> <span class="s1">&#39;training&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;OutputLogger(</span><span class="si">{</span><span class="n">clean_dict</span><span class="si">}</span><span class="s2">)&quot;</span></div>


<div class="viewcode-block" id="OutputComparisonLogger"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputComparisonLogger">[docs]</a><span class="k">class</span> <span class="nc">OutputComparisonLogger</span><span class="p">(</span><span class="n">OutputLogger</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Same as OutputLogger, but also requires the original activation</span>
<span class="sd">    in order to calculate the comparison at calibration time</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># TODO(future PR): make the comparison function configurable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">comparison_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ao</span><span class="o">.</span><span class="n">ns</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">compute_sqnr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">comparison_fn_name</span> <span class="o">=</span> <span class="s1">&#39;sqnr&#39;</span>
        <span class="c1"># precalculated comparisons of logger output versus reference</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">comparisons</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># precalculated comparisons function</span>

<div class="viewcode-block" id="OutputComparisonLogger.forward"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputComparisonLogger.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x_ref</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># blank docblock to make autodoc happy</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">enabled</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">),</span> <span class="s1">&#39;non-tensor inputs not yet supported&#39;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_activations</span><span class="p">:</span>
            <span class="c1"># save the activation, for debugging</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
        <span class="c1"># save the comparison</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">comparisons</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">comparison_fn</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x_ref</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">x</span></div>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">clean_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">k</span><span class="p">:</span> <span class="n">v</span>
            <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="c1"># skip nn.Module keys</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">k</span> <span class="o">!=</span> <span class="s1">&#39;training&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;OutputComparisonLogger(</span><span class="si">{</span><span class="n">clean_dict</span><span class="si">}</span><span class="s2">)&quot;</span></div>


<div class="viewcode-block" id="NSTracer"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.NSTracer">[docs]</a><span class="k">class</span> <span class="nc">NSTracer</span><span class="p">(</span><span class="n">quantize_fx</span><span class="o">.</span><span class="n">QuantizationTracer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Just like a regular FX quantization tracer, but treats observers and fake_quantize</span>
<span class="sd">    modules as leaf modules.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="NSTracer.is_leaf_module"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.NSTracer.is_leaf_module">[docs]</a>    <span class="k">def</span> <span class="nf">is_leaf_module</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">m</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">module_qualified_name</span> <span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>  <span class="c1"># blank docblock to make autodoc happy</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ao</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">ObserverBase</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">ao</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">FakeQuantizeBase</span><span class="p">):</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">is_leaf_module</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">module_qualified_name</span><span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">_extract_weights_one_model</span><span class="p">(</span>
    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">nodes_and_names_to_instrument</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span>
    <span class="n">results</span><span class="p">:</span> <span class="n">NSResultsType</span><span class="p">,</span>
    <span class="n">op_to_type_to_weight_extraction_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;quantization_api._numeric_suite_fx._extract_weights_one_model&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">ref_name</span> <span class="ow">in</span> <span class="n">nodes_and_names_to_instrument</span><span class="p">:</span>
        <span class="n">res_type</span> <span class="o">=</span> <span class="n">NSSingleResultValuesType</span><span class="o">.</span><span class="n">WEIGHT</span><span class="o">.</span><span class="n">value</span>
        <span class="n">extracted_weight</span> <span class="o">=</span> <span class="n">extract_weight_from_node</span><span class="p">(</span>
            <span class="n">node</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">op_to_type_to_weight_extraction_fn</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">extracted_weight</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ref_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
                <span class="n">results</span><span class="p">[</span><span class="n">ref_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="n">res_type</span><span class="p">:</span> <span class="p">{}}</span>
            <span class="n">results</span><span class="p">[</span><span class="n">ref_name</span><span class="p">][</span><span class="n">res_type</span><span class="p">][</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">extracted_weight</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_extract_weights_impl</span><span class="p">(</span>
    <span class="n">model_name_a</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">gm_a</span><span class="p">:</span> <span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">model_name_b</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">gm_b</span><span class="p">:</span> <span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">base_name_to_sets_of_related_ops</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">unmatchable_types_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">op_to_type_to_weight_extraction_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NSResultsType</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;quantization_api._numeric_suite_fx._extract_weights_impl&quot;</span><span class="p">)</span>
    <span class="n">matched_subgraph_pairs</span> <span class="o">=</span> <span class="n">get_matching_subgraph_pairs</span><span class="p">(</span>
        <span class="n">gm_a</span><span class="p">,</span> <span class="n">gm_b</span><span class="p">,</span> <span class="n">base_name_to_sets_of_related_ops</span><span class="p">,</span>
        <span class="n">unmatchable_types_map</span><span class="p">)</span>

    <span class="c1"># split the subgraph pairs into one data structure for each model</span>
    <span class="n">nodes_and_names_to_instrument_a</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">nodes_and_names_to_instrument_b</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">match_name</span><span class="p">,</span> <span class="n">match</span> <span class="ow">in</span> <span class="n">matched_subgraph_pairs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">subgraph_a</span><span class="p">,</span> <span class="n">subgraph_b</span> <span class="o">=</span> <span class="n">match</span>
        <span class="n">nodes_and_names_to_instrument_a</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">subgraph_a</span><span class="o">.</span><span class="n">base_op_node</span><span class="p">,</span> <span class="n">match_name</span><span class="p">))</span>
        <span class="n">nodes_and_names_to_instrument_b</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">subgraph_b</span><span class="o">.</span><span class="n">base_op_node</span><span class="p">,</span> <span class="n">match_name</span><span class="p">))</span>

    <span class="c1"># populate the results, one model at a time</span>
    <span class="n">results</span><span class="p">:</span> <span class="n">NSResultsType</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">_extract_weights_one_model</span><span class="p">(</span>
        <span class="n">model_name_a</span><span class="p">,</span> <span class="n">gm_a</span><span class="p">,</span> <span class="n">nodes_and_names_to_instrument_a</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span>
        <span class="n">op_to_type_to_weight_extraction_fn</span><span class="p">)</span>
    <span class="n">_extract_weights_one_model</span><span class="p">(</span>
        <span class="n">model_name_b</span><span class="p">,</span> <span class="n">gm_b</span><span class="p">,</span> <span class="n">nodes_and_names_to_instrument_b</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span>
        <span class="n">op_to_type_to_weight_extraction_fn</span><span class="p">)</span>

    <span class="c1"># fill in missing fqn entries</span>
    <span class="n">maybe_add_missing_fqns</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

    <span class="c1"># rekey on names of nodes in gm_b</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">rekey_logger_info_on_node_name_of_model</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">model_name_b</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span>


<div class="viewcode-block" id="extract_weights"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_weights">[docs]</a><span class="k">def</span> <span class="nf">extract_weights</span><span class="p">(</span>
    <span class="n">model_name_a</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model_a</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">model_name_b</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model_b</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">base_name_to_sets_of_related_ops</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">unmatchable_types_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">op_to_type_to_weight_extraction_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Callable</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NSResultsType</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract weights from model A and model B, and return a comparison.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_name_a: string name of model A to use in results</span>
<span class="sd">        model_a: model A</span>
<span class="sd">        model_name_b: string name of model B to use in results</span>
<span class="sd">        model_b: model B</span>
<span class="sd">        base_name_to_sets_of_related_ops: optional override of subgraph base nodes, subject to change</span>
<span class="sd">        unmatchable_types_map: optional override of unmatchable types, subject to change</span>
<span class="sd">        op_to_type_to_weight_extraction_fn: optional override of function which extracts weight</span>
<span class="sd">            from a type, subject to change</span>

<span class="sd">    Return:</span>
<span class="sd">        NSResultsType, containing the weight comparisons</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;quantization_api._numeric_suite_fx.extract_weights&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">base_name_to_sets_of_related_ops</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">base_name_to_sets_of_related_ops</span> <span class="o">=</span> \
            <span class="n">get_base_name_to_sets_of_related_ops</span><span class="p">()</span>
    <span class="n">type_a_related_to_b</span> <span class="o">=</span> \
        <span class="n">get_type_a_related_to_b</span><span class="p">(</span><span class="n">base_name_to_sets_of_related_ops</span><span class="p">)</span>

    <span class="c1"># TODO(future PR): expose these</span>
    <span class="n">skipped_module_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">skipped_module_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">tracer_a</span> <span class="o">=</span> <span class="n">NSTracer</span><span class="p">(</span><span class="n">skipped_module_names</span><span class="p">,</span> <span class="n">skipped_module_classes</span><span class="p">)</span>
    <span class="n">tracer_b</span> <span class="o">=</span> <span class="n">NSTracer</span><span class="p">(</span><span class="n">skipped_module_names</span><span class="p">,</span> <span class="n">skipped_module_classes</span><span class="p">)</span>
    <span class="n">gm_a</span> <span class="o">=</span> <span class="n">GraphModule</span><span class="p">(</span><span class="n">model_a</span><span class="p">,</span> <span class="n">tracer_a</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model_a</span><span class="p">))</span>
    <span class="n">maybe_model_a_node_name_to_scope</span> <span class="o">=</span> <span class="n">_get_observed_graph_module_attr</span><span class="p">(</span><span class="n">model_a</span><span class="p">,</span> <span class="s1">&#39;node_name_to_scope&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">maybe_model_a_node_name_to_scope</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gm_a</span><span class="o">.</span><span class="n">_node_name_to_scope</span> <span class="o">=</span> <span class="n">maybe_model_a_node_name_to_scope</span>
    <span class="n">gm_b</span> <span class="o">=</span> <span class="n">GraphModule</span><span class="p">(</span><span class="n">model_b</span><span class="p">,</span> <span class="n">tracer_b</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model_b</span><span class="p">))</span>
    <span class="n">maybe_model_b_node_name_to_scope</span> <span class="o">=</span> <span class="n">_get_observed_graph_module_attr</span><span class="p">(</span><span class="n">model_b</span><span class="p">,</span> <span class="s1">&#39;node_name_to_scope&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">maybe_model_b_node_name_to_scope</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gm_b</span><span class="o">.</span><span class="n">_node_name_to_scope</span> <span class="o">=</span> <span class="n">maybe_model_b_node_name_to_scope</span>
    <span class="k">return</span> <span class="n">_extract_weights_impl</span><span class="p">(</span>
        <span class="n">model_name_a</span><span class="p">,</span> <span class="n">gm_a</span><span class="p">,</span> <span class="n">model_name_b</span><span class="p">,</span> <span class="n">gm_b</span><span class="p">,</span> <span class="n">base_name_to_sets_of_related_ops</span><span class="p">,</span>
        <span class="n">unmatchable_types_map</span><span class="p">,</span> <span class="n">op_to_type_to_weight_extraction_fn</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_add_loggers_one_model</span><span class="p">(</span>
    <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">nodes_and_names_to_instrument_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span>
    <span class="n">nodes_and_names_to_instrument_outputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span>
    <span class="n">logger_cls</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;quantization_api._numeric_suite_fx._add_loggers_one_model&quot;</span><span class="p">)</span>

    <span class="c1"># TODO(future PR): do not observe nodes we do not care</span>
    <span class="c1">#   about (both fp32, denylist, etc)</span>
    <span class="n">node_to_instrument_inputs_to_ref_name</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">node_to_instrument_outputs_to_ref_name</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="n">Node</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">ref_name</span><span class="p">,</span> <span class="n">ref_node_type</span> <span class="ow">in</span> <span class="n">nodes_and_names_to_instrument_inputs</span><span class="p">:</span>
        <span class="n">node_to_instrument_inputs_to_ref_name</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ref_name</span><span class="p">,</span> <span class="n">ref_node_type</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">ref_name</span><span class="p">,</span> <span class="n">ref_node_type</span> <span class="ow">in</span> <span class="n">nodes_and_names_to_instrument_outputs</span><span class="p">:</span>
        <span class="n">node_to_instrument_outputs_to_ref_name</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">ref_name</span><span class="p">,</span> <span class="n">ref_node_type</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">add_loggers_to_model</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">node_to_instrument_inputs_to_ref_name</span><span class="p">,</span>
        <span class="n">node_to_instrument_outputs_to_ref_name</span><span class="p">,</span> <span class="n">logger_cls</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">_add_loggers_impl</span><span class="p">(</span>
    <span class="n">name_a</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">gm_a</span><span class="p">:</span> <span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">name_b</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">gm_b</span><span class="p">:</span> <span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">logger_cls</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">should_log_inputs</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">base_name_to_sets_of_related_ops</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">unmatchable_types_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;quantization_api._numeric_suite_fx._add_loggers_impl&quot;</span><span class="p">)</span>
    <span class="n">matched_subgraph_pairs</span> <span class="o">=</span> <span class="n">get_matching_subgraph_pairs</span><span class="p">(</span>
        <span class="n">gm_a</span><span class="p">,</span> <span class="n">gm_b</span><span class="p">,</span>
        <span class="n">base_name_to_sets_of_related_ops</span><span class="p">,</span> <span class="n">unmatchable_types_map</span><span class="p">)</span>
    <span class="n">nodes_and_names_to_instrument_inputs_a</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">nodes_and_names_to_instrument_inputs_b</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">nodes_and_names_to_instrument_outputs_a</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">nodes_and_names_to_instrument_outputs_b</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">match_name</span><span class="p">,</span> <span class="p">(</span><span class="n">subgraph_a</span><span class="p">,</span> <span class="n">subgraph_b</span><span class="p">)</span> <span class="ow">in</span> <span class="n">matched_subgraph_pairs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">ref_node_type_a</span> <span class="o">=</span> <span class="n">get_target_type_str</span><span class="p">(</span><span class="n">subgraph_a</span><span class="o">.</span><span class="n">base_op_node</span><span class="p">,</span> <span class="n">gm_a</span><span class="p">)</span>
        <span class="n">ref_node_type_b</span> <span class="o">=</span> <span class="n">get_target_type_str</span><span class="p">(</span><span class="n">subgraph_b</span><span class="o">.</span><span class="n">base_op_node</span><span class="p">,</span> <span class="n">gm_b</span><span class="p">)</span>
        <span class="c1"># Note: for matching inputs we use start_node, such as observing</span>
        <span class="c1"># the input of linear in linear-relu</span>
        <span class="k">if</span> <span class="n">should_log_inputs</span><span class="p">:</span>
            <span class="n">nodes_and_names_to_instrument_inputs_a</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">(</span><span class="n">subgraph_a</span><span class="o">.</span><span class="n">start_node</span><span class="p">,</span> <span class="n">match_name</span><span class="p">,</span> <span class="n">ref_node_type_a</span><span class="p">))</span>
            <span class="n">nodes_and_names_to_instrument_inputs_b</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">(</span><span class="n">subgraph_b</span><span class="o">.</span><span class="n">start_node</span><span class="p">,</span> <span class="n">match_name</span><span class="p">,</span> <span class="n">ref_node_type_b</span><span class="p">))</span>
        <span class="c1"># Note: for matching activations we always use end_node,</span>
        <span class="c1"># such as observing the output of relu in linear-relu</span>
        <span class="n">nodes_and_names_to_instrument_outputs_a</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">(</span><span class="n">subgraph_a</span><span class="o">.</span><span class="n">end_node</span><span class="p">,</span> <span class="n">match_name</span><span class="p">,</span> <span class="n">ref_node_type_a</span><span class="p">))</span>
        <span class="n">nodes_and_names_to_instrument_outputs_b</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">(</span><span class="n">subgraph_b</span><span class="o">.</span><span class="n">end_node</span><span class="p">,</span> <span class="n">match_name</span><span class="p">,</span> <span class="n">ref_node_type_b</span><span class="p">))</span>

    <span class="n">new_model_a</span> <span class="o">=</span> <span class="n">_add_loggers_one_model</span><span class="p">(</span>
        <span class="n">name_a</span><span class="p">,</span> <span class="n">gm_a</span><span class="p">,</span> <span class="n">nodes_and_names_to_instrument_inputs_a</span><span class="p">,</span>
        <span class="n">nodes_and_names_to_instrument_outputs_a</span><span class="p">,</span> <span class="n">logger_cls</span><span class="p">)</span>
    <span class="n">new_model_b</span> <span class="o">=</span> <span class="n">_add_loggers_one_model</span><span class="p">(</span>
        <span class="n">name_b</span><span class="p">,</span> <span class="n">gm_b</span><span class="p">,</span> <span class="n">nodes_and_names_to_instrument_inputs_b</span><span class="p">,</span>
        <span class="n">nodes_and_names_to_instrument_outputs_b</span><span class="p">,</span> <span class="n">logger_cls</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">new_model_a</span><span class="p">,</span> <span class="n">new_model_b</span><span class="p">)</span>


<div class="viewcode-block" id="add_loggers"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.add_loggers">[docs]</a><span class="k">def</span> <span class="nf">add_loggers</span><span class="p">(</span>
    <span class="n">name_a</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model_a</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">name_b</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model_b</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">logger_cls</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">should_log_inputs</span> <span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">base_name_to_sets_of_related_ops</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">unmatchable_types_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Instrument model A and model B with loggers.</span>

<span class="sd">    Args:</span>
<span class="sd">        name_a: string name of model A to use in results</span>
<span class="sd">        model_a: model A</span>
<span class="sd">        name_b: string name of model B to use in results</span>
<span class="sd">        model_b: model B</span>
<span class="sd">        logger_cls: class of Logger to use</span>
<span class="sd">        base_name_to_sets_of_related_ops: optional override of subgraph base nodes, subject to change</span>
<span class="sd">        unmatchable_types_map: optional override of unmatchable types, subject to change</span>

<span class="sd">    Return:</span>
<span class="sd">        Returns a tuple of (model_a_with_loggers, model_b_with_loggers).  Modifies both models inplace.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;quantization_api._numeric_suite_fx.add_loggers&quot;</span><span class="p">)</span>
    <span class="c1"># TODO(future PR): expose these</span>
    <span class="n">skipped_module_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">skipped_module_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">tracer_a</span> <span class="o">=</span> <span class="n">NSTracer</span><span class="p">(</span><span class="n">skipped_module_names</span><span class="p">,</span> <span class="n">skipped_module_classes</span><span class="p">)</span>
    <span class="n">tracer_b</span> <span class="o">=</span> <span class="n">NSTracer</span><span class="p">(</span><span class="n">skipped_module_names</span><span class="p">,</span> <span class="n">skipped_module_classes</span><span class="p">)</span>
    <span class="n">gm_a</span> <span class="o">=</span> <span class="n">GraphModule</span><span class="p">(</span><span class="n">model_a</span><span class="p">,</span> <span class="n">tracer_a</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model_a</span><span class="p">))</span>
    <span class="n">maybe_model_a_node_name_to_scope</span> <span class="o">=</span> <span class="n">_get_observed_graph_module_attr</span><span class="p">(</span><span class="n">model_a</span><span class="p">,</span> <span class="s1">&#39;node_name_to_scope&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">maybe_model_a_node_name_to_scope</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gm_a</span><span class="o">.</span><span class="n">_node_name_to_scope</span> <span class="o">=</span> <span class="n">maybe_model_a_node_name_to_scope</span>
    <span class="n">gm_b</span> <span class="o">=</span> <span class="n">GraphModule</span><span class="p">(</span><span class="n">model_b</span><span class="p">,</span> <span class="n">tracer_b</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model_b</span><span class="p">))</span>
    <span class="n">maybe_model_b_node_name_to_scope</span> <span class="o">=</span> <span class="n">_get_observed_graph_module_attr</span><span class="p">(</span><span class="n">model_b</span><span class="p">,</span> <span class="s1">&#39;node_name_to_scope&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">maybe_model_b_node_name_to_scope</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gm_b</span><span class="o">.</span><span class="n">_node_name_to_scope</span> <span class="o">=</span> <span class="n">maybe_model_b_node_name_to_scope</span>
    <span class="k">return</span> <span class="n">_add_loggers_impl</span><span class="p">(</span>
        <span class="n">name_a</span><span class="p">,</span> <span class="n">gm_a</span><span class="p">,</span> <span class="n">name_b</span><span class="p">,</span> <span class="n">gm_b</span><span class="p">,</span> <span class="n">logger_cls</span><span class="p">,</span>
        <span class="n">should_log_inputs</span><span class="o">=</span><span class="n">should_log_inputs</span><span class="p">,</span>
        <span class="n">base_name_to_sets_of_related_ops</span><span class="o">=</span><span class="n">base_name_to_sets_of_related_ops</span><span class="p">,</span>
        <span class="n">unmatchable_types_map</span><span class="o">=</span><span class="n">unmatchable_types_map</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_extract_logger_info_one_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">results</span><span class="p">:</span> <span class="n">NSResultsType</span><span class="p">,</span>
    <span class="n">logger_cls</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;quantization_api._numeric_suite_fx._extract_logger_info_one_model&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">gm_name</span><span class="p">,</span> <span class="n">mod</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="c1"># TODO(future PR): better check when scripted</span>
        <span class="n">is_logger</span> <span class="o">=</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">logger_cls</span><span class="p">)</span>  <span class="c1"># type: ignore[arg-type]</span>
            <span class="ow">or</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">RecursiveScriptModule</span><span class="p">)</span>
                <span class="ow">and</span> <span class="n">mod</span><span class="o">.</span><span class="n">original_name</span> <span class="o">==</span> <span class="s1">&#39;OutputLogger&#39;</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">is_logger</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">ref_name</span>
            <span class="k">if</span> <span class="n">key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
                <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">assert</span> <span class="n">mod</span><span class="o">.</span><span class="n">model_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> \
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mod</span><span class="o">.</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> is already present in results&quot;</span>
            <span class="k">if</span> <span class="n">mod</span><span class="o">.</span><span class="n">results_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">]:</span>
                <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">mod</span><span class="o">.</span><span class="n">results_type</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">if</span> <span class="n">mod</span><span class="o">.</span><span class="n">model_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">mod</span><span class="o">.</span><span class="n">results_type</span><span class="p">]:</span>
                <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">mod</span><span class="o">.</span><span class="n">results_type</span><span class="p">][</span><span class="n">mod</span><span class="o">.</span><span class="n">model_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">stats_to_use</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">stats</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">stats_rnn</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">stats_to_use</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">stats_rnn</span>
            <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">mod</span><span class="o">.</span><span class="n">results_type</span><span class="p">,</span>
                <span class="s1">&#39;values&#39;</span><span class="p">:</span> <span class="n">stats_to_use</span><span class="p">,</span>
                <span class="s1">&#39;ref_node_name&#39;</span><span class="p">:</span> <span class="n">mod</span><span class="o">.</span><span class="n">ref_node_name</span><span class="p">,</span>
                <span class="s1">&#39;ref_node_target_type&#39;</span><span class="p">:</span> <span class="n">mod</span><span class="o">.</span><span class="n">ref_node_target_type</span><span class="p">,</span>
                <span class="s1">&#39;prev_node_name&#39;</span><span class="p">:</span> <span class="n">mod</span><span class="o">.</span><span class="n">prev_node_name</span><span class="p">,</span>
                <span class="s1">&#39;prev_node_target_type&#39;</span><span class="p">:</span> <span class="n">mod</span><span class="o">.</span><span class="n">prev_node_target_type</span><span class="p">,</span>
                <span class="s1">&#39;index_within_arg&#39;</span><span class="p">:</span> <span class="n">mod</span><span class="o">.</span><span class="n">index_within_arg</span><span class="p">,</span>
                <span class="s1">&#39;index_of_arg&#39;</span><span class="p">:</span> <span class="n">mod</span><span class="o">.</span><span class="n">index_of_arg</span><span class="p">,</span>
                <span class="s1">&#39;fqn&#39;</span><span class="p">:</span> <span class="n">mod</span><span class="o">.</span><span class="n">fqn</span><span class="p">,</span>
                <span class="s1">&#39;qconfig_str&#39;</span><span class="p">:</span> <span class="n">mod</span><span class="o">.</span><span class="n">qconfig_str</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="s1">&#39;comparisons&#39;</span><span class="p">):</span>
                <span class="n">data</span><span class="p">[</span><span class="s1">&#39;comparisons&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">comparisons</span>
                <span class="n">data</span><span class="p">[</span><span class="s1">&#39;comparison_fn_name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">comparison_fn_name</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span><span class="p">[</span><span class="s1">&#39;comparisons&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="n">data</span><span class="p">[</span><span class="s1">&#39;comparison_fn_name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
            <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">mod</span><span class="o">.</span><span class="n">results_type</span><span class="p">][</span><span class="n">mod</span><span class="o">.</span><span class="n">model_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="c1"># ensure the list stays sorted</span>
            <span class="n">results</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">mod</span><span class="o">.</span><span class="n">results_type</span><span class="p">][</span><span class="n">mod</span><span class="o">.</span><span class="n">model_name</span><span class="p">]</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span>
                <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">res</span><span class="p">:</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;index_of_arg&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">res</span><span class="p">[</span><span class="s1">&#39;index_within_arg&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>


<span class="c1"># TODO(future PR): align on naming</span>
<span class="c1"># this is equivalent of just the comparison extraction part of `ns.compare_model_outputs`</span>
<div class="viewcode-block" id="extract_logger_info"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_logger_info">[docs]</a><span class="k">def</span> <span class="nf">extract_logger_info</span><span class="p">(</span>
    <span class="n">model_a</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">model_b</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">logger_cls</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">model_name_to_use_for_layer_names</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NSResultsType</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Traverse all loggers in `model_a` and `model_b`, and extract the logged</span>
<span class="sd">    information.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_a: model A</span>
<span class="sd">        model_b: model B</span>
<span class="sd">        logger_cls: class of Logger to use</span>
<span class="sd">        model_name_to_use_for_layer_names: string name of model to use for</span>
<span class="sd">          layer names in the output</span>

<span class="sd">    Return:</span>
<span class="sd">        NSResultsType, containing the logged comparisons</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;quantization_api._numeric_suite_fx.extract_logger_info&quot;</span><span class="p">)</span>
    <span class="n">results</span><span class="p">:</span> <span class="n">NSResultsType</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="p">(</span><span class="n">model_a</span><span class="p">,</span> <span class="n">model_b</span><span class="p">):</span>
        <span class="n">_extract_logger_info_one_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">logger_cls</span><span class="p">)</span>
    <span class="c1"># fill in missing fqn entries</span>
    <span class="n">maybe_add_missing_fqns</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    <span class="c1"># rekey on the name of model b</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">rekey_logger_info_on_node_name_of_model</span><span class="p">(</span>
        <span class="n">results</span><span class="p">,</span> <span class="n">model_name_to_use_for_layer_names</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">results</span></div>


<span class="k">def</span> <span class="nf">_add_shadow_loggers_impl</span><span class="p">(</span>
    <span class="n">name_a</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">gm_a</span><span class="p">:</span> <span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">name_b</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">gm_b</span><span class="p">:</span> <span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">logger_cls</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">should_log_inputs</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">base_name_to_sets_of_related_ops</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">node_type_to_io_type_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">unmatchable_types_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;quantization_api._numeric_suite_fx._add_shadow_loggers_impl&quot;</span><span class="p">)</span>
    <span class="n">matched_subgraph_pairs</span> <span class="o">=</span> <span class="n">get_matching_subgraph_pairs</span><span class="p">(</span>
        <span class="n">gm_a</span><span class="p">,</span> <span class="n">gm_b</span><span class="p">,</span> <span class="n">base_name_to_sets_of_related_ops</span><span class="p">,</span>
        <span class="n">unmatchable_types_map</span><span class="p">)</span>
    <span class="n">gm_a_shadows_b</span> <span class="o">=</span> <span class="n">create_a_shadows_b</span><span class="p">(</span>
        <span class="n">name_a</span><span class="p">,</span> <span class="n">gm_a</span><span class="p">,</span> <span class="n">name_b</span><span class="p">,</span> <span class="n">gm_b</span><span class="p">,</span> <span class="n">matched_subgraph_pairs</span><span class="p">,</span> <span class="n">logger_cls</span><span class="p">,</span>
        <span class="n">should_log_inputs</span><span class="o">=</span><span class="n">should_log_inputs</span><span class="p">,</span>
        <span class="n">node_type_to_io_type_map</span><span class="o">=</span><span class="n">node_type_to_io_type_map</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gm_a_shadows_b</span>


<div class="viewcode-block" id="add_shadow_loggers"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.add_shadow_loggers">[docs]</a><span class="k">def</span> <span class="nf">add_shadow_loggers</span><span class="p">(</span>
    <span class="n">name_a</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model_a</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">name_b</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model_b</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">logger_cls</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">should_log_inputs</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">base_name_to_sets_of_related_ops</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">node_type_to_io_type_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">unmatchable_types_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Set</span><span class="p">[</span><span class="n">NSNodeTargetType</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Instrument model A and model B with shadow loggers.</span>

<span class="sd">    Args:</span>
<span class="sd">        name_a: string name of model A to use in results</span>
<span class="sd">        model_a: model A</span>
<span class="sd">        name_b: string name of model B to use in results</span>
<span class="sd">        model_b: model B</span>
<span class="sd">        logger_cls: class of Logger to use</span>
<span class="sd">        should_log_inputs: whether to log inputs</span>
<span class="sd">        base_name_to_sets_of_related_ops: optional override of subgraph base nodes, subject to change</span>
<span class="sd">        unmatchable_types_map: optional override of unmatchable types, subject to change</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;quantization_api._numeric_suite_fx.add_shadow_loggers&quot;</span><span class="p">)</span>
    <span class="c1"># TODO(future PR): expose these</span>
    <span class="n">skipped_module_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">skipped_module_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">tracer_a</span> <span class="o">=</span> <span class="n">NSTracer</span><span class="p">(</span><span class="n">skipped_module_names</span><span class="p">,</span> <span class="n">skipped_module_classes</span><span class="p">)</span>
    <span class="n">tracer_b</span> <span class="o">=</span> <span class="n">NSTracer</span><span class="p">(</span><span class="n">skipped_module_names</span><span class="p">,</span> <span class="n">skipped_module_classes</span><span class="p">)</span>
    <span class="n">gm_a</span> <span class="o">=</span> <span class="n">GraphModule</span><span class="p">(</span><span class="n">model_a</span><span class="p">,</span> <span class="n">tracer_a</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model_a</span><span class="p">))</span>
    <span class="n">maybe_model_a_node_name_to_scope</span> <span class="o">=</span> <span class="n">_get_observed_graph_module_attr</span><span class="p">(</span><span class="n">model_a</span><span class="p">,</span> <span class="s1">&#39;node_name_to_scope&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">maybe_model_a_node_name_to_scope</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gm_a</span><span class="o">.</span><span class="n">_node_name_to_scope</span> <span class="o">=</span> <span class="n">maybe_model_a_node_name_to_scope</span>
    <span class="n">gm_b</span> <span class="o">=</span> <span class="n">GraphModule</span><span class="p">(</span><span class="n">model_b</span><span class="p">,</span> <span class="n">tracer_b</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model_b</span><span class="p">))</span>
    <span class="n">maybe_model_b_node_name_to_scope</span> <span class="o">=</span> <span class="n">_get_observed_graph_module_attr</span><span class="p">(</span><span class="n">model_b</span><span class="p">,</span> <span class="s1">&#39;node_name_to_scope&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">maybe_model_b_node_name_to_scope</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gm_b</span><span class="o">.</span><span class="n">_node_name_to_scope</span> <span class="o">=</span> <span class="n">maybe_model_b_node_name_to_scope</span>
    <span class="k">return</span> <span class="n">_add_shadow_loggers_impl</span><span class="p">(</span>
        <span class="n">name_a</span><span class="p">,</span> <span class="n">gm_a</span><span class="p">,</span> <span class="n">name_b</span><span class="p">,</span> <span class="n">gm_b</span><span class="p">,</span> <span class="n">logger_cls</span><span class="p">,</span>
        <span class="n">should_log_inputs</span><span class="o">=</span><span class="n">should_log_inputs</span><span class="p">,</span>
        <span class="n">base_name_to_sets_of_related_ops</span><span class="o">=</span><span class="n">base_name_to_sets_of_related_ops</span><span class="p">,</span>
        <span class="n">node_type_to_io_type_map</span><span class="o">=</span><span class="n">node_type_to_io_type_map</span><span class="p">,</span>
        <span class="n">unmatchable_types_map</span><span class="o">=</span><span class="n">unmatchable_types_map</span><span class="p">)</span></div>


<div class="viewcode-block" id="extract_shadow_logger_info"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_shadow_logger_info">[docs]</a><span class="k">def</span> <span class="nf">extract_shadow_logger_info</span><span class="p">(</span>
    <span class="n">model_a_shadows_b</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">logger_cls</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">model_name_to_use_for_layer_names</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NSResultsType</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Traverse all loggers in a shadow model, and extract the logged</span>
<span class="sd">    information.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_a_shadows_b: shadow model</span>
<span class="sd">        logger_cls: class of Logger to use</span>
<span class="sd">        model_name_to_use_for_layer_names: string name of model to use for</span>
<span class="sd">          layer names in the output</span>

<span class="sd">    Return:</span>
<span class="sd">        NSResultsType, containing the logged comparisons</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_log_api_usage_once</span><span class="p">(</span><span class="s2">&quot;quantization_api._numeric_suite_fx.extract_shadow_logger_info&quot;</span><span class="p">)</span>
    <span class="n">results</span><span class="p">:</span> <span class="n">NSResultsType</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>
    <span class="n">_extract_logger_info_one_model</span><span class="p">(</span><span class="n">model_a_shadows_b</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">logger_cls</span><span class="p">)</span>
    <span class="c1"># fill in missing fqn entries</span>
    <span class="n">maybe_add_missing_fqns</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    <span class="c1"># rekey on the name of model b</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">rekey_logger_info_on_node_name_of_model</span><span class="p">(</span>
        <span class="n">results</span><span class="p">,</span> <span class="n">model_name_to_use_for_layer_names</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">results</span><span class="p">)</span></div>


<div class="viewcode-block" id="extend_logger_results_with_comparison"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extend_logger_results_with_comparison">[docs]</a><span class="k">def</span> <span class="nf">extend_logger_results_with_comparison</span><span class="p">(</span>
    <span class="n">results</span><span class="p">:</span> <span class="n">NSResultsType</span><span class="p">,</span>
    <span class="n">model_name_1</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">model_name_2</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">comparison_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">comparison_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compares the logged values from `model_name_2` against the corresponding</span>
<span class="sd">    values in `model_name_1`, using `comparison_fn`. Records the result</span>
<span class="sd">    in `model_name_2`&#39;s results under `comparison_name`. Modifies `results` inplace.</span>

<span class="sd">    Args:</span>
<span class="sd">        results: the result data structure from `extract_logger_info` or</span>
<span class="sd">          `extract_shadow_logger_info`.</span>
<span class="sd">        model_name_1: string name of model 1</span>
<span class="sd">        model_name_2: string name of model 2</span>
<span class="sd">        comparison_fn: function to compare two Tensors</span>
<span class="sd">        comparison_name: string name of model to use for</span>
<span class="sd">          layer names in the output</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">results_type_to_results</span> <span class="ow">in</span> <span class="n">results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">model_name_to_results</span> <span class="ow">in</span> <span class="n">results_type_to_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">assert</span> <span class="n">model_name_1</span> <span class="ow">in</span> <span class="n">model_name_to_results</span><span class="p">,</span> \
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name_1</span><span class="si">}</span><span class="s2"> not found in results&quot;</span>
            <span class="k">assert</span> <span class="n">model_name_2</span> <span class="ow">in</span> <span class="n">model_name_to_results</span><span class="p">,</span> \
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name_2</span><span class="si">}</span><span class="s2"> not found in results&quot;</span>

            <span class="n">results_1</span> <span class="o">=</span> <span class="n">model_name_to_results</span><span class="p">[</span><span class="n">model_name_1</span><span class="p">]</span>
            <span class="n">results_2</span> <span class="o">=</span> <span class="n">model_name_to_results</span><span class="p">[</span><span class="n">model_name_2</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">result_2</span> <span class="ow">in</span> <span class="n">results_2</span><span class="p">:</span>
                <span class="n">index_within_arg_2</span> <span class="o">=</span> <span class="n">result_2</span><span class="p">[</span><span class="s1">&#39;index_within_arg&#39;</span><span class="p">]</span>
                <span class="n">index_of_arg_2</span> <span class="o">=</span> <span class="n">result_2</span><span class="p">[</span><span class="s1">&#39;index_of_arg&#39;</span><span class="p">]</span>
                <span class="c1"># find corresponding result_1</span>
                <span class="n">result_1</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">for</span> <span class="n">cur_result_1</span> <span class="ow">in</span> <span class="n">results_1</span><span class="p">:</span>
                    <span class="n">index_within_arg_1</span> <span class="o">=</span> <span class="n">cur_result_1</span><span class="p">[</span><span class="s1">&#39;index_within_arg&#39;</span><span class="p">]</span>
                    <span class="n">index_of_arg_1</span> <span class="o">=</span> <span class="n">cur_result_1</span><span class="p">[</span><span class="s1">&#39;index_of_arg&#39;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="p">(</span>
                        <span class="p">(</span><span class="n">index_within_arg_1</span> <span class="o">==</span> <span class="n">index_within_arg_2</span><span class="p">)</span> <span class="ow">and</span>
                        <span class="p">(</span><span class="n">index_of_arg_1</span> <span class="o">==</span> <span class="n">index_of_arg_2</span><span class="p">)</span>
                    <span class="p">):</span>
                        <span class="n">result_1</span> <span class="o">=</span> <span class="n">cur_result_1</span>
                        <span class="k">break</span>
                <span class="k">assert</span> <span class="n">result_1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

                <span class="n">values_1</span> <span class="o">=</span> <span class="n">result_1</span><span class="p">[</span><span class="s1">&#39;values&#39;</span><span class="p">]</span>
                <span class="n">values_2</span> <span class="o">=</span> <span class="n">result_2</span><span class="p">[</span><span class="s1">&#39;values&#39;</span><span class="p">]</span>
                <span class="n">result_2</span><span class="p">[</span><span class="n">comparison_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">value_1</span><span class="p">,</span> <span class="n">value_2</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">values_1</span><span class="p">,</span> <span class="n">values_2</span><span class="p">):</span>
                    <span class="n">comparison_result</span> <span class="o">=</span> <span class="n">comparison_fn</span><span class="p">(</span><span class="n">value_1</span><span class="p">,</span> <span class="n">value_2</span><span class="p">)</span>
                    <span class="n">result_2</span><span class="p">[</span><span class="n">comparison_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">comparison_result</span><span class="p">)</span></div>

<div class="viewcode-block" id="prepare_n_shadows_model"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.prepare_n_shadows_model">[docs]</a><span class="k">def</span> <span class="nf">prepare_n_shadows_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">example_inputs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">qconfig_multi_mapping</span><span class="p">:</span> <span class="n">QConfigMultiMapping</span><span class="p">,</span>
    <span class="n">backend_config</span><span class="p">:</span> <span class="n">BackendConfig</span><span class="p">,</span>
    <span class="n">custom_prepare_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">custom_prepare_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">custom_tracer</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GraphModule</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a model with a graph with M ops such as</span>


<span class="sd">      args_kwargs_m -&gt; op_m -&gt; output_m</span>


<span class="sd">    And a set of N qconfigs for each op, creates a new model, with</span>
<span class="sd">    each of the subgraph of `op_m` transformed into</span>

<span class="sd">    .. code::</span>

<span class="sd">           |---------&gt; op_m_n -&gt; log_m_n</span>
<span class="sd">           |                     /</span>
<span class="sd">      args_kwargs_m ---------&gt; op_m -&gt; log_m_0</span>

<span class="sd">    Where op_m_n is op_m wrapped in a submodule and transformed with</span>
<span class="sd">    qconfig_n, and its inner graph looks like</span>

<span class="sd">    .. code::</span>

<span class="sd">      args_m -------- op_m_prepared_with_qconfig_n -&gt; out_m_n</span>
<span class="sd">                  /</span>
<span class="sd">      kwargs_m ---</span>

<span class="sd">    This is useful for testing different quantization of multiple layers in</span>
<span class="sd">    a single pass through the model.</span>

<span class="sd">    High level TODOs for future PRs:</span>
<span class="sd">    * figure out a better way to name the output structure</span>
<span class="sd">    * return a results data structure instead of printing it out</span>
<span class="sd">    * add examples to docblocks</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">custom_tracer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tracer</span> <span class="o">=</span> <span class="n">quantize_fx</span><span class="o">.</span><span class="n">QuantizationTracer</span><span class="p">([],</span> <span class="p">[])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tracer</span> <span class="o">=</span> <span class="n">custom_tracer</span>
    <span class="n">mt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tracer</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
    <span class="c1"># this is necessary to ensure logger FQNs get populated</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">_node_name_to_scope</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="n">node_name_to_scope</span>

    <span class="c1"># run example input propagation, we need this to call prepare_fx on</span>
    <span class="c1"># individual subgraphs</span>
    <span class="n">output_prop</span> <span class="o">=</span> <span class="n">OutputProp</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span>
    <span class="n">output_prop</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="o">*</span><span class="n">example_inputs</span><span class="p">)</span>

    <span class="c1"># Find the set of subgraphs in the original graph which we need to</span>
    <span class="c1"># consider.</span>
    <span class="n">modules</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">named_modules</span><span class="p">(</span><span class="n">remove_duplicate</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">patterns</span> <span class="o">=</span> <span class="n">_get_pattern_to_quantize_handlers</span><span class="p">(</span><span class="n">backend_config</span><span class="p">)</span>
    <span class="n">root_node_getter_mapping</span> <span class="o">=</span> \
        <span class="n">get_fusion_pattern_to_root_node_getter</span><span class="p">(</span><span class="n">backend_config</span><span class="p">)</span>
    <span class="n">standalone_module_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">standalone_module_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Type</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">custom_module_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Type</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">matches</span> <span class="o">=</span> <span class="n">_find_matches</span><span class="p">(</span>
        <span class="n">mt</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">modules</span><span class="p">,</span> <span class="n">patterns</span><span class="p">,</span> <span class="n">root_node_getter_mapping</span><span class="p">,</span>
        <span class="n">standalone_module_names</span><span class="p">,</span> <span class="n">standalone_module_classes</span><span class="p">,</span> <span class="n">custom_module_classes</span><span class="p">)</span>
    <span class="n">subgraphs_dedup</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">]]</span> <span class="o">=</span> \
        <span class="n">_get_dedup_subgraphs</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span>

    <span class="c1"># generate node to qconfig for each subgraph</span>
    <span class="c1"># TODO(future PR): deduplicate repeating entries</span>
    <span class="n">list_of_node_name_to_qconfig</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">QConfigAny</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">qconfig_mapping</span> <span class="ow">in</span> <span class="n">qconfig_multi_mapping</span><span class="o">.</span><span class="n">qconfig_mappings_list</span><span class="p">:</span>
        <span class="n">node_name_to_qconfig</span> <span class="o">=</span> <span class="n">_generate_node_name_to_qconfig</span><span class="p">(</span>
            <span class="n">mt</span><span class="p">,</span> <span class="n">modules</span><span class="p">,</span> <span class="n">mt</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">qconfig_mapping</span><span class="p">,</span> <span class="n">tracer</span><span class="o">.</span><span class="n">node_name_to_scope</span><span class="p">)</span>
        <span class="n">list_of_node_name_to_qconfig</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_name_to_qconfig</span><span class="p">)</span>

    <span class="c1"># For each region in the model, do the following:</span>
    <span class="c1">#   For each qconfig for that region, do the following:</span>
    <span class="c1">#     1. create a copy of the region wrapped in a module</span>
    <span class="c1">#     2. pass original args, original kwargs, and expected output to module</span>
    <span class="c1">#     3. add an output comparison logger and hook it up to compare</span>
    <span class="c1">#        actual output to expected output</span>
    <span class="c1">#     4. run `prepare_fx` on the module</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">subgraph_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">match_name</span><span class="p">,</span> <span class="n">nodes_in_this_subgraph</span><span class="p">))</span> <span class="ow">in</span> \
            <span class="nb">enumerate</span><span class="p">(</span><span class="n">subgraphs_dedup</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="n">create_n_transformed_and_logged_copies_of_subgraph</span><span class="p">(</span>
            <span class="n">mt</span><span class="p">,</span> <span class="n">subgraph_idx</span><span class="p">,</span> <span class="n">match_name</span><span class="p">,</span> <span class="n">nodes_in_this_subgraph</span><span class="p">,</span>
            <span class="n">qconfig_multi_mapping</span><span class="o">.</span><span class="n">qconfig_mappings_list</span><span class="p">,</span> <span class="n">list_of_node_name_to_qconfig</span><span class="p">,</span>
            <span class="n">custom_prepare_fn</span><span class="p">,</span> <span class="n">custom_prepare_kwargs</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">mt</span></div>

<span class="c1"># TODO(future PR): we should rethink the names of all the PNP APIs</span>
<span class="k">def</span> <span class="nf">_prepare_n_shadows_add_loggers_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">example_inputs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">qconfig_mapping</span><span class="p">:</span> <span class="n">QConfigMapping</span><span class="p">,</span>
    <span class="n">backend_config</span><span class="p">:</span> <span class="n">BackendConfig</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Note: this API is not recommended for wide usage, it is only</span>
<span class="sd">    provided for customers who need to migrate from the `add_loggers`</span>
<span class="sd">    API.</span>

<span class="sd">    This creates a model which provides logging for the following</span>
<span class="sd">    problem: if we quantize `model` with `qconfig_mapping` and feed</span>
<span class="sd">    the same input through both models, log the comparisons of</span>
<span class="sd">    corresponding intermediate layers.</span>

<span class="sd">    The problem is solved with a single model.  Specifically, we</span>
<span class="sd">    partition `model` into N subgraphs, create a copy of each relevant</span>
<span class="sd">    subgraph, wrap it in a module, apply the quantization API to that</span>
<span class="sd">    module, and hook up loggers to measure the comparisons.</span>

<span class="sd">    Example starting graph:</span>

<span class="sd">      x0 -&gt; op0 -&gt; x1 -&gt; op1 -&gt; x2</span>

<span class="sd">    Example config: quantize op0 to int8, do nothing to op1.</span>
<span class="sd">    The following graph will be created:</span>

<span class="sd">    .. code::</span>

<span class="sd">      x0_0 -&gt; op0_0 -&gt; x1_0 -&gt; log -----&gt; op1_0 -&gt; x2_0 -&gt; log</span>
<span class="sd">       \                        \                           \       # noqa: W605</span>
<span class="sd">         ---&gt; op0_1 -&gt; x1_1 ----&gt; clog -&gt; op1_0 -&gt; x2_1 ----&gt; clog</span>

<span class="sd">    Where op0_0 is op0, op0_1 is op0 wrapped in a submodule and quantized</span>
<span class="sd">    to int8, op1_0 is op1 (appearing in the graph twice), log is a logger,</span>
<span class="sd">    and clog is a comparison logger.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">tracer</span> <span class="o">=</span> <span class="n">quantize_fx</span><span class="o">.</span><span class="n">QuantizationTracer</span><span class="p">([],</span> <span class="p">[])</span>
    <span class="n">mt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tracer</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
    <span class="c1"># this is necessary to ensure logger FQNs get populated</span>
    <span class="n">mt</span><span class="o">.</span><span class="n">_node_name_to_scope</span> <span class="o">=</span> <span class="n">tracer</span><span class="o">.</span><span class="n">node_name_to_scope</span>

    <span class="c1"># run example input propagation, we need this to call prepare_fx on</span>
    <span class="c1"># individual subgraphs</span>
    <span class="n">output_prop</span> <span class="o">=</span> <span class="n">OutputProp</span><span class="p">(</span><span class="n">mt</span><span class="p">)</span>
    <span class="n">output_prop</span><span class="o">.</span><span class="n">propagate</span><span class="p">(</span><span class="o">*</span><span class="n">example_inputs</span><span class="p">)</span>

    <span class="c1"># Find the set of subgraphs in the original graph which we need to</span>
    <span class="c1"># consider.</span>
    <span class="n">modules</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">mt</span><span class="o">.</span><span class="n">named_modules</span><span class="p">(</span><span class="n">remove_duplicate</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
    <span class="n">patterns</span> <span class="o">=</span> <span class="n">_get_pattern_to_quantize_handlers</span><span class="p">(</span><span class="n">backend_config</span><span class="p">)</span>
    <span class="n">root_node_getter_mapping</span> <span class="o">=</span> \
        <span class="n">get_fusion_pattern_to_root_node_getter</span><span class="p">(</span><span class="n">backend_config</span><span class="p">)</span>
    <span class="n">standalone_module_names</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">standalone_module_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Type</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">custom_module_classes</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Type</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">matches</span> <span class="o">=</span> <span class="n">_find_matches</span><span class="p">(</span>
        <span class="n">mt</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">modules</span><span class="p">,</span> <span class="n">patterns</span><span class="p">,</span> <span class="n">root_node_getter_mapping</span><span class="p">,</span>
        <span class="n">standalone_module_names</span><span class="p">,</span> <span class="n">standalone_module_classes</span><span class="p">,</span> <span class="n">custom_module_classes</span><span class="p">)</span>
    <span class="n">subgraphs_dedup</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Node</span><span class="p">]]</span> <span class="o">=</span> \
        <span class="n">_get_dedup_subgraphs</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span>

    <span class="c1"># generate node to qconfig for each subgraph</span>
    <span class="n">node_name_to_qconfig</span> <span class="o">=</span> <span class="n">_generate_node_name_to_qconfig</span><span class="p">(</span>
        <span class="n">mt</span><span class="p">,</span> <span class="n">modules</span><span class="p">,</span> <span class="n">mt</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">qconfig_mapping</span><span class="p">,</span> <span class="n">tracer</span><span class="o">.</span><span class="n">node_name_to_scope</span><span class="p">)</span>

    <span class="c1"># Now, mutate the graph to be the add_loggers graph with propagation</span>
    <span class="c1"># error.</span>
    <span class="n">create_add_loggers_graph</span><span class="p">(</span>
        <span class="n">mt</span><span class="p">,</span> <span class="n">subgraphs_dedup</span><span class="p">,</span> <span class="n">qconfig_mapping</span><span class="p">,</span> <span class="n">node_name_to_qconfig</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mt</span>

<span class="c1"># TODO(future PR): we should rethink the names of all the PNP APIs</span>
<span class="k">def</span> <span class="nf">_n_shadows_compare_weights</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">example_inputs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">qconfig_mapping</span><span class="p">:</span> <span class="n">QConfigMapping</span><span class="p">,</span>
    <span class="n">backend_config</span><span class="p">:</span> <span class="n">BackendConfig</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NSResultsType</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Note: this API is not recommended for wide usage, it is only</span>
<span class="sd">    provided for customers who need to migrate from the `add_loggers`</span>
<span class="sd">    API.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">qconfig_multi_mapping</span> <span class="o">=</span> \
        <span class="n">QConfigMultiMapping</span><span class="o">.</span><span class="n">from_list_qconfig_mapping</span><span class="p">([</span><span class="n">qconfig_mapping</span><span class="p">])</span>
    <span class="n">mp</span> <span class="o">=</span> <span class="n">prepare_n_shadows_model</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">,</span> <span class="n">qconfig_multi_mapping</span><span class="p">,</span> <span class="n">backend_config</span><span class="p">)</span>
    <span class="c1"># passing inputs through the model is necessary to populate</span>
    <span class="c1"># observers which observe weights with real values</span>
    <span class="n">mp</span><span class="p">(</span><span class="o">*</span><span class="n">example_inputs</span><span class="p">)</span>
    <span class="n">mq</span> <span class="o">=</span> <span class="n">convert_n_shadows_model</span><span class="p">(</span><span class="n">mp</span><span class="p">)</span>
    <span class="n">weight_comparison</span> <span class="o">=</span> <span class="n">extract_weight_comparison</span><span class="p">(</span><span class="n">mq</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">weight_comparison</span>

<span class="c1"># TODO(future PR): consider aligning API signature with other similar quantization</span>
<span class="c1"># functions (enable_fake_quant, etc)</span>
<div class="viewcode-block" id="loggers_set_enabled"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.loggers_set_enabled">[docs]</a><span class="k">def</span> <span class="nf">loggers_set_enabled</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">enabled</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sets the `enabled` setting on a `model`&#39;s loggers</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">child</span><span class="p">,</span> <span class="n">OutputLogger</span><span class="p">):</span>
            <span class="n">child</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="n">enabled</span></div>

<span class="c1"># TODO(future PR): consider aligning API signature with other similar quantization</span>
<span class="c1"># functions (enable_fake_quant, etc)</span>
<div class="viewcode-block" id="loggers_set_save_activations"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.loggers_set_save_activations">[docs]</a><span class="k">def</span> <span class="nf">loggers_set_save_activations</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">save_activations</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sets the `save_activations` setting on a `model`&#39;s loggers</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_modules</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">child</span><span class="p">,</span> <span class="n">OutputLogger</span><span class="p">):</span>
            <span class="n">child</span><span class="o">.</span><span class="n">save_activations</span> <span class="o">=</span> <span class="n">save_activations</span></div>

<div class="viewcode-block" id="convert_n_shadows_model"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.convert_n_shadows_model">[docs]</a><span class="k">def</span> <span class="nf">convert_n_shadows_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">GraphModule</span><span class="p">,</span>
    <span class="n">custom_convert_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">custom_convert_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">GraphModule</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given a model from `prepare_n_shadows_model`, runs `convert_fx`</span>
<span class="sd">    on each shadow submodule.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
        <span class="c1"># TODO(future PR): consider matching in a safer way than</span>
        <span class="c1"># node name string match</span>
        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">SHADOW_WRAPPER_NODE_NAME_PREFIX</span><span class="p">):</span>
            <span class="n">orig_mod</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">custom_convert_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">converted_mod</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ao</span><span class="o">.</span><span class="n">quantization</span><span class="o">.</span><span class="n">quantize_fx</span><span class="o">.</span><span class="n">convert_fx</span><span class="p">(</span>
                    <span class="n">orig_mod</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">custom_convert_kwargs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">custom_convert_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">converted_mod</span> <span class="o">=</span> <span class="n">custom_convert_fn</span><span class="p">(</span><span class="n">orig_mod</span><span class="p">,</span> <span class="o">**</span><span class="n">custom_convert_kwargs</span><span class="p">)</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">node</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">converted_mod</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span></div>

<div class="viewcode-block" id="extract_results_n_shadows_model"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_results_n_shadows_model">[docs]</a><span class="k">def</span> <span class="nf">extract_results_n_shadows_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NSResultsType</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extracts logger results from `model`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">results</span><span class="p">:</span> <span class="n">NSResultsType</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">_extract_logger_info_one_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">OutputLogger</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">results</span></div>

<div class="viewcode-block" id="print_comparisons_n_shadows_model"><a class="viewcode-back" href="../../../../torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.print_comparisons_n_shadows_model">[docs]</a><span class="k">def</span> <span class="nf">print_comparisons_n_shadows_model</span><span class="p">(</span><span class="n">results</span><span class="p">:</span> <span class="n">NSResultsType</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Prints a summary of extracted `results`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">results_grouped</span> <span class="o">=</span> <span class="n">group_results_by_subgraph</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    <span class="n">results_comparison</span> <span class="o">=</span> <span class="n">create_results_comparison</span><span class="p">(</span><span class="n">results_grouped</span><span class="p">)</span>
    <span class="n">print_n_shadows_summary</span><span class="p">(</span><span class="n">results_comparison</span><span class="p">)</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/sphinx_highlight.js"></script>
         <script src="../../../../_static/clipboard.min.js"></script>
         <script src="../../../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>