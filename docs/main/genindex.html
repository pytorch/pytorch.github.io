


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Index &mdash; PyTorch main documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/genindex.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="_static/sphinx-dropdown.css" type="text/css" />
  <link rel="stylesheet" href="_static/panels-bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="#" />
    <link rel="search" title="Search" href="search.html" />

<!--
  Search engines should not index the main version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch">
                  <span class="dropdown-title">ExecuTorch</span>
                </a>
              </div>
            </div>  
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>main (2.4.0a0+giteda279c ) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          

<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/genindex.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community/build_ci_governance.html">PyTorch Governance | Build + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/design.html">PyTorch Design Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/governance.html">PyTorch Governance | Mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/persons_of_interest.html">PyTorch Governance | Maintainers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/amp_examples.html">CUDA Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.func.html">Extending torch.func with autograd.Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/fsdp.html">FSDP Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpu.html">torch.cpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_cuda_memory.html">Understanding CUDA Memory Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_cuda_memory.html#generating-a-snapshot">Generating a Snapshot</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_cuda_memory.html#using-the-visualizer">Using the visualizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_cuda_memory.html#snapshot-api-reference">Snapshot API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="xpu.html">torch.xpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="meta.html">Meta device</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="export.html">torch.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch.compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="fx.experimental.html">torch.fx.experimental</a></li>
<li class="toctree-l1"><a class="reference internal" href="hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.attention.html">torch.nn.attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">torch.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="deterministic.html">torch.utils.deterministic</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="future_mod.html">torch.__future__</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">torch._logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_environment_variables.html">Torch Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Index</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              

<h1 id="index">Index</h1>

<div class="genindex-jumpbox">
 <a href="#_"><strong>_</strong></a>
 | <a href="#A"><strong>A</strong></a>
 | <a href="#B"><strong>B</strong></a>
 | <a href="#C"><strong>C</strong></a>
 | <a href="#D"><strong>D</strong></a>
 | <a href="#E"><strong>E</strong></a>
 | <a href="#F"><strong>F</strong></a>
 | <a href="#G"><strong>G</strong></a>
 | <a href="#H"><strong>H</strong></a>
 | <a href="#I"><strong>I</strong></a>
 | <a href="#J"><strong>J</strong></a>
 | <a href="#K"><strong>K</strong></a>
 | <a href="#L"><strong>L</strong></a>
 | <a href="#M"><strong>M</strong></a>
 | <a href="#N"><strong>N</strong></a>
 | <a href="#O"><strong>O</strong></a>
 | <a href="#P"><strong>P</strong></a>
 | <a href="#Q"><strong>Q</strong></a>
 | <a href="#R"><strong>R</strong></a>
 | <a href="#S"><strong>S</strong></a>
 | <a href="#T"><strong>T</strong></a>
 | <a href="#U"><strong>U</strong></a>
 | <a href="#V"><strong>V</strong></a>
 | <a href="#W"><strong>W</strong></a>
 | <a href="#X"><strong>X</strong></a>
 | <a href="#Z"><strong>Z</strong></a>
 
</div>
<h2 id="_">_</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState.__getstate__">__getstate__() (torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.__init__">__init__() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.GraphModule.__init__">(torch.fx.GraphModule method)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Event.__init__">(torch.monitor.Event method)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Stat.__init__">(torch.monitor.Stat method)</a>
</li>
        <li><a href="monitor.html#torch.monitor.TensorboardEventHandler.__init__">(torch.monitor.TensorboardEventHandler method)</a>
</li>
        <li><a href="package.html#torch.package.PackageExporter.__init__">(torch.package.PackageExporter method)</a>
</li>
        <li><a href="package.html#torch.package.PackageImporter.__init__">(torch.package.PackageImporter method)</a>
</li>
        <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.__init__">(torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      </ul></li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState.__setstate__">__setstate__() (torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState method)</a>
</li>
      <li><a href="generated/torch._assert.html#torch._assert">_assert() (in module torch)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._assign_worker_ranks">_assign_worker_ranks() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="generated/torch.cuda.jiterator._create_jit_fn.html#torch.cuda.jiterator._create_jit_fn">_create_jit_fn() (in module torch.cuda.jiterator)</a>
</li>
      <li><a href="generated/torch.cuda.jiterator._create_multi_output_jit_fn.html#torch.cuda.jiterator._create_multi_output_jit_fn">_create_multi_output_jit_fn() (in module torch.cuda.jiterator)</a>
</li>
      <li><a href="torch_cuda_memory.html#torch.cuda.memory._dump_snapshot">_dump_snapshot() (in module torch.cuda.memory)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._exit_barrier">_exit_barrier() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="generated/torch._foreach_abs.html#torch._foreach_abs">_foreach_abs() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_abs_.html#torch._foreach_abs_">_foreach_abs_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_acos.html#torch._foreach_acos">_foreach_acos() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_acos_.html#torch._foreach_acos_">_foreach_acos_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_asin.html#torch._foreach_asin">_foreach_asin() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_asin_.html#torch._foreach_asin_">_foreach_asin_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_atan.html#torch._foreach_atan">_foreach_atan() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_atan_.html#torch._foreach_atan_">_foreach_atan_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_ceil.html#torch._foreach_ceil">_foreach_ceil() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_ceil_.html#torch._foreach_ceil_">_foreach_ceil_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_cos.html#torch._foreach_cos">_foreach_cos() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_cos_.html#torch._foreach_cos_">_foreach_cos_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_cosh.html#torch._foreach_cosh">_foreach_cosh() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_cosh_.html#torch._foreach_cosh_">_foreach_cosh_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_erf.html#torch._foreach_erf">_foreach_erf() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_erf_.html#torch._foreach_erf_">_foreach_erf_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_erfc.html#torch._foreach_erfc">_foreach_erfc() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_erfc_.html#torch._foreach_erfc_">_foreach_erfc_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_exp.html#torch._foreach_exp">_foreach_exp() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_exp_.html#torch._foreach_exp_">_foreach_exp_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_expm1.html#torch._foreach_expm1">_foreach_expm1() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_expm1_.html#torch._foreach_expm1_">_foreach_expm1_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_floor.html#torch._foreach_floor">_foreach_floor() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_floor_.html#torch._foreach_floor_">_foreach_floor_() (in module torch)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch._foreach_frac.html#torch._foreach_frac">_foreach_frac() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_frac_.html#torch._foreach_frac_">_foreach_frac_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_lgamma.html#torch._foreach_lgamma">_foreach_lgamma() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_lgamma_.html#torch._foreach_lgamma_">_foreach_lgamma_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log.html#torch._foreach_log">_foreach_log() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log10.html#torch._foreach_log10">_foreach_log10() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log10_.html#torch._foreach_log10_">_foreach_log10_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log1p.html#torch._foreach_log1p">_foreach_log1p() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log1p_.html#torch._foreach_log1p_">_foreach_log1p_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log2.html#torch._foreach_log2">_foreach_log2() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log2_.html#torch._foreach_log2_">_foreach_log2_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log_.html#torch._foreach_log_">_foreach_log_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_neg.html#torch._foreach_neg">_foreach_neg() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_neg_.html#torch._foreach_neg_">_foreach_neg_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_reciprocal.html#torch._foreach_reciprocal">_foreach_reciprocal() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_reciprocal_.html#torch._foreach_reciprocal_">_foreach_reciprocal_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_round.html#torch._foreach_round">_foreach_round() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_round_.html#torch._foreach_round_">_foreach_round_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sigmoid.html#torch._foreach_sigmoid">_foreach_sigmoid() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sigmoid_.html#torch._foreach_sigmoid_">_foreach_sigmoid_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sin.html#torch._foreach_sin">_foreach_sin() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sin_.html#torch._foreach_sin_">_foreach_sin_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sinh.html#torch._foreach_sinh">_foreach_sinh() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sinh_.html#torch._foreach_sinh_">_foreach_sinh_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sqrt.html#torch._foreach_sqrt">_foreach_sqrt() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sqrt_.html#torch._foreach_sqrt_">_foreach_sqrt_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_tan.html#torch._foreach_tan">_foreach_tan() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_tan_.html#torch._foreach_tan_">_foreach_tan_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_trunc.html#torch._foreach_trunc">_foreach_trunc() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_trunc_.html#torch._foreach_trunc_">_foreach_trunc_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_zero_.html#torch._foreach_zero_">_foreach_zero_() (in module torch)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._initialize_workers">_initialize_workers() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile">_KinetoProfile (class in torch.profiler)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._monitor_workers">_monitor_workers() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="torch_cuda_memory.html#torch.cuda.memory._record_memory_history">_record_memory_history() (in module torch.cuda.memory)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._rendezvous">_rendezvous() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._restart_workers">_restart_workers() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._shutdown">_shutdown() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="torch_cuda_memory.html#torch.cuda.memory._snapshot">_snapshot() (in module torch.cuda.memory)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._start_workers">_start_workers() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._stop_workers">_stop_workers() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="A">A</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.abs.html#torch.abs">abs() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.abs.html#torch.Tensor.abs">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.abs_.html#torch.Tensor.abs_">abs_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.absolute.html#torch.absolute">absolute() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.absolute.html#torch.Tensor.absolute">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.absolute_.html#torch.Tensor.absolute_">absolute_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.AbsTransform">AbsTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.acos.html#torch.acos">acos() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.acos.html#torch.Tensor.acos">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.acos_.html#torch.Tensor.acos_">acos_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.acosh.html#torch.acosh">acosh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.acosh.html#torch.Tensor.acosh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.acosh_.html#torch.Tensor.acosh_">acosh_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerClient.acquire">acquire() (torch.distributed.elastic.timer.TimerClient method)</a>
</li>
      <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta">Adadelta (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad">Adagrad (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam">Adam (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax">Adamax (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW">AdamW (class in torch.optim)</a>
</li>
      <li><a href="export.html#torch.export.unflatten.FlatArgsAdapter.adapt">adapt() (torch.export.unflatten.FlatArgsAdapter method)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.ONNXProgram.adapt_torch_inputs_to_onnx">adapt_torch_inputs_to_onnx() (torch.onnx.ONNXProgram method)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.ONNXProgram.adapt_torch_outputs_to_onnx">adapt_torch_outputs_to_onnx() (torch.onnx.ONNXProgram method)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Timer.adaptive_autorange">adaptive_autorange() (torch.utils.benchmark.Timer method)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_avg_pool1d.html#torch.nn.functional.adaptive_avg_pool1d">adaptive_avg_pool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.adaptive_avg_pool2d.html#torch.ao.nn.quantized.functional.adaptive_avg_pool2d">adaptive_avg_pool2d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_avg_pool2d.html#torch.nn.functional.adaptive_avg_pool2d">adaptive_avg_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.adaptive_avg_pool3d.html#torch.ao.nn.quantized.functional.adaptive_avg_pool3d">adaptive_avg_pool3d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_avg_pool3d.html#torch.nn.functional.adaptive_avg_pool3d">adaptive_avg_pool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_max_pool1d.html#torch.nn.functional.adaptive_max_pool1d">adaptive_max_pool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_max_pool2d.html#torch.nn.functional.adaptive_max_pool2d">adaptive_max_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_max_pool3d.html#torch.nn.functional.adaptive_max_pool3d">adaptive_max_pool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveAvgPool1d.html#torch.nn.AdaptiveAvgPool1d">AdaptiveAvgPool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveAvgPool2d.html#torch.nn.AdaptiveAvgPool2d">AdaptiveAvgPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveAvgPool3d.html#torch.nn.AdaptiveAvgPool3d">AdaptiveAvgPool3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html#torch.nn.AdaptiveLogSoftmaxWithLoss">AdaptiveLogSoftmaxWithLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveMaxPool1d.html#torch.nn.AdaptiveMaxPool1d">AdaptiveMaxPool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveMaxPool2d.html#torch.nn.AdaptiveMaxPool2d">AdaptiveMaxPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveMaxPool3d.html#torch.nn.AdaptiveMaxPool3d">AdaptiveMaxPool3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.add.html#torch.add">add() (in module torch)</a>

      <ul>
        <li><a href="distributed.html#torch.distributed.Store.add">(in module torch.distributed.Store)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.add">(torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.add">(torch.distributed.elastic.rendezvous.etcd_store.EtcdStore method)</a>
</li>
        <li><a href="generated/torch.fx.experimental.symbolic_shapes.DimConstraints.html#torch.fx.experimental.symbolic_shapes.DimConstraints.add">(torch.fx.experimental.symbolic_shapes.DimConstraints method)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Stat.add">(torch.monitor.Stat method)</a>
</li>
        <li><a href="generated/torch.Tensor.add.html#torch.Tensor.add">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.add_.html#torch.Tensor.add_">add_() (torch.Tensor method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_audio">add_audio() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars">add_custom_scalars() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.add_dependency">add_dependency() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.add_done_callback">add_done_callback() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.add_dtype_config">add_dtype_config() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_embedding">add_embedding() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.DimConstraints.html#torch.fx.experimental.symbolic_shapes.DimConstraints.add_equality">add_equality() (torch.fx.experimental.symbolic_shapes.DimConstraints method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_figure">add_figure() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_graph">add_graph() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_histogram">add_histogram() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_hparams">add_hparams() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_image">add_image() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_images">add_images() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.add_loggers">add_loggers() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_mesh">add_mesh() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile.add_metadata">add_metadata() (torch.profiler._KinetoProfile method)</a>
</li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile.add_metadata_json">add_metadata_json() (torch.profiler._KinetoProfile method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.add_module">add_module() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.add_module">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.add_param_group">add_param_group() (torch.distributed.optim.ZeroRedundancyOptimizer method)</a>

      <ul>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.add_param_group">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.add_param_group">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.add_param_group">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.add_param_group">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.add_param_group">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.add_param_group">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.add_param_group">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.add_param_group">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.Optimizer.add_param_group.html#torch.optim.Optimizer.add_param_group">(torch.optim.Optimizer method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.add_param_group">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.add_param_group">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.add_param_group">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.add_param_group">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.add_param_group">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve">add_pr_curve() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.add_pruning_method">add_pruning_method() (torch.nn.utils.prune.PruningContainer method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.add_quant_dequant.html#torch.ao.quantization.add_quant_dequant">add_quant_dequant (class in torch.ao.quantization)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.add_relu">add_relu() (torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.add_scalar">add_scalar() (torch.ao.ns._numeric_suite.Shadow method)</a>

      <ul>
        <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar">(torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      </ul></li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalars">add_scalars() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.add_shadow_loggers">add_shadow_loggers() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule.add_submodule">add_submodule() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_text">add_text() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.add_var_to_val">add_var_to_val() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_video">add_video() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="generated/torch.addbmm.html#torch.addbmm">addbmm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.addbmm.html#torch.Tensor.addbmm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addbmm_.html#torch.Tensor.addbmm_">addbmm_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.addcdiv.html#torch.addcdiv">addcdiv() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.addcdiv.html#torch.Tensor.addcdiv">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addcdiv_.html#torch.Tensor.addcdiv_">addcdiv_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.addcmul.html#torch.addcmul">addcmul() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.addcmul.html#torch.Tensor.addcmul">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addcmul_.html#torch.Tensor.addcmul_">addcmul_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.addmm.html#torch.addmm">addmm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.sparse.addmm.html#torch.sparse.addmm">(in module torch.sparse)</a>
</li>
        <li><a href="generated/torch.Tensor.addmm.html#torch.Tensor.addmm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addmm_.html#torch.Tensor.addmm_">addmm_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.addmv.html#torch.addmv">addmv() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.addmv.html#torch.Tensor.addmv">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addmv_.html#torch.Tensor.addmv_">addmv_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.addr.html#torch.addr">addr() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.addr.html#torch.Tensor.addr">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addr_.html#torch.Tensor.addr_">addr_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.adjoint.html#torch.adjoint">adjoint() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.adjoint.html#torch.Tensor.adjoint">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.affine_grid.html#torch.nn.functional.affine_grid">affine_grid() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.AffineTransform">AffineTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="monitor.html#torch.monitor.Aggregation">Aggregation (class in torch.monitor)</a>
</li>
      <li><a href="special.html#torch.special.airy_ai">airy_ai() (in module torch.special)</a>
</li>
      <li><a href="named_tensor.html#torch.Tensor.align_as">align_as() (torch.Tensor method)</a>
</li>
      <li><a href="named_tensor.html#torch.Tensor.align_to">align_to() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.all.html#torch.all">all() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.all.html#torch.Tensor.all">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.all_gather">all_gather() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_gather_into_tensor">all_gather_into_tensor() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_gather_object">all_gather_object() (in module torch.distributed)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.all_input_nodes">all_input_nodes (torch.fx.Node property)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.all_mismatch_leaf_graph_info">all_mismatch_leaf_graph_info() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.all_paths">all_paths() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_reduce">all_reduce() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_to_all">all_to_all() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_to_all_single">all_to_all_single() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.allclose.html#torch.allclose">allclose() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.allclose.html#torch.Tensor.allclose">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="backends.html#torch.backends.cuda.matmul.allow_bf16_reduced_precision_reduction">allow_bf16_reduced_precision_reduction (in module torch.backends.cuda.matmul)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction">allow_fp16_reduced_precision_reduction (in module torch.backends.cuda.matmul)</a>
</li>
      <li><a href="generated/torch.compiler.allow_in_graph.html#torch.compiler.allow_in_graph">allow_in_graph() (in module torch.compiler)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.allow_mutation_on_saved_tensors">allow_mutation_on_saved_tensors (class in torch.autograd.graph)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.matmul.allow_tf32">allow_tf32 (in module torch.backends.cuda.matmul)</a>

      <ul>
        <li><a href="backends.html#torch.backends.cudnn.allow_tf32">(in module torch.backends.cudnn)</a>
</li>
      </ul></li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.default_hooks.allreduce_hook">allreduce_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)</a>
</li>
      <li><a href="generated/torch.nn.functional.alpha_dropout.html#torch.nn.functional.alpha_dropout">alpha_dropout() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.AlphaDropout.html#torch.nn.AlphaDropout">AlphaDropout (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.amax.html#torch.amax">amax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.amax.html#torch.Tensor.amax">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.amin.html#torch.amin">amin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.amin.html#torch.Tensor.amin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.aminmax.html#torch.aminmax">aminmax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.aminmax.html#torch.Tensor.aminmax">(torch.Tensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.angle.html#torch.angle">angle() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.angle.html#torch.Tensor.angle">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.annotate.html#torch.jit.annotate">annotate() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.any.html#torch.any">any() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.any.html#torch.Tensor.any">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Node.append">append() (torch.fx.Node method)</a>

      <ul>
        <li><a href="generated/torch.nn.ModuleList.html#torch.nn.ModuleList.append">(torch.nn.ModuleList method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterList.html#torch.nn.ParameterList.append">(torch.nn.ParameterList method)</a>
</li>
        <li><a href="generated/torch.nn.Sequential.html#torch.nn.Sequential.append">(torch.nn.Sequential method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.function.BackwardCFunction.html#torch.autograd.function.BackwardCFunction.apply">apply() (torch.autograd.function.BackwardCFunction method)</a>

      <ul>
        <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.apply">(torch.distributed.fsdp.FullyShardedDataParallel method)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.apply">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.apply">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.apply">(torch.nn.utils.prune.BasePruningMethod class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.apply">(torch.nn.utils.prune.CustomFromMask class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.apply">(torch.nn.utils.prune.Identity class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.apply">(torch.nn.utils.prune.L1Unstructured class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.apply">(torch.nn.utils.prune.LnStructured class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.apply">(torch.nn.utils.prune.PruningContainer class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.apply">(torch.nn.utils.prune.RandomStructured class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.apply">(torch.nn.utils.prune.RandomUnstructured class method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.apply_.html#torch.Tensor.apply_">apply_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.autograd.function.BackwardCFunction.html#torch.autograd.function.BackwardCFunction.apply_jvp">apply_jvp() (torch.autograd.function.BackwardCFunction method)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.apply_mask">apply_mask() (torch.nn.utils.prune.BasePruningMethod method)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.apply_mask">(torch.nn.utils.prune.CustomFromMask method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.apply_mask">(torch.nn.utils.prune.Identity method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.apply_mask">(torch.nn.utils.prune.L1Unstructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.apply_mask">(torch.nn.utils.prune.LnStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.apply_mask">(torch.nn.utils.prune.PruningContainer method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.apply_mask">(torch.nn.utils.prune.RandomStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.apply_mask">(torch.nn.utils.prune.RandomUnstructured method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.arange.html#torch.arange">arange() (in module torch)</a>
</li>
      <li><a href="generated/torch.arccos.html#torch.arccos">arccos() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arccos.html#torch.Tensor.arccos">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arccos_.html#torch.Tensor.arccos_">arccos_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.arccosh.html#torch.arccosh">arccosh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arccosh.html#torch.Tensor.arccosh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arccosh_.html#torch.Tensor.arccosh_">arccosh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.arcsin.html#torch.arcsin">arcsin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arcsin.html#torch.Tensor.arcsin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arcsin_.html#torch.Tensor.arcsin_">arcsin_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.arcsinh.html#torch.arcsinh">arcsinh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arcsinh.html#torch.Tensor.arcsinh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arcsinh_.html#torch.Tensor.arcsinh_">arcsinh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.arctan.html#torch.arctan">arctan() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arctan.html#torch.Tensor.arctan">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.arctan2.html#torch.arctan2">arctan2() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arctan2.html#torch.Tensor.arctan2">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arctan2_.html#torch.Tensor.arctan2_">arctan2_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.arctan_.html#torch.Tensor.arctan_">arctan_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.arctanh.html#torch.arctanh">arctanh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arctanh.html#torch.Tensor.arctanh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arctanh_.html#torch.Tensor.arctanh_">arctanh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.are_deterministic_algorithms_enabled.html#torch.are_deterministic_algorithms_enabled">are_deterministic_algorithms_enabled() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.arg_constraints">arg_constraints (torch.distributions.bernoulli.Bernoulli attribute)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.arg_constraints">(torch.distributions.beta.Beta attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.arg_constraints">(torch.distributions.binomial.Binomial attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.arg_constraints">(torch.distributions.categorical.Categorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.arg_constraints">(torch.distributions.cauchy.Cauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.chi2.Chi2.arg_constraints">(torch.distributions.chi2.Chi2 attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.arg_constraints">(torch.distributions.continuous_bernoulli.ContinuousBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.arg_constraints">(torch.distributions.dirichlet.Dirichlet attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.arg_constraints">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.arg_constraints">(torch.distributions.exponential.Exponential attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.arg_constraints">(torch.distributions.fishersnedecor.FisherSnedecor attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.arg_constraints">(torch.distributions.gamma.Gamma attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.arg_constraints">(torch.distributions.geometric.Geometric attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.arg_constraints">(torch.distributions.gumbel.Gumbel attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.arg_constraints">(torch.distributions.half_cauchy.HalfCauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.arg_constraints">(torch.distributions.half_normal.HalfNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.arg_constraints">(torch.distributions.independent.Independent attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.inverse_gamma.InverseGamma.arg_constraints">(torch.distributions.inverse_gamma.InverseGamma attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.arg_constraints">(torch.distributions.kumaraswamy.Kumaraswamy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.arg_constraints">(torch.distributions.laplace.Laplace attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky.arg_constraints">(torch.distributions.lkj_cholesky.LKJCholesky attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.arg_constraints">(torch.distributions.log_normal.LogNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.arg_constraints">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.arg_constraints">(torch.distributions.mixture_same_family.MixtureSameFamily attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.arg_constraints">(torch.distributions.multinomial.Multinomial attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.arg_constraints">(torch.distributions.multivariate_normal.MultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.arg_constraints">(torch.distributions.negative_binomial.NegativeBinomial attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.arg_constraints">(torch.distributions.normal.Normal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.arg_constraints">(torch.distributions.one_hot_categorical.OneHotCategorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.arg_constraints">(torch.distributions.pareto.Pareto attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.arg_constraints">(torch.distributions.poisson.Poisson attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.arg_constraints">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.arg_constraints">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.arg_constraints">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.arg_constraints">(torch.distributions.studentT.StudentT attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.arg_constraints">(torch.distributions.transformed_distribution.TransformedDistribution attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.arg_constraints">(torch.distributions.uniform.Uniform attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.arg_constraints">(torch.distributions.von_mises.VonMises attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.arg_constraints">(torch.distributions.weibull.Weibull attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.arg_constraints">(torch.distributions.wishart.Wishart attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.argmax.html#torch.argmax">argmax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.argmax.html#torch.Tensor.argmax">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.argmin.html#torch.argmin">argmin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.argmin.html#torch.Tensor.argmin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Node.args">args (torch.fx.Node property)</a>
</li>
      <li><a href="generated/torch.argsort.html#torch.argsort">argsort() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.argsort.html#torch.Tensor.argsort">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.argwhere.html#torch.argwhere">argwhere() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.argwhere.html#torch.Tensor.argwhere">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="nested.html#torch.nested.as_nested_tensor">as_nested_tensor() (in module torch.nested)</a>
</li>
      <li><a href="generated/torch.sparse.as_sparse_gradcheck.html#torch.sparse.as_sparse_gradcheck">as_sparse_gradcheck() (in module torch.sparse)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.CallgrindStats.as_standardized">as_standardized() (torch.utils.benchmark.CallgrindStats method)</a>
</li>
      <li><a href="generated/torch.as_strided.html#torch.as_strided">as_strided() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.as_strided.html#torch.Tensor.as_strided">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.as_subclass.html#torch.Tensor.as_subclass">as_subclass() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.as_tensor.html#torch.as_tensor">as_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.asarray.html#torch.asarray">asarray() (in module torch)</a>
</li>
      <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD">ASGD (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.asin.html#torch.asin">asin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.asin.html#torch.Tensor.asin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.asin_.html#torch.Tensor.asin_">asin_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.asinh.html#torch.asinh">asinh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.asinh.html#torch.Tensor.asinh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.asinh_.html#torch.Tensor.asinh_">asinh_() (torch.Tensor method)</a>
</li>
      <li><a href="testing.html#torch.testing.assert_allclose">assert_allclose() (in module torch.testing)</a>
</li>
      <li><a href="testing.html#torch.testing.assert_close">assert_close() (in module torch.testing)</a>
</li>
      <li><a href="generated/torch.compiler.assume_constant_result.html#torch.compiler.assume_constant_result">assume_constant_result() (in module torch.compiler)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.functions.async_execution">async_execution() (in module torch.distributed.rpc.functions)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict_saver.async_save">async_save() (in module torch.distributed.checkpoint.state_dict_saver)</a>
</li>
      <li><a href="generated/torch.atan.html#torch.atan">atan() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.atan.html#torch.Tensor.atan">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.atan2.html#torch.atan2">atan2() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.atan2.html#torch.Tensor.atan2">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.atan2_.html#torch.Tensor.atan2_">atan2_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.atan_.html#torch.Tensor.atan_">atan_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.atanh.html#torch.atanh">atanh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.atanh.html#torch.Tensor.atanh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.atanh_.html#torch.Tensor.atanh_">atanh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.atleast_1d.html#torch.atleast_1d">atleast_1d() (in module torch)</a>
</li>
      <li><a href="generated/torch.atleast_2d.html#torch.atleast_2d">atleast_2d() (in module torch)</a>
</li>
      <li><a href="generated/torch.atleast_3d.html#torch.atleast_3d">atleast_3d() (in module torch)</a>
</li>
      <li><a href="generated/torch.jit.Attribute.html#torch.jit.Attribute">Attribute (class in torch.jit)</a>
</li>
      <li><a href="amp.html#torch.autocast">autocast (class in torch)</a>

      <ul>
        <li><a href="amp.html#torch.cpu.amp.autocast">(class in torch.cpu.amp)</a>
</li>
        <li><a href="amp.html#torch.cuda.amp.autocast">(class in torch.cuda.amp)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.avg_pool1d.html#torch.nn.functional.avg_pool1d">avg_pool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.avg_pool2d.html#torch.ao.nn.quantized.functional.avg_pool2d">avg_pool2d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.avg_pool2d.html#torch.nn.functional.avg_pool2d">avg_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.avg_pool3d.html#torch.ao.nn.quantized.functional.avg_pool3d">avg_pool3d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.avg_pool3d.html#torch.nn.functional.avg_pool3d">avg_pool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.AvgPool1d.html#torch.nn.AvgPool1d">AvgPool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AvgPool2d.html#torch.nn.AvgPool2d">AvgPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AvgPool3d.html#torch.nn.AvgPool3d">AvgPool3d (class in torch.nn)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="B">B</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributed.html#torch.distributed.Backend">Backend (class in torch.distributed)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig">BackendConfig (class in torch.ao.quantization.backend_config)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig">BackendPatternConfig (class in torch.ao.quantization.backend_config)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.BackendType">BackendType (class in torch.distributed.rpc)</a>
</li>
      <li><a href="generated/torch.autograd.backward.html#torch.autograd.backward">backward() (in module torch.autograd)</a>

      <ul>
        <li><a href="rpc.html#torch.distributed.autograd.backward">(in module torch.distributed.autograd)</a>
</li>
        <li><a href="generated/torch.autograd.Function.backward.html#torch.autograd.Function.backward">(torch.autograd.Function static method)</a>
</li>
        <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction.backward">(torch.autograd.function.InplaceFunction static method)</a>
</li>
        <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.backward">(torch.autograd.function.NestedIOFunction method)</a>
</li>
        <li><a href="rpc.html#torch.distributed.rpc.PyRRef.backward">(torch.distributed.rpc.PyRRef method)</a>
</li>
        <li><a href="generated/torch.Tensor.backward.html#torch.Tensor.backward">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.backward_extended">backward_extended() (torch.autograd.function.NestedIOFunction method)</a>
</li>
      <li><a href="generated/torch.autograd.function.BackwardCFunction.html#torch.autograd.function.BackwardCFunction">BackwardCFunction (class in torch.autograd.function)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.BackwardPrefetch">BackwardPrefetch (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="generated/torch.baddbmm.html#torch.baddbmm">baddbmm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.baddbmm.html#torch.Tensor.baddbmm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.baddbmm_.html#torch.Tensor.baddbmm_">baddbmm_() (torch.Tensor method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.barrier">barrier() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.signal.windows.bartlett.html#torch.signal.windows.bartlett">bartlett() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.bartlett_window.html#torch.bartlett_window">bartlett_window() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod">BasePruningMethod (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="distributed.html#torch.distributed.batch_isend_irecv">batch_isend_irecv() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.nn.functional.batch_norm.html#torch.nn.functional.batch_norm">batch_norm() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution.batch_shape">batch_shape (torch.distributions.distribution.Distribution property)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.batch_sizes">batch_sizes (torch.nn.utils.rnn.PackedSequence attribute)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.batched_powerSGD_hook">batched_powerSGD_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook)</a>
</li>
      <li><a href="generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d">BatchNorm1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.BatchNorm2d.html#torch.ao.nn.quantized.BatchNorm2d">BatchNorm2d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.BatchNorm3d.html#torch.ao.nn.quantized.BatchNorm3d">BatchNorm3d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.BatchNorm3d.html#torch.nn.BatchNorm3d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="data.html#torch.utils.data.BatchSampler">BatchSampler (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.nn.BCELoss.html#torch.nn.BCELoss">BCELoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss">BCEWithLogitsLoss (class in torch.nn)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.benchmark">benchmark (in module torch.backends.cudnn)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.benchmark_limit">benchmark_limit (in module torch.backends.cudnn)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli">Bernoulli (class in torch.distributions.bernoulli)</a>
</li>
      <li><a href="generated/torch.bernoulli.html#torch.bernoulli">bernoulli() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bernoulli.html#torch.Tensor.bernoulli">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bernoulli_.html#torch.Tensor.bernoulli_">bernoulli_() (torch.Tensor method)</a>
</li>
      <li><a href="special.html#torch.special.bessel_j0">bessel_j0() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.bessel_j1">bessel_j1() (in module torch.special)</a>
</li>
      <li><a href="distributions.html#torch.distributions.beta.Beta">Beta (class in torch.distributions.beta)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.default_hooks.bf16_compress_hook">bf16_compress_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.default_hooks.bf16_compress_wrapper">bf16_compress_wrapper() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.bfloat16">bfloat16() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.bfloat16">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.bfloat16.html#torch.Tensor.bfloat16">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.bfloat16">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.bfloat16">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.BFloat16Storage">BFloat16Storage (class in torch)</a>
</li>
      <li><a href="generated/torch.nn.Bilinear.html#torch.nn.Bilinear">Bilinear (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.bilinear.html#torch.nn.functional.bilinear">bilinear() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.binary_cross_entropy.html#torch.nn.functional.binary_cross_entropy">binary_cross_entropy() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.binary_cross_entropy_with_logits.html#torch.nn.functional.binary_cross_entropy_with_logits">binary_cross_entropy_with_logits() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.bincount.html#torch.bincount">bincount() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bincount.html#torch.Tensor.bincount">(torch.Tensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.bind_symbols">bind_symbols() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.binomial.Binomial">Binomial (class in torch.distributions.binomial)</a>
</li>
      <li><a href="generated/torch.bitwise_and.html#torch.bitwise_and">bitwise_and() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_and.html#torch.Tensor.bitwise_and">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_and_.html#torch.Tensor.bitwise_and_">bitwise_and_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.bitwise_left_shift.html#torch.bitwise_left_shift">bitwise_left_shift() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_left_shift.html#torch.Tensor.bitwise_left_shift">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_left_shift_.html#torch.Tensor.bitwise_left_shift_">bitwise_left_shift_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.bitwise_not.html#torch.bitwise_not">bitwise_not() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_not.html#torch.Tensor.bitwise_not">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_not_.html#torch.Tensor.bitwise_not_">bitwise_not_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.bitwise_or.html#torch.bitwise_or">bitwise_or() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_or.html#torch.Tensor.bitwise_or">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_or_.html#torch.Tensor.bitwise_or_">bitwise_or_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.bitwise_right_shift.html#torch.bitwise_right_shift">bitwise_right_shift() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_right_shift.html#torch.Tensor.bitwise_right_shift">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_right_shift_.html#torch.Tensor.bitwise_right_shift_">bitwise_right_shift_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.bitwise_xor.html#torch.bitwise_xor">bitwise_xor() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_xor.html#torch.Tensor.bitwise_xor">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_xor_.html#torch.Tensor.bitwise_xor_">bitwise_xor_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.signal.windows.blackman.html#torch.signal.windows.blackman">blackman() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.blackman_window.html#torch.blackman_window">blackman_window() (in module torch)</a>
</li>
      <li><a href="generated/torch.block_diag.html#torch.block_diag">block_diag() (in module torch)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Timer.blocked_autorange">blocked_autorange() (torch.utils.benchmark.Timer method)</a>
</li>
      <li><a href="generated/torch.bmm.html#torch.bmm">bmm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bmm.html#torch.Tensor.bmm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.BNReLU2d.html#torch.ao.nn.intrinsic.BNReLU2d">BNReLU2d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.BNReLU2d.html#torch.ao.nn.intrinsic.quantized.BNReLU2d">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.BNReLU3d.html#torch.ao.nn.intrinsic.BNReLU3d">BNReLU3d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.BNReLU3d.html#torch.ao.nn.intrinsic.quantized.BNReLU3d">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bool.html#torch.Tensor.bool">bool() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.bool">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.bool">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.BoolStorage">BoolStorage (class in torch)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.bound_sympy">bound_sympy() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="fx.html#torch.fx.Interpreter.boxed_run">boxed_run() (torch.fx.Interpreter method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.breakpoint">breakpoint() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.cuda.comm.broadcast.html#torch.cuda.comm.broadcast">broadcast() (in module torch.cuda.comm)</a>

      <ul>
        <li><a href="distributed.html#torch.distributed.broadcast">(in module torch.distributed)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.comm.broadcast_coalesced.html#torch.cuda.comm.broadcast_coalesced">broadcast_coalesced() (in module torch.cuda.comm)</a>
</li>
      <li><a href="distributed.html#torch.distributed.broadcast_object_list">broadcast_object_list() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.broadcast_shapes.html#torch.broadcast_shapes">broadcast_shapes() (in module torch)</a>
</li>
      <li><a href="generated/torch.broadcast_tensors.html#torch.broadcast_tensors">broadcast_tensors() (in module torch)</a>
</li>
      <li><a href="generated/torch.broadcast_to.html#torch.broadcast_to">broadcast_to() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.broadcast_to.html#torch.Tensor.broadcast_to">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader">BroadcastingTorchSaveReader (class in torch.distributed.checkpoint.format_utils)</a>
</li>
      <li><a href="generated/torch.bucketize.html#torch.bucketize">bucketize() (in module torch)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.buffer">buffer() (in module torch.distributed.GradBucket)</a>
</li>
      <li><a href="export.html#torch.export.ExportedProgram.buffers">buffers() (torch.export.ExportedProgram method)</a>

      <ul>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.buffers">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.buffers">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.BuildExtension">BuildExtension() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.Tensor.byte.html#torch.Tensor.byte">byte() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.byte">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.byte">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.ByteStorage">ByteStorage (class in torch)</a>
</li>
      <li><a href="storage.html#torch.UntypedStorage.byteswap">byteswap() (torch.UntypedStorage method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="C">C</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend">C10dRendezvousBackend (class in torch.distributed.elastic.rendezvous.c10d_rendezvous_backend)</a>
</li>
      <li><a href="generated/torch.nn.utils.parametrize.cached.html#torch.nn.utils.parametrize.cached">cached() (in module torch.nn.utils.parametrize)</a>
</li>
      <li><a href="generated/torch.cuda.caching_allocator_alloc.html#torch.cuda.caching_allocator_alloc">caching_allocator_alloc() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.caching_allocator_delete.html#torch.cuda.caching_allocator_delete">caching_allocator_delete() (in module torch.cuda)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.calculate_gain">calculate_gain() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.MinMaxObserver.html#torch.ao.quantization.observer.MinMaxObserver.calculate_qparams">calculate_qparams() (torch.ao.quantization.observer.MinMaxObserver method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.call_function">call_function() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.call_function">(torch.fx.Interpreter method)</a>
</li>
        <li><a href="fx.html#torch.fx.Transformer.call_function">(torch.fx.Transformer method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.call_method">call_method() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.call_method">(torch.fx.Interpreter method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.call_module">call_module() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.call_module">(torch.fx.Interpreter method)</a>
</li>
        <li><a href="fx.html#torch.fx.Tracer.call_module">(torch.fx.Tracer method)</a>
</li>
        <li><a href="fx.html#torch.fx.Transformer.call_module">(torch.fx.Transformer method)</a>
</li>
      </ul></li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.CallgrindStats">CallgrindStats (class in torch.utils.benchmark)</a>
</li>
      <li><a href="generated/torch.can_cast.html#torch.can_cast">can_cast() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.can_device_access_peer.html#torch.cuda.can_device_access_peer">can_device_access_peer() (in module torch.cuda)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.can_use_efficient_attention">can_use_efficient_attention() (in module torch.backends.cuda)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.can_use_flash_attention">can_use_flash_attention() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.canonicalize_bool_expr.html#torch.fx.experimental.symbolic_shapes.canonicalize_bool_expr">canonicalize_bool_expr() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.capture_begin">capture_begin() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.capture_end">capture_end() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="generated/torch.cartesian_prod.html#torch.cartesian_prod">cartesian_prod() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.cat">cat (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.cat.html#torch.cat">cat() (in module torch)</a>

      <ul>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.cat">(torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.categorical.Categorical">Categorical (class in torch.distributions.categorical)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.CatTransform">CatTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributions.html#torch.distributions.cauchy.Cauchy">Cauchy (class in torch.distributions.cauchy)</a>
</li>
      <li><a href="generated/torch.Tensor.cauchy_.html#torch.Tensor.cauchy_">cauchy_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.attention.bias.causal_lower_right.html#torch.nn.attention.bias.causal_lower_right">causal_lower_right() (in module torch.nn.attention.bias)</a>
</li>
      <li><a href="generated/torch.nn.attention.bias.causal_upper_left.html#torch.nn.attention.bias.causal_upper_left">causal_upper_left() (in module torch.nn.attention.bias)</a>
</li>
      <li><a href="generated/torch.nn.attention.bias.CausalBias.html#torch.nn.attention.bias.CausalBias">CausalBias (class in torch.nn.attention.bias)</a>
</li>
      <li><a href="generated/torch.nn.attention.bias.CausalVariant.html#torch.nn.attention.bias.CausalVariant">CausalVariant (class in torch.nn.attention.bias)</a>
</li>
      <li><a href="generated/torch.Tensor.ccol_indices.html#torch.Tensor.ccol_indices">ccol_indices() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.cdf">cdf() (torch.distributions.cauchy.Cauchy method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.cdf">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.cdf">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.cdf">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.cdf">(torch.distributions.gamma.Gamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.cdf">(torch.distributions.half_cauchy.HalfCauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.cdf">(torch.distributions.half_normal.HalfNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.cdf">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.cdf">(torch.distributions.mixture_same_family.MixtureSameFamily method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.cdf">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.cdf">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.cdf">(torch.distributions.uniform.Uniform method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cdist.html#torch.cdist">cdist() (in module torch)</a>
</li>
      <li><a href="generated/torch.Tensor.cdouble.html#torch.Tensor.cdouble">cdouble() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ceil.html#torch.ceil">ceil() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ceil.html#torch.Tensor.ceil">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.ceil_.html#torch.Tensor.ceil_">ceil_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.celu.html#torch.ao.nn.quantized.functional.celu">celu (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.CELU.html#torch.nn.CELU">CELU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.celu.html#torch.nn.functional.celu">celu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.Tensor.cfloat.html#torch.Tensor.cfloat">cfloat() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.chain_matmul.html#torch.chain_matmul">chain_matmul() (in module torch)</a>
</li>
      <li><a href="data.html#torch.utils.data.ChainDataset">ChainDataset (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ChainedScheduler.html#torch.optim.lr_scheduler.ChainedScheduler">ChainedScheduler (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.Tensor.chalf.html#torch.Tensor.chalf">chalf() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.cuda.change_current_allocator.html#torch.cuda.change_current_allocator">change_current_allocator() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.nn.ChannelShuffle.html#torch.nn.ChannelShuffle">ChannelShuffle (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.Tensor.char.html#torch.Tensor.char">char() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.char">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.char">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.CharStorage">CharStorage (class in torch)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.check">check() (torch.distributed.elastic.rendezvous.etcd_store.EtcdStore method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.constraints.Constraint.check">(torch.distributions.constraints.Constraint method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.check_equal">check_equal() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.check_is_root">check_is_root() (torch.distributed.fsdp.FullyShardedDataParallel method)</a>
</li>
      <li><a href="generated/torch.sparse.check_sparse_tensor_invariants.html#torch.sparse.check_sparse_tensor_invariants">check_sparse_tensor_invariants (class in torch.sparse)</a>
</li>
      <li><a href="checkpoint.html#torch.utils.checkpoint.checkpoint">checkpoint() (in module torch.utils.checkpoint)</a>
</li>
      <li><a href="checkpoint.html#torch.utils.checkpoint.checkpoint_sequential">checkpoint_sequential() (in module torch.utils.checkpoint)</a>
</li>
      <li><a href="distributions.html#torch.distributions.chi2.Chi2">Chi2 (class in torch.distributions.chi2)</a>
</li>
      <li><a href="elastic/errors.html#torch.distributed.elastic.multiprocessing.errors.ChildFailedError">ChildFailedError (class in torch.distributed.elastic.multiprocessing.errors)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.children">children() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.children">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cholesky.html#torch.cholesky">cholesky() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.cholesky.html#torch.linalg.cholesky">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.cholesky.html#torch.Tensor.cholesky">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.cholesky_ex.html#torch.linalg.cholesky_ex">cholesky_ex() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.cholesky_inverse.html#torch.cholesky_inverse">cholesky_inverse() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cholesky_inverse.html#torch.Tensor.cholesky_inverse">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cholesky_solve.html#torch.cholesky_solve">cholesky_solve() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cholesky_solve.html#torch.Tensor.cholesky_solve">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.chunk.html#torch.chunk">chunk() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.chunk.html#torch.Tensor.chunk">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.CircularPad1d.html#torch.nn.CircularPad1d">CircularPad1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.CircularPad2d.html#torch.nn.CircularPad2d">CircularPad2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.CircularPad3d.html#torch.nn.CircularPad3d">CircularPad3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.clamp.html#torch.ao.nn.quantized.functional.clamp">clamp (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.clamp.html#torch.clamp">clamp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.clamp.html#torch.Tensor.clamp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.clamp_.html#torch.Tensor.clamp_">clamp_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.cleanup">cleanup() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.cufft_plan_cache.clear">clear() (in module torch.backends.cuda.cufft_plan_cache)</a>

      <ul>
        <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.clear">(torch.autograd.profiler_util.StringTable method)</a>
</li>
        <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.clear">(torch.nn.ModuleDict method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.clear">(torch.nn.ParameterDict method)</a>
</li>
        <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.clear">(torch.onnx.verification.GraphInfo method)</a>
</li>
      </ul></li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerServer.clear_timers">clear_timers() (torch.distributed.elastic.timer.TimerServer method)</a>
</li>
      <li><a href="generated/torch.clip.html#torch.clip">clip() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.clip.html#torch.Tensor.clip">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.clip_.html#torch.Tensor.clip_">clip_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.utils.clip_grad_norm.html#torch.nn.utils.clip_grad_norm">clip_grad_norm() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.nn.utils.clip_grad_norm_.html#torch.nn.utils.clip_grad_norm_">clip_grad_norm_() (in module torch.nn.utils)</a>

      <ul>
        <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.clip_grad_norm_">(torch.distributed.fsdp.FullyShardedDataParallel method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.clip_grad_value_.html#torch.nn.utils.clip_grad_value_">clip_grad_value_() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.cuda.clock_rate.html#torch.cuda.clock_rate">clock_rate() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.clone.html#torch.clone">clone() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.autograd.grad_mode.inference_mode.html#torch.autograd.grad_mode.inference_mode.clone">(torch.autograd.grad_mode.inference_mode method)</a>
</li>
        <li><a href="generated/torch.autograd.grad_mode.set_grad_enabled.html#torch.autograd.grad_mode.set_grad_enabled.clone">(torch.autograd.grad_mode.set_grad_enabled method)</a>
</li>
        <li><a href="generated/torch.autograd.grad_mode.set_multithreading_enabled.html#torch.autograd.grad_mode.set_multithreading_enabled.clone">(torch.autograd.grad_mode.set_multithreading_enabled method)</a>
</li>
        <li><a href="generated/torch.Tensor.clone.html#torch.Tensor.clone">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.clone">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.clone">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.close">close (torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout property)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.close">close() (torch.package.PackageExporter method)</a>

      <ul>
        <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.close">(torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.LazyBatchNorm1d.html#torch.nn.LazyBatchNorm1d.cls_to_become">cls_to_become (torch.nn.LazyBatchNorm1d attribute)</a>

      <ul>
        <li><a href="generated/torch.nn.LazyBatchNorm2d.html#torch.nn.LazyBatchNorm2d.cls_to_become">(torch.nn.LazyBatchNorm2d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyBatchNorm3d.html#torch.nn.LazyBatchNorm3d.cls_to_become">(torch.nn.LazyBatchNorm3d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConv1d.html#torch.nn.LazyConv1d.cls_to_become">(torch.nn.LazyConv1d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConv2d.html#torch.nn.LazyConv2d.cls_to_become">(torch.nn.LazyConv2d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConv3d.html#torch.nn.LazyConv3d.cls_to_become">(torch.nn.LazyConv3d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConvTranspose1d.html#torch.nn.LazyConvTranspose1d.cls_to_become">(torch.nn.LazyConvTranspose1d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConvTranspose2d.html#torch.nn.LazyConvTranspose2d.cls_to_become">(torch.nn.LazyConvTranspose2d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConvTranspose3d.html#torch.nn.LazyConvTranspose3d.cls_to_become">(torch.nn.LazyConvTranspose3d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyInstanceNorm1d.html#torch.nn.LazyInstanceNorm1d.cls_to_become">(torch.nn.LazyInstanceNorm1d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyInstanceNorm2d.html#torch.nn.LazyInstanceNorm2d.cls_to_become">(torch.nn.LazyInstanceNorm2d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyInstanceNorm3d.html#torch.nn.LazyInstanceNorm3d.cls_to_become">(torch.nn.LazyInstanceNorm3d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear.cls_to_become">(torch.nn.LazyLinear attribute)</a>
</li>
        <li><a href="generated/torch.nn.parameter.UninitializedParameter.html#torch.nn.parameter.UninitializedParameter.cls_to_become">(torch.nn.parameter.UninitializedParameter attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.coalesce.html#torch.Tensor.coalesce">coalesce() (torch.Tensor method)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule.code">code (torch.fx.GraphModule property)</a>

      <ul>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.code">(torch.jit.ScriptModule property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.code_with_constants">code_with_constants (torch.jit.ScriptModule property)</a>
</li>
      <li><a href="generated/torch.Tensor.col_indices.html#torch.Tensor.col_indices">col_indices() (torch.Tensor method)</a>
</li>
      <li><a href="data.html#torch.utils.data._utils.collate.collate">collate() (in module torch.utils.data._utils.collate)</a>
</li>
      <li><a href="futures.html#torch.futures.collect_all">collect_all() (in module torch.futures)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Timer.collect_callgrind">collect_callgrind() (torch.utils.benchmark.Timer method)</a>
</li>
      <li><a href="generated/torch.column_stack.html#torch.column_stack">column_stack() (in module torch)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.ColwiseParallel">ColwiseParallel (class in torch.distributed.tensor.parallel)</a>
</li>
      <li><a href="generated/torch.combinations.html#torch.combinations">combinations() (in module torch)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.commit_tensor">commit_tensor() (torch.distributed.checkpoint.LoadPlanner method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.compare_model_outputs">compare_model_outputs() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.compare_model_stub">compare_model_stub() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store.compare_set">compare_set() (in module torch.distributed.Store)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.compare_weights">compare_weights() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="generated/torch.compile.html#torch.compile">compile() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.compiler.compile.html#torch.compiler.compile">(in module torch.compiler)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.compile">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.compile">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.compiled_with_cxx11_abi.html#torch.compiled_with_cxx11_abi">compiled_with_cxx11_abi() (in module torch)</a>
</li>
      <li><a href="generated/torch.complex.html#torch.complex">complex() (in module torch)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.complex_double">complex_double() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.complex_double">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.TypedStorage.complex_float">complex_float() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.complex_float">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.ComplexDoubleStorage">ComplexDoubleStorage (class in torch)</a>
</li>
      <li><a href="storage.html#torch.ComplexFloatStorage">ComplexFloatStorage (class in torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.component_distribution">component_distribution (torch.distributions.mixture_same_family.MixtureSameFamily property)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.ComposeTransform">ComposeTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns.fx.utils.compute_cosine_similarity">compute_cosine_similarity() (in module torch.ao.ns.fx.utils)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.compute_mask">compute_mask() (torch.nn.utils.prune.BasePruningMethod method)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.compute_mask">(torch.nn.utils.prune.LnStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.compute_mask">(torch.nn.utils.prune.PruningContainer method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.compute_mask">(torch.nn.utils.prune.RandomStructured method)</a>
</li>
      </ul></li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns.fx.utils.compute_normalized_l2_error">compute_normalized_l2_error() (in module torch.ao.ns.fx.utils)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns.fx.utils.compute_sqnr">compute_sqnr() (in module torch.ao.ns.fx.utils)</a>
</li>
      <li><a href="generated/torch.concat.html#torch.concat">concat() (in module torch)</a>
</li>
      <li><a href="data.html#torch.utils.data.ConcatDataset">ConcatDataset (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.concatenate.html#torch.concatenate">concatenate() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.inverse_gamma.InverseGamma.concentration">concentration (torch.distributions.inverse_gamma.InverseGamma property)</a>
</li>
      <li><a href="distributions.html#torch.distributions.beta.Beta.concentration0">concentration0 (torch.distributions.beta.Beta property)</a>
</li>
      <li><a href="distributions.html#torch.distributions.beta.Beta.concentration1">concentration1 (torch.distributions.beta.Beta property)</a>
</li>
      <li><a href="generated/torch.cond.html#torch.cond">cond() (in module torch)</a>

      <ul>
        <li><a href="cond.html#torch._higher_order_ops.cond.cond">(in module torch._higher_order_ops.cond)</a>
</li>
        <li><a href="generated/torch.linalg.cond.html#torch.linalg.cond">(in module torch.linalg)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.configs">configs (torch.ao.quantization.backend_config.BackendConfig property)</a>
</li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.configure">configure() (in module torch.distributed.elastic.metrics)</a>

      <ul>
        <li><a href="elastic/timer.html#torch.distributed.elastic.timer.configure">(in module torch.distributed.elastic.timer)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="rpc.html#torch.distributed.rpc.PyRRef.confirmed_by_owner">confirmed_by_owner() (torch.distributed.rpc.PyRRef method)</a>
</li>
      <li><a href="generated/torch.conj.html#torch.conj">conj() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.conj.html#torch.Tensor.conj">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.conj_physical.html#torch.conj_physical">conj_physical() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.conj_physical.html#torch.Tensor.conj_physical">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.conj_physical_.html#torch.Tensor.conj_physical_">conj_physical_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.api.ConsoleMetricHandler">ConsoleMetricHandler (class in torch.distributed.elastic.metrics.api)</a>
</li>
      <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.consolidate_state_dict">consolidate_state_dict() (torch.distributed.optim.ZeroRedundancyOptimizer method)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.constant_">constant_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ConstantLR.html#torch.optim.lr_scheduler.ConstantLR">ConstantLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.nn.ConstantPad1d.html#torch.nn.ConstantPad1d">ConstantPad1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ConstantPad2d.html#torch.nn.ConstantPad2d">ConstantPad2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ConstantPad3d.html#torch.nn.ConstantPad3d">ConstantPad3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.constrain_range.html#torch.fx.experimental.symbolic_shapes.constrain_range">constrain_range() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.constrain_unify.html#torch.fx.experimental.symbolic_shapes.constrain_unify">constrain_unify() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.Constraint">Constraint (class in torch.distributions.constraints)</a>

      <ul>
        <li><a href="export.html#torch.export.Constraint">(in module torch.export)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.constraint_registry.ConstraintRegistry">ConstraintRegistry (class in torch.distributions.constraint_registry)</a>
</li>
      <li><a href="rpc.html#torch.distributed.autograd.context">context (class in torch.distributed.autograd)</a>
</li>
      <li><a href="generated/torch.Tensor.contiguous.html#torch.Tensor.contiguous">contiguous() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli">ContinuousBernoulli (class in torch.distributions.continuous_bernoulli)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.Conv1d.html#torch.ao.nn.quantized.Conv1d">Conv1d (class in torch.ao.nn.quantized)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.conv1d.html#torch.ao.nn.quantized.functional.conv1d">conv1d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Conv1d.html#torch.nn.Conv1d">Conv1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv1d.html#torch.nn.functional.conv1d">conv1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.qat.Conv2d.html#torch.ao.nn.qat.Conv2d">Conv2d (class in torch.ao.nn.qat)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantized.Conv2d.html#torch.ao.nn.quantized.Conv2d">(class in torch.ao.nn.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.functional.conv2d.html#torch.ao.nn.quantized.functional.conv2d">conv2d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Conv2d.html#torch.nn.Conv2d">Conv2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv2d.html#torch.nn.functional.conv2d">conv2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.qat.Conv3d.html#torch.ao.nn.qat.Conv3d">Conv3d (class in torch.ao.nn.qat)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantized.Conv3d.html#torch.ao.nn.quantized.Conv3d">(class in torch.ao.nn.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.functional.conv3d.html#torch.ao.nn.quantized.functional.conv3d">conv3d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Conv3d.html#torch.nn.Conv3d">Conv3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv3d.html#torch.nn.functional.conv3d">conv3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv_transpose1d.html#torch.nn.functional.conv_transpose1d">conv_transpose1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv_transpose2d.html#torch.nn.functional.conv_transpose2d">conv_transpose2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv_transpose3d.html#torch.nn.functional.conv_transpose3d">conv_transpose3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBn1d.html#torch.ao.nn.intrinsic.ConvBn1d">ConvBn1d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBn1d.html#torch.ao.nn.intrinsic.qat.ConvBn1d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBn2d.html#torch.ao.nn.intrinsic.ConvBn2d">ConvBn2d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBn2d.html#torch.ao.nn.intrinsic.qat.ConvBn2d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBn3d.html#torch.ao.nn.intrinsic.ConvBn3d">ConvBn3d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBn3d.html#torch.ao.nn.intrinsic.qat.ConvBn3d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBnReLU1d.html#torch.ao.nn.intrinsic.ConvBnReLU1d">ConvBnReLU1d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBnReLU1d.html#torch.ao.nn.intrinsic.qat.ConvBnReLU1d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBnReLU2d.html#torch.ao.nn.intrinsic.ConvBnReLU2d">ConvBnReLU2d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBnReLU2d.html#torch.ao.nn.intrinsic.qat.ConvBnReLU2d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBnReLU3d.html#torch.ao.nn.intrinsic.ConvBnReLU3d">ConvBnReLU3d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBnReLU3d.html#torch.ao.nn.intrinsic.qat.ConvBnReLU3d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.convert.html#torch.ao.quantization.convert">convert (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.nn.utils.convert_conv2d_weight_memory_format.html#torch.nn.utils.convert_conv2d_weight_memory_format">convert_conv2d_weight_memory_format() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.nn.utils.convert_conv3d_weight_memory_format.html#torch.nn.utils.convert_conv3d_weight_memory_format">convert_conv3d_weight_memory_format() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.ao.quantization.quantize_fx.convert_fx.html#torch.ao.quantization.quantize_fx.convert_fx">convert_fx (class in torch.ao.quantization.quantize_fx)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.convert_n_shadows_model">convert_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm.convert_sync_batchnorm">convert_sync_batchnorm() (torch.nn.SyncBatchNorm class method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.html#torch.ao.quantization.fx.custom_config.ConvertCustomConfig">ConvertCustomConfig (class in torch.ao.quantization.fx.custom_config)</a>
</li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvReLU1d.html#torch.ao.nn.intrinsic.ConvReLU1d">ConvReLU1d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.ConvReLU1d.html#torch.ao.nn.intrinsic.quantized.ConvReLU1d">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvReLU2d.html#torch.ao.nn.intrinsic.ConvReLU2d">ConvReLU2d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvReLU2d.html#torch.ao.nn.intrinsic.qat.ConvReLU2d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.ConvReLU2d.html#torch.ao.nn.intrinsic.quantized.ConvReLU2d">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvReLU3d.html#torch.ao.nn.intrinsic.ConvReLU3d">ConvReLU3d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvReLU3d.html#torch.ao.nn.intrinsic.qat.ConvReLU3d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.ConvReLU3d.html#torch.ao.nn.intrinsic.quantized.ConvReLU3d">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.ConvTranspose1d.html#torch.ao.nn.quantized.ConvTranspose1d">ConvTranspose1d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.ConvTranspose1d.html#torch.nn.ConvTranspose1d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.ConvTranspose2d.html#torch.ao.nn.quantized.ConvTranspose2d">ConvTranspose2d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.ConvTranspose3d.html#torch.ao.nn.quantized.ConvTranspose3d">ConvTranspose3d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.ConvTranspose3d.html#torch.nn.ConvTranspose3d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.copy">copy() (torch.autograd.profiler_util.StringTable method)</a>

      <ul>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.copy">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.copy_.html#torch.Tensor.copy_">copy_() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.copy_">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.copy_">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.copysign.html#torch.copysign">copysign() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.copysign.html#torch.Tensor.copysign">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.copysign_.html#torch.Tensor.copysign_">copysign_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.CorrCholeskyTransform">CorrCholeskyTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.corrcoef.html#torch.corrcoef">corrcoef() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.corrcoef.html#torch.Tensor.corrcoef">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cos.html#torch.cos">cos() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cos.html#torch.Tensor.cos">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.cos_.html#torch.Tensor.cos_">cos_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.cosh.html#torch.cosh">cosh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cosh.html#torch.Tensor.cosh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.cosh_.html#torch.Tensor.cosh_">cosh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.signal.windows.cosine.html#torch.signal.windows.cosine">cosine() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.nn.functional.cosine_embedding_loss.html#torch.nn.functional.cosine_embedding_loss">cosine_embedding_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.cosine_similarity.html#torch.nn.functional.cosine_similarity">cosine_similarity() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR">CosineAnnealingLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts">CosineAnnealingWarmRestarts (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.nn.CosineEmbeddingLoss.html#torch.nn.CosineEmbeddingLoss">CosineEmbeddingLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.CosineSimilarity.html#torch.nn.CosineSimilarity">CosineSimilarity (class in torch.nn)</a>
</li>
      <li><a href="monitor.html#torch.monitor.Stat.count">count (torch.monitor.Stat property)</a>
</li>
      <li><a href="generated/torch.autograd.forward_ad.UnpackedDualTensor.html#torch.autograd.forward_ad.UnpackedDualTensor.count">count() (torch.autograd.forward_ad.UnpackedDualTensor method)</a>

      <ul>
        <li><a href="generated/torch.autograd.profiler_util.Kernel.html#torch.autograd.profiler_util.Kernel.count">(torch.autograd.profiler_util.Kernel method)</a>
</li>
        <li><a href="generated/torch.jit.Attribute.html#torch.jit.Attribute.count">(torch.jit.Attribute method)</a>
</li>
        <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.count">(torch.nn.utils.rnn.PackedSequence method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.count_nonzero.html#torch.count_nonzero">count_nonzero() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.count_nonzero.html#torch.Tensor.count_nonzero">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.CallgrindStats.counts">counts() (torch.utils.benchmark.CallgrindStats method)</a>
</li>
      <li><a href="generated/torch.cov.html#torch.cov">cov() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cov.html#torch.Tensor.cov">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.covariance_matrix">covariance_matrix (torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.covariance_matrix">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.CppExtension">CppExtension() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.cpu">cpu() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.cpu">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.cpu.html#torch.Tensor.cpu">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.cpu">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.cpu">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.CPUOffload">CPUOffload (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.create_arg">create_arg() (torch.fx.Tracer method)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.create_args_for_root">create_args_for_root() (torch.fx.Tracer method)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.create_backend">create_backend() (in module torch.distributed.elastic.rendezvous.c10d_rendezvous_backend)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.create_backend">(in module torch.distributed.elastic.rendezvous.etcd_rendezvous_backend)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.create_global_plan">create_global_plan() (torch.distributed.checkpoint.LoadPlanner method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.create_global_plan">(torch.distributed.checkpoint.SavePlanner method)</a>
</li>
      </ul></li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.create_handler">create_handler() (in module torch.distributed.elastic.rendezvous.dynamic_rendezvous)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry.create_handler">(torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.create_local_plan">create_local_plan() (torch.distributed.checkpoint.LoadPlanner method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.create_local_plan">(torch.distributed.checkpoint.SavePlanner method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.create_node">create_node() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Tracer.create_node">(torch.fx.Tracer method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Tracer.create_proxy">create_proxy() (torch.fx.Tracer method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.create_symbol">create_symbol() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.create_symbolic_sizes_strides_storage_offset">create_symbolic_sizes_strides_storage_offset() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.create_symboolnode">create_symboolnode() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.create_symintnode">create_symintnode() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.create_unbacked_symbool">create_unbacked_symbool() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.create_unbacked_symfloat">create_unbacked_symfloat() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.create_unbacked_symint">create_unbacked_symint() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.create_unspecified_symbol">create_unspecified_symbol() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.create_unspecified_symint_and_symbol">create_unspecified_symint_and_symbol() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.cross.html#torch.cross">cross() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.cross.html#torch.linalg.cross">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.cross.html#torch.Tensor.cross">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.cross_entropy.html#torch.nn.functional.cross_entropy">cross_entropy() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss">CrossEntropyLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.Tensor.crow_indices.html#torch.Tensor.crow_indices">crow_indices() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.functional.ctc_loss.html#torch.nn.functional.ctc_loss">ctc_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.CTCLoss.html#torch.nn.CTCLoss">CTCLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.cuda">cuda() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.cuda">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.cuda.html#torch.Tensor.cuda">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.cuda">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.cuda">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.CUDAExtension">CUDAExtension() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph">CUDAGraph (class in torch.cuda)</a>
</li>
      <li><a href="generated/torch.compiler.cudagraph_mark_step_begin.html#torch.compiler.cudagraph_mark_step_begin">cudagraph_mark_step_begin() (in module torch.compiler)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAPluggableAllocator.html#torch.cuda.CUDAPluggableAllocator">CUDAPluggableAllocator (class in torch.cuda)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.cudnn_sdp_enabled">cudnn_sdp_enabled() (in module torch.backends.cuda)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.cufft_plan_cache">cufft_plan_cache (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.cummax.html#torch.cummax">cummax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cummax.html#torch.Tensor.cummax">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cummin.html#torch.cummin">cummin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cummin.html#torch.Tensor.cummin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cumprod.html#torch.cumprod">cumprod() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cumprod.html#torch.Tensor.cumprod">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.cumprod_.html#torch.Tensor.cumprod_">cumprod_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.cumsum.html#torch.cumsum">cumsum() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cumsum.html#torch.Tensor.cumsum">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.cumsum_.html#torch.Tensor.cumsum_">cumsum_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.cumulative_trapezoid.html#torch.cumulative_trapezoid">cumulative_trapezoid() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.CumulativeDistributionTransform">CumulativeDistributionTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.mps.current_allocated_memory.html#torch.mps.current_allocated_memory">current_allocated_memory() (in module torch.mps)</a>
</li>
      <li><a href="generated/torch.cuda.current_blas_handle.html#torch.cuda.current_blas_handle">current_blas_handle() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cpu.current_device.html#torch.cpu.current_device">current_device() (in module torch.cpu)</a>

      <ul>
        <li><a href="generated/torch.cuda.current_device.html#torch.cuda.current_device">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.xpu.current_device.html#torch.xpu.current_device">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.profiler.KinetoStepTracker.html#torch.autograd.profiler.KinetoStepTracker.current_step">current_step() (torch.autograd.profiler.KinetoStepTracker class method)</a>
</li>
      <li><a href="generated/torch.cpu.current_stream.html#torch.cpu.current_stream">current_stream() (in module torch.cpu)</a>

      <ul>
        <li><a href="generated/torch.cuda.current_stream.html#torch.cuda.current_stream">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.xpu.current_stream.html#torch.xpu.current_stream">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="amp.html#torch.cuda.amp.custom_bwd">custom_bwd() (in module torch.cuda.amp)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.custom_from_mask.html#torch.nn.utils.prune.custom_from_mask">custom_from_mask() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.custom_fwd">custom_fwd() (in module torch.cuda.amp)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask">CustomFromMask (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="export.html#torch.export.graph_signature.CustomObjArgument">CustomObjArgument (class in torch.export.graph_signature)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.CyclicLR.html#torch.optim.lr_scheduler.CyclicLR">CyclicLR (class in torch.optim.lr_scheduler)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="D">D</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="monitor.html#torch.monitor.Event.data">data (torch.monitor.Event property)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.data">(torch.nn.utils.rnn.PackedSequence attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.torch.nn.parallel.data_parallel.html#torch.nn.parallel.data_parallel">data_parallel() (in module torch.nn.parallel)</a>
</li>
      <li><a href="generated/torch.Tensor.data_ptr.html#torch.Tensor.data_ptr">data_ptr() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.data_ptr">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.data_ptr">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="monitor.html#torch.monitor.data_value_t">data_value_t (class in torch.monitor)</a>
</li>
      <li><a href="data.html#torch.utils.data.DataLoader">DataLoader (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.nn.DataParallel.html#torch.nn.DataParallel">DataParallel (class in torch.nn)</a>
</li>
      <li><a href="data.html#torch.utils.data.Dataset">Dataset (class in torch.utils.data)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.dcp_to_torch_save">dcp_to_torch_save() (in module torch.distributed.checkpoint.format_utils)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.debug_dump">debug_dump() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_activation_only_qconfig.html#torch.ao.quantization.qconfig.default_activation_only_qconfig">default_activation_only_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="data.html#torch.utils.data.default_collate">default_collate() (in module torch.utils.data)</a>
</li>
      <li><a href="data.html#torch.utils.data.default_convert">default_convert() (in module torch.utils.data)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_debug_observer.html#torch.ao.quantization.observer.default_debug_observer">default_debug_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_debug_qconfig.html#torch.ao.quantization.qconfig.default_debug_qconfig">default_debug_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_dynamic_qconfig.html#torch.ao.quantization.qconfig.default_dynamic_qconfig">default_dynamic_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_dynamic_quant_observer.html#torch.ao.quantization.observer.default_dynamic_quant_observer">default_dynamic_quant_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.default_eval_fn.html#torch.ao.quantization.default_eval_fn">default_eval_fn (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.default_factory">default_factory (torch.autograd.profiler_util.StringTable attribute)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_fake_quant.html#torch.ao.quantization.fake_quantize.default_fake_quant">default_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_float_qparams_observer.html#torch.ao.quantization.observer.default_float_qparams_observer">default_float_qparams_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_fused_act_fake_quant.html#torch.ao.quantization.fake_quantize.default_fused_act_fake_quant">default_fused_act_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant.html#torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant">default_fused_per_channel_wt_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant.html#torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant">default_fused_wt_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="torch.html#torch.torch.default_generator">default_generator (torch.torch attribute)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_histogram_fake_quant.html#torch.ao.quantization.fake_quantize.default_histogram_fake_quant">default_histogram_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_histogram_observer.html#torch.ao.quantization.observer.default_histogram_observer">default_histogram_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_observer.html#torch.ao.quantization.observer.default_observer">default_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_per_channel_qconfig.html#torch.ao.quantization.qconfig.default_per_channel_qconfig">default_per_channel_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant.html#torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant">default_per_channel_weight_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_per_channel_weight_observer.html#torch.ao.quantization.observer.default_per_channel_weight_observer">default_per_channel_weight_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_placeholder_observer.html#torch.ao.quantization.observer.default_placeholder_observer">default_placeholder_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_qat_qconfig.html#torch.ao.quantization.qconfig.default_qat_qconfig">default_qat_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_qat_qconfig_v2.html#torch.ao.quantization.qconfig.default_qat_qconfig_v2">default_qat_qconfig_v2 (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_qconfig.html#torch.ao.quantization.qconfig.default_qconfig">default_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.cuda.default_stream.html#torch.cuda.default_stream">default_stream() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_weight_fake_quant.html#torch.ao.quantization.fake_quantize.default_weight_fake_quant">default_weight_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_weight_observer.html#torch.ao.quantization.observer.default_weight_observer">default_weight_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_weight_only_qconfig.html#torch.ao.quantization.qconfig.default_weight_only_qconfig">default_weight_only_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultLoadPlanner">DefaultLoadPlanner (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.DefaultLogsSpecs">DefaultLogsSpecs (class in torch.distributed.elastic.multiprocessing.api)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultSavePlanner">DefaultSavePlanner (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.defer_runtime_assert">defer_runtime_assert() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="library.html#torch.library.define">define() (in module torch.library)</a>

      <ul>
        <li><a href="library.html#torch.library.Library.define">(torch.library.Library method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.definitely_false.html#torch.fx.experimental.symbolic_shapes.definitely_false">definitely_false() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.definitely_true.html#torch.fx.experimental.symbolic_shapes.definitely_true">definitely_true() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.deg2rad.html#torch.deg2rad">deg2rad() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.deg2rad.html#torch.Tensor.deg2rad">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.GraphModule.delete_all_unused_submodules">delete_all_unused_submodules() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store.delete_key">delete_key() (in module torch.distributed.Store)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule.delete_submodule">delete_submodule() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.CallgrindStats.delta">delta() (torch.utils.benchmark.CallgrindStats method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.denied_modules">denied_modules() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.FunctionCounts.denoise">denoise() (torch.utils.benchmark.FunctionCounts method)</a>
</li>
      <li><a href="generated/torch.Tensor.dense_dim.html#torch.Tensor.dense_dim">dense_dim() (torch.Tensor method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.deny">deny() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.dependency_graph_string">dependency_graph_string() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.dependent_property">dependent_property (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.dequantize.html#torch.dequantize">dequantize() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantizable.MultiheadAttention.html#torch.ao.nn.quantizable.MultiheadAttention.dequantize">(torch.ao.nn.quantizable.MultiheadAttention method)</a>
</li>
        <li><a href="generated/torch.Tensor.dequantize.html#torch.Tensor.dequantize">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.DeQuantStub.html#torch.ao.quantization.DeQuantStub">DeQuantStub (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.det.html#torch.det">det() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.det.html#torch.linalg.det">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.det.html#torch.Tensor.det">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.detach.html#torch.Tensor.detach">detach() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.detach_.html#torch.Tensor.detach_">detach_() (torch.Tensor method)</a>
</li>
      <li><a href="autograd.html#torch.autograd.detect_anomaly">detect_anomaly (class in torch.autograd)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.deterministic">deterministic (in module torch.backends.cudnn)</a>
</li>
      <li><a href="tensor_attributes.html#torch.device">device (class in torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.device.html#torch.cuda.device">(class in torch.cuda)</a>
</li>
        <li><a href="generated/torch.xpu.device.html#torch.xpu.device">(class in torch.xpu)</a>
</li>
        <li><a href="generated/torch.autograd.profiler_util.Kernel.html#torch.autograd.profiler_util.Kernel.device">(torch.autograd.profiler_util.Kernel attribute)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.device">(torch.Generator attribute)</a>
</li>
        <li><a href="generated/torch.Tensor.device.html#torch.Tensor.device">(torch.Tensor attribute)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.device">(torch.TypedStorage property)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.device">(torch.UntypedStorage attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cpu.device_count.html#torch.cpu.device_count">device_count() (in module torch.cpu)</a>

      <ul>
        <li><a href="generated/torch.cuda.device_count.html#torch.cuda.device_count">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.xpu.device_count.html#torch.xpu.device_count">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.device_maps">device_maps (torch.distributed.rpc.TensorPipeRpcBackendOptions property)</a>
</li>
      <li><a href="generated/torch.cuda.device_of.html#torch.cuda.device_of">device_of (class in torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.xpu.device_of.html#torch.xpu.device_of">(class in torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.device_mesh.DeviceMesh">DeviceMesh (class in torch.distributed.device_mesh)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.devices">devices (torch.distributed.rpc.TensorPipeRpcBackendOptions property)</a>
</li>
      <li><a href="distributions.html#torch.distributions.chi2.Chi2.df">df (torch.distributions.chi2.Chi2 property)</a>
</li>
      <li><a href="generated/torch.diag.html#torch.diag">diag() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.diag.html#torch.Tensor.diag">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.diag_embed.html#torch.diag_embed">diag_embed() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.diag_embed.html#torch.Tensor.diag_embed">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.diagflat.html#torch.diagflat">diagflat() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.diagflat.html#torch.Tensor.diagflat">(torch.Tensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="onnx_dynamo.html#torch.onnx.ONNXProgram.diagnostic_context">diagnostic_context (torch.onnx.ONNXProgram property)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.DiagnosticOptions">DiagnosticOptions (class in torch.onnx)</a>
</li>
      <li><a href="generated/torch.diagonal.html#torch.diagonal">diagonal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.diagonal.html#torch.linalg.diagonal">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.diagonal.html#torch.Tensor.diagonal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.diagonal_scatter.html#torch.diagonal_scatter">diagonal_scatter() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.diagonal_scatter.html#torch.Tensor.diagonal_scatter">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.diff.html#torch.diff">diff() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.diff.html#torch.Tensor.diff">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.digamma.html#torch.digamma">digamma() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.digamma">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.digamma.html#torch.Tensor.digamma">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.digamma_.html#torch.Tensor.digamma_">digamma_() (torch.Tensor method)</a>
</li>
      <li><a href="export.html#torch.export.dynamic_shapes.Dim">Dim() (in module torch.export.dynamic_shapes)</a>
</li>
      <li><a href="generated/torch.Tensor.dim.html#torch.Tensor.dim">dim() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.dim_order.html#torch.Tensor.dim_order">dim_order() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.DimConstraints.html#torch.fx.experimental.symbolic_shapes.DimConstraints">DimConstraints (class in torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.DimDynamic.html#torch.fx.experimental.symbolic_shapes.DimDynamic">DimDynamic (class in torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="export.html#torch.export.dims">dims() (in module torch.export)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.dirac_">dirac_() (in module torch.nn.init)</a>
</li>
      <li><a href="package.html#torch.package.Directory">Directory (class in torch.package)</a>
</li>
      <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet">Dirichlet (class in torch.distributions.dirichlet)</a>
</li>
      <li><a href="generated/torch.compiler.disable.html#torch.compiler.disable">disable() (in module torch.compiler)</a>

      <ul>
        <li><a href="generated/torch.sparse.check_sparse_tensor_invariants.html#torch.sparse.check_sparse_tensor_invariants.disable">(torch.sparse.check_sparse_tensor_invariants static method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.disable_fake_quant.html#torch.ao.quantization.fake_quantize.disable_fake_quant">disable_fake_quant (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="onnx_torchscript.html#torch.onnx.disable_log">disable_log() (in module torch.onnx)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.disable_observer.html#torch.ao.quantization.fake_quantize.disable_observer">disable_observer (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.disable_saved_tensors_hooks">disable_saved_tensors_hooks (class in torch.autograd.graph)</a>
</li>
      <li><a href="generated/torch.dist.html#torch.dist">dist() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.dist.html#torch.Tensor.dist">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.DistBackendError">DistBackendError (class in torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.DistError">DistError (class in torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.DistNetworkError">DistNetworkError (class in torch.distributed)</a>
</li>
      <li><a href="generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel">DistributedDataParallel (class in torch.nn.parallel)</a>
</li>
      <li><a href="distributed.optim.html#torch.distributed.optim.DistributedOptimizer">DistributedOptimizer (class in torch.distributed.optim)</a>
</li>
      <li><a href="data.html#torch.utils.data.distributed.DistributedSampler">DistributedSampler (class in torch.utils.data.distributed)</a>
</li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution">Distribution (class in torch.distributions.distribution)</a>
</li>
      <li><a href="distributed.html#torch.distributed.DistStoreError">DistStoreError (class in torch.distributed)</a>
</li>
      <li><a href="generated/torch.div.html#torch.div">div() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.div.html#torch.Tensor.div">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.div_.html#torch.Tensor.div_">div_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.divide.html#torch.divide">divide() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.divide.html#torch.Tensor.divide">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.divide_.html#torch.Tensor.divide_">divide_() (torch.Tensor method)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.done">done() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.dot.html#torch.dot">dot() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.dot.html#torch.Tensor.dot">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.double">double() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.double">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.double.html#torch.Tensor.double">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.double">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.double">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.DoubleStorage">DoubleStorage (class in torch)</a>
</li>
      <li><a href="hub.html#torch.hub.download_url_to_file">download_url_to_file() (in module torch.hub)</a>
</li>
      <li><a href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine.draw">draw() (torch.quasirandom.SobolEngine method)</a>
</li>
      <li><a href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine.draw_base2">draw_base2() (torch.quasirandom.SobolEngine method)</a>
</li>
      <li><a href="generated/torch.mps.driver_allocated_memory.html#torch.mps.driver_allocated_memory">driver_allocated_memory() (in module torch.mps)</a>
</li>
      <li><a href="generated/torch.nn.Dropout.html#torch.nn.Dropout">Dropout (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.dropout.html#torch.nn.functional.dropout">dropout() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.Dropout1d.html#torch.nn.Dropout1d">Dropout1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.dropout1d.html#torch.nn.functional.dropout1d">dropout1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.Dropout2d.html#torch.nn.Dropout2d">Dropout2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.dropout2d.html#torch.nn.functional.dropout2d">dropout2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.Dropout3d.html#torch.nn.Dropout3d">Dropout3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.dropout3d.html#torch.nn.functional.dropout3d">dropout3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.dsplit.html#torch.dsplit">dsplit() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.dsplit.html#torch.Tensor.dsplit">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.dstack.html#torch.dstack">dstack() (in module torch)</a>
</li>
      <li><a href="tensor_attributes.html#torch.dtype">dtype (class in torch)</a>

      <ul>
        <li><a href="storage.html#torch.BFloat16Storage.dtype">(torch.BFloat16Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.BoolStorage.dtype">(torch.BoolStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.ByteStorage.dtype">(torch.ByteStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.CharStorage.dtype">(torch.CharStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.ComplexDoubleStorage.dtype">(torch.ComplexDoubleStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.ComplexFloatStorage.dtype">(torch.ComplexFloatStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.DoubleStorage.dtype">(torch.DoubleStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.FloatStorage.dtype">(torch.FloatStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.HalfStorage.dtype">(torch.HalfStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.IntStorage.dtype">(torch.IntStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.LongStorage.dtype">(torch.LongStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.QInt32Storage.dtype">(torch.QInt32Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.QInt8Storage.dtype">(torch.QInt8Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.QUInt2x4Storage.dtype">(torch.QUInt2x4Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.QUInt4x2Storage.dtype">(torch.QUInt4x2Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.QUInt8Storage.dtype">(torch.QUInt8Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.ShortStorage.dtype">(torch.ShortStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.dtype">(torch.TypedStorage attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.dtype">dtype() (torch.onnx.JitScalarType method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.DTypeConfig.html#torch.ao.quantization.backend_config.DTypeConfig">DTypeConfig (class in torch.ao.quantization.backend_config)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.DTypeWithConstraints.html#torch.ao.quantization.backend_config.DTypeWithConstraints">DTypeWithConstraints (class in torch.ao.quantization.backend_config)</a>
</li>
      <li><a href="generated/torch.autograd.forward_ad.dual_level.html#torch.autograd.forward_ad.dual_level">dual_level (class in torch.autograd.forward_ad)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.Kernel.html#torch.autograd.profiler_util.Kernel.duration">duration (torch.autograd.profiler_util.Kernel attribute)</a>
</li>
      <li><a href="export.html#torch.export.dynamic_shapes.dynamic_dim">dynamic_dim() (in module torch.export.dynamic_shapes)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.DynamicMetaLoadPlanner">DynamicMetaLoadPlanner (class in torch.distributed.checkpoint.format_utils)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler">DynamicRendezvousHandler (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.dynamo_export">dynamo_export() (in module torch.onnx)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="E">E</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.linalg.eig.html#torch.linalg.eig">eig() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.eigh.html#torch.linalg.eigh">eigh() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.eigvals.html#torch.linalg.eigvals">eigvals() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.eigvalsh.html#torch.linalg.eigvalsh">eigvalsh() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.einsum.html#torch.einsum">einsum() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.elapsed_time">elapsed_time() (torch.cuda.Event method)</a>

      <ul>
        <li><a href="generated/torch.mps.event.Event.html#torch.mps.event.Event.elapsed_time">(torch.mps.event.Event method)</a>
</li>
        <li><a href="generated/torch.xpu.Event.html#torch.xpu.Event.elapsed_time">(torch.xpu.Event method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.profiler_util.Interval.html#torch.autograd.profiler_util.Interval.elapsed_us">elapsed_us() (torch.autograd.profiler_util.Interval method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.ElasticAgent">ElasticAgent (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="generated/torch.Tensor.element_size.html#torch.Tensor.element_size">element_size() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.element_size">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.element_size">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.eliminate_dead_code">eliminate_dead_code() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.ELU.html#torch.ao.nn.quantized.ELU">ELU (class in torch.ao.nn.quantized)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.elu.html#torch.ao.nn.quantized.functional.elu">elu (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.ELU.html#torch.nn.ELU">ELU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.elu.html#torch.nn.functional.elu">elu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.elu_.html#torch.nn.functional.elu_">elu_() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.Embedding.html#torch.ao.nn.quantized.Embedding">Embedding (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.Embedding.html#torch.nn.Embedding">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.embedding.html#torch.nn.functional.embedding">embedding() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.embedding_bag.html#torch.nn.functional.embedding_bag">embedding_bag() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.EmbeddingBag.html#torch.ao.nn.quantized.EmbeddingBag">EmbeddingBag (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="autograd.html#torch.autograd.profiler.emit_itt">emit_itt (class in torch.autograd.profiler)</a>
</li>
      <li><a href="autograd.html#torch.autograd.profiler.emit_nvtx">emit_nvtx (class in torch.autograd.profiler)</a>
</li>
      <li><a href="generated/torch.empty.html#torch.empty">empty() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.empty_cache.html#torch.cuda.empty_cache">empty_cache() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.mps.empty_cache.html#torch.mps.empty_cache">(in module torch.mps)</a>
</li>
        <li><a href="generated/torch.xpu.empty_cache.html#torch.xpu.empty_cache">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.empty_like.html#torch.empty_like">empty_like() (in module torch)</a>
</li>
      <li><a href="generated/torch.empty_strided.html#torch.empty_strided">empty_strided() (in module torch)</a>
</li>
      <li><a href="package.html#torch.package.EmptyMatchError">EmptyMatchError (class in torch.package)</a>
</li>
      <li><a href="generated/torch.sparse.check_sparse_tensor_invariants.html#torch.sparse.check_sparse_tensor_invariants.enable">enable() (torch.sparse.check_sparse_tensor_invariants static method)</a>
</li>
      <li><a href="cuda._sanitizer.html#torch.cuda._sanitizer.enable_cuda_sanitizer">enable_cuda_sanitizer() (in module torch.cuda._sanitizer)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.enable_cudnn_sdp">enable_cudnn_sdp() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.enable_debug_mode">enable_debug_mode() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.enable_fake_mode">enable_fake_mode() (in module torch.onnx)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.enable_fake_quant.html#torch.ao.quantization.fake_quantize.enable_fake_quant">enable_fake_quant (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.enable_flash_sdp">enable_flash_sdp() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.enable_grad.html#torch.enable_grad">enable_grad (class in torch)</a>
</li>
      <li><a href="onnx_torchscript.html#torch.onnx.enable_log">enable_log() (in module torch.onnx)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.enable_math_sdp">enable_math_sdp() (in module torch.backends.cuda)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.enable_mem_efficient_sdp">enable_mem_efficient_sdp() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.enable_observer.html#torch.ao.quantization.fake_quantize.enable_observer">enable_observer (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.jit.enable_onednn_fusion.html#torch.jit.enable_onednn_fusion">enable_onednn_fusion() (in module torch.jit)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.enabled">enabled (in module torch.backends.cudnn)</a>

      <ul>
        <li><a href="backends.html#torch.backends.opt_einsum.enabled">(in module torch.backends.opt_einsum)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.profiler.EnforceUnique.html#torch.autograd.profiler.EnforceUnique">EnforceUnique (class in torch.autograd.profiler)</a>
</li>
      <li><a href="generated/torch.autograd.forward_ad.enter_dual_level.html#torch.autograd.forward_ad.enter_dual_level">enter_dual_level() (in module torch.autograd.forward_ad)</a>
</li>
      <li><a href="special.html#torch.special.entr">entr() (in module torch.special)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.entropy">entropy() (torch.distributions.bernoulli.Bernoulli method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.entropy">(torch.distributions.beta.Beta method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.entropy">(torch.distributions.binomial.Binomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.entropy">(torch.distributions.categorical.Categorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.entropy">(torch.distributions.cauchy.Cauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.entropy">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.entropy">(torch.distributions.dirichlet.Dirichlet method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.entropy">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exp_family.ExponentialFamily.entropy">(torch.distributions.exp_family.ExponentialFamily method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.entropy">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.entropy">(torch.distributions.gamma.Gamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.entropy">(torch.distributions.geometric.Geometric method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.entropy">(torch.distributions.gumbel.Gumbel method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.entropy">(torch.distributions.half_cauchy.HalfCauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.entropy">(torch.distributions.half_normal.HalfNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.entropy">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.inverse_gamma.InverseGamma.entropy">(torch.distributions.inverse_gamma.InverseGamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.entropy">(torch.distributions.kumaraswamy.Kumaraswamy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.entropy">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.entropy">(torch.distributions.log_normal.LogNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.entropy">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.entropy">(torch.distributions.multinomial.Multinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.entropy">(torch.distributions.multivariate_normal.MultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.entropy">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.entropy">(torch.distributions.one_hot_categorical.OneHotCategorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.entropy">(torch.distributions.pareto.Pareto method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.entropy">(torch.distributions.studentT.StudentT method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.entropy">(torch.distributions.uniform.Uniform method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.entropy">(torch.distributions.weibull.Weibull method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.entropy">(torch.distributions.wishart.Wishart method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.enumerate_support">enumerate_support() (torch.distributions.bernoulli.Bernoulli method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.enumerate_support">(torch.distributions.binomial.Binomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.enumerate_support">(torch.distributions.categorical.Categorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.enumerate_support">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.enumerate_support">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support">(torch.distributions.one_hot_categorical.OneHotCategorical method)</a>
</li>
      </ul></li>
      <li>
    environment variable

      <ul>
        <li><a href="jit.html#envvar-PYTORCH_JIT">PYTORCH_JIT</a>
</li>
      </ul></li>
      <li><a href="generated/torch.eq.html#torch.eq">eq() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.eq.html#torch.Tensor.eq">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.eq_.html#torch.Tensor.eq_">eq_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.equal.html#torch.equal">equal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.equal.html#torch.Tensor.equal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.EqualityConstraint.html#torch.fx.experimental.symbolic_shapes.EqualityConstraint">EqualityConstraint (class in torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.erase_node">erase_node() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.autograd.profiler.KinetoStepTracker.html#torch.autograd.profiler.KinetoStepTracker.erase_step_count">erase_step_count() (torch.autograd.profiler.KinetoStepTracker class method)</a>
</li>
      <li><a href="generated/torch.erf.html#torch.erf">erf() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.erf">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.erf.html#torch.Tensor.erf">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.erf_.html#torch.Tensor.erf_">erf_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.erfc.html#torch.erfc">erfc() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.erfc">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.erfc.html#torch.Tensor.erfc">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.erfc_.html#torch.Tensor.erfc_">erfc_() (torch.Tensor method)</a>
</li>
      <li><a href="special.html#torch.special.erfcx">erfcx() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.erfinv.html#torch.erfinv">erfinv() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.erfinv">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.erfinv.html#torch.Tensor.erfinv">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.erfinv_.html#torch.Tensor.erfinv_">erfinv_() (torch.Tensor method)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="elastic/errors.html#torch.distributed.elastic.multiprocessing.errors.ErrorHandler">ErrorHandler (class in torch.distributed.elastic.multiprocessing.errors)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.essential_node_count">essential_node_count() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.essential_node_kinds">essential_node_kinds() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend">EtcdRendezvousBackend (class in torch.distributed.elastic.rendezvous.etcd_rendezvous_backend)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous.EtcdRendezvousHandler">EtcdRendezvousHandler (class in torch.distributed.elastic.rendezvous.etcd_rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_server.EtcdServer">EtcdServer (class in torch.distributed.elastic.rendezvous.etcd_server)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore">EtcdStore (class in torch.distributed.elastic.rendezvous.etcd_store)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.eval">eval() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.eval">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.evaluate_expr">evaluate_expr() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.evaluate_guards_expression">evaluate_guards_expression() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.evaluate_guards_for_args">evaluate_guards_for_args() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event">Event (class in torch.cuda)</a>

      <ul>
        <li><a href="elastic/events.html#torch.distributed.elastic.events.api.Event">(class in torch.distributed.elastic.events.api)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Event">(class in torch.monitor)</a>
</li>
        <li><a href="generated/torch.mps.event.Event.html#torch.mps.event.Event">(class in torch.mps.event)</a>
</li>
        <li><a href="generated/torch.xpu.Event.html#torch.xpu.Event">(class in torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution.event_shape">event_shape (torch.distributions.distribution.Distribution property)</a>
</li>
      <li><a href="monitor.html#torch.monitor.EventHandlerHandle">EventHandlerHandle (class in torch.monitor)</a>
</li>
      <li><a href="elastic/events.html#torch.distributed.elastic.events.api.EventMetadataValue">EventMetadataValue (in module torch.distributed.elastic.events.api)</a>
</li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile.events">events() (torch.profiler._KinetoProfile method)</a>
</li>
      <li><a href="elastic/events.html#torch.distributed.elastic.events.api.EventSource">EventSource (class in torch.distributed.elastic.events.api)</a>
</li>
      <li><a href="generated/torch.autograd.forward_ad.exit_dual_level.html#torch.autograd.forward_ad.exit_dual_level">exit_dual_level() (in module torch.autograd.forward_ad)</a>
</li>
      <li><a href="generated/torch.exp.html#torch.exp">exp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.exp.html#torch.Tensor.exp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.exp2.html#torch.exp2">exp2() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.exp2">(in module torch.special)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.exp_.html#torch.Tensor.exp_">exp_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.expand">expand() (torch.distributions.bernoulli.Bernoulli method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.expand">(torch.distributions.beta.Beta method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.expand">(torch.distributions.binomial.Binomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.expand">(torch.distributions.categorical.Categorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.expand">(torch.distributions.cauchy.Cauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.chi2.Chi2.expand">(torch.distributions.chi2.Chi2 method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.expand">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.expand">(torch.distributions.dirichlet.Dirichlet method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.expand">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.expand">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.expand">(torch.distributions.fishersnedecor.FisherSnedecor method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.expand">(torch.distributions.gamma.Gamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.expand">(torch.distributions.geometric.Geometric method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.expand">(torch.distributions.gumbel.Gumbel method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.expand">(torch.distributions.half_cauchy.HalfCauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.expand">(torch.distributions.half_normal.HalfNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.expand">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.inverse_gamma.InverseGamma.expand">(torch.distributions.inverse_gamma.InverseGamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.expand">(torch.distributions.kumaraswamy.Kumaraswamy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.expand">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky.expand">(torch.distributions.lkj_cholesky.LKJCholesky method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.expand">(torch.distributions.log_normal.LogNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.expand">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.expand">(torch.distributions.mixture_same_family.MixtureSameFamily method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.expand">(torch.distributions.multinomial.Multinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.expand">(torch.distributions.multivariate_normal.MultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.expand">(torch.distributions.negative_binomial.NegativeBinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.expand">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.expand">(torch.distributions.one_hot_categorical.OneHotCategorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.expand">(torch.distributions.pareto.Pareto method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.expand">(torch.distributions.poisson.Poisson method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.expand">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.expand">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.expand">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.expand">(torch.distributions.studentT.StudentT method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.expand">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.expand">(torch.distributions.uniform.Uniform method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.expand">(torch.distributions.von_mises.VonMises method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.expand">(torch.distributions.weibull.Weibull method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.expand">(torch.distributions.wishart.Wishart method)</a>
</li>
        <li><a href="generated/torch.Tensor.expand.html#torch.Tensor.expand">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.expand_as.html#torch.Tensor.expand_as">expand_as() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.expires">expires() (in module torch.distributed.elastic.timer)</a>
</li>
      <li><a href="special.html#torch.special.expit">expit() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.expm1.html#torch.expm1">expm1() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.expm1">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.expm1.html#torch.Tensor.expm1">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.expm1_.html#torch.Tensor.expm1_">expm1_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.exponential.Exponential">Exponential (class in torch.distributions.exponential)</a>
</li>
      <li><a href="generated/torch.signal.windows.exponential.html#torch.signal.windows.exponential">exponential() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.Tensor.exponential_.html#torch.Tensor.exponential_">exponential_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.exp_family.ExponentialFamily">ExponentialFamily (class in torch.distributions.exp_family)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR">ExponentialLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="export.html#torch.export.export">export() (in module torch.export)</a>

      <ul>
        <li><a href="jit.html#torch.jit.export">(in module torch.jit)</a>
</li>
        <li><a href="onnx_torchscript.html#torch.onnx.export">(in module torch.onnx)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.profiler.profile.export_chrome_trace.html#torch.autograd.profiler.profile.export_chrome_trace">export_chrome_trace() (torch.autograd.profiler.profile method)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler._KinetoProfile.export_chrome_trace">(torch.profiler._KinetoProfile method)</a>
</li>
      </ul></li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile.export_memory_timeline">export_memory_timeline() (torch.profiler._KinetoProfile method)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.export_repro">export_repro() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile.export_stacks">export_stacks() (torch.profiler._KinetoProfile method)</a>
</li>
      <li><a href="onnx_torchscript.html#torch.onnx.export_to_pretty_string">export_to_pretty_string() (in module torch.onnx)</a>
</li>
      <li><a href="export.html#torch.export.ExportBackwardSignature">ExportBackwardSignature (class in torch.export)</a>
</li>
      <li><a href="export.html#torch.export.ExportedProgram">ExportedProgram (class in torch.export)</a>
</li>
      <li><a href="export.html#torch.export.ExportGraphSignature">ExportGraphSignature (class in torch.export)</a>

      <ul>
        <li><a href="export.html#torch.export.graph_signature.ExportGraphSignature">(class in torch.export.graph_signature)</a>
</li>
      </ul></li>
      <li><a href="onnx_dynamo.html#torch.onnx.ExportOptions">ExportOptions (class in torch.onnx)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.ExpTransform">ExpTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.nn.ModuleList.html#torch.nn.ModuleList.extend">extend() (torch.nn.ModuleList method)</a>

      <ul>
        <li><a href="generated/torch.nn.ParameterList.html#torch.nn.ParameterList.extend">(torch.nn.ParameterList method)</a>
</li>
      </ul></li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extend_logger_results_with_comparison">extend_logger_results_with_comparison() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.extern">extern() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream">ExternalStream (class in torch.cuda)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.externed_modules">externed_modules() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize.html#torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize.extra_repr">extra_repr() (torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize method)</a>

      <ul>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.extra_repr">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.extra_repr">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_logger_info">extract_logger_info() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_results_n_shadows_model">extract_results_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_shadow_logger_info">extract_shadow_logger_info() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_weights">extract_weights() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="generated/torch.eye.html#torch.eye">eye() (in module torch)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.eye_">eye_() (in module torch.nn.init)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="F">F</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="onnx_dynamo.html#torch.onnx.ONNXProgram.fake_context">fake_context (torch.onnx.ONNXProgram property)</a>
</li>
      <li><a href="generated/torch.fake_quantize_per_channel_affine.html#torch.fake_quantize_per_channel_affine">fake_quantize_per_channel_affine() (in module torch)</a>
</li>
      <li><a href="generated/torch.fake_quantize_per_tensor_affine.html#torch.fake_quantize_per_tensor_affine">fake_quantize_per_tensor_affine() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.FakeQuantize.html#torch.ao.quantization.fake_quantize.FakeQuantize">FakeQuantize (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.FakeQuantizeBase.html#torch.ao.quantization.fake_quantize.FakeQuantizeBase">FakeQuantizeBase (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="library.html#torch.library.fallthrough_kernel">fallthrough_kernel() (in module torch.library)</a>
</li>
      <li><a href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine.fast_forward">fast_forward() (torch.quasirandom.SobolEngine method)</a>
</li>
      <li><a href="generated/torch.nn.functional.feature_alpha_dropout.html#torch.nn.functional.feature_alpha_dropout">feature_alpha_dropout() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.FeatureAlphaDropout.html#torch.nn.FeatureAlphaDropout">FeatureAlphaDropout (class in torch.nn)</a>
</li>
      <li><a href="fx.html#torch.fx.Interpreter.fetch_args_kwargs_from_env">fetch_args_kwargs_from_env() (torch.fx.Interpreter method)</a>
</li>
      <li><a href="fx.html#torch.fx.Interpreter.fetch_attr">fetch_attr() (torch.fx.Interpreter method)</a>
</li>
      <li><a href="generated/torch.fft.fft.html#torch.fft.fft">fft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.fft2.html#torch.fft.fft2">fft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.fftfreq.html#torch.fft.fftfreq">fftfreq() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.fftn.html#torch.fft.fftn">fftn() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.fftshift.html#torch.fft.fftshift">fftshift() (in module torch.fft)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.file_structure">file_structure() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.filename">filename (torch.TypedStorage property)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.filename">(torch.UntypedStorage property)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.FileStore">FileStore (class in torch.distributed)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.FileSystemReader">FileSystemReader (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.FileSystemWriter">FileSystemWriter (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.FileTimerClient">FileTimerClient (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.FileTimerServer">FileTimerServer (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="generated/torch.Tensor.fill_.html#torch.Tensor.fill_">fill_() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.fill_">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.fill_">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.fill_diagonal_.html#torch.Tensor.fill_diagonal_">fill_diagonal_() (torch.Tensor method)</a>
</li>
      <li><a href="deterministic.html#torch.utils.deterministic.fill_uninitialized_memory">fill_uninitialized_memory (in module torch.utils.deterministic)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.FunctionCounts.filter">filter() (torch.utils.benchmark.FunctionCounts method)</a>
</li>
      <li><a href="onnx_torchscript.html#torch.onnx.verification.find_mismatch">find_mismatch() (in module torch.onnx.verification)</a>

      <ul>
        <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.find_mismatch">(torch.onnx.verification.GraphInfo method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.find_partition">find_partition() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.finish">finish() (torch.distributed.checkpoint.StorageWriter method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.finish_plan">finish_plan() (torch.distributed.checkpoint.LoadPlanner method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.finish_plan">(torch.distributed.checkpoint.SavePlanner method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor">FisherSnedecor (class in torch.distributions.fishersnedecor)</a>
</li>
      <li><a href="generated/torch.fix.html#torch.fix">fix() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.fix.html#torch.Tensor.fix">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.fix_.html#torch.Tensor.fix_">fix_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize.html#torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize">FixedQParamsFakeQuantize (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="backends.html#torch.backends.nnpack.flags">flags() (in module torch.backends.nnpack)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.flash_sdp_enabled">flash_sdp_enabled() (in module torch.backends.cuda)</a>
</li>
      <li><a href="export.html#torch.export.unflatten.FlatArgsAdapter">FlatArgsAdapter (class in torch.export.unflatten)</a>
</li>
      <li><a href="generated/torch.nn.Flatten.html#torch.nn.Flatten">Flatten (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.flatten.html#torch.flatten">flatten() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.flatten.html#torch.Tensor.flatten">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.RNNBase.html#torch.nn.RNNBase.flatten_parameters">flatten_parameters() (torch.nn.RNNBase method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.flatten_sharded_optim_state_dict">flatten_sharded_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="generated/torch.flip.html#torch.flip">flip() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.flip.html#torch.Tensor.flip">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fliplr.html#torch.fliplr">fliplr() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.fliplr.html#torch.Tensor.fliplr">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.flipud.html#torch.flipud">flipud() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.flipud.html#torch.Tensor.flipud">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.float">float() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.float">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.float.html#torch.Tensor.float">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.float">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.float">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.qconfig.float16_dynamic_qconfig.html#torch.ao.quantization.qconfig.float16_dynamic_qconfig">float16_dynamic_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.float16_static_qconfig.html#torch.ao.quantization.qconfig.float16_static_qconfig">float16_static_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.float8_e4m3fn">float8_e4m3fn() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.float8_e4m3fn">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.TypedStorage.float8_e4m3fnuz">float8_e4m3fnuz() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.float8_e4m3fnuz">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.TypedStorage.float8_e5m2">float8_e5m2() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.float8_e5m2">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.TypedStorage.float8_e5m2fnuz">float8_e5m2fnuz() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.float8_e5m2fnuz">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.float_power.html#torch.float_power">float_power() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.float_power.html#torch.Tensor.float_power">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.float_power_.html#torch.Tensor.float_power_">float_power_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.float_qparams_weight_only_qconfig.html#torch.ao.quantization.qconfig.float_qparams_weight_only_qconfig">float_qparams_weight_only_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.FloatFunctional.html#torch.ao.nn.quantized.FloatFunctional">FloatFunctional (class in torch.ao.nn.quantized)</a>
</li>
      <li><a href="storage.html#torch.FloatStorage">FloatStorage (class in torch)</a>
</li>
      <li><a href="generated/torch.floor.html#torch.floor">floor() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.floor.html#torch.Tensor.floor">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.floor_.html#torch.Tensor.floor_">floor_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.floor_divide.html#torch.floor_divide">floor_divide() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.floor_divide.html#torch.Tensor.floor_divide">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.floor_divide_.html#torch.Tensor.floor_divide_">floor_divide_() (torch.Tensor method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.flush">flush() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="generated/torch.fmax.html#torch.fmax">fmax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.fmax.html#torch.Tensor.fmax">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fmin.html#torch.fmin">fmin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.fmin.html#torch.Tensor.fmin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fmod.html#torch.fmod">fmod() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.fmod.html#torch.Tensor.fmod">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.fmod_.html#torch.Tensor.fmod_">fmod_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.Fold.html#torch.nn.Fold">Fold (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.fold.html#torch.nn.functional.fold">fold() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.DimConstraints.html#torch.fx.experimental.symbolic_shapes.DimConstraints.forced_specializations">forced_specializations() (torch.fx.experimental.symbolic_shapes.DimConstraints method)</a>
</li>
      <li><a href="generated/torch.jit.fork.html#torch.jit.fork">fork() (in module torch.jit)</a>
</li>
      <li><a href="random.html#torch.random.fork_rng">fork_rng() (in module torch.random)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.format_guards">format_guards() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.format_node">format_node() (torch.fx.Node method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantizable.MultiheadAttention.html#torch.ao.nn.quantizable.MultiheadAttention.forward">forward() (torch.ao.nn.quantizable.MultiheadAttention method)</a>

      <ul>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Logger.forward">(torch.ao.ns._numeric_suite.Logger method)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.OutputLogger.forward">(torch.ao.ns._numeric_suite.OutputLogger method)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.forward">(torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.ShadowLogger.forward">(torch.ao.ns._numeric_suite.ShadowLogger method)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputComparisonLogger.forward">(torch.ao.ns._numeric_suite_fx.OutputComparisonLogger method)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputLogger.forward">(torch.ao.ns._numeric_suite_fx.OutputLogger method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.observer.MinMaxObserver.html#torch.ao.quantization.observer.MinMaxObserver.forward">(torch.ao.quantization.observer.MinMaxObserver method)</a>
</li>
        <li><a href="generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward">(torch.autograd.Function static method)</a>
</li>
        <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction.forward">(torch.autograd.function.InplaceFunction static method)</a>
</li>
        <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.forward">(torch.autograd.function.NestedIOFunction method)</a>
</li>
        <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.forward">(torch.distributed.fsdp.FullyShardedDataParallel method)</a>
</li>
        <li><a href="pipeline.html#torch.distributed.pipeline.sync.Pipe.forward">(torch.distributed.pipeline.sync.Pipe method)</a>
</li>
        <li><a href="generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag.forward">(torch.nn.EmbeddingBag method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.forward">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention.forward">(torch.nn.MultiheadAttention method)</a>
</li>
        <li><a href="generated/torch.nn.Transformer.html#torch.nn.Transformer.forward">(torch.nn.Transformer method)</a>
</li>
        <li><a href="generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder.forward">(torch.nn.TransformerDecoder method)</a>
</li>
        <li><a href="generated/torch.nn.TransformerDecoderLayer.html#torch.nn.TransformerDecoderLayer.forward">(torch.nn.TransformerDecoderLayer method)</a>
</li>
        <li><a href="generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder.forward">(torch.nn.TransformerEncoder method)</a>
</li>
        <li><a href="generated/torch.nn.TransformerEncoderLayer.html#torch.nn.TransformerEncoderLayer.forward">(torch.nn.TransformerEncoderLayer method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.forward_extended">forward_extended() (torch.autograd.function.NestedIOFunction method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform.forward_shape">forward_shape() (torch.distributions.transforms.Transform method)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.default_hooks.fp16_compress_hook">fp16_compress_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.default_hooks.fp16_compress_wrapper">fp16_compress_wrapper() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)</a>
</li>
      <li><a href="generated/torch.frac.html#torch.frac">frac() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.frac.html#torch.Tensor.frac">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.frac_.html#torch.Tensor.frac_">frac_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.functional.fractional_max_pool2d.html#torch.nn.functional.fractional_max_pool2d">fractional_max_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.fractional_max_pool3d.html#torch.nn.functional.fractional_max_pool3d">fractional_max_pool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.FractionalMaxPool2d.html#torch.nn.FractionalMaxPool2d">FractionalMaxPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.FractionalMaxPool3d.html#torch.nn.FractionalMaxPool3d">FractionalMaxPool3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.jit.freeze.html#torch.jit.freeze">freeze() (in module torch.jit)</a>

      <ul>
        <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.freeze">(torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.qat.freeze_bn_stats.html#torch.ao.nn.intrinsic.qat.freeze_bn_stats">freeze_bn_stats (class in torch.ao.nn.intrinsic.qat)</a>
</li>
      <li><a href="generated/torch.frexp.html#torch.frexp">frexp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.frexp.html#torch.Tensor.frexp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler.from_backend">from_backend() (torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler class method)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.from_buffer">from_buffer() (torch.TypedStorage class method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.from_buffer">(torch.UntypedStorage static method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.from_dict">from_dict() (torch.ao.quantization.backend_config.BackendConfig class method)</a>

      <ul>
        <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.from_dict">(torch.ao.quantization.backend_config.BackendPatternConfig class method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.backend_config.DTypeConfig.html#torch.ao.quantization.backend_config.DTypeConfig.from_dict">(torch.ao.quantization.backend_config.DTypeConfig class method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.html#torch.ao.quantization.fx.custom_config.ConvertCustomConfig.from_dict">(torch.ao.quantization.fx.custom_config.ConvertCustomConfig class method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig.html#torch.ao.quantization.fx.custom_config.FuseCustomConfig.from_dict">(torch.ao.quantization.fx.custom_config.FuseCustomConfig class method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.from_dict">(torch.ao.quantization.fx.custom_config.PrepareCustomConfig class method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.from_dict">(torch.ao.quantization.qconfig_mapping.QConfigMapping class method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.from_dlpack.html#torch.from_dlpack">from_dlpack() (in module torch)</a>

      <ul>
        <li><a href="dlpack.html#torch.utils.dlpack.from_dlpack">(in module torch.utils.dlpack)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.from_dtype">from_dtype() (torch.onnx.JitScalarType class method)</a>
</li>
      <li><a href="generated/torch.from_file.html#torch.from_file">from_file() (in module torch)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.from_file">(torch.TypedStorage class method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.from_file">(torch.UntypedStorage static method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.qat.Linear.html#torch.ao.nn.qat.Linear.from_float">from_float() (torch.ao.nn.qat.Linear class method)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantized.Conv1d.html#torch.ao.nn.quantized.Conv1d.from_float">(torch.ao.nn.quantized.Conv1d class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.Conv2d.html#torch.ao.nn.quantized.Conv2d.from_float">(torch.ao.nn.quantized.Conv2d class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.Conv3d.html#torch.ao.nn.quantized.Conv3d.from_float">(torch.ao.nn.quantized.Conv3d class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.dynamic.Linear.html#torch.ao.nn.quantized.dynamic.Linear.from_float">(torch.ao.nn.quantized.dynamic.Linear class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.Embedding.html#torch.ao.nn.quantized.Embedding.from_float">(torch.ao.nn.quantized.Embedding class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.EmbeddingBag.html#torch.ao.nn.quantized.EmbeddingBag.from_float">(torch.ao.nn.quantized.EmbeddingBag class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.Linear.html#torch.ao.nn.quantized.Linear.from_float">(torch.ao.nn.quantized.Linear class method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.from_ipc_handle">from_ipc_handle() (torch.cuda.Event class method)</a>
</li>
      <li><a href="generated/torch.from_numpy.html#torch.from_numpy">from_numpy() (in module torch)</a>
</li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.from_onnx_type">from_onnx_type() (torch.onnx.JitScalarType class method)</a>
</li>
      <li><a href="generated/torch.nn.Embedding.html#torch.nn.Embedding.from_pretrained">from_pretrained() (torch.nn.Embedding class method)</a>

      <ul>
        <li><a href="generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag.from_pretrained">(torch.nn.EmbeddingBag class method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.dynamic.Linear.html#torch.ao.nn.quantized.dynamic.Linear.from_reference">from_reference() (torch.ao.nn.quantized.dynamic.Linear class method)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantized.Linear.html#torch.ao.nn.quantized.Linear.from_reference">(torch.ao.nn.quantized.Linear class method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.from_value">from_value() (torch.onnx.JitScalarType class method)</a>
</li>
      <li><a href="generated/torch.frombuffer.html#torch.frombuffer">frombuffer() (in module torch)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.fromkeys">fromkeys() (torch.autograd.profiler_util.StringTable method)</a>

      <ul>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.fromkeys">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.fsdp_modules">fsdp_modules() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="generated/torch.full.html#torch.full">full() (in module torch)</a>
</li>
      <li><a href="generated/torch.full_like.html#torch.full_like">full_like() (in module torch)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.full_optim_state_dict">full_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullOptimStateDictConfig">FullOptimStateDictConfig (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullStateDictConfig">FullStateDictConfig (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel">FullyShardedDataParallel (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="autograd.html#torch.autograd.Function">Function (class in torch.autograd)</a>
</li>
      <li><a href="generated/torch.func.functional_call.html#torch.func.functional_call">functional_call() (in module torch.func)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.stateless.functional_call.html#torch.nn.utils.stateless.functional_call">(in module torch.nn.utils.stateless)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.func.functionalize.html#torch.func.functionalize">functionalize() (in module torch.func)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.FunctionCounts">FunctionCounts (class in torch.utils.benchmark)</a>
</li>
      <li><a href="generated/torch.nn.utils.fuse_conv_bn_eval.html#torch.nn.utils.fuse_conv_bn_eval">fuse_conv_bn_eval() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.nn.utils.fuse_conv_bn_weights.html#torch.nn.utils.fuse_conv_bn_weights">fuse_conv_bn_weights() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.ao.quantization.quantize_fx.fuse_fx.html#torch.ao.quantization.quantize_fx.fuse_fx">fuse_fx (class in torch.ao.quantization.quantize_fx)</a>
</li>
      <li><a href="generated/torch.nn.utils.fuse_linear_bn_eval.html#torch.nn.utils.fuse_linear_bn_eval">fuse_linear_bn_eval() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.nn.utils.fuse_linear_bn_weights.html#torch.nn.utils.fuse_linear_bn_weights">fuse_linear_bn_weights() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fuse_modules.fuse_modules.html#torch.ao.quantization.fuse_modules.fuse_modules">fuse_modules (class in torch.ao.quantization.fuse_modules)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig.html#torch.ao.quantization.fx.custom_config.FuseCustomConfig">FuseCustomConfig (class in torch.ao.quantization.fx.custom_config)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize.html#torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize">FusedMovingAvgObsFakeQuantize (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="futures.html#torch.futures.Future">Future (class in torch.futures)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.FXFloatFunctional.html#torch.ao.nn.quantized.FXFloatFunctional">FXFloatFunctional (class in torch.ao.nn.quantized)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="G">G</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributions.html#torch.distributions.gamma.Gamma">Gamma (class in torch.distributions.gamma)</a>
</li>
      <li><a href="special.html#torch.special.gammainc">gammainc() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.gammaincc">gammaincc() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.gammaln">gammaln() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.gather.html#torch.gather">gather() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.comm.gather.html#torch.cuda.comm.gather">(in module torch.cuda.comm)</a>
</li>
        <li><a href="distributed.html#torch.distributed.gather">(in module torch.distributed)</a>
</li>
        <li><a href="generated/torch.Tensor.gather.html#torch.Tensor.gather">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.gather_object">gather_object() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.signal.windows.gaussian.html#torch.signal.windows.gaussian">gaussian() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.nn.functional.gaussian_nll_loss.html#torch.nn.functional.gaussian_nll_loss">gaussian_nll_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.GaussianNLLLoss.html#torch.nn.GaussianNLLLoss">GaussianNLLLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.gcd.html#torch.gcd">gcd() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.gcd.html#torch.Tensor.gcd">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.gcd_.html#torch.Tensor.gcd_">gcd_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ge.html#torch.ge">ge() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ge.html#torch.Tensor.ge">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.ge_.html#torch.Tensor.ge_">ge_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.GELU.html#torch.nn.GELU">GELU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.gelu.html#torch.nn.functional.gelu">gelu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.signal.windows.general_cosine.html#torch.signal.windows.general_cosine">general_cosine() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.signal.windows.general_hamming.html#torch.signal.windows.general_hamming">general_hamming() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.utils.generate_methods_for_privateuse1_backend.html#torch.utils.generate_methods_for_privateuse1_backend">generate_methods_for_privateuse1_backend() (in module torch.utils)</a>
</li>
      <li><a href="generated/torch.nn.Transformer.html#torch.nn.Transformer.generate_square_subsequent_mask">generate_square_subsequent_mask() (torch.nn.Transformer static method)</a>
</li>
      <li><a href="generated/torch.Generator.html#torch.Generator">Generator (class in torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.geometric.Geometric">Geometric (class in torch.distributions.geometric)</a>
</li>
      <li><a href="generated/torch.Tensor.geometric_.html#torch.Tensor.geometric_">geometric_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.geqrf.html#torch.geqrf">geqrf() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.geqrf.html#torch.Tensor.geqrf">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ger.html#torch.ger">ger() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ger.html#torch.Tensor.ger">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.Store.get">get() (in module torch.distributed.Store)</a>

      <ul>
        <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.get">(torch.autograd.profiler_util.StringTable method)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.get">(torch.distributed.elastic.rendezvous.etcd_store.EtcdStore method)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousParameters.get">(torch.distributed.elastic.rendezvous.RendezvousParameters method)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Stat.get">(torch.monitor.Stat method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.get">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="multiprocessing.html#torch.multiprocessing.get_all_sharing_strategies">get_all_sharing_strategies() (in module torch.multiprocessing)</a>
</li>
      <li><a href="generated/torch.cuda.get_allocator_backend.html#torch.cuda.get_allocator_backend">get_allocator_backend() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.get_arch_list.html#torch.cuda.get_arch_list">get_arch_list() (in module torch.cuda)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousParameters.get_as_bool">get_as_bool() (torch.distributed.elastic.rendezvous.RendezvousParameters method)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousParameters.get_as_int">get_as_int() (torch.distributed.elastic.rendezvous.RendezvousParameters method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.get_attr">get_attr() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.get_attr">(torch.fx.Interpreter method)</a>
</li>
        <li><a href="fx.html#torch.fx.Transformer.get_attr">(torch.fx.Transformer method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.get_backend">get_backend() (in module torch.distributed)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.get_backend">(torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.get_buffer">get_buffer() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.get_buffer">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.get_compiler_abi_compatibility_and_version">get_compiler_abi_compatibility_and_version() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.utils.get_cpp_backtrace.html#torch.utils.get_cpp_backtrace">get_cpp_backtrace() (in module torch.utils)</a>
</li>
      <li><a href="backends.html#torch.backends.cpu.get_cpu_capability">get_cpu_capability() (in module torch.backends.cpu)</a>
</li>
      <li><a href="library.html#torch.library.get_ctx">get_ctx() (in module torch.library)</a>
</li>
      <li><a href="generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction.get_debug_state">get_debug_state() (torch.jit.ScriptFunction method)</a>
</li>
      <li><a href="generated/torch.get_default_device.html#torch.get_default_device">get_default_device() (in module torch)</a>
</li>
      <li><a href="generated/torch.get_default_dtype.html#torch.get_default_dtype">get_default_dtype() (in module torch)</a>
</li>
      <li><a href="notes/serialization.html#torch.serialization.get_default_load_endianness">get_default_load_endianness() (in module torch.serialization)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping.html#torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping">get_default_qat_qconfig_mapping (class in torch.ao.quantization.qconfig_mapping)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping.html#torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping">get_default_qconfig_mapping (class in torch.ao.quantization.qconfig_mapping)</a>
</li>
      <li><a href="generated/torch.get_deterministic_debug_mode.html#torch.get_deterministic_debug_mode">get_deterministic_debug_mode() (in module torch)</a>
</li>
      <li><a href="generated/torch.Tensor.get_device.html#torch.Tensor.get_device">get_device() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.get_device">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.get_device">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.get_device_capability.html#torch.cuda.get_device_capability">get_device_capability() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.xpu.get_device_capability.html#torch.xpu.get_device_capability">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.get_device_name.html#torch.cuda.get_device_name">get_device_name() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.xpu.get_device_name.html#torch.xpu.get_device_name">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.get_device_properties.html#torch.cuda.get_device_properties">get_device_properties() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.xpu.get_device_properties.html#torch.xpu.get_device_properties">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="hub.html#torch.hub.get_dir">get_dir() (in module torch.hub)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.WorkerSpec.get_entrypoint_name">get_entrypoint_name() (torch.distributed.elastic.agent.server.WorkerSpec method)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerServer.get_expired_timers">get_expired_timers() (torch.distributed.elastic.timer.TimerServer method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.get_extra_state">get_extra_state() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.get_extra_state">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="backends.html#torch.backends.mha.get_fastpath_enabled">get_fastpath_enabled() (in module torch.backends.mha)</a>
</li>
      <li><a href="generated/torch.get_float32_matmul_precision.html#torch.get_float32_matmul_precision">get_float32_matmul_precision() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.get_gencode_flags.html#torch.cuda.get_gencode_flags">get_gencode_flags() (in module torch.cuda)</a>
</li>
      <li><a href="distributed.html#torch.distributed.get_global_rank">get_global_rank() (in module torch.distributed)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.get_gradient_edge">get_gradient_edge() (in module torch.autograd.graph)</a>
</li>
      <li><a href="rpc.html#torch.distributed.autograd.get_gradients">get_gradients() (in module torch.distributed.autograd)</a>
</li>
      <li><a href="distributed.html#torch.distributed.get_group_rank">get_group_rank() (in module torch.distributed)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.get_ignored_functions">get_ignored_functions() (in module torch.overrides)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ChainedScheduler.html#torch.optim.lr_scheduler.ChainedScheduler.get_last_lr">get_last_lr() (torch.optim.lr_scheduler.ChainedScheduler method)</a>

      <ul>
        <li><a href="generated/torch.optim.lr_scheduler.ConstantLR.html#torch.optim.lr_scheduler.ConstantLR.get_last_lr">(torch.optim.lr_scheduler.ConstantLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR.get_last_lr">(torch.optim.lr_scheduler.CosineAnnealingLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.get_last_lr">(torch.optim.lr_scheduler.CosineAnnealingWarmRestarts method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CyclicLR.html#torch.optim.lr_scheduler.CyclicLR.get_last_lr">(torch.optim.lr_scheduler.CyclicLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR.get_last_lr">(torch.optim.lr_scheduler.ExponentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR.get_last_lr">(torch.optim.lr_scheduler.LambdaLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LinearLR.html#torch.optim.lr_scheduler.LinearLR.get_last_lr">(torch.optim.lr_scheduler.LinearLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR.get_last_lr">(torch.optim.lr_scheduler.MultiplicativeLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR.get_last_lr">(torch.optim.lr_scheduler.MultiStepLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR.get_last_lr">(torch.optim.lr_scheduler.OneCycleLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.PolynomialLR.html#torch.optim.lr_scheduler.PolynomialLR.get_last_lr">(torch.optim.lr_scheduler.PolynomialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html#torch.optim.lr_scheduler.ReduceLROnPlateau.get_last_lr">(torch.optim.lr_scheduler.ReduceLROnPlateau method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.SequentialLR.html#torch.optim.lr_scheduler.SequentialLR.get_last_lr">(torch.optim.lr_scheduler.SequentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR.get_last_lr">(torch.optim.lr_scheduler.StepLR method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.get_logger_dict">get_logger_dict() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="elastic/events.html#torch.distributed.elastic.events.get_logging_handler">get_logging_handler() (in module torch.distributed.elastic.events)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.CyclicLR.html#torch.optim.lr_scheduler.CyclicLR.get_lr">get_lr() (torch.optim.lr_scheduler.CyclicLR method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.get_matching_activations">get_matching_activations() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_model_state_dict">get_model_state_dict() (in module torch.distributed.checkpoint.state_dict)</a>
</li>
      <li><a href="rpc.html#torch.distributed.nn.api.remote_module.RemoteModule.get_module_rref">get_module_rref() (torch.distributed.nn.api.remote_module.RemoteModule method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.get_nontrivial_guards">get_nontrivial_guards() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.get_num_interop_threads.html#torch.get_num_interop_threads">get_num_interop_threads() (in module torch)</a>
</li>
      <li><a href="generated/torch.get_num_threads.html#torch.get_num_threads">get_num_threads() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.get_observer_state_dict.html#torch.ao.quantization.observer.get_observer_state_dict">get_observer_state_dict (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.OnnxRegistry.get_op_functions">get_op_functions() (torch.onnx.OnnxRegistry method)</a>
</li>
      <li><a href="backends.html#torch.backends.opt_einsum.get_opt_einsum">get_opt_einsum() (in module torch.backends.opt_einsum)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_optimizer_state_dict">get_optimizer_state_dict() (in module torch.distributed.checkpoint.state_dict)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.get_overridable_functions">get_overridable_functions() (in module torch.overrides)</a>
</li>
      <li><a href="future_mod.html#torch.__future__.get_overwrite_module_params_on_conversion">get_overwrite_module_params_on_conversion() (in module torch.__future__)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.get_parameter">get_parameter() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.get_parameter">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.get_process_group_ranks">get_process_group_ranks() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.get_rank">get_rank() (in module torch.distributed)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.get_rdeps">get_rdeps() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="export.html#torch.export.graph_signature.ExportGraphSignature.get_replace_hook">get_replace_hook() (torch.export.graph_signature.ExportGraphSignature method)</a>
</li>
      <li><a href="generated/torch.get_rng_state.html#torch.get_rng_state">get_rng_state() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.get_rng_state.html#torch.cuda.get_rng_state">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.mps.get_rng_state.html#torch.mps.get_rng_state">(in module torch.mps)</a>
</li>
        <li><a href="random.html#torch.random.get_rng_state">(in module torch.random)</a>
</li>
        <li><a href="generated/torch.xpu.get_rng_state.html#torch.xpu.get_rng_state">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.get_rng_state_all.html#torch.cuda.get_rng_state_all">get_rng_state_all() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.xpu.get_rng_state_all.html#torch.xpu.get_rng_state_all">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.get_run_id">get_run_id() (torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      <li><a href="multiprocessing.html#torch.multiprocessing.get_sharing_strategy">get_sharing_strategy() (in module torch.multiprocessing)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.get_state">get_state() (torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend method)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.get_state">(torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend method)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend.get_state">(torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend method)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.get_state">(torch.Generator method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict">get_state_dict() (in module torch.distributed.checkpoint.state_dict)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.get_state_dict_type">get_state_dict_type() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.get_submodule">get_submodule() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.get_submodule">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="elastic/subprocess_handler.html#torch.distributed.elastic.multiprocessing.subprocess_handler.handlers.get_subprocess_handler">get_subprocess_handler() (in module torch.distributed.elastic.multiprocessing.subprocess_handler.handlers)</a>
</li>
      <li><a href="future_mod.html#torch.__future__.get_swap_module_params_on_conversion">get_swap_module_params_on_conversion() (in module torch.__future__)</a>
</li>
      <li><a href="generated/torch.cuda.get_sync_debug_mode.html#torch.cuda.get_sync_debug_mode">get_sync_debug_mode() (in module torch.cuda)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.get_testing_overrides">get_testing_overrides() (in module torch.overrides)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.get_unique_id">get_unique_id() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.ElasticAgent.get_worker_group">get_worker_group() (torch.distributed.elastic.agent.server.ElasticAgent method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.get_worker_info">get_worker_info() (in module torch.distributed.rpc)</a>

      <ul>
        <li><a href="data.html#torch.utils.data.get_worker_info">(in module torch.utils.data)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.get_world_size">get_world_size() (in module torch.distributed)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.getattr">getattr() (torch.fx.Tracer method)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.global_unstructured.html#torch.nn.utils.prune.global_unstructured">global_unstructured() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.nn.GLU.html#torch.nn.GLU">GLU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.glu.html#torch.nn.functional.glu">glu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.Tensor.grad.html#torch.Tensor.grad">grad (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.autograd.grad.html#torch.autograd.grad">grad() (in module torch.autograd)</a>

      <ul>
        <li><a href="generated/torch.func.grad.html#torch.func.grad">(in module torch.func)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.func.grad_and_value.html#torch.func.grad_and_value">grad_and_value() (in module torch.func)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket">GradBucket (class in torch.distributed)</a>
</li>
      <li><a href="generated/torch.autograd.gradcheck.gradcheck.html#torch.autograd.gradcheck.gradcheck">gradcheck() (in module torch.autograd.gradcheck)</a>
</li>
      <li><a href="generated/torch.autograd.gradcheck.GradcheckError.html#torch.autograd.gradcheck.GradcheckError">GradcheckError</a>
</li>
      <li><a href="generated/torch.autograd.gradcheck.gradgradcheck.html#torch.autograd.gradcheck.gradgradcheck">gradgradcheck() (in module torch.autograd.gradcheck)</a>
</li>
      <li><a href="generated/torch.gradient.html#torch.gradient">gradient() (in module torch)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.GradientEdge">GradientEdge (class in torch.autograd.graph)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.gradients">gradients() (in module torch.distributed.GradBucket)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler">GradScaler (class in torch.cuda.amp)</a>
</li>
      <li><a href="generated/torch.cuda.graph.html#torch.cuda.graph">graph (class in torch.cuda)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph">Graph (class in torch.fx)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule.graph">graph (torch.fx.GraphModule property)</a>

      <ul>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.graph">(torch.jit.ScriptModule property)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.graph_copy">graph_copy() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.cuda.graph_pool_handle.html#torch.cuda.graph_pool_handle">graph_pool_handle() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo">GraphInfo (class in torch.onnx.verification)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule">GraphModule (class in torch.fx)</a>
</li>
      <li><a href="generated/torch.greater.html#torch.greater">greater() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.greater.html#torch.Tensor.greater">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.greater_.html#torch.Tensor.greater_">greater_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.greater_equal.html#torch.greater_equal">greater_equal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.greater_equal.html#torch.Tensor.greater_equal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.greater_equal_.html#torch.Tensor.greater_equal_">greater_equal_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.greater_than">greater_than (in module torch.distributions.constraints)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.greater_than_eq">greater_than_eq (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.nn.functional.grid_sample.html#torch.nn.functional.grid_sample">grid_sample() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.group_norm.html#torch.nn.functional.group_norm">group_norm() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.GroupNorm.html#torch.ao.nn.quantized.GroupNorm">GroupNorm (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.GroupNorm.html#torch.nn.GroupNorm">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.dynamic.GRU.html#torch.ao.nn.quantized.dynamic.GRU">GRU (class in torch.ao.nn.quantized.dynamic)</a>

      <ul>
        <li><a href="generated/torch.nn.GRU.html#torch.nn.GRU">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.dynamic.GRUCell.html#torch.ao.nn.quantized.dynamic.GRUCell">GRUCell (class in torch.ao.nn.quantized.dynamic)</a>

      <ul>
        <li><a href="generated/torch.nn.GRUCell.html#torch.nn.GRUCell">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.gt.html#torch.gt">gt() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.gt.html#torch.Tensor.gt">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.gt_.html#torch.Tensor.gt_">gt_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.guard_size_oblivious.html#torch.fx.experimental.symbolic_shapes.guard_size_oblivious">guard_size_oblivious() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="distributions.html#torch.distributions.gumbel.Gumbel">Gumbel (class in torch.distributions.gumbel)</a>
</li>
      <li><a href="generated/torch.nn.functional.gumbel_softmax.html#torch.nn.functional.gumbel_softmax">gumbel_softmax() (in module torch.nn.functional)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="H">H</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="tensors.html#torch.Tensor.H">H (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.half">half() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.half">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.half.html#torch.Tensor.half">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.half">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.half">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.constraints.half_open_interval">half_open_interval (in module torch.distributions.constraints)</a>
</li>
      <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy">HalfCauchy (class in torch.distributions.half_cauchy)</a>
</li>
      <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal">HalfNormal (class in torch.distributions.half_normal)</a>
</li>
      <li><a href="storage.html#torch.HalfStorage">HalfStorage (class in torch)</a>
</li>
      <li><a href="generated/torch.signal.windows.hamming.html#torch.signal.windows.hamming">hamming() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.hamming_window.html#torch.hamming_window">hamming_window() (in module torch)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.handle_torch_function">handle_torch_function() (in module torch.overrides)</a>
</li>
      <li><a href="generated/torch.signal.windows.hann.html#torch.signal.windows.hann">hann() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.hann_window.html#torch.hann_window">hann_window() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.Hardshrink.html#torch.nn.Hardshrink">Hardshrink (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.hardshrink.html#torch.nn.functional.hardshrink">hardshrink() (in module torch.nn.functional)</a>

      <ul>
        <li><a href="generated/torch.Tensor.hardshrink.html#torch.Tensor.hardshrink">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.functional.hardsigmoid.html#torch.ao.nn.quantized.functional.hardsigmoid">hardsigmoid (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Hardsigmoid.html#torch.nn.Hardsigmoid">Hardsigmoid (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.hardsigmoid.html#torch.nn.functional.hardsigmoid">hardsigmoid() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.Hardswish.html#torch.ao.nn.quantized.Hardswish">Hardswish (class in torch.ao.nn.quantized)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.hardswish.html#torch.ao.nn.quantized.functional.hardswish">hardswish (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Hardswish.html#torch.nn.Hardswish">Hardswish (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.hardswish.html#torch.nn.functional.hardswish">hardswish() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.hardtanh.html#torch.ao.nn.quantized.functional.hardtanh">hardtanh (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Hardtanh.html#torch.nn.Hardtanh">Hardtanh (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.hardtanh.html#torch.nn.functional.hardtanh">hardtanh() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.hardtanh_.html#torch.nn.functional.hardtanh_">hardtanh_() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.has_enumerate_support">has_enumerate_support (torch.distributions.bernoulli.Bernoulli attribute)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.has_enumerate_support">(torch.distributions.binomial.Binomial attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.has_enumerate_support">(torch.distributions.categorical.Categorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.has_enumerate_support">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.has_enumerate_support">(torch.distributions.one_hot_categorical.OneHotCategorical attribute)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.Directory.has_file">has_file() (torch.package.Directory method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.has_free_symbols.html#torch.fx.experimental.symbolic_shapes.has_free_symbols">has_free_symbols() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.has_mismatch">has_mismatch() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.beta.Beta.has_rsample">has_rsample (torch.distributions.beta.Beta attribute)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.has_rsample">(torch.distributions.cauchy.Cauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.has_rsample">(torch.distributions.continuous_bernoulli.ContinuousBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.has_rsample">(torch.distributions.dirichlet.Dirichlet attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.has_rsample">(torch.distributions.exponential.Exponential attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.has_rsample">(torch.distributions.fishersnedecor.FisherSnedecor attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.has_rsample">(torch.distributions.gamma.Gamma attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.has_rsample">(torch.distributions.half_cauchy.HalfCauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.has_rsample">(torch.distributions.half_normal.HalfNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.has_rsample">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.inverse_gamma.InverseGamma.has_rsample">(torch.distributions.inverse_gamma.InverseGamma attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.has_rsample">(torch.distributions.kumaraswamy.Kumaraswamy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.has_rsample">(torch.distributions.laplace.Laplace attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.has_rsample">(torch.distributions.log_normal.LogNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.has_rsample">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.has_rsample">(torch.distributions.mixture_same_family.MixtureSameFamily attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.has_rsample">(torch.distributions.multivariate_normal.MultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.has_rsample">(torch.distributions.normal.Normal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.has_rsample">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.has_rsample">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.has_rsample">(torch.distributions.studentT.StudentT attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.has_rsample">(torch.distributions.transformed_distribution.TransformedDistribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.has_rsample">(torch.distributions.uniform.Uniform attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.has_rsample">(torch.distributions.von_mises.VonMises attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.has_rsample">(torch.distributions.wishart.Wishart attribute)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torch.overrides.html#torch.overrides.has_torch_function">has_torch_function() (in module torch.overrides)</a>
</li>
      <li><a href="generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin.has_uninitialized_params">has_uninitialized_params() (torch.nn.modules.lazy.LazyModuleMixin method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.HashStore">HashStore (class in torch.distributed)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.heartbeat">heartbeat (torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout property)</a>
</li>
      <li><a href="generated/torch.heaviside.html#torch.heaviside">heaviside() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.heaviside.html#torch.Tensor.heaviside">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="hub.html#torch.hub.help">help() (in module torch.hub)</a>
</li>
      <li><a href="generated/torch.autograd.functional.hessian.html#torch.autograd.functional.hessian">hessian() (in module torch.autograd.functional)</a>

      <ul>
        <li><a href="generated/torch.func.hessian.html#torch.func.hessian">(in module torch.func)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fft.hfft.html#torch.fft.hfft">hfft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.hfft2.html#torch.fft.hfft2">hfft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.hfftn.html#torch.fft.hfftn">hfftn() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.nn.functional.hinge_embedding_loss.html#torch.nn.functional.hinge_embedding_loss">hinge_embedding_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.HingeEmbeddingLoss.html#torch.nn.HingeEmbeddingLoss">HingeEmbeddingLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.hint_int.html#torch.fx.experimental.symbolic_shapes.hint_int">hint_int() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.histc.html#torch.histc">histc() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.histc.html#torch.Tensor.histc">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.histogram.html#torch.histogram">histogram() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.histogram.html#torch.Tensor.histogram">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.histogramdd.html#torch.histogramdd">histogramdd() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.HistogramObserver.html#torch.ao.quantization.observer.HistogramObserver">HistogramObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.linalg.householder_product.html#torch.linalg.householder_product">householder_product() (in module torch.linalg)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.hpu">hpu() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.hpu">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.hsplit.html#torch.hsplit">hsplit() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.hsplit.html#torch.Tensor.hsplit">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.hspmm.html#torch.hspmm">hspmm() (in module torch)</a>
</li>
      <li><a href="generated/torch.hstack.html#torch.hstack">hstack() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.functional.huber_loss.html#torch.nn.functional.huber_loss">huber_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.HuberLoss.html#torch.nn.HuberLoss">HuberLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.autograd.functional.hvp.html#torch.autograd.functional.hvp">hvp() (in module torch.autograd.functional)</a>
</li>
      <li><a href="generated/torch.hypot.html#torch.hypot">hypot() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.hypot.html#torch.Tensor.hypot">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.hypot_.html#torch.Tensor.hypot_">hypot_() (torch.Tensor method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="I">I</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.i0.html#torch.i0">i0() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.i0">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.i0.html#torch.Tensor.i0">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.i0_.html#torch.Tensor.i0_">i0_() (torch.Tensor method)</a>
</li>
      <li><a href="special.html#torch.special.i0e">i0e() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.i1">i1() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.i1e">i1e() (in module torch.special)</a>
</li>
      <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.icdf">icdf() (torch.distributions.cauchy.Cauchy method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.icdf">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.icdf">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.icdf">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.icdf">(torch.distributions.half_cauchy.HalfCauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.icdf">(torch.distributions.half_normal.HalfNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.icdf">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.icdf">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.icdf">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.icdf">(torch.distributions.uniform.Uniform method)</a>
</li>
      </ul></li>
      <li><a href="rpc.html#torch.distributed.rpc.WorkerInfo.id">id (torch.distributed.rpc.WorkerInfo property)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.id">id() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="generated/torch.nn.Identity.html#torch.nn.Identity">Identity (class in torch.nn)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity">(class in torch.nn.utils.prune)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.prune.identity.html#torch.nn.utils.prune.identity">identity() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.fft.ifft.html#torch.fft.ifft">ifft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.ifft2.html#torch.fft.ifft2">ifft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.ifftn.html#torch.fft.ifftn">ifftn() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.ifftshift.html#torch.fft.ifftshift">ifftshift() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.igamma.html#torch.igamma">igamma() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.igamma.html#torch.Tensor.igamma">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.igamma_.html#torch.Tensor.igamma_">igamma_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.igammac.html#torch.igammac">igammac() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.igammac.html#torch.Tensor.igammac">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.igammac_.html#torch.Tensor.igammac_">igammac_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.jit.ignore.html#torch.jit.ignore">ignore() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.fft.ihfft.html#torch.fft.ihfft">ihfft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.ihfft2.html#torch.fft.ihfft2">ihfft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.ihfftn.html#torch.fft.ihfftn">ihfftn() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.Tensor.imag.html#torch.Tensor.imag">imag (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.imag.html#torch.imag">imag() (in module torch)</a>
</li>
      <li><a href="library.html#torch.library.impl">impl() (in module torch.library)</a>

      <ul>
        <li><a href="library.html#torch.library.Library.impl">(torch.library.Library method)</a>
</li>
      </ul></li>
      <li><a href="library.html#torch.library.impl_abstract">impl_abstract() (in module torch.library)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.import_module">import_module() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.MemRecordsAcc.html#torch.autograd.profiler_util.MemRecordsAcc.in_interval">in_interval() (torch.autograd.profiler_util.MemRecordsAcc method)</a>
</li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.include_paths">include_paths() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.autograd.profiler.KinetoStepTracker.html#torch.autograd.profiler.KinetoStepTracker.increment_step">increment_step() (torch.autograd.profiler.KinetoStepTracker class method)</a>
</li>
      <li><a href="generated/torch.autograd.graph.increment_version.html#torch.autograd.graph.increment_version">increment_version() (in module torch.autograd.graph)</a>
</li>
      <li><a href="distributions.html#torch.distributions.independent.Independent">Independent (class in torch.distributions.independent)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.independent">independent (in module torch.distributions.constraints)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.IndependentTransform">IndependentTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.index">index() (in module torch.distributed.GradBucket)</a>

      <ul>
        <li><a href="generated/torch.autograd.forward_ad.UnpackedDualTensor.html#torch.autograd.forward_ad.UnpackedDualTensor.index">(torch.autograd.forward_ad.UnpackedDualTensor method)</a>
</li>
        <li><a href="generated/torch.autograd.profiler_util.Kernel.html#torch.autograd.profiler_util.Kernel.index">(torch.autograd.profiler_util.Kernel method)</a>
</li>
        <li><a href="generated/torch.jit.Attribute.html#torch.jit.Attribute.index">(torch.jit.Attribute method)</a>
</li>
        <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.index">(torch.nn.utils.rnn.PackedSequence method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.index_add.html#torch.index_add">index_add() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.index_add.html#torch.Tensor.index_add">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.index_add_.html#torch.Tensor.index_add_">index_add_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.index_copy.html#torch.index_copy">index_copy() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.index_copy.html#torch.Tensor.index_copy">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.index_copy_.html#torch.Tensor.index_copy_">index_copy_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.index_fill.html#torch.Tensor.index_fill">index_fill() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.index_fill_.html#torch.Tensor.index_fill_">index_fill_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.index_put.html#torch.Tensor.index_put">index_put() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.index_put_.html#torch.Tensor.index_put_">index_put_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.index_reduce.html#torch.index_reduce">index_reduce() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.index_reduce.html#torch.Tensor.index_reduce">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.index_reduce_.html#torch.Tensor.index_reduce_">index_reduce_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.index_select.html#torch.index_select">index_select() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.index_select.html#torch.Tensor.index_select">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.indices.html#torch.Tensor.indices">indices() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.autograd.grad_mode.inference_mode.html#torch.autograd.grad_mode.inference_mode">inference_mode (class in torch.autograd.grad_mode)</a>
</li>
      <li><a href="generated/torch.cuda.init.html#torch.cuda.init">init() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.xpu.init.html#torch.xpu.init">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.device_mesh.init_device_mesh">init_device_mesh() (in module torch.distributed.device_mesh)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.RpcBackendOptions.init_method">init_method (torch.distributed.rpc.RpcBackendOptions property)</a>

      <ul>
        <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.init_method">(torch.distributed.rpc.TensorPipeRpcBackendOptions property)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.init_process_group">init_process_group() (in module torch.distributed)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.init_rpc">init_rpc() (in module torch.distributed.rpc)</a>
</li>
      <li><a href="generated/torch.autograd.profiler.KinetoStepTracker.html#torch.autograd.profiler.KinetoStepTracker.init_step_count">init_step_count() (torch.autograd.profiler.KinetoStepTracker class method)</a>
</li>
      <li><a href="generated/torch.initial_seed.html#torch.initial_seed">initial_seed() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.initial_seed.html#torch.cuda.initial_seed">(in module torch.cuda)</a>
</li>
        <li><a href="random.html#torch.random.initial_seed">(in module torch.random)</a>
</li>
        <li><a href="generated/torch.xpu.initial_seed.html#torch.xpu.initial_seed">(in module torch.xpu)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.initial_seed">(torch.Generator method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin.initialize_parameters">initialize_parameters() (torch.nn.modules.lazy.LazyModuleMixin method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.inlined_graph">inlined_graph (torch.jit.ScriptModule property)</a>
</li>
      <li><a href="generated/torch.inner.html#torch.inner">inner() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.inner.html#torch.Tensor.inner">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction">InplaceFunction (class in torch.autograd.function)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.ObservationType.html#torch.ao.quantization.backend_config.ObservationType.INPUT_OUTPUT_NOT_OBSERVED">INPUT_OUTPUT_NOT_OBSERVED (torch.ao.quantization.backend_config.ObservationType attribute)</a>
</li>
      <li><a href="export.html#torch.export.graph_signature.InputKind">InputKind (class in torch.export.graph_signature)</a>
</li>
      <li><a href="export.html#torch.export.graph_signature.InputSpec">InputSpec (class in torch.export.graph_signature)</a>
</li>
      <li><a href="generated/torch.nn.ModuleList.html#torch.nn.ModuleList.insert">insert() (torch.nn.ModuleList method)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.insert_arg">insert_arg() (torch.fx.Node method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.inserting_after">inserting_after() (torch.fx.Graph method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.inserting_before">inserting_before() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.nn.functional.instance_norm.html#torch.nn.functional.instance_norm">instance_norm() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.InstanceNorm1d.html#torch.ao.nn.quantized.InstanceNorm1d">InstanceNorm1d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.InstanceNorm1d.html#torch.nn.InstanceNorm1d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.InstanceNorm2d.html#torch.ao.nn.quantized.InstanceNorm2d">InstanceNorm2d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.InstanceNorm3d.html#torch.ao.nn.quantized.InstanceNorm3d">InstanceNorm3d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.InstanceNorm3d.html#torch.nn.InstanceNorm3d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.int.html#torch.Tensor.int">int() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.int">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.int">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.int_repr.html#torch.Tensor.int_repr">int_repr() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.integer_interval">integer_interval (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.jit.interface.html#torch.jit.interface">interface() (in module torch.jit)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.intern">intern() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.interned_modules">interned_modules() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.interpolate.html#torch.ao.nn.quantized.functional.interpolate">interpolate (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.interpolate.html#torch.nn.functional.interpolate">interpolate() (in module torch.nn.functional)</a>
</li>
      <li><a href="fx.html#torch.fx.Interpreter">Interpreter (class in torch.fx)</a>
</li>
      <li><a href="export.html#torch.export.unflatten.InterpreterModule">InterpreterModule (class in torch.export.unflatten)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.Interval.html#torch.autograd.profiler_util.Interval">Interval (class in torch.autograd.profiler_util)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.interval">interval (in module torch.distributions.constraints)</a>
</li>
      <li><a href="storage.html#torch.IntStorage">IntStorage (class in torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform.inv">inv (torch.distributions.transforms.Transform property)</a>
</li>
      <li><a href="generated/torch.linalg.inv.html#torch.linalg.inv">inv() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.inv_ex.html#torch.linalg.inv_ex">inv_ex() (in module torch.linalg)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.InvalidExportOptionsError">InvalidExportOptionsError (class in torch.onnx)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.inverse.html#torch.inverse">inverse() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.inverse.html#torch.Tensor.inverse">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform.inverse_shape">inverse_shape() (torch.distributions.transforms.Transform method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.inverse_gamma.InverseGamma">InverseGamma (class in torch.distributions.inverse_gamma)</a>
</li>
      <li><a href="generated/torch.cuda.ipc_collect.html#torch.cuda.ipc_collect">ipc_collect() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.ipc_handle">ipc_handle() (torch.cuda.Event method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.ipu">ipu() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.ipu">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.irecv">irecv() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.fft.irfft.html#torch.fft.irfft">irfft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.irfft2.html#torch.fft.irfft2">irfft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.irfftn.html#torch.fft.irfftn">irfftn() (in module torch.fft)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.is_available">is_available() (in module torch.backends.cudnn)</a>

      <ul>
        <li><a href="backends.html#torch.backends.mkl.is_available">(in module torch.backends.mkl)</a>
</li>
        <li><a href="backends.html#torch.backends.mkldnn.is_available">(in module torch.backends.mkldnn)</a>
</li>
        <li><a href="backends.html#torch.backends.mps.is_available">(in module torch.backends.mps)</a>
</li>
        <li><a href="backends.html#torch.backends.nnpack.is_available">(in module torch.backends.nnpack)</a>
</li>
        <li><a href="backends.html#torch.backends.openmp.is_available">(in module torch.backends.openmp)</a>
</li>
        <li><a href="backends.html#torch.backends.opt_einsum.is_available">(in module torch.backends.opt_einsum)</a>
</li>
        <li><a href="generated/torch.cpu.is_available.html#torch.cpu.is_available">(in module torch.cpu)</a>
</li>
        <li><a href="generated/torch.cuda.is_available.html#torch.cuda.is_available">(in module torch.cuda)</a>
</li>
        <li><a href="distributed.html#torch.distributed.is_available">(in module torch.distributed)</a>
</li>
        <li><a href="profiler.html#torch.profiler.itt.is_available">(in module torch.profiler.itt)</a>
</li>
        <li><a href="generated/torch.xpu.is_available.html#torch.xpu.is_available">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="backends.html#torch.backends.cuda.is_built">is_built() (in module torch.backends.cuda)</a>

      <ul>
        <li><a href="backends.html#torch.backends.mps.is_built">(in module torch.backends.mps)</a>
</li>
      </ul></li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.is_closed">is_closed() (torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      <li><a href="generated/torch.Tensor.is_coalesced.html#torch.Tensor.is_coalesced">is_coalesced() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.compiler.is_compiling.html#torch.compiler.is_compiling">is_compiling() (in module torch.compiler)</a>
</li>
      <li><a href="generated/torch.is_complex.html#torch.is_complex">is_complex() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.is_complex.html#torch.Tensor.is_complex">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.is_concrete_bool.html#torch.fx.experimental.symbolic_shapes.is_concrete_bool">is_concrete_bool() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.is_concrete_int.html#torch.fx.experimental.symbolic_shapes.is_concrete_int">is_concrete_int() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.is_conj.html#torch.is_conj">is_conj() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.is_conj.html#torch.Tensor.is_conj">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.is_contiguous.html#torch.Tensor.is_contiguous">is_contiguous() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.is_cuda">is_cuda (torch.nn.utils.rnn.PackedSequence property)</a>

      <ul>
        <li><a href="generated/torch.Tensor.is_cuda.html#torch.Tensor.is_cuda">(torch.Tensor attribute)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.is_cuda">(torch.TypedStorage property)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.is_cuda">(torch.UntypedStorage property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.is_current_stream_capturing.html#torch.cuda.is_current_stream_capturing">is_current_stream_capturing() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.is_deterministic_algorithms_warn_only_enabled.html#torch.is_deterministic_algorithms_warn_only_enabled">is_deterministic_algorithms_warn_only_enabled() (in module torch)</a>
</li>
      <li><a href="generated/torch.compiler.is_dynamo_compiling.html#torch.compiler.is_dynamo_compiling">is_dynamo_compiling() (in module torch.compiler)</a>
</li>
      <li><a href="generated/torch.sparse.check_sparse_tensor_invariants.html#torch.sparse.check_sparse_tensor_invariants.is_enabled">is_enabled() (torch.sparse.check_sparse_tensor_invariants static method)</a>
</li>
      <li><a href="generated/torch.is_floating_point.html#torch.is_floating_point">is_floating_point() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.is_floating_point.html#torch.Tensor.is_floating_point">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.is_gloo_available">is_gloo_available() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.is_grad_enabled.html#torch.is_grad_enabled">is_grad_enabled() (in module torch)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.is_hpu">is_hpu (torch.TypedStorage property)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.is_hpu">(torch.UntypedStorage property)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Node.is_impure">is_impure() (torch.fx.Node method)</a>
</li>
      <li><a href="onnx_torchscript.html#torch.onnx.is_in_onnx_export">is_in_onnx_export() (in module torch.onnx)</a>
</li>
      <li><a href="generated/torch.Tensor.is_inference.html#torch.Tensor.is_inference">is_inference() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.is_inference_mode_enabled.html#torch.is_inference_mode_enabled">is_inference_mode_enabled() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.is_initialized.html#torch.cuda.is_initialized">is_initialized() (in module torch.cuda)</a>

      <ul>
        <li><a href="distributed.html#torch.distributed.is_initialized">(in module torch.distributed)</a>
</li>
        <li><a href="generated/torch.xpu.is_initialized.html#torch.xpu.is_initialized">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="torch.html#torch.SymFloat.is_integer">is_integer() (torch.SymFloat method)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.is_last">is_last() (in module torch.distributed.GradBucket)</a>
</li>
      <li><a href="generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf">is_leaf (torch.Tensor attribute)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.NSTracer.is_leaf_module">is_leaf_module() (torch.ao.ns._numeric_suite_fx.NSTracer method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Tracer.is_leaf_module">(torch.fx.Tracer method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.is_meta.html#torch.Tensor.is_meta">is_meta (torch.Tensor attribute)</a>
</li>
      <li><a href="distributed.html#torch.distributed.is_mpi_available">is_mpi_available() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.is_nccl_available">is_nccl_available() (in module torch.distributed)</a>
</li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.is_ninja_available">is_ninja_available() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.is_nonzero.html#torch.is_nonzero">is_nonzero() (in module torch)</a>
</li>
      <li><a href="onnx_dynamo_onnxruntime_backend.html#torch.onnx.is_onnxrt_backend_supported">is_onnxrt_backend_supported() (in module torch.onnx)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.PyRRef.is_owner">is_owner() (torch.distributed.rpc.PyRRef method)</a>
</li>
      <li><a href="generated/torch.nn.utils.parametrize.is_parametrized.html#torch.nn.utils.parametrize.is_parametrized">is_parametrized() (in module torch.nn.utils.parametrize)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.is_pinned">is_pinned() (torch.nn.utils.rnn.PackedSequence method)</a>

      <ul>
        <li><a href="generated/torch.Tensor.is_pinned.html#torch.Tensor.is_pinned">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.is_pinned">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.is_pinned">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.prune.is_pruned.html#torch.nn.utils.prune.is_pruned">is_pruned() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.Tensor.is_quantized.html#torch.Tensor.is_quantized">is_quantized (torch.Tensor attribute)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.OnnxRegistry.is_registered_op">is_registered_op() (torch.onnx.OnnxRegistry method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.WorkerState.is_running">is_running() (torch.distributed.elastic.agent.server.WorkerState static method)</a>
</li>
      <li><a href="jit_language_reference.html#torch.jit.is_scripting">is_scripting() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.Tensor.is_set_to.html#torch.Tensor.is_set_to">is_set_to() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.is_shared.html#torch.Tensor.is_shared">is_shared() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.is_shared">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.is_shared">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.is_signed.html#torch.Tensor.is_signed">is_signed() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.is_sparse.html#torch.Tensor.is_sparse">is_sparse (torch.Tensor attribute)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.is_sparse">(torch.TypedStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.is_sparse">(torch.UntypedStorage attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.is_sparse_csr.html#torch.Tensor.is_sparse_csr">is_sparse_csr (torch.Tensor attribute)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.is_sparse_csr">(torch.UntypedStorage attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.is_storage.html#torch.is_storage">is_storage() (in module torch)</a>
</li>
      <li><a href="generated/torch.is_tensor.html#torch.is_tensor">is_tensor() (in module torch)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.is_tensor_like">is_tensor_like() (in module torch.overrides)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.is_tensor_method_or_property">is_tensor_method_or_property() (in module torch.overrides)</a>
</li>
      <li><a href="distributed.html#torch.distributed.is_torchelastic_launched">is_torchelastic_launched() (in module torch.distributed)</a>
</li>
      <li><a href="jit_language_reference.html#torch.jit.is_tracing">is_tracing() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.is_unbacked_symint">is_unbacked_symint() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.is_warn_always_enabled.html#torch.is_warn_always_enabled">is_warn_always_enabled() (in module torch)</a>
</li>
      <li><a href="generated/torch.isclose.html#torch.isclose">isclose() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isclose.html#torch.Tensor.isclose">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.isend">isend() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.isfinite.html#torch.isfinite">isfinite() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isfinite.html#torch.Tensor.isfinite">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.isin.html#torch.isin">isin() (in module torch)</a>
</li>
      <li><a href="generated/torch.isinf.html#torch.isinf">isinf() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isinf.html#torch.Tensor.isinf">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.isinstance.html#torch.jit.isinstance">isinstance() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.isnan.html#torch.isnan">isnan() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isnan.html#torch.Tensor.isnan">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.isneginf.html#torch.isneginf">isneginf() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isneginf.html#torch.Tensor.isneginf">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.isposinf.html#torch.isposinf">isposinf() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isposinf.html#torch.Tensor.isposinf">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.isreal.html#torch.isreal">isreal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isreal.html#torch.Tensor.isreal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.istft.html#torch.istft">istft() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.istft.html#torch.Tensor.istft">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.item.html#torch.Tensor.item">item() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.items">items() (torch.autograd.profiler_util.StringTable method)</a>

      <ul>
        <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.items">(torch.nn.ModuleDict method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.items">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.itemsize.html#torch.Tensor.itemsize">itemsize (torch.Tensor attribute)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.iter">iter() (torch.fx.Tracer method)</a>
</li>
      <li><a href="data.html#torch.utils.data.IterableDataset">IterableDataset (class in torch.utils.data)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="J">J</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.func.jacfwd.html#torch.func.jacfwd">jacfwd() (in module torch.func)</a>
</li>
      <li><a href="generated/torch.autograd.functional.jacobian.html#torch.autograd.functional.jacobian">jacobian() (in module torch.autograd.functional)</a>
</li>
      <li><a href="generated/torch.func.jacrev.html#torch.func.jacrev">jacrev() (in module torch.func)</a>
</li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType">JitScalarType (class in torch.onnx)</a>
</li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Join">Join (class in torch.distributed.algorithms)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.join">join (torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout property)</a>
</li>
      <li><a href="multiprocessing.html#torch.multiprocessing.SpawnContext.join">join() (torch.multiprocessing.SpawnContext method)</a>

      <ul>
        <li><a href="generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.join">(torch.nn.parallel.DistributedDataParallel method)</a>
</li>
      </ul></li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Joinable.join_device">join_device (torch.distributed.algorithms.Joinable property)</a>

      <ul>
        <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.join_device">(torch.distributed.optim.ZeroRedundancyOptimizer property)</a>
</li>
      </ul></li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Joinable.join_hook">join_hook() (torch.distributed.algorithms.Joinable method)</a>

      <ul>
        <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.join_hook">(torch.distributed.optim.ZeroRedundancyOptimizer method)</a>
</li>
        <li><a href="generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.join_hook">(torch.nn.parallel.DistributedDataParallel method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Joinable.join_process_group">join_process_group (torch.distributed.algorithms.Joinable property)</a>

      <ul>
        <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.join_process_group">(torch.distributed.optim.ZeroRedundancyOptimizer property)</a>
</li>
      </ul></li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Joinable">Joinable (class in torch.distributed.algorithms)</a>
</li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.JoinHook">JoinHook (class in torch.distributed.algorithms)</a>
</li>
      <li><a href="generated/torch.autograd.functional.jvp.html#torch.autograd.functional.jvp">jvp() (in module torch.autograd.functional)</a>

      <ul>
        <li><a href="generated/torch.func.jvp.html#torch.func.jvp">(in module torch.func)</a>
</li>
        <li><a href="generated/torch.autograd.Function.jvp.html#torch.autograd.Function.jvp">(torch.autograd.Function static method)</a>
</li>
        <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction.jvp">(torch.autograd.function.InplaceFunction static method)</a>
</li>
        <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.jvp">(torch.autograd.function.NestedIOFunction static method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="K">K</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="nn.init.html#torch.nn.init.kaiming_normal_">kaiming_normal_() (in module torch.nn.init)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.kaiming_uniform_">kaiming_uniform_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.signal.windows.kaiser.html#torch.signal.windows.kaiser">kaiser() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.kaiser_window.html#torch.kaiser_window">kaiser_window() (in module torch)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.Kernel.html#torch.autograd.profiler_util.Kernel">Kernel (class in torch.autograd.profiler_util)</a>
</li>
      <li><a href="generated/torch.autograd.profiler.profile.key_averages.html#torch.autograd.profiler.profile.key_averages">key_averages() (torch.autograd.profiler.profile method)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler._KinetoProfile.key_averages">(torch.profiler._KinetoProfile method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.keys">keys() (torch.autograd.profiler_util.StringTable method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Tracer.keys">(torch.fx.Tracer method)</a>
</li>
        <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.keys">(torch.nn.ModuleDict method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.keys">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.autograd.profiler.KinetoStepTracker.html#torch.autograd.profiler.KinetoStepTracker">KinetoStepTracker (class in torch.autograd.profiler)</a>
</li>
      <li><a href="generated/torch.nn.functional.kl_div.html#torch.nn.functional.kl_div">kl_div() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.kl.kl_divergence">kl_divergence() (in module torch.distributions.kl)</a>
</li>
      <li><a href="generated/torch.nn.KLDivLoss.html#torch.nn.KLDivLoss">KLDivLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.kron.html#torch.kron">kron() (in module torch)</a>
</li>
      <li><a href="generated/torch.kthvalue.html#torch.kthvalue">kthvalue() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.kthvalue.html#torch.Tensor.kthvalue">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy">Kumaraswamy (class in torch.distributions.kumaraswamy)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.kwargs">kwargs (torch.fx.Node property)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="L">L</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.nn.functional.l1_loss.html#torch.nn.functional.l1_loss">l1_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.l1_unstructured.html#torch.nn.utils.prune.l1_unstructured">l1_unstructured() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.nn.L1Loss.html#torch.nn.L1Loss">L1Loss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured">L1Unstructured (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR">LambdaLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="distributions.html#torch.distributions.laplace.Laplace">Laplace (class in torch.distributions.laplace)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.last_call">last_call (torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout property)</a>
</li>
      <li><a href="generated/torch.nn.functional.layer_norm.html#torch.nn.functional.layer_norm">layer_norm() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.LayerNorm.html#torch.ao.nn.quantized.LayerNorm">LayerNorm (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="tensor_attributes.html#torch.layout">layout (class in torch)</a>
</li>
      <li><a href="generated/torch.nn.LazyBatchNorm1d.html#torch.nn.LazyBatchNorm1d">LazyBatchNorm1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyBatchNorm2d.html#torch.nn.LazyBatchNorm2d">LazyBatchNorm2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyBatchNorm3d.html#torch.nn.LazyBatchNorm3d">LazyBatchNorm3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConv1d.html#torch.nn.LazyConv1d">LazyConv1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConv2d.html#torch.nn.LazyConv2d">LazyConv2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConv3d.html#torch.nn.LazyConv3d">LazyConv3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConvTranspose1d.html#torch.nn.LazyConvTranspose1d">LazyConvTranspose1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConvTranspose2d.html#torch.nn.LazyConvTranspose2d">LazyConvTranspose2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConvTranspose3d.html#torch.nn.LazyConvTranspose3d">LazyConvTranspose3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyInstanceNorm1d.html#torch.nn.LazyInstanceNorm1d">LazyInstanceNorm1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyInstanceNorm2d.html#torch.nn.LazyInstanceNorm2d">LazyInstanceNorm2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyInstanceNorm3d.html#torch.nn.LazyInstanceNorm3d">LazyInstanceNorm3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear">LazyLinear (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin">LazyModuleMixin (class in torch.nn.modules.lazy)</a>
</li>
      <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS">LBFGS (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.lcm.html#torch.lcm">lcm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.lcm.html#torch.Tensor.lcm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.lcm_.html#torch.Tensor.lcm_">lcm_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ldexp.html#torch.ldexp">ldexp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ldexp.html#torch.Tensor.ldexp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.ldexp_.html#torch.Tensor.ldexp_">ldexp_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.linalg.ldl_factor.html#torch.linalg.ldl_factor">ldl_factor() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.ldl_factor_ex.html#torch.linalg.ldl_factor_ex">ldl_factor_ex() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.ldl_solve.html#torch.linalg.ldl_solve">ldl_solve() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.le.html#torch.le">le() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.le.html#torch.Tensor.le">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.le_.html#torch.Tensor.le_">le_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.leaky_relu.html#torch.ao.nn.quantized.functional.leaky_relu">leaky_relu (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.leaky_relu.html#torch.nn.functional.leaky_relu">leaky_relu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.leaky_relu_.html#torch.nn.functional.leaky_relu_">leaky_relu_() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.LeakyReLU.html#torch.ao.nn.quantized.LeakyReLU">LeakyReLU (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.lerp.html#torch.lerp">lerp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.lerp.html#torch.Tensor.lerp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.lerp_.html#torch.Tensor.lerp_">lerp_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.less.html#torch.less">less() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.less.html#torch.Tensor.less">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.less_.html#torch.Tensor.less_">less_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.less_equal.html#torch.less_equal">less_equal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.less_equal.html#torch.Tensor.less_equal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.less_equal_.html#torch.Tensor.less_equal_">less_equal_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.less_than">less_than (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.lgamma.html#torch.lgamma">lgamma() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.lgamma.html#torch.Tensor.lgamma">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.lgamma_.html#torch.Tensor.lgamma_">lgamma_() (torch.Tensor method)</a>
</li>
      <li><a href="library.html#torch.library.Library">Library (class in torch.library)</a>
</li>
      <li><a href="generated/torch.ao.nn.qat.Linear.html#torch.ao.nn.qat.Linear">Linear (class in torch.ao.nn.qat)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.qat.dynamic.Linear.html#torch.ao.nn.qat.dynamic.Linear">(class in torch.ao.nn.qat.dynamic)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.Linear.html#torch.ao.nn.quantized.Linear">(class in torch.ao.nn.quantized)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.dynamic.Linear.html#torch.ao.nn.quantized.dynamic.Linear">(class in torch.ao.nn.quantized.dynamic)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.functional.linear.html#torch.ao.nn.quantized.functional.linear">linear (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Linear.html#torch.nn.Linear">Linear (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.linear.html#torch.nn.functional.linear">linear() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.func.linearize.html#torch.func.linearize">linearize() (in module torch.func)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.LinearLR.html#torch.optim.lr_scheduler.LinearLR">LinearLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.ao.nn.intrinsic.LinearReLU.html#torch.ao.nn.intrinsic.LinearReLU">LinearReLU (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.LinearReLU.html#torch.ao.nn.intrinsic.qat.LinearReLU">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.LinearReLU.html#torch.ao.nn.intrinsic.quantized.LinearReLU">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU.html#torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU">(class in torch.ao.nn.intrinsic.quantized.dynamic)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linspace.html#torch.linspace">linspace() (in module torch)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.lint">lint() (torch.fx.Graph method)</a>
</li>
      <li><a href="hub.html#torch.hub.list">list() (in module torch.hub)</a>
</li>
      <li><a href="generated/torch.compiler.list_backends.html#torch.compiler.list_backends">list_backends() (in module torch.compiler)</a>
</li>
      <li><a href="generated/torch.cuda.list_gpu_processes.html#torch.cuda.list_gpu_processes">list_gpu_processes() (in module torch.cuda)</a>
</li>
      <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky">LKJCholesky (class in torch.distributions.lkj_cholesky)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.ln_structured.html#torch.nn.utils.prune.ln_structured">ln_structured() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured">LnStructured (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.load.html#torch.load">load() (in module torch)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict_loader.load">(in module torch.distributed.checkpoint.state_dict_loader)</a>
</li>
        <li><a href="export.html#torch.export.load">(in module torch.export)</a>
</li>
        <li><a href="hub.html#torch.hub.load">(in module torch.hub)</a>
</li>
        <li><a href="generated/torch.jit.load.html#torch.jit.load">(in module torch.jit)</a>
</li>
        <li><a href="cpp_extension.html#torch.utils.cpp_extension.load">(in module torch.utils.cpp_extension)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.PackageImporter.load_binary">load_binary() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.load_bytes">load_bytes() (torch.distributed.checkpoint.LoadPlanner method)</a>
</li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.load_inline">load_inline() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.autograd.profiler.load_nvprof.html#torch.autograd.profiler.load_nvprof">load_nvprof() (in module torch.autograd.profiler)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.load_observer_state_dict.html#torch.ao.quantization.observer.load_observer_state_dict">load_observer_state_dict (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.load_pickle">load_pickle() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict_loader.load_state_dict">load_state_dict() (in module torch.distributed.checkpoint.state_dict_loader)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.stateful.Stateful.load_state_dict">(torch.distributed.checkpoint.stateful.Stateful method)</a>
</li>
        <li><a href="distributed.optim.html#torch.distributed.optim.PostLocalSGDOptimizer.load_state_dict">(torch.distributed.optim.PostLocalSGDOptimizer method)</a>
</li>
        <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.load_state_dict">(torch.distributed.optim.ZeroRedundancyOptimizer method)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.load_state_dict">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.load_state_dict">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.load_state_dict">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.load_state_dict">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.load_state_dict">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.load_state_dict">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.load_state_dict">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.load_state_dict">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.load_state_dict">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ChainedScheduler.html#torch.optim.lr_scheduler.ChainedScheduler.load_state_dict">(torch.optim.lr_scheduler.ChainedScheduler method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ConstantLR.html#torch.optim.lr_scheduler.ConstantLR.load_state_dict">(torch.optim.lr_scheduler.ConstantLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR.load_state_dict">(torch.optim.lr_scheduler.CosineAnnealingLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.load_state_dict">(torch.optim.lr_scheduler.CosineAnnealingWarmRestarts method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR.load_state_dict">(torch.optim.lr_scheduler.ExponentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR.load_state_dict">(torch.optim.lr_scheduler.LambdaLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LinearLR.html#torch.optim.lr_scheduler.LinearLR.load_state_dict">(torch.optim.lr_scheduler.LinearLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict">(torch.optim.lr_scheduler.MultiplicativeLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR.load_state_dict">(torch.optim.lr_scheduler.MultiStepLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR.load_state_dict">(torch.optim.lr_scheduler.OneCycleLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.PolynomialLR.html#torch.optim.lr_scheduler.PolynomialLR.load_state_dict">(torch.optim.lr_scheduler.PolynomialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.SequentialLR.html#torch.optim.lr_scheduler.SequentialLR.load_state_dict">(torch.optim.lr_scheduler.SequentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR.load_state_dict">(torch.optim.lr_scheduler.StepLR method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.load_state_dict">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.Optimizer.load_state_dict.html#torch.optim.Optimizer.load_state_dict">(torch.optim.Optimizer method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.load_state_dict">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.load_state_dict">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.load_state_dict">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.load_state_dict">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.load_state_dict">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="hub.html#torch.hub.load_state_dict_from_url">load_state_dict_from_url() (in module torch.hub)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.load_text">load_text() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="model_zoo.html#torch.utils.model_zoo.load_url">load_url() (in module torch.utils.model_zoo)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlan">LoadPlan (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner">LoadPlanner (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="generated/torch.lobpcg.html#torch.lobpcg">lobpcg() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.loc">loc (torch.distributions.log_normal.LogNormal property)</a>
</li>
      <li><a href="generated/torch.nn.functional.local_response_norm.html#torch.nn.functional.local_response_norm">local_response_norm() (in module torch.nn.functional)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.PyRRef.local_value">local_value() (torch.distributed.rpc.PyRRef method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent">LocalElasticAgent (class in torch.distributed.elastic.agent.server.local_elastic_agent)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.LocalOptimStateDictConfig">LocalOptimStateDictConfig (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="generated/torch.nn.LocalResponseNorm.html#torch.nn.LocalResponseNorm">LocalResponseNorm (class in torch.nn)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.LocalStateDictConfig">LocalStateDictConfig (class in torch.distributed.fsdp)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.LocalTimerClient">LocalTimerClient (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.LocalTimerServer">LocalTimerServer (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="generated/torch.log.html#torch.log">log() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.log.html#torch.Tensor.log">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.log10.html#torch.log10">log10() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.log10.html#torch.Tensor.log10">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.log10_.html#torch.Tensor.log10_">log10_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.log1p.html#torch.log1p">log1p() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.log1p">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.log1p.html#torch.Tensor.log1p">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.log1p_.html#torch.Tensor.log1p_">log1p_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.log2.html#torch.log2">log2() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.log2.html#torch.Tensor.log2">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.log2_.html#torch.Tensor.log2_">log2_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.log_.html#torch.Tensor.log_">log_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform.log_abs_det_jacobian">log_abs_det_jacobian() (torch.distributions.transforms.Transform method)</a>
</li>
      <li><a href="monitor.html#torch.monitor.log_event">log_event() (in module torch.monitor)</a>
</li>
      <li><a href="special.html#torch.special.log_ndtr">log_ndtr() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.Tensor.log_normal_.html#torch.Tensor.log_normal_">log_normal_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.log_prob">log_prob() (torch.distributions.bernoulli.Bernoulli method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.log_prob">(torch.distributions.beta.Beta method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.log_prob">(torch.distributions.binomial.Binomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.log_prob">(torch.distributions.categorical.Categorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.log_prob">(torch.distributions.cauchy.Cauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.log_prob">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.log_prob">(torch.distributions.dirichlet.Dirichlet method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.log_prob">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.log_prob">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.log_prob">(torch.distributions.fishersnedecor.FisherSnedecor method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.log_prob">(torch.distributions.gamma.Gamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.log_prob">(torch.distributions.geometric.Geometric method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.log_prob">(torch.distributions.gumbel.Gumbel method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.log_prob">(torch.distributions.half_cauchy.HalfCauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.log_prob">(torch.distributions.half_normal.HalfNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.log_prob">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.log_prob">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky.log_prob">(torch.distributions.lkj_cholesky.LKJCholesky method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.log_prob">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.log_prob">(torch.distributions.mixture_same_family.MixtureSameFamily method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.log_prob">(torch.distributions.multinomial.Multinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.log_prob">(torch.distributions.multivariate_normal.MultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.log_prob">(torch.distributions.negative_binomial.NegativeBinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.log_prob">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.log_prob">(torch.distributions.one_hot_categorical.OneHotCategorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.log_prob">(torch.distributions.poisson.Poisson method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.log_prob">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.log_prob">(torch.distributions.studentT.StudentT method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.log_prob">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.log_prob">(torch.distributions.uniform.Uniform method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.log_prob">(torch.distributions.von_mises.VonMises method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.log_prob">(torch.distributions.wishart.Wishart method)</a>
</li>
        <li><a href="generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html#torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob">(torch.nn.AdaptiveLogSoftmaxWithLoss method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.log_softmax.html#torch.nn.functional.log_softmax">log_softmax() (in module torch.nn.functional)</a>

      <ul>
        <li><a href="generated/torch.sparse.log_softmax.html#torch.sparse.log_softmax">(in module torch.sparse)</a>
</li>
        <li><a href="special.html#torch.special.log_softmax">(in module torch.special)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.logaddexp.html#torch.logaddexp">logaddexp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logaddexp.html#torch.Tensor.logaddexp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.logaddexp2.html#torch.logaddexp2">logaddexp2() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logaddexp2.html#torch.Tensor.logaddexp2">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.logcumsumexp.html#torch.logcumsumexp">logcumsumexp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logcumsumexp.html#torch.Tensor.logcumsumexp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.logdet.html#torch.logdet">logdet() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logdet.html#torch.Tensor.logdet">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Logger">Logger (class in torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.loggers_set_enabled">loggers_set_enabled() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.loggers_set_save_activations">loggers_set_save_activations() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="generated/torch.logical_and.html#torch.logical_and">logical_and() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logical_and.html#torch.Tensor.logical_and">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.logical_and_.html#torch.Tensor.logical_and_">logical_and_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.logical_not.html#torch.logical_not">logical_not() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logical_not.html#torch.Tensor.logical_not">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.logical_not_.html#torch.Tensor.logical_not_">logical_not_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.logical_or.html#torch.logical_or">logical_or() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logical_or.html#torch.Tensor.logical_or">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.logical_or_.html#torch.Tensor.logical_or_">logical_or_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.logical_xor.html#torch.logical_xor">logical_xor() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logical_xor.html#torch.Tensor.logical_xor">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.logical_xor_.html#torch.Tensor.logical_xor_">logical_xor_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.logit.html#torch.logit">logit() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.logit">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.logit.html#torch.Tensor.logit">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.logit_.html#torch.Tensor.logit_">logit_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli">LogitRelaxedBernoulli (class in torch.distributions.relaxed_bernoulli)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.logits">logits (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.logits">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.logits">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.logits">(torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.logits">(torch.distributions.geometric.Geometric property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.logits">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.logits">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.logits">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.logits">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical property)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.log_normal.LogNormal">LogNormal (class in torch.distributions.log_normal)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.LogsDest">LogsDest (class in torch.distributed.elastic.multiprocessing.api)</a>
</li>
      <li><a href="generated/torch.nn.LogSigmoid.html#torch.nn.LogSigmoid">LogSigmoid (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.logsigmoid.html#torch.nn.functional.logsigmoid">logsigmoid() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax">LogSoftmax (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.logspace.html#torch.logspace">logspace() (in module torch)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.LogsSpecs">LogsSpecs (class in torch.distributed.elastic.multiprocessing.api)</a>
</li>
      <li><a href="generated/torch.logsumexp.html#torch.logsumexp">logsumexp() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.logsumexp">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.logsumexp.html#torch.Tensor.logsumexp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.long.html#torch.Tensor.long">long() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.long">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.long">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.LongStorage">LongStorage (class in torch)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultSavePlanner.lookup_object">lookup_object() (torch.distributed.checkpoint.DefaultSavePlanner method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultLoadPlanner.lookup_tensor">lookup_tensor() (torch.distributed.checkpoint.DefaultLoadPlanner method)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.loss_parallel">loss_parallel() (in module torch.distributed.tensor.parallel)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.LowerCholeskyTransform">LowerCholeskyTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal">LowRankMultivariateNormal (class in torch.distributions.lowrank_multivariate_normal)</a>
</li>
      <li><a href="generated/torch.nn.functional.lp_pool1d.html#torch.nn.functional.lp_pool1d">lp_pool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.lp_pool2d.html#torch.nn.functional.lp_pool2d">lp_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.lp_pool3d.html#torch.nn.functional.lp_pool3d">lp_pool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.LPPool1d.html#torch.nn.LPPool1d">LPPool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LPPool2d.html#torch.nn.LPPool2d">LPPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LPPool3d.html#torch.nn.LPPool3d">LPPool3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantizable.LSTM.html#torch.ao.nn.quantizable.LSTM">LSTM (class in torch.ao.nn.quantizable)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantized.dynamic.LSTM.html#torch.ao.nn.quantized.dynamic.LSTM">(class in torch.ao.nn.quantized.dynamic)</a>
</li>
        <li><a href="generated/torch.nn.LSTM.html#torch.nn.LSTM">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.dynamic.LSTMCell.html#torch.ao.nn.quantized.dynamic.LSTMCell">LSTMCell (class in torch.ao.nn.quantized.dynamic)</a>

      <ul>
        <li><a href="generated/torch.nn.LSTMCell.html#torch.nn.LSTMCell">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.lstsq.html#torch.linalg.lstsq">lstsq() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.lt.html#torch.lt">lt() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.lt.html#torch.Tensor.lt">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.lt_.html#torch.Tensor.lt_">lt_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.lu.html#torch.lu">lu() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.lu.html#torch.linalg.lu">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.lu.html#torch.Tensor.lu">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.lu_factor.html#torch.linalg.lu_factor">lu_factor() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.lu_factor_ex.html#torch.linalg.lu_factor_ex">lu_factor_ex() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.lu_solve.html#torch.lu_solve">lu_solve() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.lu_solve.html#torch.linalg.lu_solve">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.lu_solve.html#torch.Tensor.lu_solve">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.lu_unpack.html#torch.lu_unpack">lu_unpack() (in module torch)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="M">M</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.JoinHook.main_hook">main_hook() (torch.distributed.algorithms.JoinHook method)</a>
</li>
      <li><a href="generated/torch.autograd.forward_ad.make_dual.html#torch.autograd.forward_ad.make_dual">make_dual() (in module torch.autograd.forward_ad)</a>
</li>
      <li><a href="generated/torch.cuda.make_graphed_callables.html#torch.cuda.make_graphed_callables">make_graphed_callables() (in module torch.cuda)</a>
</li>
      <li><a href="testing.html#torch.testing.make_tensor">make_tensor() (in module torch.testing)</a>
</li>
      <li><a href="generated/torch.manual_seed.html#torch.manual_seed">manual_seed() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.manual_seed.html#torch.cuda.manual_seed">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.mps.manual_seed.html#torch.mps.manual_seed">(in module torch.mps)</a>
</li>
        <li><a href="random.html#torch.random.manual_seed">(in module torch.random)</a>
</li>
        <li><a href="generated/torch.xpu.manual_seed.html#torch.xpu.manual_seed">(in module torch.xpu)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.manual_seed">(torch.Generator method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.manual_seed_all.html#torch.cuda.manual_seed_all">manual_seed_all() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.xpu.manual_seed_all.html#torch.xpu.manual_seed_all">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.map_.html#torch.Tensor.map_">map_() (torch.Tensor method)</a>
</li>
      <li><a href="fx.html#torch.fx.Interpreter.map_nodes_to_values">map_nodes_to_values() (torch.fx.Interpreter method)</a>
</li>
      <li><a href="generated/torch.nn.functional.margin_ranking_loss.html#torch.nn.functional.margin_ranking_loss">margin_ranking_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.MarginRankingLoss.html#torch.nn.MarginRankingLoss">MarginRankingLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.cuda.nvtx.mark.html#torch.cuda.nvtx.mark">mark() (in module torch.cuda.nvtx)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler.itt.mark">(in module torch.profiler.itt)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.function.BackwardCFunction.html#torch.autograd.function.BackwardCFunction.mark_dirty">mark_dirty() (torch.autograd.function.BackwardCFunction method)</a>

      <ul>
        <li><a href="generated/torch.autograd.function.FunctionCtx.mark_dirty.html#torch.autograd.function.FunctionCtx.mark_dirty">(torch.autograd.function.FunctionCtx method)</a>
</li>
        <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction.mark_dirty">(torch.autograd.function.InplaceFunction method)</a>
</li>
        <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.mark_dirty">(torch.autograd.function.NestedIOFunction method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.function.BackwardCFunction.html#torch.autograd.function.BackwardCFunction.mark_non_differentiable">mark_non_differentiable() (torch.autograd.function.BackwardCFunction method)</a>

      <ul>
        <li><a href="generated/torch.autograd.function.FunctionCtx.mark_non_differentiable.html#torch.autograd.function.FunctionCtx.mark_non_differentiable">(torch.autograd.function.FunctionCtx method)</a>
</li>
        <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction.mark_non_differentiable">(torch.autograd.function.InplaceFunction method)</a>
</li>
        <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.mark_non_differentiable">(torch.autograd.function.NestedIOFunction method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.masked_fill.html#torch.Tensor.masked_fill">masked_fill() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.masked_fill_.html#torch.Tensor.masked_fill_">masked_fill_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.masked_scatter.html#torch.Tensor.masked_scatter">masked_scatter() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.masked_scatter_.html#torch.Tensor.masked_scatter_">masked_scatter_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.masked_select.html#torch.masked_select">masked_select() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.masked_select.html#torch.Tensor.masked_select">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="backends.html#torch.backends.cuda.math_sdp_enabled">math_sdp_enabled() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.matmul.html#torch.matmul">matmul() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.matmul.html#torch.linalg.matmul">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.matmul.html#torch.Tensor.matmul">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.matrix_exp.html#torch.matrix_exp">matrix_exp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.matrix_exp.html#torch.linalg.matrix_exp">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.matrix_exp.html#torch.Tensor.matrix_exp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.matrix_norm.html#torch.linalg.matrix_norm">matrix_norm() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.matrix_power.html#torch.matrix_power">matrix_power() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.matrix_power.html#torch.linalg.matrix_power">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.matrix_power.html#torch.Tensor.matrix_power">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.matrix_rank.html#torch.linalg.matrix_rank">matrix_rank() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.max.html#torch.max">max() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.max.html#torch.Tensor.max">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.max_memory_allocated.html#torch.cuda.max_memory_allocated">max_memory_allocated() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.max_memory_cached.html#torch.cuda.max_memory_cached">max_memory_cached() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.max_memory_reserved.html#torch.cuda.max_memory_reserved">max_memory_reserved() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.max_pool1d.html#torch.ao.nn.quantized.functional.max_pool1d">max_pool1d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_pool1d.html#torch.nn.functional.max_pool1d">max_pool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.max_pool2d.html#torch.ao.nn.quantized.functional.max_pool2d">max_pool2d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_pool2d.html#torch.nn.functional.max_pool2d">max_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_pool3d.html#torch.nn.functional.max_pool3d">max_pool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.cufft_plan_cache.max_size">max_size (in module torch.backends.cuda.cufft_plan_cache)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_unpool1d.html#torch.nn.functional.max_unpool1d">max_unpool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_unpool2d.html#torch.nn.functional.max_unpool2d">max_unpool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_unpool3d.html#torch.nn.functional.max_unpool3d">max_unpool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.maximum.html#torch.maximum">maximum() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.maximum.html#torch.Tensor.maximum">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.MaxPool1d.html#torch.nn.MaxPool1d">MaxPool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d">MaxPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MaxPool3d.html#torch.nn.MaxPool3d">MaxPool3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MaxUnpool1d.html#torch.nn.MaxUnpool1d">MaxUnpool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MaxUnpool2d.html#torch.nn.MaxUnpool2d">MaxUnpool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MaxUnpool3d.html#torch.nn.MaxUnpool3d">MaxUnpool3d (class in torch.nn)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.mean">mean (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.mean">(torch.distributions.beta.Beta property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.mean">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.mean">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.mean">(torch.distributions.cauchy.Cauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.mean">(torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.mean">(torch.distributions.dirichlet.Dirichlet property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.mean">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.mean">(torch.distributions.exponential.Exponential property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.mean">(torch.distributions.fishersnedecor.FisherSnedecor property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.mean">(torch.distributions.gamma.Gamma property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.mean">(torch.distributions.geometric.Geometric property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.mean">(torch.distributions.gumbel.Gumbel property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.mean">(torch.distributions.half_cauchy.HalfCauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.mean">(torch.distributions.half_normal.HalfNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.mean">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.inverse_gamma.InverseGamma.mean">(torch.distributions.inverse_gamma.InverseGamma property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.mean">(torch.distributions.kumaraswamy.Kumaraswamy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.mean">(torch.distributions.laplace.Laplace property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.mean">(torch.distributions.log_normal.LogNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mean">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.mean">(torch.distributions.mixture_same_family.MixtureSameFamily property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.mean">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.mean">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.mean">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.mean">(torch.distributions.normal.Normal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.mean">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.mean">(torch.distributions.pareto.Pareto property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.mean">(torch.distributions.poisson.Poisson property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.mean">(torch.distributions.studentT.StudentT property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.mean">(torch.distributions.uniform.Uniform property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.mean">(torch.distributions.von_mises.VonMises property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.mean">(torch.distributions.weibull.Weibull property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.mean">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.mean.html#torch.mean">mean() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.mean.html#torch.Tensor.mean">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Measurement">Measurement (class in torch.utils.benchmark)</a>
</li>
      <li><a href="generated/torch.median.html#torch.median">median() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.median.html#torch.Tensor.median">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="backends.html#torch.backends.cuda.mem_efficient_sdp_enabled">mem_efficient_sdp_enabled() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.mem_get_info.html#torch.cuda.mem_get_info">mem_get_info() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_allocated.html#torch.cuda.memory_allocated">memory_allocated() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_cached.html#torch.cuda.memory_cached">memory_cached() (in module torch.cuda)</a>
</li>
      <li><a href="tensor_attributes.html#torch.memory_format">memory_format (class in torch)</a>
</li>
      <li><a href="generated/torch.cuda.memory_reserved.html#torch.cuda.memory_reserved">memory_reserved() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_snapshot.html#torch.cuda.memory_snapshot">memory_snapshot() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_stats.html#torch.cuda.memory_stats">memory_stats() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_summary.html#torch.cuda.memory_summary">memory_summary() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_usage.html#torch.cuda.memory_usage">memory_usage() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.MemRecordsAcc.html#torch.autograd.profiler_util.MemRecordsAcc">MemRecordsAcc (class in torch.autograd.profiler_util)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Measurement.merge">merge() (torch.utils.benchmark.Measurement static method)</a>
</li>
      <li><a href="generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention.merge_masks">merge_masks() (torch.nn.MultiheadAttention method)</a>
</li>
      <li><a href="generated/torch.meshgrid.html#torch.meshgrid">meshgrid() (in module torch)</a>
</li>
      <li><a href="generated/torch.autograd.graph.Node.metadata.html#torch.autograd.graph.Node.metadata">metadata() (torch.autograd.graph.Node method)</a>
</li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.api.MetricHandler">MetricHandler (class in torch.distributed.elastic.metrics.api)</a>
</li>
      <li><a href="tensors.html#torch.Tensor.mH">mH (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.min.html#torch.min">min() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.min.html#torch.Tensor.min">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.minimum.html#torch.minimum">minimum() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.minimum.html#torch.Tensor.minimum">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.observer.MinMaxObserver.html#torch.ao.quantization.observer.MinMaxObserver">MinMaxObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.nn.Mish.html#torch.nn.Mish">Mish (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.mish.html#torch.nn.functional.mish">mish() (in module torch.nn.functional)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.MixedPrecision">MixedPrecision (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.mixture_distribution">mixture_distribution (torch.distributions.mixture_same_family.MixtureSameFamily property)</a>
</li>
      <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily">MixtureSameFamily (class in torch.distributions.mixture_same_family)</a>
</li>
      <li><a href="generated/torch.mm.html#torch.mm">mm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.sparse.mm.html#torch.sparse.mm">(in module torch.sparse)</a>
</li>
        <li><a href="generated/torch.Tensor.mm.html#torch.Tensor.mm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.PackageExporter.mock">mock() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.mocked_modules">mocked_modules() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.mode">mode (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.mode">(torch.distributions.beta.Beta property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.mode">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.mode">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.mode">(torch.distributions.cauchy.Cauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.mode">(torch.distributions.dirichlet.Dirichlet property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.mode">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.mode">(torch.distributions.exponential.Exponential property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.mode">(torch.distributions.fishersnedecor.FisherSnedecor property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.mode">(torch.distributions.gamma.Gamma property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.mode">(torch.distributions.geometric.Geometric property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.mode">(torch.distributions.gumbel.Gumbel property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.mode">(torch.distributions.half_cauchy.HalfCauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.mode">(torch.distributions.half_normal.HalfNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.mode">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.inverse_gamma.InverseGamma.mode">(torch.distributions.inverse_gamma.InverseGamma property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.mode">(torch.distributions.kumaraswamy.Kumaraswamy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.mode">(torch.distributions.laplace.Laplace property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.mode">(torch.distributions.log_normal.LogNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mode">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.mode">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.mode">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.mode">(torch.distributions.normal.Normal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.mode">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.mode">(torch.distributions.pareto.Pareto property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.mode">(torch.distributions.poisson.Poisson property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.mode">(torch.distributions.studentT.StudentT property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.mode">(torch.distributions.uniform.Uniform property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.mode">(torch.distributions.von_mises.VonMises property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.mode">(torch.distributions.weibull.Weibull property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.mode">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.mode.html#torch.mode">mode() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.mode.html#torch.Tensor.mode">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.pt2e.export_utils.model_is_exported.html#torch.ao.quantization.pt2e.export_utils.model_is_exported">model_is_exported (class in torch.ao.quantization.pt2e.export_utils)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.ONNXProgram.model_proto">model_proto (torch.onnx.ONNXProgram property)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.ONNXProgram.model_signature">model_signature (torch.onnx.ONNXProgram property)</a>
</li>
      <li>
    module

      <ul>
        <li><a href="torch.html#module-torch">torch</a>
</li>
        <li><a href="config_mod.html#module-torch.__config__">torch.__config__</a>
</li>
        <li><a href="future_mod.html#module-torch.__future__">torch.__future__</a>
</li>
        <li><a href="logging.html#module-torch._logging">torch._logging</a>
</li>
        <li><a href="amp.html#module-torch.amp">torch.amp</a>
</li>
        <li><a href="amp.html#module-torch.amp.autocast_mode">torch.amp.autocast_mode</a>
</li>
        <li><a href="amp.html#module-torch.amp.grad_scaler">torch.amp.grad_scaler</a>
</li>
        <li><a href="quantization.html#module-torch.ao">torch.ao</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn">torch.ao.nn</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic">torch.ao.nn.intrinsic</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.modules">torch.ao.nn.intrinsic.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.modules.fused">torch.ao.nn.intrinsic.modules.fused</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.qat">torch.ao.nn.intrinsic.qat</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.qat.modules">torch.ao.nn.intrinsic.qat.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.qat.modules.conv_fused">torch.ao.nn.intrinsic.qat.modules.conv_fused</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.qat.modules.linear_fused">torch.ao.nn.intrinsic.qat.modules.linear_fused</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.qat.modules.linear_relu">torch.ao.nn.intrinsic.qat.modules.linear_relu</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized">torch.ao.nn.intrinsic.quantized</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.dynamic">torch.ao.nn.intrinsic.quantized.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.dynamic.modules">torch.ao.nn.intrinsic.quantized.dynamic.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu">torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.modules">torch.ao.nn.intrinsic.quantized.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.quantized.modules.bn_relu">torch.ao.nn.intrinsic.quantized.modules.bn_relu</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.quantized.modules.conv_add">torch.ao.nn.intrinsic.quantized.modules.conv_add</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.quantized.modules.conv_relu">torch.ao.nn.intrinsic.quantized.modules.conv_relu</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.quantized.modules.linear_relu">torch.ao.nn.intrinsic.quantized.modules.linear_relu</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat">torch.ao.nn.qat</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.dynamic">torch.ao.nn.qat.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.dynamic.modules">torch.ao.nn.qat.dynamic.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.qat.dynamic.modules.linear">torch.ao.nn.qat.dynamic.modules.linear</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.modules">torch.ao.nn.qat.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.qat.modules.conv">torch.ao.nn.qat.modules.conv</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.qat.modules.embedding_ops">torch.ao.nn.qat.modules.embedding_ops</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.qat.modules.linear">torch.ao.nn.qat.modules.linear</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable">torch.ao.nn.quantizable</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable.modules">torch.ao.nn.quantizable.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable.modules.activation">torch.ao.nn.quantizable.modules.activation</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable.modules.rnn">torch.ao.nn.quantizable.modules.rnn</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized">torch.ao.nn.quantized</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.dynamic">torch.ao.nn.quantized.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.dynamic.modules">torch.ao.nn.quantized.dynamic.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.dynamic.modules.conv">torch.ao.nn.quantized.dynamic.modules.conv</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.dynamic.modules.linear">torch.ao.nn.quantized.dynamic.modules.linear</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.dynamic.modules.rnn">torch.ao.nn.quantized.dynamic.modules.rnn</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.functional">torch.ao.nn.quantized.functional</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.modules">torch.ao.nn.quantized.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.activation">torch.ao.nn.quantized.modules.activation</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.batchnorm">torch.ao.nn.quantized.modules.batchnorm</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.conv">torch.ao.nn.quantized.modules.conv</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.dropout">torch.ao.nn.quantized.modules.dropout</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.embedding_ops">torch.ao.nn.quantized.modules.embedding_ops</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.functional_modules">torch.ao.nn.quantized.modules.functional_modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.linear">torch.ao.nn.quantized.modules.linear</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.normalization">torch.ao.nn.quantized.modules.normalization</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.rnn">torch.ao.nn.quantized.modules.rnn</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.utils">torch.ao.nn.quantized.modules.utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference">torch.ao.nn.quantized.reference</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules">torch.ao.nn.quantized.reference.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules.conv">torch.ao.nn.quantized.reference.modules.conv</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules.linear">torch.ao.nn.quantized.reference.modules.linear</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules.rnn">torch.ao.nn.quantized.reference.modules.rnn</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules.sparse">torch.ao.nn.quantized.reference.modules.sparse</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules.utils">torch.ao.nn.quantized.reference.modules.utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.sparse">torch.ao.nn.sparse</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized">torch.ao.nn.sparse.quantized</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized.dynamic">torch.ao.nn.sparse.quantized.dynamic</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized.dynamic.linear">torch.ao.nn.sparse.quantized.dynamic.linear</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized.linear">torch.ao.nn.sparse.quantized.linear</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized.utils">torch.ao.nn.sparse.quantized.utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns">torch.ao.ns</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite.html#module-torch.ao.ns._numeric_suite">torch.ao.ns._numeric_suite</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite_fx.html#module-torch.ao.ns._numeric_suite_fx">torch.ao.ns._numeric_suite_fx</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns.fx">torch.ao.ns.fx</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns.fx.graph_matcher">torch.ao.ns.fx.graph_matcher</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns.fx.graph_passes">torch.ao.ns.fx.graph_passes</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns.fx.mappings">torch.ao.ns.fx.mappings</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns.fx.n_shadows_utils">torch.ao.ns.fx.n_shadows_utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns.fx.ns_types">torch.ao.ns.fx.ns_types</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns.fx.pattern_utils">torch.ao.ns.fx.pattern_utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns.fx.qconfig_multi_mapping">torch.ao.ns.fx.qconfig_multi_mapping</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns.fx.utils">torch.ao.ns.fx.utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns.fx.weight_utils">torch.ao.ns.fx.weight_utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning">torch.ao.pruning</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning.scheduler">torch.ao.pruning.scheduler</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning.scheduler.base_scheduler">torch.ao.pruning.scheduler.base_scheduler</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning.scheduler.cubic_scheduler">torch.ao.pruning.scheduler.cubic_scheduler</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning.scheduler.lambda_scheduler">torch.ao.pruning.scheduler.lambda_scheduler</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier">torch.ao.pruning.sparsifier</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier.base_sparsifier">torch.ao.pruning.sparsifier.base_sparsifier</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier.nearly_diagonal_sparsifier">torch.ao.pruning.sparsifier.nearly_diagonal_sparsifier</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier.utils">torch.ao.pruning.sparsifier.utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier.weight_norm_sparsifier">torch.ao.pruning.sparsifier.weight_norm_sparsifier</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization">torch.ao.quantization</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config">torch.ao.quantization.backend_config</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.backend_config">torch.ao.quantization.backend_config.backend_config</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.executorch">torch.ao.quantization.backend_config.executorch</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.fbgemm">torch.ao.quantization.backend_config.fbgemm</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.native">torch.ao.quantization.backend_config.native</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.observation_type">torch.ao.quantization.backend_config.observation_type</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.onednn">torch.ao.quantization.backend_config.onednn</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.qnnpack">torch.ao.quantization.backend_config.qnnpack</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.tensorrt">torch.ao.quantization.backend_config.tensorrt</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.utils">torch.ao.quantization.backend_config.utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.x86">torch.ao.quantization.backend_config.x86</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fake_quantize">torch.ao.quantization.fake_quantize</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fuse_modules">torch.ao.quantization.fuse_modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fuser_method_mappings">torch.ao.quantization.fuser_method_mappings</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx">torch.ao.quantization.fx</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.convert">torch.ao.quantization.fx.convert</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.custom_config">torch.ao.quantization.fx.custom_config</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.fuse">torch.ao.quantization.fx.fuse</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.fuse_handler">torch.ao.quantization.fx.fuse_handler</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.graph_module">torch.ao.quantization.fx.graph_module</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.lower_to_fbgemm">torch.ao.quantization.fx.lower_to_fbgemm</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.lower_to_qnnpack">torch.ao.quantization.fx.lower_to_qnnpack</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.lstm_utils">torch.ao.quantization.fx.lstm_utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.match_utils">torch.ao.quantization.fx.match_utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.pattern_utils">torch.ao.quantization.fx.pattern_utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.prepare">torch.ao.quantization.fx.prepare</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.qconfig_mapping_utils">torch.ao.quantization.fx.qconfig_mapping_utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.quantize_handler">torch.ao.quantization.fx.quantize_handler</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.tracer">torch.ao.quantization.fx.tracer</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.utils">torch.ao.quantization.fx.utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.observer">torch.ao.quantization.observer</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.quantization.pt2e">torch.ao.quantization.pt2e</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.duplicate_dq_pass">torch.ao.quantization.pt2e.duplicate_dq_pass</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.export_utils">torch.ao.quantization.pt2e.export_utils</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.quantization.pt2e.generate_numeric_debug_handle">torch.ao.quantization.pt2e.generate_numeric_debug_handle</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.graph_utils">torch.ao.quantization.pt2e.graph_utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.port_metadata_pass">torch.ao.quantization.pt2e.port_metadata_pass</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.prepare">torch.ao.quantization.pt2e.prepare</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.qat_utils">torch.ao.quantization.pt2e.qat_utils</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.quantization.pt2e.representation">torch.ao.quantization.pt2e.representation</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.representation.rewrite">torch.ao.quantization.pt2e.representation.rewrite</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.utils">torch.ao.quantization.pt2e.utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.qconfig">torch.ao.quantization.qconfig</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.qconfig_mapping">torch.ao.quantization.qconfig_mapping</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quant_type">torch.ao.quantization.quant_type</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantization_mappings">torch.ao.quantization.quantization_mappings</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantize">torch.ao.quantization.quantize</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantize_fx">torch.ao.quantization.quantize_fx</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantize_jit">torch.ao.quantization.quantize_jit</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantize_pt2e">torch.ao.quantization.quantize_pt2e</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.quantization.quantizer">torch.ao.quantization.quantizer</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.composable_quantizer">torch.ao.quantization.quantizer.composable_quantizer</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.embedding_quantizer">torch.ao.quantization.quantizer.embedding_quantizer</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.quantizer">torch.ao.quantization.quantizer.quantizer</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.utils">torch.ao.quantization.quantizer.utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.x86_inductor_quantizer">torch.ao.quantization.quantizer.x86_inductor_quantizer</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.xnnpack_quantizer">torch.ao.quantization.quantizer.xnnpack_quantizer</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.xnnpack_quantizer_utils">torch.ao.quantization.quantizer.xnnpack_quantizer_utils</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.stubs">torch.ao.quantization.stubs</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.utils">torch.ao.quantization.utils</a>
</li>
        <li><a href="autograd.html#module-torch.autograd">torch.autograd</a>
</li>
        <li><a href="autograd.html#module-torch.autograd.anomaly_mode">torch.autograd.anomaly_mode</a>
</li>
        <li><a href="autograd.html#module-torch.autograd.forward_ad">torch.autograd.forward_ad</a>
</li>
        <li><a href="autograd.html#module-torch.autograd.function">torch.autograd.function</a>
</li>
        <li><a href="autograd.html#module-torch.autograd.functional">torch.autograd.functional</a>
</li>
        <li><a href="autograd.html#module-torch.autograd.grad_mode">torch.autograd.grad_mode</a>
</li>
        <li><a href="autograd.html#module-torch.autograd.gradcheck">torch.autograd.gradcheck</a>
</li>
        <li><a href="autograd.html#module-torch.autograd.graph">torch.autograd.graph</a>
</li>
        <li><a href="autograd.html#module-torch.autograd.profiler">torch.autograd.profiler</a>
</li>
        <li><a href="autograd.html#module-torch.autograd.profiler_legacy">torch.autograd.profiler_legacy</a>
</li>
        <li><a href="autograd.html#module-torch.autograd.profiler_util">torch.autograd.profiler_util</a>
</li>
        <li><a href="autograd.html#module-torch.autograd.variable">torch.autograd.variable</a>
</li>
        <li><a href="backends.html#module-torch.backends">torch.backends</a>
</li>
        <li><a href="backends.html#module-torch.backends.cpu">torch.backends.cpu</a>
</li>
        <li><a href="backends.html#module-torch.backends.cuda">torch.backends.cuda</a>
</li>
        <li><a href="backends.html#module-torch.backends.cudnn">torch.backends.cudnn</a>
</li>
        <li><a href="backends.html#module-torch.backends.cudnn.rnn">torch.backends.cudnn.rnn</a>
</li>
        <li><a href="backends.html#module-torch.backends.mha">torch.backends.mha</a>
</li>
        <li><a href="backends.html#module-torch.backends.mkl">torch.backends.mkl</a>
</li>
        <li><a href="backends.html#module-torch.backends.mkldnn">torch.backends.mkldnn</a>
</li>
        <li><a href="backends.html#module-torch.backends.mps">torch.backends.mps</a>
</li>
        <li><a href="backends.html#module-torch.backends.nnpack">torch.backends.nnpack</a>
</li>
        <li><a href="backends.html#module-torch.backends.openmp">torch.backends.openmp</a>
</li>
        <li><a href="backends.html#module-torch.backends.opt_einsum">torch.backends.opt_einsum</a>
</li>
        <li><a href="backends.html#module-torch.backends.quantized">torch.backends.quantized</a>
</li>
        <li><a href="backends.html#module-torch.backends.xeon">torch.backends.xeon</a>
</li>
        <li><a href="backends.html#module-torch.backends.xeon.run_cpu">torch.backends.xeon.run_cpu</a>
</li>
        <li><a href="backends.html#module-torch.backends.xnnpack">torch.backends.xnnpack</a>
</li>
        <li><a href="torch.compiler_api.html#module-torch.compiler">torch.compiler</a>
</li>
        <li><a href="torch.html#module-torch.contrib">torch.contrib</a>
</li>
        <li><a href="cpu.html#module-torch.cpu">torch.cpu</a>
</li>
        <li><a href="amp.html#module-torch.cpu.amp">torch.cpu.amp</a>
</li>
        <li><a href="amp.html#module-torch.cpu.amp.autocast_mode">torch.cpu.amp.autocast_mode</a>
</li>
        <li><a href="amp.html#module-torch.cpu.amp.grad_scaler">torch.cpu.amp.grad_scaler</a>
</li>
        <li><a href="cuda.html#module-torch.cuda">torch.cuda</a>
</li>
        <li><a href="cuda._sanitizer.html#module-torch.cuda._sanitizer">torch.cuda._sanitizer</a>
</li>
        <li><a href="amp.html#module-torch.cuda.amp">torch.cuda.amp</a>
</li>
        <li><a href="amp.html#module-torch.cuda.amp.autocast_mode">torch.cuda.amp.autocast_mode</a>
</li>
        <li><a href="amp.html#module-torch.cuda.amp.common">torch.cuda.amp.common</a>
</li>
        <li><a href="amp.html#module-torch.cuda.amp.grad_scaler">torch.cuda.amp.grad_scaler</a>
</li>
        <li><a href="cuda.html#module-torch.cuda.comm">torch.cuda.comm</a>
</li>
        <li><a href="cuda.html#module-torch.cuda.error">torch.cuda.error</a>
</li>
        <li><a href="cuda.html#module-torch.cuda.graphs">torch.cuda.graphs</a>
</li>
        <li><a href="cuda.html#module-torch.cuda.jiterator">torch.cuda.jiterator</a>
</li>
        <li><a href="cuda.html#module-torch.cuda.memory">torch.cuda.memory</a>
</li>
        <li><a href="cuda.html#module-torch.cuda.nccl">torch.cuda.nccl</a>
</li>
        <li><a href="cuda.html#module-torch.cuda.nvtx">torch.cuda.nvtx</a>
</li>
        <li><a href="cuda.html#module-torch.cuda.profiler">torch.cuda.profiler</a>
</li>
        <li><a href="cuda.html#module-torch.cuda.random">torch.cuda.random</a>
</li>
        <li><a href="cuda.html#module-torch.cuda.sparse">torch.cuda.sparse</a>
</li>
        <li><a href="cuda.html#module-torch.cuda.streams">torch.cuda.streams</a>
</li>
        <li><a href="distributed.html#module-torch.distributed">torch.distributed</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms">torch.distributed.algorithms</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks">torch.distributed.algorithms.ddp_comm_hooks</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.ddp_zero_hook">torch.distributed.algorithms.ddp_comm_hooks.ddp_zero_hook</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks">torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.default_hooks">torch.distributed.algorithms.ddp_comm_hooks.default_hooks</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks">torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks">torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.post_localSGD_hook">torch.distributed.algorithms.ddp_comm_hooks.post_localSGD_hook</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook">torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.quantization_hooks">torch.distributed.algorithms.ddp_comm_hooks.quantization_hooks</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.join">torch.distributed.algorithms.join</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.model_averaging">torch.distributed.algorithms.model_averaging</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.model_averaging.averagers">torch.distributed.algorithms.model_averaging.averagers</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.model_averaging.hierarchical_model_averager">torch.distributed.algorithms.model_averaging.hierarchical_model_averager</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.model_averaging.utils">torch.distributed.algorithms.model_averaging.utils</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.argparse_util">torch.distributed.argparse_util</a>
</li>
        <li><a href="rpc.html#module-torch.distributed.autograd">torch.distributed.autograd</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.c10d_logger">torch.distributed.c10d_logger</a>
</li>
        <li><a href="distributed.checkpoint.html#module-torch.distributed.checkpoint">torch.distributed.checkpoint</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.api">torch.distributed.checkpoint.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.default_planner">torch.distributed.checkpoint.default_planner</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.filesystem">torch.distributed.checkpoint.filesystem</a>
</li>
        <li><a href="distributed.checkpoint.html#module-torch.distributed.checkpoint.format_utils">torch.distributed.checkpoint.format_utils</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.metadata">torch.distributed.checkpoint.metadata</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.optimizer">torch.distributed.checkpoint.optimizer</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.planner">torch.distributed.checkpoint.planner</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.planner_helpers">torch.distributed.checkpoint.planner_helpers</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.resharding">torch.distributed.checkpoint.resharding</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.state_dict">torch.distributed.checkpoint.state_dict</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.state_dict_loader">torch.distributed.checkpoint.state_dict_loader</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.state_dict_saver">torch.distributed.checkpoint.state_dict_saver</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.stateful">torch.distributed.checkpoint.stateful</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.storage">torch.distributed.checkpoint.storage</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.utils">torch.distributed.checkpoint.utils</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.collective_utils">torch.distributed.collective_utils</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.constants">torch.distributed.constants</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.device_mesh">torch.distributed.device_mesh</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.distributed_c10d">torch.distributed.distributed_c10d</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic">torch.distributed.elastic</a>
</li>
        <li><a href="elastic/agent.html#module-torch.distributed.elastic.agent">torch.distributed.elastic.agent</a>
</li>
        <li><a href="elastic/agent.html#module-torch.distributed.elastic.agent.server">torch.distributed.elastic.agent.server</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.agent.server.api">torch.distributed.elastic.agent.server.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.agent.server.local_elastic_agent">torch.distributed.elastic.agent.server.local_elastic_agent</a>
</li>
        <li><a href="elastic/events.html#module-torch.distributed.elastic.events">torch.distributed.elastic.events</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.events.api">torch.distributed.elastic.events.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.events.handlers">torch.distributed.elastic.events.handlers</a>
</li>
        <li><a href="elastic/metrics.html#module-torch.distributed.elastic.metrics">torch.distributed.elastic.metrics</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.metrics.api">torch.distributed.elastic.metrics.api</a>
</li>
        <li><a href="elastic/multiprocessing.html#module-torch.distributed.elastic.multiprocessing">torch.distributed.elastic.multiprocessing</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.multiprocessing.api">torch.distributed.elastic.multiprocessing.api</a>
</li>
        <li><a href="elastic/errors.html#module-torch.distributed.elastic.multiprocessing.errors">torch.distributed.elastic.multiprocessing.errors</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.multiprocessing.errors.error_handler">torch.distributed.elastic.multiprocessing.errors.error_handler</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.multiprocessing.errors.handlers">torch.distributed.elastic.multiprocessing.errors.handlers</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.multiprocessing.redirects">torch.distributed.elastic.multiprocessing.redirects</a>
</li>
        <li><a href="elastic/subprocess_handler.html#module-torch.distributed.elastic.multiprocessing.subprocess_handler">torch.distributed.elastic.multiprocessing.subprocess_handler</a>
</li>
        <li><a href="elastic/subprocess_handler.html#module-torch.distributed.elastic.multiprocessing.subprocess_handler.handlers">torch.distributed.elastic.multiprocessing.subprocess_handler.handlers</a>
</li>
        <li><a href="elastic/subprocess_handler.html#module-torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler">torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.multiprocessing.tail_log">torch.distributed.elastic.multiprocessing.tail_log</a>
</li>
        <li><a href="elastic/rendezvous.html#module-torch.distributed.elastic.rendezvous">torch.distributed.elastic.rendezvous</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.api">torch.distributed.elastic.rendezvous.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.c10d_rendezvous_backend">torch.distributed.elastic.rendezvous.c10d_rendezvous_backend</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.dynamic_rendezvous">torch.distributed.elastic.rendezvous.dynamic_rendezvous</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.etcd_rendezvous">torch.distributed.elastic.rendezvous.etcd_rendezvous</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.etcd_rendezvous_backend">torch.distributed.elastic.rendezvous.etcd_rendezvous_backend</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.etcd_server">torch.distributed.elastic.rendezvous.etcd_server</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.etcd_store">torch.distributed.elastic.rendezvous.etcd_store</a>
</li>
        <li><a href="elastic/rendezvous.html#module-torch.distributed.elastic.rendezvous.registry">torch.distributed.elastic.rendezvous.registry</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.static_tcp_rendezvous">torch.distributed.elastic.rendezvous.static_tcp_rendezvous</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.utils">torch.distributed.elastic.rendezvous.utils</a>
</li>
        <li><a href="elastic/timer.html#module-torch.distributed.elastic.timer">torch.distributed.elastic.timer</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.timer.api">torch.distributed.elastic.timer.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.timer.file_based_local_timer">torch.distributed.elastic.timer.file_based_local_timer</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.timer.local_timer">torch.distributed.elastic.timer.local_timer</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils">torch.distributed.elastic.utils</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.api">torch.distributed.elastic.utils.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.data">torch.distributed.elastic.utils.data</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.data.cycling_iterator">torch.distributed.elastic.utils.data.cycling_iterator</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.data.elastic_distributed_sampler">torch.distributed.elastic.utils.data.elastic_distributed_sampler</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.distributed">torch.distributed.elastic.utils.distributed</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.log_level">torch.distributed.elastic.utils.log_level</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.logging">torch.distributed.elastic.utils.logging</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.store">torch.distributed.elastic.utils.store</a>
</li>
        <li><a href="fsdp.html#module-torch.distributed.fsdp">torch.distributed.fsdp</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.fsdp.api">torch.distributed.fsdp.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.fsdp.fully_sharded_data_parallel">torch.distributed.fsdp.fully_sharded_data_parallel</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.fsdp.sharded_grad_scaler">torch.distributed.fsdp.sharded_grad_scaler</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.fsdp.wrap">torch.distributed.fsdp.wrap</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.launch">torch.distributed.launch</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.launcher">torch.distributed.launcher</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.launcher.api">torch.distributed.launcher.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.logging_handlers">torch.distributed.logging_handlers</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn">torch.distributed.nn</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn.api">torch.distributed.nn.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn.api.remote_module">torch.distributed.nn.api.remote_module</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn.functional">torch.distributed.nn.functional</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn.jit">torch.distributed.nn.jit</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn.jit.instantiator">torch.distributed.nn.jit.instantiator</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn.jit.templates">torch.distributed.nn.jit.templates</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn.jit.templates.remote_module_template">torch.distributed.nn.jit.templates.remote_module_template</a>
</li>
        <li><a href="distributed.optim.html#module-torch.distributed.optim">torch.distributed.optim</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.apply_optimizer_in_backward">torch.distributed.optim.apply_optimizer_in_backward</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_adadelta">torch.distributed.optim.functional_adadelta</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_adagrad">torch.distributed.optim.functional_adagrad</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_adam">torch.distributed.optim.functional_adam</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_adamax">torch.distributed.optim.functional_adamax</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_adamw">torch.distributed.optim.functional_adamw</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_rmsprop">torch.distributed.optim.functional_rmsprop</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_rprop">torch.distributed.optim.functional_rprop</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_sgd">torch.distributed.optim.functional_sgd</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.named_optimizer">torch.distributed.optim.named_optimizer</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.optimizer">torch.distributed.optim.optimizer</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.post_localSGD_optimizer">torch.distributed.optim.post_localSGD_optimizer</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.utils">torch.distributed.optim.utils</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.optim.zero_redundancy_optimizer">torch.distributed.optim.zero_redundancy_optimizer</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline">torch.distributed.pipeline</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync">torch.distributed.pipeline.sync</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.batchnorm">torch.distributed.pipeline.sync.batchnorm</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.checkpoint">torch.distributed.pipeline.sync.checkpoint</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.copy">torch.distributed.pipeline.sync.copy</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.dependency">torch.distributed.pipeline.sync.dependency</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.microbatch">torch.distributed.pipeline.sync.microbatch</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.phony">torch.distributed.pipeline.sync.phony</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.pipe">torch.distributed.pipeline.sync.pipe</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.pipeline">torch.distributed.pipeline.sync.pipeline</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip">torch.distributed.pipeline.sync.skip</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip.layout">torch.distributed.pipeline.sync.skip.layout</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip.namespace">torch.distributed.pipeline.sync.skip.namespace</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip.portal">torch.distributed.pipeline.sync.skip.portal</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip.skippable">torch.distributed.pipeline.sync.skip.skippable</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip.tracker">torch.distributed.pipeline.sync.skip.tracker</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.stream">torch.distributed.pipeline.sync.stream</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.utils">torch.distributed.pipeline.sync.utils</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.worker">torch.distributed.pipeline.sync.worker</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.remote_device">torch.distributed.remote_device</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.rendezvous">torch.distributed.rendezvous</a>
</li>
        <li><a href="rpc.html#module-torch.distributed.rpc">torch.distributed.rpc</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.rpc.api">torch.distributed.rpc.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.rpc.backend_registry">torch.distributed.rpc.backend_registry</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.rpc.constants">torch.distributed.rpc.constants</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.rpc.functions">torch.distributed.rpc.functions</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.rpc.internal">torch.distributed.rpc.internal</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.rpc.options">torch.distributed.rpc.options</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.rpc.rref_proxy">torch.distributed.rpc.rref_proxy</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.rpc.server_process_global_profiler">torch.distributed.rpc.server_process_global_profiler</a>
</li>
        <li><a href="elastic/run.html#module-torch.distributed.run">torch.distributed.run</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.tensor">torch.distributed.tensor</a>
</li>
        <li><a href="distributed.tensor.parallel.html#module-torch.distributed.tensor.parallel">torch.distributed.tensor.parallel</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.api">torch.distributed.tensor.parallel.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.ddp">torch.distributed.tensor.parallel.ddp</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.fsdp">torch.distributed.tensor.parallel.fsdp</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.input_reshard">torch.distributed.tensor.parallel.input_reshard</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.loss">torch.distributed.tensor.parallel.loss</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.style">torch.distributed.tensor.parallel.style</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.utils">torch.distributed.utils</a>
</li>
        <li><a href="distributions.html#module-torch.distributions">torch.distributions</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.bernoulli">torch.distributions.bernoulli</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.beta">torch.distributions.beta</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.binomial">torch.distributions.binomial</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.categorical">torch.distributions.categorical</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.cauchy">torch.distributions.cauchy</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.chi2">torch.distributions.chi2</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.constraint_registry">torch.distributions.constraint_registry</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.constraints">torch.distributions.constraints</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.continuous_bernoulli">torch.distributions.continuous_bernoulli</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.dirichlet">torch.distributions.dirichlet</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.distribution">torch.distributions.distribution</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.exp_family">torch.distributions.exp_family</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.exponential">torch.distributions.exponential</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.fishersnedecor">torch.distributions.fishersnedecor</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.gamma">torch.distributions.gamma</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.geometric">torch.distributions.geometric</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.gumbel">torch.distributions.gumbel</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.half_cauchy">torch.distributions.half_cauchy</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.half_normal">torch.distributions.half_normal</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.independent">torch.distributions.independent</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.inverse_gamma">torch.distributions.inverse_gamma</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.kl">torch.distributions.kl</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.kumaraswamy">torch.distributions.kumaraswamy</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.laplace">torch.distributions.laplace</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.lkj_cholesky">torch.distributions.lkj_cholesky</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.log_normal">torch.distributions.log_normal</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.logistic_normal">torch.distributions.logistic_normal</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.lowrank_multivariate_normal">torch.distributions.lowrank_multivariate_normal</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.mixture_same_family">torch.distributions.mixture_same_family</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.multinomial">torch.distributions.multinomial</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.multivariate_normal">torch.distributions.multivariate_normal</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.negative_binomial">torch.distributions.negative_binomial</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.normal">torch.distributions.normal</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.one_hot_categorical">torch.distributions.one_hot_categorical</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.pareto">torch.distributions.pareto</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.poisson">torch.distributions.poisson</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.relaxed_bernoulli">torch.distributions.relaxed_bernoulli</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.relaxed_categorical">torch.distributions.relaxed_categorical</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.studentT">torch.distributions.studentT</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.transformed_distribution">torch.distributions.transformed_distribution</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.transforms">torch.distributions.transforms</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.uniform">torch.distributions.uniform</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.utils">torch.distributions.utils</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.von_mises">torch.distributions.von_mises</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.weibull">torch.distributions.weibull</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.wishart">torch.distributions.wishart</a>
</li>
        <li><a href="export.html#module-torch.export">torch.export</a>
</li>
        <li><a href="export.html#module-torch.export.custom_obj">torch.export.custom_obj</a>
</li>
        <li><a href="export.html#module-torch.export.dynamic_shapes">torch.export.dynamic_shapes</a>
</li>
        <li><a href="export.html#module-torch.export.exported_program">torch.export.exported_program</a>
</li>
        <li><a href="export.html#module-torch.export.graph_signature">torch.export.graph_signature</a>
</li>
        <li><a href="export.html#module-torch.export.unflatten">torch.export.unflatten</a>
</li>
        <li><a href="fft.html#module-torch.fft">torch.fft</a>
</li>
        <li><a href="func.api.html#module-torch.func">torch.func</a>
</li>
        <li><a href="torch.html#module-torch.functional">torch.functional</a>
</li>
        <li><a href="futures.html#module-torch.futures">torch.futures</a>
</li>
        <li><a href="fx.html#module-torch.fx">torch.fx</a>
</li>
        <li><a href="fx.html#module-torch.fx.annotate">torch.fx.annotate</a>
</li>
        <li><a href="fx.html#module-torch.fx.config">torch.fx.config</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental">torch.fx.experimental</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.accelerator_partitioner">torch.fx.experimental.accelerator_partitioner</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.const_fold">torch.fx.experimental.const_fold</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.debug">torch.fx.experimental.debug</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.graph_gradual_typechecker">torch.fx.experimental.graph_gradual_typechecker</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.merge_matmul">torch.fx.experimental.merge_matmul</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.meta_tracer">torch.fx.experimental.meta_tracer</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types">torch.fx.experimental.migrate_gradual_types</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.constraint">torch.fx.experimental.migrate_gradual_types.constraint</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.constraint_generator">torch.fx.experimental.migrate_gradual_types.constraint_generator</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.constraint_transformation">torch.fx.experimental.migrate_gradual_types.constraint_transformation</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.operation">torch.fx.experimental.migrate_gradual_types.operation</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.transform_to_z3">torch.fx.experimental.migrate_gradual_types.transform_to_z3</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.util">torch.fx.experimental.migrate_gradual_types.util</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.z3_types">torch.fx.experimental.migrate_gradual_types.z3_types</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.normalize">torch.fx.experimental.normalize</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.optimization">torch.fx.experimental.optimization</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.partitioner_utils">torch.fx.experimental.partitioner_utils</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.proxy_tensor">torch.fx.experimental.proxy_tensor</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.recording">torch.fx.experimental.recording</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.refinement_types">torch.fx.experimental.refinement_types</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.rewriter">torch.fx.experimental.rewriter</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.schema_type_annotation">torch.fx.experimental.schema_type_annotation</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.sym_node">torch.fx.experimental.sym_node</a>
</li>
        <li><a href="fx.experimental.html#module-torch.fx.experimental.symbolic_shapes">torch.fx.experimental.symbolic_shapes</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification">torch.fx.experimental.unification</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.core">torch.fx.experimental.unification.core</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.dispatch">torch.fx.experimental.unification.dispatch</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.match">torch.fx.experimental.unification.match</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.more">torch.fx.experimental.unification.more</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch">torch.fx.experimental.unification.multipledispatch</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch.conflict">torch.fx.experimental.unification.multipledispatch.conflict</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch.core">torch.fx.experimental.unification.multipledispatch.core</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch.dispatcher">torch.fx.experimental.unification.multipledispatch.dispatcher</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch.utils">torch.fx.experimental.unification.multipledispatch.utils</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch.variadic">torch.fx.experimental.unification.multipledispatch.variadic</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.unification_tools">torch.fx.experimental.unification.unification_tools</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.utils">torch.fx.experimental.unification.utils</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.variable">torch.fx.experimental.unification.variable</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unify_refinements">torch.fx.experimental.unify_refinements</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.validator">torch.fx.experimental.validator</a>
</li>
        <li><a href="fx.html#module-torch.fx.graph">torch.fx.graph</a>
</li>
        <li><a href="fx.html#module-torch.fx.graph_module">torch.fx.graph_module</a>
</li>
        <li><a href="fx.html#module-torch.fx.immutable_collections">torch.fx.immutable_collections</a>
</li>
        <li><a href="fx.html#module-torch.fx.interpreter">torch.fx.interpreter</a>
</li>
        <li><a href="fx.html#module-torch.fx.node">torch.fx.node</a>
</li>
        <li><a href="fx.html#module-torch.fx.operator_schemas">torch.fx.operator_schemas</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes">torch.fx.passes</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.annotate_getitem_nodes">torch.fx.passes.annotate_getitem_nodes</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.backends">torch.fx.passes.backends</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.backends.cudagraphs">torch.fx.passes.backends.cudagraphs</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.dialect">torch.fx.passes.dialect</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.dialect.common">torch.fx.passes.dialect.common</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.dialect.common.cse_pass">torch.fx.passes.dialect.common.cse_pass</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.fake_tensor_prop">torch.fx.passes.fake_tensor_prop</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.graph_drawer">torch.fx.passes.graph_drawer</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.graph_manipulation">torch.fx.passes.graph_manipulation</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.infra">torch.fx.passes.infra</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.infra.partitioner">torch.fx.passes.infra.partitioner</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.infra.pass_base">torch.fx.passes.infra.pass_base</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.infra.pass_manager">torch.fx.passes.infra.pass_manager</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.net_min_base">torch.fx.passes.net_min_base</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.operator_support">torch.fx.passes.operator_support</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.param_fetch">torch.fx.passes.param_fetch</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.pass_manager">torch.fx.passes.pass_manager</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.reinplace">torch.fx.passes.reinplace</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.shape_prop">torch.fx.passes.shape_prop</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.split_module">torch.fx.passes.split_module</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.split_utils">torch.fx.passes.split_utils</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.splitter_base">torch.fx.passes.splitter_base</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.tests">torch.fx.passes.tests</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.tests.test_pass_manager">torch.fx.passes.tests.test_pass_manager</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.tools_common">torch.fx.passes.tools_common</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.utils">torch.fx.passes.utils</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.utils.common">torch.fx.passes.utils.common</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.utils.fuser_utils">torch.fx.passes.utils.fuser_utils</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.utils.matcher_utils">torch.fx.passes.utils.matcher_utils</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.utils.matcher_with_name_node_map_utils">torch.fx.passes.utils.matcher_with_name_node_map_utils</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.utils.source_matcher_utils">torch.fx.passes.utils.source_matcher_utils</a>
</li>
        <li><a href="fx.html#module-torch.fx.proxy">torch.fx.proxy</a>
</li>
        <li><a href="fx.html#module-torch.fx.subgraph_rewriter">torch.fx.subgraph_rewriter</a>
</li>
        <li><a href="fx.html#module-torch.fx.tensor_type">torch.fx.tensor_type</a>
</li>
        <li><a href="fx.html#module-torch.fx.traceback">torch.fx.traceback</a>
</li>
        <li><a href="hub.html#module-torch.hub">torch.hub</a>
</li>
        <li><a href="jit.html#module-torch.jit">torch.jit</a>
</li>
        <li><a href="jit.html#module-torch.jit.annotations">torch.jit.annotations</a>
</li>
        <li><a href="jit.html#module-torch.jit.frontend">torch.jit.frontend</a>
</li>
        <li><a href="jit.html#module-torch.jit.generate_bytecode">torch.jit.generate_bytecode</a>
</li>
        <li><a href="jit.html#module-torch.jit.mobile">torch.jit.mobile</a>
</li>
        <li><a href="jit.html#module-torch.jit.quantized">torch.jit.quantized</a>
</li>
        <li><a href="jit_builtin_functions.html#module-torch.jit.supported_ops">torch.jit.supported_ops</a>
</li>
        <li><a href="jit_unsupported.html#module-torch.jit.unsupported_tensor_ops">torch.jit.unsupported_tensor_ops</a>
</li>
        <li><a href="library.html#module-torch.library">torch.library</a>
</li>
        <li><a href="linalg.html#module-torch.linalg">torch.linalg</a>
</li>
        <li><a href="masked.html#module-torch.masked">torch.masked</a>
</li>
        <li><a href="masked.html#module-torch.masked.maskedtensor">torch.masked.maskedtensor</a>
</li>
        <li><a href="masked.html#module-torch.masked.maskedtensor.binary">torch.masked.maskedtensor.binary</a>
</li>
        <li><a href="masked.html#module-torch.masked.maskedtensor.core">torch.masked.maskedtensor.core</a>
</li>
        <li><a href="masked.html#module-torch.masked.maskedtensor.creation">torch.masked.maskedtensor.creation</a>
</li>
        <li><a href="masked.html#module-torch.masked.maskedtensor.passthrough">torch.masked.maskedtensor.passthrough</a>
</li>
        <li><a href="masked.html#module-torch.masked.maskedtensor.reductions">torch.masked.maskedtensor.reductions</a>
</li>
        <li><a href="masked.html#module-torch.masked.maskedtensor.unary">torch.masked.maskedtensor.unary</a>
</li>
        <li><a href="monitor.html#module-torch.monitor">torch.monitor</a>
</li>
        <li><a href="mps.html#module-torch.mps">torch.mps</a>
</li>
        <li><a href="mps.html#module-torch.mps.event">torch.mps.event</a>
</li>
        <li><a href="mps.html#module-torch.mps.profiler">torch.mps.profiler</a>
</li>
        <li><a href="multiprocessing.html#module-torch.multiprocessing">torch.multiprocessing</a>
</li>
        <li><a href="multiprocessing.html#module-torch.multiprocessing.pool">torch.multiprocessing.pool</a>
</li>
        <li><a href="multiprocessing.html#module-torch.multiprocessing.queue">torch.multiprocessing.queue</a>
</li>
        <li><a href="multiprocessing.html#module-torch.multiprocessing.reductions">torch.multiprocessing.reductions</a>
</li>
        <li><a href="multiprocessing.html#module-torch.multiprocessing.spawn">torch.multiprocessing.spawn</a>
</li>
        <li><a href="nested.html#module-torch.nested">torch.nested</a>
</li>
        <li><a href="nn.html#module-torch.nn">torch.nn</a>
</li>
        <li><a href="nn.attention.html#module-torch.nn.attention">torch.nn.attention</a>
</li>
        <li><a href="nn.attention.bias.html#module-torch.nn.attention.bias">torch.nn.attention.bias</a>
</li>
        <li><a href="nn.html#module-torch.nn.backends">torch.nn.backends</a>
</li>
        <li><a href="nn.html#module-torch.nn.backends.thnn">torch.nn.backends.thnn</a>
</li>
        <li><a href="nn.html#module-torch.nn.common_types">torch.nn.common_types</a>
</li>
        <li><a href="nn.html#module-torch.nn.cpp">torch.nn.cpp</a>
</li>
        <li><a href="nn.html#module-torch.nn.functional">torch.nn.functional</a>
</li>
        <li><a href="nn.html#module-torch.nn.grad">torch.nn.grad</a>
</li>
        <li><a href="nn.html#module-torch.nn.init">torch.nn.init</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic">torch.nn.intrinsic</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.modules">torch.nn.intrinsic.modules</a>
</li>
        <li><a href="quantization.html#module-torch.nn.intrinsic.modules.fused">torch.nn.intrinsic.modules.fused</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.qat">torch.nn.intrinsic.qat</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.qat.modules">torch.nn.intrinsic.qat.modules</a>
</li>
        <li><a href="quantization.html#module-torch.nn.intrinsic.qat.modules.conv_fused">torch.nn.intrinsic.qat.modules.conv_fused</a>
</li>
        <li><a href="quantization.html#module-torch.nn.intrinsic.qat.modules.linear_fused">torch.nn.intrinsic.qat.modules.linear_fused</a>
</li>
        <li><a href="quantization.html#module-torch.nn.intrinsic.qat.modules.linear_relu">torch.nn.intrinsic.qat.modules.linear_relu</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized">torch.nn.intrinsic.quantized</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.dynamic">torch.nn.intrinsic.quantized.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.dynamic.modules">torch.nn.intrinsic.quantized.dynamic.modules</a>
</li>
        <li><a href="quantization.html#module-torch.nn.intrinsic.quantized.dynamic.modules.linear_relu">torch.nn.intrinsic.quantized.dynamic.modules.linear_relu</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.modules">torch.nn.intrinsic.quantized.modules</a>
</li>
        <li><a href="quantization.html#module-torch.nn.intrinsic.quantized.modules.bn_relu">torch.nn.intrinsic.quantized.modules.bn_relu</a>
</li>
        <li><a href="quantization.html#module-torch.nn.intrinsic.quantized.modules.conv_relu">torch.nn.intrinsic.quantized.modules.conv_relu</a>
</li>
        <li><a href="quantization.html#module-torch.nn.intrinsic.quantized.modules.linear_relu">torch.nn.intrinsic.quantized.modules.linear_relu</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules">torch.nn.modules</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.activation">torch.nn.modules.activation</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.adaptive">torch.nn.modules.adaptive</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.batchnorm">torch.nn.modules.batchnorm</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.channelshuffle">torch.nn.modules.channelshuffle</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.container">torch.nn.modules.container</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.conv">torch.nn.modules.conv</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.distance">torch.nn.modules.distance</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.dropout">torch.nn.modules.dropout</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.flatten">torch.nn.modules.flatten</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.fold">torch.nn.modules.fold</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.instancenorm">torch.nn.modules.instancenorm</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.lazy">torch.nn.modules.lazy</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.linear">torch.nn.modules.linear</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.loss">torch.nn.modules.loss</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.module">torch.nn.modules.module</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.normalization">torch.nn.modules.normalization</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.padding">torch.nn.modules.padding</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.pixelshuffle">torch.nn.modules.pixelshuffle</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.pooling">torch.nn.modules.pooling</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.rnn">torch.nn.modules.rnn</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.sparse">torch.nn.modules.sparse</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.transformer">torch.nn.modules.transformer</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.upsampling">torch.nn.modules.upsampling</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules.utils">torch.nn.modules.utils</a>
</li>
        <li><a href="nn.html#module-torch.nn.parallel">torch.nn.parallel</a>
</li>
        <li><a href="nn.html#module-torch.nn.parallel.comm">torch.nn.parallel.comm</a>
</li>
        <li><a href="nn.html#module-torch.nn.parallel.data_parallel">torch.nn.parallel.data_parallel</a>
</li>
        <li><a href="nn.html#module-torch.nn.parallel.distributed">torch.nn.parallel.distributed</a>
</li>
        <li><a href="nn.html#module-torch.nn.parallel.parallel_apply">torch.nn.parallel.parallel_apply</a>
</li>
        <li><a href="nn.html#module-torch.nn.parallel.replicate">torch.nn.parallel.replicate</a>
</li>
        <li><a href="nn.html#module-torch.nn.parallel.scatter_gather">torch.nn.parallel.scatter_gather</a>
</li>
        <li><a href="nn.html#module-torch.nn.parameter">torch.nn.parameter</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.qat">torch.nn.qat</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.qat.dynamic">torch.nn.qat.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.qat.dynamic.modules">torch.nn.qat.dynamic.modules</a>
</li>
        <li><a href="quantization.html#module-torch.nn.qat.dynamic.modules.linear">torch.nn.qat.dynamic.modules.linear</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.qat.modules">torch.nn.qat.modules</a>
</li>
        <li><a href="quantization.html#module-torch.nn.qat.modules.conv">torch.nn.qat.modules.conv</a>
</li>
        <li><a href="quantization.html#module-torch.nn.qat.modules.embedding_ops">torch.nn.qat.modules.embedding_ops</a>
</li>
        <li><a href="quantization.html#module-torch.nn.qat.modules.linear">torch.nn.qat.modules.linear</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantizable">torch.nn.quantizable</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantizable.modules">torch.nn.quantizable.modules</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantizable.modules.activation">torch.nn.quantizable.modules.activation</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantizable.modules.rnn">torch.nn.quantizable.modules.rnn</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantized">torch.nn.quantized</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantized.dynamic">torch.nn.quantized.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantized.dynamic.modules">torch.nn.quantized.dynamic.modules</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.dynamic.modules.conv">torch.nn.quantized.dynamic.modules.conv</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.dynamic.modules.linear">torch.nn.quantized.dynamic.modules.linear</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.dynamic.modules.rnn">torch.nn.quantized.dynamic.modules.rnn</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.functional">torch.nn.quantized.functional</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantized.modules">torch.nn.quantized.modules</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.activation">torch.nn.quantized.modules.activation</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.batchnorm">torch.nn.quantized.modules.batchnorm</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.conv">torch.nn.quantized.modules.conv</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.dropout">torch.nn.quantized.modules.dropout</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.embedding_ops">torch.nn.quantized.modules.embedding_ops</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.functional_modules">torch.nn.quantized.modules.functional_modules</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.linear">torch.nn.quantized.modules.linear</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.normalization">torch.nn.quantized.modules.normalization</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.rnn">torch.nn.quantized.modules.rnn</a>
</li>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.utils">torch.nn.quantized.modules.utils</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils">torch.nn.utils</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.clip_grad">torch.nn.utils.clip_grad</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.convert_parameters">torch.nn.utils.convert_parameters</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.fusion">torch.nn.utils.fusion</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.init">torch.nn.utils.init</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.memory_format">torch.nn.utils.memory_format</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.parametrizations">torch.nn.utils.parametrizations</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.parametrize">torch.nn.utils.parametrize</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.prune">torch.nn.utils.prune</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.rnn">torch.nn.utils.rnn</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.spectral_norm">torch.nn.utils.spectral_norm</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.stateless">torch.nn.utils.stateless</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.weight_norm">torch.nn.utils.weight_norm</a>
</li>
        <li><a href="onnx_torchscript.html#module-torch.onnx">torch.onnx</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.errors">torch.onnx.errors</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.operators">torch.onnx.operators</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_caffe2">torch.onnx.symbolic_caffe2</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_helper">torch.onnx.symbolic_helper</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset10">torch.onnx.symbolic_opset10</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset11">torch.onnx.symbolic_opset11</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset12">torch.onnx.symbolic_opset12</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset13">torch.onnx.symbolic_opset13</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset14">torch.onnx.symbolic_opset14</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset15">torch.onnx.symbolic_opset15</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset16">torch.onnx.symbolic_opset16</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset17">torch.onnx.symbolic_opset17</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset18">torch.onnx.symbolic_opset18</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset19">torch.onnx.symbolic_opset19</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset20">torch.onnx.symbolic_opset20</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset7">torch.onnx.symbolic_opset7</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset8">torch.onnx.symbolic_opset8</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset9">torch.onnx.symbolic_opset9</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.utils">torch.onnx.utils</a>
</li>
        <li><a href="onnx.html#module-torch.onnx.verification">torch.onnx.verification</a>
</li>
        <li><a href="optim.html#module-torch.optim">torch.optim</a>
</li>
        <li><a href="optim.html#module-torch.optim.adadelta">torch.optim.adadelta</a>
</li>
        <li><a href="optim.html#module-torch.optim.adagrad">torch.optim.adagrad</a>
</li>
        <li><a href="optim.html#module-torch.optim.adam">torch.optim.adam</a>
</li>
        <li><a href="optim.html#module-torch.optim.adamax">torch.optim.adamax</a>
</li>
        <li><a href="optim.html#module-torch.optim.adamw">torch.optim.adamw</a>
</li>
        <li><a href="optim.html#module-torch.optim.asgd">torch.optim.asgd</a>
</li>
        <li><a href="optim.html#module-torch.optim.lbfgs">torch.optim.lbfgs</a>
</li>
        <li><a href="optim.html#module-torch.optim.lr_scheduler">torch.optim.lr_scheduler</a>
</li>
        <li><a href="optim.html#module-torch.optim.nadam">torch.optim.nadam</a>
</li>
        <li><a href="optim.html#module-torch.optim.optimizer">torch.optim.optimizer</a>
</li>
        <li><a href="optim.html#module-torch.optim.radam">torch.optim.radam</a>
</li>
        <li><a href="optim.html#module-torch.optim.rmsprop">torch.optim.rmsprop</a>
</li>
        <li><a href="optim.html#module-torch.optim.rprop">torch.optim.rprop</a>
</li>
        <li><a href="optim.html#module-torch.optim.sgd">torch.optim.sgd</a>
</li>
        <li><a href="optim.html#module-torch.optim.sparse_adam">torch.optim.sparse_adam</a>
</li>
        <li><a href="optim.html#module-torch.optim.swa_utils">torch.optim.swa_utils</a>
</li>
        <li><a href="torch.overrides.html#module-torch.overrides">torch.overrides</a>
</li>
        <li><a href="package.html#module-torch.package">torch.package</a>
</li>
        <li><a href="package.html#module-torch.package.analyze">torch.package.analyze</a>
</li>
        <li><a href="package.html#module-torch.package.analyze.find_first_use_of_broken_modules">torch.package.analyze.find_first_use_of_broken_modules</a>
</li>
        <li><a href="package.html#module-torch.package.analyze.is_from_package">torch.package.analyze.is_from_package</a>
</li>
        <li><a href="package.html#module-torch.package.analyze.trace_dependencies">torch.package.analyze.trace_dependencies</a>
</li>
        <li><a href="package.html#module-torch.package.file_structure_representation">torch.package.file_structure_representation</a>
</li>
        <li><a href="package.html#module-torch.package.find_file_dependencies">torch.package.find_file_dependencies</a>
</li>
        <li><a href="package.html#module-torch.package.glob_group">torch.package.glob_group</a>
</li>
        <li><a href="package.html#module-torch.package.importer">torch.package.importer</a>
</li>
        <li><a href="package.html#module-torch.package.package_exporter">torch.package.package_exporter</a>
</li>
        <li><a href="package.html#module-torch.package.package_importer">torch.package.package_importer</a>
</li>
        <li><a href="profiler.html#module-torch.profiler">torch.profiler</a>
</li>
        <li><a href="profiler.html#module-torch.profiler.itt">torch.profiler.itt</a>
</li>
        <li><a href="profiler.html#module-torch.profiler.profiler">torch.profiler.profiler</a>
</li>
        <li><a href="profiler.html#module-torch.profiler.python_tracer">torch.profiler.python_tracer</a>
</li>
        <li><a href="quantization-support.html#module-torch.quantization">torch.quantization</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fake_quantize">torch.quantization.fake_quantize</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fuse_modules">torch.quantization.fuse_modules</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fuser_method_mappings">torch.quantization.fuser_method_mappings</a>
</li>
        <li><a href="quantization-support.html#module-torch.quantization.fx">torch.quantization.fx</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fx.convert">torch.quantization.fx.convert</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fx.fuse">torch.quantization.fx.fuse</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fx.fusion_patterns">torch.quantization.fx.fusion_patterns</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fx.graph_module">torch.quantization.fx.graph_module</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fx.match_utils">torch.quantization.fx.match_utils</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fx.pattern_utils">torch.quantization.fx.pattern_utils</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fx.prepare">torch.quantization.fx.prepare</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fx.quantization_patterns">torch.quantization.fx.quantization_patterns</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fx.quantization_types">torch.quantization.fx.quantization_types</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.fx.utils">torch.quantization.fx.utils</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.observer">torch.quantization.observer</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.qconfig">torch.quantization.qconfig</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.quant_type">torch.quantization.quant_type</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.quantization_mappings">torch.quantization.quantization_mappings</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.quantize">torch.quantization.quantize</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.quantize_fx">torch.quantization.quantize_fx</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.quantize_jit">torch.quantization.quantize_jit</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.stubs">torch.quantization.stubs</a>
</li>
        <li><a href="quantization.html#module-torch.quantization.utils">torch.quantization.utils</a>
</li>
        <li><a href="torch.html#module-torch.quasirandom">torch.quasirandom</a>
</li>
        <li><a href="random.html#module-torch.random">torch.random</a>
</li>
        <li><a href="torch.html#module-torch.return_types">torch.return_types</a>
</li>
        <li><a href="torch.html#module-torch.serialization">torch.serialization</a>
</li>
        <li><a href="signal.html#module-torch.signal">torch.signal</a>
</li>
        <li><a href="signal.html#module-torch.signal.windows">torch.signal.windows</a>
</li>
        <li><a href="torch.html#module-torch.signal.windows.windows">torch.signal.windows.windows</a>
</li>
        <li><a href="sparse.html#module-torch.sparse">torch.sparse</a>
</li>
        <li><a href="torch.html#module-torch.sparse.semi_structured">torch.sparse.semi_structured</a>
</li>
        <li><a href="special.html#module-torch.special">torch.special</a>
</li>
        <li><a href="torch.html#module-torch.storage">torch.storage</a>
</li>
        <li><a href="testing.html#module-torch.testing">torch.testing</a>
</li>
        <li><a href="torch.html#module-torch.torch_version">torch.torch_version</a>
</li>
        <li><a href="torch.html#module-torch.types">torch.types</a>
</li>
        <li><a href="utils.html#module-torch.utils">torch.utils</a>
</li>
        <li><a href="torch.html#module-torch.utils.backcompat">torch.utils.backcompat</a>
</li>
        <li><a href="utils.html#module-torch.utils.backend_registration">torch.utils.backend_registration</a>
</li>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark">torch.utils.benchmark</a>
</li>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.examples">torch.utils.benchmark.examples</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.blas_compare_setup">torch.utils.benchmark.examples.blas_compare_setup</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.compare">torch.utils.benchmark.examples.compare</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.fuzzer">torch.utils.benchmark.examples.fuzzer</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.op_benchmark">torch.utils.benchmark.examples.op_benchmark</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.simple_timeit">torch.utils.benchmark.examples.simple_timeit</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.spectral_ops_fuzz_test">torch.utils.benchmark.examples.spectral_ops_fuzz_test</a>
</li>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.op_fuzzers">torch.utils.benchmark.op_fuzzers</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.op_fuzzers.binary">torch.utils.benchmark.op_fuzzers.binary</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.op_fuzzers.sparse_binary">torch.utils.benchmark.op_fuzzers.sparse_binary</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.op_fuzzers.sparse_unary">torch.utils.benchmark.op_fuzzers.sparse_unary</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.op_fuzzers.spectral">torch.utils.benchmark.op_fuzzers.spectral</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.op_fuzzers.unary">torch.utils.benchmark.op_fuzzers.unary</a>
</li>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.utils">torch.utils.benchmark.utils</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.common">torch.utils.benchmark.utils.common</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.compare">torch.utils.benchmark.utils.compare</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.compile">torch.utils.benchmark.utils.compile</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.cpp_jit">torch.utils.benchmark.utils.cpp_jit</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.fuzzer">torch.utils.benchmark.utils.fuzzer</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.sparse_fuzzer">torch.utils.benchmark.utils.sparse_fuzzer</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.timer">torch.utils.benchmark.utils.timer</a>
</li>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.utils.valgrind_wrapper">torch.utils.benchmark.utils.valgrind_wrapper</a>
</li>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.valgrind_wrapper.timer_interface">torch.utils.benchmark.utils.valgrind_wrapper.timer_interface</a>
</li>
        <li><a href="bottleneck.html#module-torch.utils.bottleneck">torch.utils.bottleneck</a>
</li>
        <li><a href="utils.html#module-torch.utils.bundled_inputs">torch.utils.bundled_inputs</a>
</li>
        <li><a href="utils.html#module-torch.utils.checkpoint">torch.utils.checkpoint</a>
</li>
        <li><a href="utils.html#module-torch.utils.collect_env">torch.utils.collect_env</a>
</li>
        <li><a href="utils.html#module-torch.utils.cpp_backtrace">torch.utils.cpp_backtrace</a>
</li>
        <li><a href="utils.html#module-torch.utils.cpp_extension">torch.utils.cpp_extension</a>
</li>
        <li><a href="data.html#module-torch.utils.data">torch.utils.data</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.backward_compatibility">torch.utils.data.backward_compatibility</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.dataloader">torch.utils.data.dataloader</a>
</li>
        <li><a href="data.html#module-torch.utils.data.datapipes">torch.utils.data.datapipes</a>
</li>
        <li><a href="data.html#module-torch.utils.data.datapipes.dataframe">torch.utils.data.datapipes.dataframe</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.dataframe.dataframe_wrapper">torch.utils.data.datapipes.dataframe.dataframe_wrapper</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.dataframe.dataframes">torch.utils.data.datapipes.dataframe.dataframes</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.dataframe.datapipes">torch.utils.data.datapipes.dataframe.datapipes</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.dataframe.structures">torch.utils.data.datapipes.dataframe.structures</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.datapipe">torch.utils.data.datapipes.datapipe</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.gen_pyi">torch.utils.data.datapipes.gen_pyi</a>
</li>
        <li><a href="data.html#module-torch.utils.data.datapipes.iter">torch.utils.data.datapipes.iter</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.callable">torch.utils.data.datapipes.iter.callable</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.combinatorics">torch.utils.data.datapipes.iter.combinatorics</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.combining">torch.utils.data.datapipes.iter.combining</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.filelister">torch.utils.data.datapipes.iter.filelister</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.fileopener">torch.utils.data.datapipes.iter.fileopener</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.grouping">torch.utils.data.datapipes.iter.grouping</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.routeddecoder">torch.utils.data.datapipes.iter.routeddecoder</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.selecting">torch.utils.data.datapipes.iter.selecting</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.sharding">torch.utils.data.datapipes.iter.sharding</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.streamreader">torch.utils.data.datapipes.iter.streamreader</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.utils">torch.utils.data.datapipes.iter.utils</a>
</li>
        <li><a href="data.html#module-torch.utils.data.datapipes.map">torch.utils.data.datapipes.map</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.map.callable">torch.utils.data.datapipes.map.callable</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.map.combinatorics">torch.utils.data.datapipes.map.combinatorics</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.map.combining">torch.utils.data.datapipes.map.combining</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.map.grouping">torch.utils.data.datapipes.map.grouping</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.map.utils">torch.utils.data.datapipes.map.utils</a>
</li>
        <li><a href="data.html#module-torch.utils.data.datapipes.utils">torch.utils.data.datapipes.utils</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.utils.common">torch.utils.data.datapipes.utils.common</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.utils.decoder">torch.utils.data.datapipes.utils.decoder</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.datapipes.utils.snapshot">torch.utils.data.datapipes.utils.snapshot</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.dataset">torch.utils.data.dataset</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.distributed">torch.utils.data.distributed</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.graph">torch.utils.data.graph</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.graph_settings">torch.utils.data.graph_settings</a>
</li>
        <li><a href="utils.html#module-torch.utils.data.sampler">torch.utils.data.sampler</a>
</li>
        <li><a href="deterministic.html#module-torch.utils.deterministic">torch.utils.deterministic</a>
</li>
        <li><a href="utils.html#module-torch.utils.dlpack">torch.utils.dlpack</a>
</li>
        <li><a href="utils.html#module-torch.utils.file_baton">torch.utils.file_baton</a>
</li>
        <li><a href="utils.html#module-torch.utils.flop_counter">torch.utils.flop_counter</a>
</li>
        <li><a href="torch.html#module-torch.utils.hipify">torch.utils.hipify</a>
</li>
        <li><a href="utils.html#module-torch.utils.hipify.constants">torch.utils.hipify.constants</a>
</li>
        <li><a href="utils.html#module-torch.utils.hipify.cuda_to_hip_mappings">torch.utils.hipify.cuda_to_hip_mappings</a>
</li>
        <li><a href="utils.html#module-torch.utils.hipify.hipify_python">torch.utils.hipify.hipify_python</a>
</li>
        <li><a href="utils.html#module-torch.utils.hipify.version">torch.utils.hipify.version</a>
</li>
        <li><a href="utils.html#module-torch.utils.hooks">torch.utils.hooks</a>
</li>
        <li><a href="jit_utils.html#module-torch.utils.jit">torch.utils.jit</a>
</li>
        <li><a href="utils.html#module-torch.utils.jit.log_extract">torch.utils.jit.log_extract</a>
</li>
        <li><a href="utils.html#module-torch.utils.mkldnn">torch.utils.mkldnn</a>
</li>
        <li><a href="utils.html#module-torch.utils.mobile_optimizer">torch.utils.mobile_optimizer</a>
</li>
        <li><a href="torch.html#module-torch.utils.model_dump">torch.utils.model_dump</a>
</li>
        <li><a href="model_zoo.html#module-torch.utils.model_zoo">torch.utils.model_zoo</a>
</li>
        <li><a href="utils.html#module-torch.utils.show_pickle">torch.utils.show_pickle</a>
</li>
        <li><a href="tensorboard.html#module-torch.utils.tensorboard">torch.utils.tensorboard</a>
</li>
        <li><a href="utils.html#module-torch.utils.tensorboard.summary">torch.utils.tensorboard.summary</a>
</li>
        <li><a href="utils.html#module-torch.utils.tensorboard.writer">torch.utils.tensorboard.writer</a>
</li>
        <li><a href="utils.html#module-torch.utils.throughput_benchmark">torch.utils.throughput_benchmark</a>
</li>
        <li><a href="torch.html#module-torch.utils.viz">torch.utils.viz</a>
</li>
        <li><a href="utils.html#module-torch.utils.weak">torch.utils.weak</a>
</li>
        <li><a href="torch.html#module-torch.version">torch.version</a>
</li>
        <li><a href="xpu.html#module-torch.xpu">torch.xpu</a>
</li>
        <li><a href="xpu.html#module-torch.xpu.random">torch.xpu.random</a>
</li>
        <li><a href="xpu.html#module-torch.xpu.streams">torch.xpu.streams</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.nn.Module.html#torch.nn.Module">Module (class in torch.nn)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.module">module (torch.distributed.fsdp.FullyShardedDataParallel property)</a>
</li>
      <li><a href="export.html#torch.export.ExportedProgram.module">module() (torch.export.ExportedProgram method)</a>
</li>
      <li><a href="generated/torch.Tensor.module_load.html#torch.Tensor.module_load">module_load() (torch.Tensor method)</a>
</li>
      <li><a href="export.html#torch.export.ModuleCallEntry">ModuleCallEntry (class in torch.export)</a>
</li>
      <li><a href="export.html#torch.export.ModuleCallSignature">ModuleCallSignature (class in torch.export)</a>
</li>
      <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict">ModuleDict (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ModuleList.html#torch.nn.ModuleList">ModuleList (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.modules">modules() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.modules">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.monitored_barrier">monitored_barrier() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.moveaxis.html#torch.moveaxis">moveaxis() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.moveaxis.html#torch.Tensor.moveaxis">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.movedim.html#torch.movedim">movedim() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.movedim.html#torch.Tensor.movedim">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.observer.MovingAverageMinMaxObserver.html#torch.ao.quantization.observer.MovingAverageMinMaxObserver">MovingAverageMinMaxObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver.html#torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver">MovingAveragePerChannelMinMaxObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="storage.html#torch.UntypedStorage.mps">mps() (torch.UntypedStorage method)</a>
</li>
      <li><a href="generated/torch.nn.functional.mse_loss.html#torch.nn.functional.mse_loss">mse_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.MSELoss.html#torch.nn.MSELoss">MSELoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.msort.html#torch.msort">msort() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.msort.html#torch.Tensor.msort">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="tensors.html#torch.Tensor.mT">mT (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.mul.html#torch.mul">mul() (in module torch)</a>

      <ul>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.mul">(torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
        <li><a href="generated/torch.Tensor.mul.html#torch.Tensor.mul">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.mul_.html#torch.Tensor.mul_">mul_() (torch.Tensor method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.mul_scalar">mul_scalar() (torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
      <li><a href="generated/torch.linalg.multi_dot.html#torch.linalg.multi_dot">multi_dot() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.nn.functional.multi_margin_loss.html#torch.nn.functional.multi_margin_loss">multi_margin_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="special.html#torch.special.multigammaln">multigammaln() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantizable.MultiheadAttention.html#torch.ao.nn.quantizable.MultiheadAttention">MultiheadAttention (class in torch.ao.nn.quantizable)</a>

      <ul>
        <li><a href="generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.multilabel_margin_loss.html#torch.nn.functional.multilabel_margin_loss">multilabel_margin_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.multilabel_soft_margin_loss.html#torch.nn.functional.multilabel_soft_margin_loss">multilabel_soft_margin_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.MultiLabelMarginLoss.html#torch.nn.MultiLabelMarginLoss">MultiLabelMarginLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MultiLabelSoftMarginLoss.html#torch.nn.MultiLabelSoftMarginLoss">MultiLabelSoftMarginLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MultiMarginLoss.html#torch.nn.MultiMarginLoss">MultiMarginLoss (class in torch.nn)</a>
</li>
      <li><a href="distributions.html#torch.distributions.multinomial.Multinomial">Multinomial (class in torch.distributions.multinomial)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.multinomial">multinomial (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.multinomial.html#torch.multinomial">multinomial() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.multinomial.html#torch.Tensor.multinomial">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR">MultiplicativeLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.multiply.html#torch.multiply">multiply() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.multiply.html#torch.Tensor.multiply">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.multiply_.html#torch.Tensor.multiply_">multiply_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.MultiprocessContext">MultiprocessContext (class in torch.distributed.elastic.multiprocessing.api)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR">MultiStepLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal">MultivariateNormal (class in torch.distributions.multivariate_normal)</a>
</li>
      <li><a href="generated/torch.mv.html#torch.mv">mv() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.mv.html#torch.Tensor.mv">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.mvlgamma.html#torch.mvlgamma">mvlgamma() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.mvlgamma.html#torch.Tensor.mvlgamma">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.mvlgamma_.html#torch.Tensor.mvlgamma_">mvlgamma_() (torch.Tensor method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="N">N</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam">NAdam (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.Kernel.html#torch.autograd.profiler_util.Kernel.name">name (torch.autograd.profiler_util.Kernel attribute)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.name">(torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend property)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.name">(torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend property)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend.name">(torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend property)</a>
</li>
        <li><a href="rpc.html#torch.distributed.rpc.WorkerInfo.name">(torch.distributed.rpc.WorkerInfo property)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Aggregation.name">(torch.monitor.Aggregation property)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Event.name">(torch.monitor.Event property)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Stat.name">(torch.monitor.Stat property)</a>
</li>
        <li><a href="generated/torch.nn.attention.SDPBackend.html#torch.nn.attention.SDPBackend.name">(torch.nn.attention.SDPBackend property)</a>
</li>
        <li><a href="profiler.html#torch.profiler.ProfilerActivity.name">(torch.profiler.ProfilerActivity property)</a>
</li>
        <li><a href="torch.html#torch.Tag.name">(torch.Tag property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.graph.Node.name.html#torch.autograd.graph.Node.name">name() (torch.autograd.graph.Node method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.named_buffers">named_buffers() (torch.distributed.fsdp.FullyShardedDataParallel method)</a>

      <ul>
        <li><a href="export.html#torch.export.ExportedProgram.named_buffers">(torch.export.ExportedProgram method)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.named_buffers">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.named_buffers">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.named_children">named_children() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.named_children">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.named_modules">named_modules() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.named_modules">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.named_parameters">named_parameters() (torch.distributed.fsdp.FullyShardedDataParallel method)</a>

      <ul>
        <li><a href="export.html#torch.export.ExportedProgram.named_parameters">(torch.export.ExportedProgram method)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.named_parameters">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.named_parameters">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="named_tensor.html#torch.Tensor.names">names (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.nan_to_num.html#torch.nan_to_num">nan_to_num() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nan_to_num.html#torch.Tensor.nan_to_num">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.nan_to_num_.html#torch.Tensor.nan_to_num_">nan_to_num_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nanmean.html#torch.nanmean">nanmean() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nanmean.html#torch.Tensor.nanmean">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nanmedian.html#torch.nanmedian">nanmedian() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nanmedian.html#torch.Tensor.nanmedian">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nanquantile.html#torch.nanquantile">nanquantile() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nanquantile.html#torch.Tensor.nanquantile">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nansum.html#torch.nansum">nansum() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nansum.html#torch.Tensor.nansum">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.narrow.html#torch.narrow">narrow() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.narrow.html#torch.Tensor.narrow">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.narrow_copy.html#torch.narrow_copy">narrow_copy() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.narrow_copy.html#torch.Tensor.narrow_copy">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.nbytes.html#torch.Tensor.nbytes">nbytes (torch.Tensor attribute)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.nbytes">nbytes() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.nbytes">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.ndim.html#torch.Tensor.ndim">ndim (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.Tensor.ndimension.html#torch.Tensor.ndimension">ndimension() (torch.Tensor method)</a>
</li>
      <li><a href="special.html#torch.special.ndtr">ndtr() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.ndtri">ndtri() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.ne.html#torch.ne">ne() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ne.html#torch.Tensor.ne">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.ne_.html#torch.Tensor.ne_">ne_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.neg.html#torch.neg">neg() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.neg.html#torch.Tensor.neg">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.neg_.html#torch.Tensor.neg_">neg_() (torch.Tensor method)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.negative.html#torch.negative">negative() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.negative.html#torch.Tensor.negative">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.negative_.html#torch.Tensor.negative_">negative_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial">NegativeBinomial (class in torch.distributions.negative_binomial)</a>
</li>
      <li><a href="generated/torch.Tensor.nelement.html#torch.Tensor.nelement">nelement() (torch.Tensor method)</a>
</li>
      <li><a href="nested.html#torch.nested.nested_tensor">nested_tensor() (in module torch.nested)</a>
</li>
      <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction">NestedIOFunction (class in torch.autograd.function)</a>
</li>
      <li><a href="storage.html#torch.UntypedStorage.new">new() (torch.UntypedStorage method)</a>
</li>
      <li><a href="generated/torch.Tensor.new_empty.html#torch.Tensor.new_empty">new_empty() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.new_full.html#torch.Tensor.new_full">new_full() (torch.Tensor method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.new_group">new_group() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.Tensor.new_ones.html#torch.Tensor.new_ones">new_ones() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.new_tensor.html#torch.Tensor.new_tensor">new_tensor() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.new_zeros.html#torch.Tensor.new_zeros">new_zeros() (torch.Tensor method)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.next">next (torch.fx.Node property)</a>
</li>
      <li><a href="generated/torch.autograd.graph.Node.next_functions.html#torch.autograd.graph.Node.next_functions">next_functions (torch.autograd.graph.Node property)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.next_rendezvous">next_rendezvous() (torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      <li><a href="generated/torch.nextafter.html#torch.nextafter">nextafter() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nextafter.html#torch.Tensor.nextafter">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.nextafter_.html#torch.Tensor.nextafter_">nextafter_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.functional.nll_loss.html#torch.nn.functional.nll_loss">nll_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss">NLLLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.no_grad.html#torch.no_grad">no_grad (class in torch)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.no_sync">no_sync() (torch.distributed.fsdp.FullyShardedDataParallel method)</a>

      <ul>
        <li><a href="generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.no_sync">(torch.nn.parallel.DistributedDataParallel method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Node">Node (class in torch.fx)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.node_copy">node_copy() (torch.fx.Graph method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.nodes">nodes (torch.fx.Graph property)</a>
</li>
      <li><a href="generated/torch.nonzero.html#torch.nonzero">nonzero() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nonzero.html#torch.Tensor.nonzero">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks.noop_hook">noop_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.NoopObserver.html#torch.ao.quantization.observer.NoopObserver">NoopObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.norm.html#torch.norm">norm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.norm.html#torch.linalg.norm">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.norm.html#torch.Tensor.norm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.normal.Normal">Normal (class in torch.distributions.normal)</a>
</li>
      <li><a href="generated/torch.normal.html#torch.normal">normal() (in module torch)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.normal_">normal_() (in module torch.nn.init)</a>

      <ul>
        <li><a href="generated/torch.Tensor.normal_.html#torch.Tensor.normal_">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.normalize.html#torch.nn.functional.normalize">normalize() (in module torch.nn.functional)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.normalized_arguments">normalized_arguments() (torch.fx.Node method)</a>
</li>
      <li><a href="generated/torch.not_equal.html#torch.not_equal">not_equal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.not_equal.html#torch.Tensor.not_equal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.not_equal_.html#torch.Tensor.not_equal_">not_equal_() (torch.Tensor method)</a>
</li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Join.notify_join_context">notify_join_context() (torch.distributed.algorithms.Join static method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.NSTracer">NSTracer (class in torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.api.NullMetricHandler">NullMetricHandler (class in torch.distributed.elastic.metrics.api)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store.num_keys">num_keys() (in module torch.distributed.Store)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.num_nodes_waiting">num_nodes_waiting() (torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.num_worker_threads">num_worker_threads (torch.distributed.rpc.TensorPipeRpcBackendOptions property)</a>
</li>
      <li><a href="generated/torch.numel.html#torch.numel">numel() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.numel.html#torch.Tensor.numel">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.numpy.html#torch.Tensor.numpy">numpy() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.signal.windows.nuttall.html#torch.signal.windows.nuttall">nuttall() (in module torch.signal.windows)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="O">O</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.ao.quantization.backend_config.ObservationType.html#torch.ao.quantization.backend_config.ObservationType">ObservationType (class in torch.ao.quantization.backend_config)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.ObserverBase.html#torch.ao.quantization.observer.ObserverBase">ObserverBase (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.on_generate_code">on_generate_code() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.autograd.function.once_differentiable.html#torch.autograd.function.once_differentiable">once_differentiable() (in module torch.autograd.function)</a>
</li>
      <li><a href="generated/torch.nn.functional.one_hot.html#torch.nn.functional.one_hot">one_hot() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR">OneCycleLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.jit.onednn_fusion_enabled.html#torch.jit.onednn_fusion_enabled">onednn_fusion_enabled() (in module torch.jit)</a>
</li>
      <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical">OneHotCategorical (class in torch.distributions.one_hot_categorical)</a>
</li>
      <li><a href="generated/torch.ones.html#torch.ones">ones() (in module torch)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.ones_">ones_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.ones_like.html#torch.ones_like">ones_like() (in module torch)</a>
</li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.onnx_compatible">onnx_compatible() (torch.onnx.JitScalarType method)</a>
</li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.onnx_type">onnx_type() (torch.onnx.JitScalarType method)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.OnnxExporterError">OnnxExporterError (class in torch.onnx)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.ONNXProgram">ONNXProgram (class in torch.onnx)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.ONNXProgramSerializer">ONNXProgramSerializer (class in torch.onnx)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.OnnxRegistry">OnnxRegistry (class in torch.onnx)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.ONNXRuntimeOptions">ONNXRuntimeOptions (class in torch.onnx)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.OnnxRegistry.opset_version">opset_version (torch.onnx.OnnxRegistry property)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.optim_state_dict">optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.optim_state_dict_to_load">optim_state_dict_to_load() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="generated/torch.jit.optimize_for_inference.html#torch.jit.optimize_for_inference">optimize_for_inference() (in module torch.jit)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="mobile_optimizer.html#torch.utils.mobile_optimizer.optimize_for_mobile">optimize_for_mobile() (in module torch.utils.mobile_optimizer)</a>
</li>
      <li><a href="optim.html#torch.optim.Optimizer">Optimizer (class in torch.optim)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.OptimStateDictConfig">OptimStateDictConfig (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="generated/torch.orgqr.html#torch.orgqr">orgqr() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.orgqr.html#torch.Tensor.orgqr">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ormqr.html#torch.ormqr">ormqr() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ormqr.html#torch.Tensor.ormqr">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.parametrizations.orthogonal.html#torch.nn.utils.parametrizations.orthogonal">orthogonal() (in module torch.nn.utils.parametrizations)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.orthogonal_">orthogonal_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.outer.html#torch.outer">outer() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.outer.html#torch.Tensor.outer">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.OutOfMemoryError.html#torch.cuda.OutOfMemoryError">OutOfMemoryError</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.output">output() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.output">(torch.fx.Interpreter method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.backend_config.ObservationType.html#torch.ao.quantization.backend_config.ObservationType.OUTPUT_SHARE_OBSERVER_WITH_INPUT">OUTPUT_SHARE_OBSERVER_WITH_INPUT (torch.ao.quantization.backend_config.ObservationType attribute)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.ObservationType.html#torch.ao.quantization.backend_config.ObservationType.OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT">OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT (torch.ao.quantization.backend_config.ObservationType attribute)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputComparisonLogger">OutputComparisonLogger (class in torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="export.html#torch.export.graph_signature.OutputKind">OutputKind (class in torch.export.graph_signature)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.OutputLogger">OutputLogger (class in torch.ao.ns._numeric_suite)</a>

      <ul>
        <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputLogger">(class in torch.ao.ns._numeric_suite_fx)</a>
</li>
      </ul></li>
      <li><a href="export.html#torch.export.graph_signature.OutputSpec">OutputSpec (class in torch.export.graph_signature)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.PyRRef.owner">owner() (torch.distributed.rpc.PyRRef method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.PyRRef.owner_name">owner_name() (torch.distributed.rpc.PyRRef method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="P">P</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributed.html#torch.distributed.P2POp">P2POp (class in torch.distributed)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence">pack_padded_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.pack_sequence.html#torch.nn.utils.rnn.pack_sequence">pack_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter">PackageExporter (class in torch.package)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter">PackageImporter (class in torch.package)</a>
</li>
      <li><a href="package.html#torch.package.PackagingError">PackagingError (class in torch.package)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence">PackedSequence (class in torch.nn.utils.rnn)</a>
</li>
      <li><a href="generated/torch.nn.functional.pad.html#torch.nn.functional.pad">pad() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.pad_packed_sequence.html#torch.nn.utils.rnn.pad_packed_sequence">pad_packed_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.pad_sequence.html#torch.nn.utils.rnn.pad_sequence">pad_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="generated/torch.nn.functional.pairwise_distance.html#torch.nn.functional.pairwise_distance">pairwise_distance() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.PairwiseDistance.html#torch.nn.PairwiseDistance">PairwiseDistance (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.parallel_and.html#torch.fx.experimental.symbolic_shapes.parallel_and">parallel_and() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="config_mod.html#torch.__config__.parallel_info">parallel_info() (in module torch.__config__)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.parallel_or.html#torch.fx.experimental.symbolic_shapes.parallel_or">parallel_or() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.parallelize_module">parallelize_module() (in module torch.distributed.tensor.parallel)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.param_shape">param_shape (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.param_shape">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.param_shape">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.param_shape">(torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.param_shape">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.param_shape">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.param_shape">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.param_shape">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter">Parameter (class in torch.nn.parameter)</a>
</li>
      <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict">ParameterDict (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ParameterList.html#torch.nn.ParameterList">ParameterList (class in torch.nn)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.parameters">parameters() (in module torch.distributed.GradBucket)</a>

      <ul>
        <li><a href="export.html#torch.export.ExportedProgram.parameters">(torch.export.ExportedProgram method)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.parameters">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.parameters">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.parameters_to_vector.html#torch.nn.utils.parameters_to_vector">parameters_to_vector() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.nn.utils.parametrize.ParametrizationList.html#torch.nn.utils.parametrize.ParametrizationList">ParametrizationList (class in torch.nn.utils.parametrize)</a>
</li>
      <li><a href="distributions.html#torch.distributions.pareto.Pareto">Pareto (class in torch.distributions.pareto)</a>
</li>
      <li><a href="generated/torch.autograd.profiler.parse_nvprof_trace.html#torch.autograd.profiler.parse_nvprof_trace">parse_nvprof_trace() (in module torch.autograd.profiler)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.path_of_module">path_of_module() (torch.fx.Tracer method)</a>
</li>
      <li><a href="generated/torch.pca_lowrank.html#torch.pca_lowrank">pca_lowrank() (in module torch)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.PContext">PContext (class in torch.distributed.elastic.multiprocessing.api)</a>
</li>
      <li><a href="generated/torch.nn.functional.pdist.html#torch.nn.functional.pdist">pdist() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.per_channel_dynamic_qconfig.html#torch.ao.quantization.qconfig.per_channel_dynamic_qconfig">per_channel_dynamic_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.PerChannelMinMaxObserver.html#torch.ao.quantization.observer.PerChannelMinMaxObserver">PerChannelMinMaxObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.permute.html#torch.permute">permute() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.permute.html#torch.Tensor.permute">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution.perplexity">perplexity() (torch.distributions.distribution.Distribution method)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.pickle_storage_type">pickle_storage_type() (torch.TypedStorage method)</a>
</li>
      <li><a href="generated/torch.Tensor.pin_memory.html#torch.Tensor.pin_memory">pin_memory() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.pin_memory">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.pin_memory">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.pinv.html#torch.linalg.pinv">pinv() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.pinverse.html#torch.pinverse">pinverse() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.pinverse.html#torch.Tensor.pinverse">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="pipeline.html#torch.distributed.pipeline.sync.Pipe">Pipe (class in torch.distributed.pipeline.sync)</a>
</li>
      <li><a href="generated/torch.nn.functional.pixel_shuffle.html#torch.nn.functional.pixel_shuffle">pixel_shuffle() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.pixel_unshuffle.html#torch.nn.functional.pixel_unshuffle">pixel_unshuffle() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.PixelShuffle.html#torch.nn.PixelShuffle">PixelShuffle (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.PixelUnshuffle.html#torch.nn.PixelUnshuffle">PixelUnshuffle (class in torch.nn)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.placeholder">placeholder() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.placeholder">(torch.fx.Interpreter method)</a>
</li>
        <li><a href="fx.html#torch.fx.Transformer.placeholder">(torch.fx.Transformer method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.observer.PlaceholderObserver.html#torch.ao.quantization.observer.PlaceholderObserver">PlaceholderObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="distributions.html#torch.distributions.poisson.Poisson">Poisson (class in torch.distributions.poisson)</a>
</li>
      <li><a href="generated/torch.poisson.html#torch.poisson">poisson() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.functional.poisson_nll_loss.html#torch.nn.functional.poisson_nll_loss">poisson_nll_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.PoissonNLLLoss.html#torch.nn.PoissonNLLLoss">PoissonNLLLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.polar.html#torch.polar">polar() (in module torch)</a>
</li>
      <li><a href="generated/torch.polygamma.html#torch.polygamma">polygamma() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.polygamma">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.polygamma.html#torch.Tensor.polygamma">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.polygamma_.html#torch.Tensor.polygamma_">polygamma_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.PolynomialLR.html#torch.optim.lr_scheduler.PolynomialLR">PolynomialLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.pool">pool() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="pipeline.html#torch.distributed.pipeline.sync.skip.skippable.pop">pop (class in torch.distributed.pipeline.sync.skip.skippable)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.pop">pop() (torch.autograd.profiler_util.StringTable method)</a>

      <ul>
        <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.pop">(torch.nn.ModuleDict method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.pop">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.popitem">popitem() (torch.autograd.profiler_util.StringTable method)</a>

      <ul>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.popitem">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.positive.html#torch.positive">positive() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.positive.html#torch.Tensor.positive">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.transforms.PositiveDefiniteTransform">PositiveDefiniteTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.JoinHook.post_hook">post_hook() (torch.distributed.algorithms.JoinHook method)</a>
</li>
      <li><a href="distributed.optim.html#torch.distributed.optim.PostLocalSGDOptimizer">PostLocalSGDOptimizer (class in torch.distributed.optim)</a>
</li>
      <li><a href="generated/torch.pow.html#torch.pow">pow() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.pow.html#torch.Tensor.pow">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.pow_.html#torch.Tensor.pow_">pow_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.cuda.power_draw.html#torch.cuda.power_draw">power_draw() (in module torch.cuda)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.powerSGD_hook">powerSGD_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState">PowerSGDState (class in torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.PowerTransform">PowerTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.precision_matrix">precision_matrix (torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.precision_matrix">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html#torch.nn.AdaptiveLogSoftmaxWithLoss.predict">predict() (torch.nn.AdaptiveLogSoftmaxWithLoss method)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.preferred_linalg_library">preferred_linalg_library() (in module torch.backends.cuda)</a>
</li>
      <li><a href="distributed.html#torch.distributed.PrefixStore">PrefixStore (class in torch.distributed)</a>
</li>
      <li><a href="generated/torch.nn.PReLU.html#torch.nn.PReLU">PReLU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.prelu.html#torch.nn.functional.prelu">prelu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.quantization.prepare.html#torch.ao.quantization.prepare">prepare (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.ao.quantization.quantize_fx.prepare_fx.html#torch.ao.quantization.quantize_fx.prepare_fx">prepare_fx (class in torch.ao.quantization.quantize_fx)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.prepare_global_plan">prepare_global_plan() (torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.prepare_global_plan">(torch.distributed.checkpoint.StorageReader method)</a>
</li>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.prepare_global_plan">(torch.distributed.checkpoint.StorageWriter method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.prepare_local_plan">prepare_local_plan() (torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.prepare_local_plan">(torch.distributed.checkpoint.StorageReader method)</a>
</li>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.prepare_local_plan">(torch.distributed.checkpoint.StorageWriter method)</a>
</li>
      </ul></li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.prepare_model_outputs">prepare_model_outputs() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.prepare_model_with_stubs">prepare_model_with_stubs() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.prepare_n_shadows_model">prepare_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="generated/torch.ao.quantization.prepare_qat.html#torch.ao.quantization.prepare_qat">prepare_qat (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.ao.quantization.quantize_fx.prepare_qat_fx.html#torch.ao.quantization.quantize_fx.prepare_qat_fx">prepare_qat_fx (class in torch.ao.quantization.quantize_fx)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig">PrepareCustomConfig (class in torch.ao.quantization.fx.custom_config)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.PrepareModuleInput">PrepareModuleInput (class in torch.distributed.tensor.parallel)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.PrepareModuleOutput">PrepareModuleOutput (class in torch.distributed.tensor.parallel)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.prepend">prepend() (torch.fx.Node method)</a>
</li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile.preset_metadata_json">preset_metadata_json() (torch.profiler._KinetoProfile method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.DimConstraints.html#torch.fx.experimental.symbolic_shapes.DimConstraints.prettify_results">prettify_results() (torch.fx.experimental.symbolic_shapes.DimConstraints method)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.pretty_print_mismatch">pretty_print_mismatch() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.pretty_print_tree">pretty_print_tree() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.prev">prev (torch.fx.Node property)</a>
</li>
      <li><a href="generated/torch.autograd.forward_ad.UnpackedDualTensor.html#torch.autograd.forward_ad.UnpackedDualTensor.primal">primal (torch.autograd.forward_ad.UnpackedDualTensor attribute)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.print_comparisons_n_shadows_model">print_comparisons_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ChainedScheduler.html#torch.optim.lr_scheduler.ChainedScheduler.print_lr">print_lr() (torch.optim.lr_scheduler.ChainedScheduler method)</a>

      <ul>
        <li><a href="generated/torch.optim.lr_scheduler.ConstantLR.html#torch.optim.lr_scheduler.ConstantLR.print_lr">(torch.optim.lr_scheduler.ConstantLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR.print_lr">(torch.optim.lr_scheduler.CosineAnnealingLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.print_lr">(torch.optim.lr_scheduler.CosineAnnealingWarmRestarts method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CyclicLR.html#torch.optim.lr_scheduler.CyclicLR.print_lr">(torch.optim.lr_scheduler.CyclicLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR.print_lr">(torch.optim.lr_scheduler.ExponentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR.print_lr">(torch.optim.lr_scheduler.LambdaLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LinearLR.html#torch.optim.lr_scheduler.LinearLR.print_lr">(torch.optim.lr_scheduler.LinearLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR.print_lr">(torch.optim.lr_scheduler.MultiplicativeLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR.print_lr">(torch.optim.lr_scheduler.MultiStepLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR.print_lr">(torch.optim.lr_scheduler.OneCycleLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.PolynomialLR.html#torch.optim.lr_scheduler.PolynomialLR.print_lr">(torch.optim.lr_scheduler.PolynomialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html#torch.optim.lr_scheduler.ReduceLROnPlateau.print_lr">(torch.optim.lr_scheduler.ReduceLROnPlateau method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.SequentialLR.html#torch.optim.lr_scheduler.SequentialLR.print_lr">(torch.optim.lr_scheduler.SequentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR.print_lr">(torch.optim.lr_scheduler.StepLR method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.GraphModule.print_readable">print_readable() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.print_tabular">print_tabular() (torch.fx.Graph method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.probs">probs (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.probs">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.probs">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.probs">(torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.probs">(torch.distributions.geometric.Geometric property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.probs">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.probs">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.probs">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.probs">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical property)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.process_inputs">process_inputs() (torch.fx.Graph method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.process_outputs">process_outputs() (torch.fx.Graph method)</a>
</li>
      <li><a href="elastic/errors.html#torch.distributed.elastic.multiprocessing.errors.ProcessFailure">ProcessFailure (class in torch.distributed.elastic.multiprocessing.errors)</a>
</li>
      <li><a href="generated/torch.prod.html#torch.prod">prod() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.prod.html#torch.Tensor.prod">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.produce_guards">produce_guards() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.produce_guards_expression">produce_guards_expression() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.prof">prof() (in module torch.distributed.elastic.metrics)</a>
</li>
      <li><a href="autograd.html#torch.autograd.profiler.profile">profile (class in torch.autograd.profiler)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler.profile">(class in torch.profiler)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.mps.profiler.profile.html#torch.mps.profiler.profile">profile() (in module torch.mps.profiler)</a>
</li>
      <li><a href="profiler.html#torch.profiler.ProfilerAction">ProfilerAction (class in torch.profiler)</a>
</li>
      <li><a href="profiler.html#torch.profiler.ProfilerActivity">ProfilerActivity (class in torch.profiler)</a>
</li>
      <li><a href="generated/torch.promote_types.html#torch.promote_types">promote_types() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.propagate_qconfig_.html#torch.ao.quantization.propagate_qconfig_">propagate_qconfig_ (class in torch.ao.quantization)</a>
</li>
      <li><a href="fx.html#torch.fx.Proxy">Proxy (class in torch.fx)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.proxy">proxy() (torch.fx.Tracer method)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.prune">prune() (torch.nn.utils.prune.BasePruningMethod method)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.prune">(torch.nn.utils.prune.CustomFromMask method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.prune">(torch.nn.utils.prune.Identity method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.prune">(torch.nn.utils.prune.L1Unstructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.prune">(torch.nn.utils.prune.LnStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.prune">(torch.nn.utils.prune.PruningContainer method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.prune">(torch.nn.utils.prune.RandomStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.prune">(torch.nn.utils.prune.RandomUnstructured method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer">PruningContainer (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="special.html#torch.special.psi">psi() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.Tensor.put_.html#torch.Tensor.put_">put_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.put_metric">put_metric() (in module torch.distributed.elastic.metrics)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.PyRRef">PyRRef (class in torch.distributed.rpc)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.python_code">python_code() (torch.fx.Graph method)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.python_version">python_version() (torch.package.PackageImporter method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="Q">Q</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.Tensor.q_per_channel_axis.html#torch.Tensor.q_per_channel_axis">q_per_channel_axis() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.q_per_channel_scales.html#torch.Tensor.q_per_channel_scales">q_per_channel_scales() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.q_per_channel_zero_points.html#torch.Tensor.q_per_channel_zero_points">q_per_channel_zero_points() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.q_scale.html#torch.Tensor.q_scale">q_scale() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.q_zero_point.html#torch.Tensor.q_zero_point">q_zero_point() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.QConfig.html#torch.ao.quantization.qconfig.QConfig">QConfig (class in torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping">QConfigMapping (class in torch.ao.quantization.qconfig_mapping)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.QFunctional.html#torch.ao.nn.quantized.QFunctional">QFunctional (class in torch.ao.nn.quantized)</a>
</li>
      <li><a href="storage.html#torch.QInt32Storage">QInt32Storage (class in torch)</a>
</li>
      <li><a href="storage.html#torch.QInt8Storage">QInt8Storage (class in torch)</a>
</li>
      <li><a href="generated/torch.qr.html#torch.qr">qr() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.qr.html#torch.linalg.qr">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.qr.html#torch.Tensor.qr">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.qscheme.html#torch.Tensor.qscheme">qscheme() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.quantile.html#torch.quantile">quantile() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.quantile.html#torch.Tensor.quantile">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.quantize.html#torch.ao.quantization.quantize">quantize (class in torch.ao.quantization)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.ao.quantization.quantize_dynamic.html#torch.ao.quantization.quantize_dynamic">quantize_dynamic (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.quantize_per_channel.html#torch.quantize_per_channel">quantize_per_channel() (in module torch)</a>
</li>
      <li><a href="generated/torch.quantize_per_tensor.html#torch.quantize_per_tensor">quantize_per_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.quantize_qat.html#torch.ao.quantization.quantize_qat">quantize_qat (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.quantized_batch_norm.html#torch.quantized_batch_norm">quantized_batch_norm() (in module torch)</a>
</li>
      <li><a href="generated/torch.quantized_max_pool1d.html#torch.quantized_max_pool1d">quantized_max_pool1d() (in module torch)</a>
</li>
      <li><a href="generated/torch.quantized_max_pool2d.html#torch.quantized_max_pool2d">quantized_max_pool2d() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.QuantStub.html#torch.ao.quantization.QuantStub">QuantStub (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.ao.quantization.QuantWrapper.html#torch.ao.quantization.QuantWrapper">QuantWrapper (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.query">query() (torch.cuda.Event method)</a>

      <ul>
        <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream.query">(torch.cuda.ExternalStream method)</a>
</li>
        <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream.query">(torch.cuda.Stream method)</a>
</li>
        <li><a href="generated/torch.mps.event.Event.html#torch.mps.event.Event.query">(torch.mps.event.Event method)</a>
</li>
        <li><a href="generated/torch.xpu.Event.html#torch.xpu.Event.query">(torch.xpu.Event method)</a>
</li>
        <li><a href="generated/torch.xpu.Stream.html#torch.xpu.Stream.query">(torch.xpu.Stream method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.QUInt2x4Storage">QUInt2x4Storage (class in torch)</a>
</li>
      <li><a href="storage.html#torch.QUInt4x2Storage">QUInt4x2Storage (class in torch)</a>
</li>
      <li><a href="storage.html#torch.QUInt8Storage">QUInt8Storage (class in torch)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="R">R</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.rad2deg.html#torch.rad2deg">rad2deg() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.rad2deg.html#torch.Tensor.rad2deg">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam">RAdam (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.rand.html#torch.rand">rand() (in module torch)</a>
</li>
      <li><a href="generated/torch.rand_like.html#torch.rand_like">rand_like() (in module torch)</a>
</li>
      <li><a href="generated/torch.randint.html#torch.randint">randint() (in module torch)</a>
</li>
      <li><a href="generated/torch.randint_like.html#torch.randint_like">randint_like() (in module torch)</a>
</li>
      <li><a href="generated/torch.randn.html#torch.randn">randn() (in module torch)</a>
</li>
      <li><a href="generated/torch.randn_like.html#torch.randn_like">randn_like() (in module torch)</a>
</li>
      <li><a href="generated/torch.Tensor.random_.html#torch.Tensor.random_">random_() (torch.Tensor method)</a>
</li>
      <li><a href="data.html#torch.utils.data.random_split">random_split() (in module torch.utils.data)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.random_structured.html#torch.nn.utils.prune.random_structured">random_structured() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.random_unstructured.html#torch.nn.utils.prune.random_unstructured">random_unstructured() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="data.html#torch.utils.data.RandomSampler">RandomSampler (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured">RandomStructured (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured">RandomUnstructured (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.randperm.html#torch.randperm">randperm() (in module torch)</a>
</li>
      <li><a href="generated/torch.range.html#torch.range">range() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.nvtx.range.html#torch.cuda.nvtx.range">(in module torch.cuda.nvtx)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.nvtx.range_pop.html#torch.cuda.nvtx.range_pop">range_pop() (in module torch.cuda.nvtx)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler.itt.range_pop">(in module torch.profiler.itt)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.nvtx.range_push.html#torch.cuda.nvtx.range_push">range_push() (in module torch.cuda.nvtx)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler.itt.range_push">(in module torch.profiler.itt)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.inverse_gamma.InverseGamma.rate">rate (torch.distributions.inverse_gamma.InverseGamma property)</a>
</li>
      <li><a href="generated/torch.ravel.html#torch.ravel">ravel() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ravel.html#torch.Tensor.ravel">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.read_data">read_data() (torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.read_data">(torch.distributed.checkpoint.StorageReader method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.read_metadata">read_metadata() (torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.read_metadata">(torch.distributed.checkpoint.StorageReader method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.ReadItem">ReadItem (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="generated/torch.Tensor.real.html#torch.Tensor.real">real (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.real.html#torch.real">real() (in module torch)</a>
</li>
      <li><a href="generated/torch.reciprocal.html#torch.reciprocal">reciprocal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.reciprocal.html#torch.Tensor.reciprocal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.reciprocal_.html#torch.Tensor.reciprocal_">reciprocal_() (torch.Tensor method)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule.recompile">recompile() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="elastic/events.html#torch.distributed.elastic.events.record">record() (in module torch.distributed.elastic.events)</a>

      <ul>
        <li><a href="elastic/errors.html#torch.distributed.elastic.multiprocessing.errors.record">(in module torch.distributed.elastic.multiprocessing.errors)</a>
</li>
        <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.record">(torch.cuda.Event method)</a>
</li>
        <li><a href="generated/torch.mps.event.Event.html#torch.mps.event.Event.record">(torch.mps.event.Event method)</a>
</li>
        <li><a href="generated/torch.xpu.Event.html#torch.xpu.Event.record">(torch.xpu.Event method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream.record_event">record_event() (torch.cuda.ExternalStream method)</a>

      <ul>
        <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream.record_event">(torch.cuda.Stream method)</a>
</li>
        <li><a href="generated/torch.xpu.Stream.html#torch.xpu.Stream.record_event">(torch.xpu.Stream method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.profiler.record_function.html#torch.autograd.profiler.record_function">record_function (class in torch.autograd.profiler)</a>
</li>
      <li><a href="generated/torch.Tensor.record_stream.html#torch.Tensor.record_stream">record_stream() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.RecordingObserver.html#torch.ao.quantization.observer.RecordingObserver">RecordingObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="distributed.html#torch.distributed.recv">recv() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.reduce">reduce() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.cuda.comm.reduce_add.html#torch.cuda.comm.reduce_add">reduce_add() (in module torch.cuda.comm)</a>
</li>
      <li><a href="distributed.html#torch.distributed.reduce_op">reduce_op (class in torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.reduce_scatter">reduce_scatter() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.reduce_scatter_tensor">reduce_scatter_tensor() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html#torch.optim.lr_scheduler.ReduceLROnPlateau">ReduceLROnPlateau (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="distributed.html#torch.distributed.ReduceOp">ReduceOp (class in torch.distributed)</a>
</li>
      <li><a href="named_tensor.html#torch.Tensor.refine_names">refine_names() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.ReflectionPad1d.html#torch.nn.ReflectionPad1d">ReflectionPad1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ReflectionPad2d.html#torch.nn.ReflectionPad2d">ReflectionPad2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ReflectionPad3d.html#torch.nn.ReflectionPad3d">ReflectionPad3d (class in torch.nn)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry.register">register() (torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.constraint_registry.ConstraintRegistry.register">(torch.distributions.constraint_registry.ConstraintRegistry method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.Backend.register_backend">register_backend() (torch.distributed.Backend class method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_backward_hook">register_backward_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_backward_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_buffer">register_buffer() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_buffer">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.register_comm_hook">register_comm_hook() (torch.distributed.fsdp.FullyShardedDataParallel method)</a>

      <ul>
        <li><a href="generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.register_comm_hook">(torch.nn.parallel.DistributedDataParallel method)</a>
</li>
      </ul></li>
      <li><a href="onnx_torchscript.html#torch.onnx.register_custom_op_symbolic">register_custom_op_symbolic() (in module torch.onnx)</a>
</li>
      <li><a href="export.html#torch.export.register_dataclass">register_dataclass() (in module torch.export)</a>
</li>
      <li><a href="monitor.html#torch.monitor.register_event_handler">register_event_handler() (in module torch.monitor)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.register_extern_hook">register_extern_hook() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_forward_hook">register_forward_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_forward_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_forward_pre_hook">register_forward_pre_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_forward_pre_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_full_backward_hook">register_full_backward_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_full_backward_pre_hook">register_full_backward_pre_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_pre_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.graph.Node.register_hook.html#torch.autograd.graph.Node.register_hook">register_hook() (torch.autograd.graph.Node method)</a>

      <ul>
        <li><a href="generated/torch.Tensor.register_hook.html#torch.Tensor.register_hook">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.PackageExporter.register_intern_hook">register_intern_hook() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.kl.register_kl">register_kl() (in module torch.distributions.kl)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_load_state_dict_post_hook">register_load_state_dict_post_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_load_state_dict_post_hook">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.register_load_state_dict_post_hook">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.register_load_state_dict_post_hook">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.register_load_state_dict_post_hook">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.register_load_state_dict_post_hook">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.register_load_state_dict_post_hook">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.register_load_state_dict_post_hook">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.register_load_state_dict_post_hook">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.register_load_state_dict_post_hook">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.register_load_state_dict_post_hook">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.register_load_state_dict_post_hook">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.register_load_state_dict_post_hook">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.register_load_state_dict_post_hook">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.register_load_state_dict_post_hook">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.register_load_state_dict_pre_hook">register_load_state_dict_pre_hook() (torch.optim.Adadelta method)</a>

      <ul>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.register_load_state_dict_pre_hook">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.register_load_state_dict_pre_hook">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.register_load_state_dict_pre_hook">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.register_load_state_dict_pre_hook">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.register_load_state_dict_pre_hook">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.register_load_state_dict_pre_hook">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.register_load_state_dict_pre_hook">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.register_load_state_dict_pre_hook">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.register_load_state_dict_pre_hook">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.register_load_state_dict_pre_hook">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.register_load_state_dict_pre_hook">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.register_load_state_dict_pre_hook">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.PackageExporter.register_mock_hook">register_mock_hook() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_module">register_module() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_module">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.modules.module.register_module_backward_hook.html#torch.nn.modules.module.register_module_backward_hook">register_module_backward_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_buffer_registration_hook.html#torch.nn.modules.module.register_module_buffer_registration_hook">register_module_buffer_registration_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_forward_hook.html#torch.nn.modules.module.register_module_forward_hook">register_module_forward_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_forward_pre_hook.html#torch.nn.modules.module.register_module_forward_pre_hook">register_module_forward_pre_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_full_backward_hook.html#torch.nn.modules.module.register_module_full_backward_hook">register_module_full_backward_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_full_backward_pre_hook.html#torch.nn.modules.module.register_module_full_backward_pre_hook">register_module_full_backward_pre_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_module_registration_hook.html#torch.nn.modules.module.register_module_module_registration_hook">register_module_module_registration_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_parameter_registration_hook.html#torch.nn.modules.module.register_module_parameter_registration_hook">register_module_parameter_registration_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.register_multi_grad_hook">register_multi_grad_hook (class in torch.autograd.graph)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.OnnxRegistry.register_op">register_op() (torch.onnx.OnnxRegistry method)</a>
</li>
      <li><a href="notes/serialization.html#torch.serialization.register_package">register_package() (in module torch.serialization)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_parameter">register_parameter() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_parameter">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.parametrize.register_parametrization.html#torch.nn.utils.parametrize.register_parametrization">register_parametrization() (in module torch.nn.utils.parametrize)</a>
</li>
      <li><a href="generated/torch.Tensor.register_post_accumulate_grad_hook.html#torch.Tensor.register_post_accumulate_grad_hook">register_post_accumulate_grad_hook() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.autograd.graph.Node.register_prehook.html#torch.autograd.graph.Node.register_prehook">register_prehook() (torch.autograd.graph.Node method)</a>
</li>
      <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.register_state_dict_post_hook">register_state_dict_post_hook() (torch.optim.Adadelta method)</a>

      <ul>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.register_state_dict_post_hook">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.register_state_dict_post_hook">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.register_state_dict_post_hook">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.register_state_dict_post_hook">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.register_state_dict_post_hook">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.register_state_dict_post_hook">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.register_state_dict_post_hook">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.register_state_dict_post_hook">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.register_state_dict_post_hook">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.register_state_dict_post_hook">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.register_state_dict_post_hook">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.register_state_dict_post_hook">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_state_dict_pre_hook">register_state_dict_pre_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_state_dict_pre_hook">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.register_state_dict_pre_hook">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.register_state_dict_pre_hook">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.register_state_dict_pre_hook">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.register_state_dict_pre_hook">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.register_state_dict_pre_hook">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.register_state_dict_pre_hook">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.register_state_dict_pre_hook">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.register_state_dict_pre_hook">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.register_state_dict_pre_hook">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.register_state_dict_pre_hook">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.register_state_dict_pre_hook">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.register_state_dict_pre_hook">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.register_state_dict_pre_hook">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.register_step_post_hook">register_step_post_hook() (torch.optim.Adadelta method)</a>

      <ul>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.register_step_post_hook">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.register_step_post_hook">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.register_step_post_hook">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.register_step_post_hook">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.register_step_post_hook">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.register_step_post_hook">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.register_step_post_hook">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.register_step_post_hook">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.register_step_post_hook">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.register_step_post_hook">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.register_step_post_hook">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.register_step_post_hook">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.register_step_pre_hook">register_step_pre_hook() (torch.optim.Adadelta method)</a>

      <ul>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.register_step_pre_hook">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.register_step_pre_hook">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.register_step_pre_hook">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.register_step_pre_hook">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.register_step_pre_hook">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.register_step_pre_hook">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.register_step_pre_hook">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.register_step_pre_hook">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.register_step_pre_hook">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.register_step_pre_hook">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.register_step_pre_hook">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.register_step_pre_hook">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerServer.register_timers">register_timers() (torch.distributed.elastic.timer.TimerServer method)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.DefaultLogsSpecs.reify">reify() (torch.distributed.elastic.multiprocessing.api.DefaultLogsSpecs method)</a>

      <ul>
        <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.LogsSpecs.reify">(torch.distributed.elastic.multiprocessing.api.LogsSpecs method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.rekey_optim_state_dict">rekey_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli">RelaxedBernoulli (class in torch.distributions.relaxed_bernoulli)</a>
</li>
      <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical">RelaxedOneHotCategorical (class in torch.distributions.relaxed_categorical)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.RelaxedUnspecConstraint.html#torch.fx.experimental.symbolic_shapes.RelaxedUnspecConstraint">RelaxedUnspecConstraint (class in torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerClient.release">release() (torch.distributed.elastic.timer.TimerClient method)</a>
</li>
      <li><a href="generated/torch.nn.ReLU.html#torch.nn.ReLU">ReLU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.relu.html#torch.nn.functional.relu">relu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.ReLU6.html#torch.ao.nn.quantized.ReLU6">ReLU6 (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.ReLU6.html#torch.nn.ReLU6">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.relu6.html#torch.nn.functional.relu6">relu6() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.relu_.html#torch.nn.functional.relu_">relu_() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.remainder.html#torch.remainder">remainder() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.remainder.html#torch.Tensor.remainder">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.remainder_.html#torch.Tensor.remainder_">remainder_() (torch.Tensor method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.remote">remote() (in module torch.distributed.rpc)</a>

      <ul>
        <li><a href="rpc.html#torch.distributed.rpc.PyRRef.remote">(torch.distributed.rpc.PyRRef method)</a>
</li>
      </ul></li>
      <li><a href="rpc.html#torch.distributed.nn.api.remote_module.RemoteModule.remote_parameters">remote_parameters() (torch.distributed.nn.api.remote_module.RemoteModule method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.nn.api.remote_module.RemoteModule">RemoteModule (class in torch.distributed.nn.api.remote_module)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.remove.html#torch.nn.utils.prune.remove">remove() (in module torch.nn.utils.prune)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.remove">(torch.nn.utils.prune.BasePruningMethod method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.remove">(torch.nn.utils.prune.CustomFromMask method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.remove">(torch.nn.utils.prune.Identity method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.remove">(torch.nn.utils.prune.L1Unstructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.remove">(torch.nn.utils.prune.LnStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.remove">(torch.nn.utils.prune.PruningContainer method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.remove">(torch.nn.utils.prune.RandomStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.remove">(torch.nn.utils.prune.RandomUnstructured method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.parametrize.remove_parametrizations.html#torch.nn.utils.parametrize.remove_parametrizations">remove_parametrizations() (in module torch.nn.utils.parametrize)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.DimConstraints.html#torch.fx.experimental.symbolic_shapes.DimConstraints.remove_redundant_dynamic_results">remove_redundant_dynamic_results() (torch.fx.experimental.symbolic_shapes.DimConstraints method)</a>
</li>
      <li><a href="generated/torch.nn.utils.remove_spectral_norm.html#torch.nn.utils.remove_spectral_norm">remove_spectral_norm() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.nn.utils.remove_weight_norm.html#torch.nn.utils.remove_weight_norm">remove_weight_norm() (in module torch.nn.utils)</a>
</li>
      <li><a href="named_tensor.html#torch.Tensor.rename">rename() (torch.Tensor method)</a>
</li>
      <li><a href="named_tensor.html#torch.Tensor.rename_">rename_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.utils.rename_privateuse1_backend.html#torch.utils.rename_privateuse1_backend">rename_privateuse1_backend() (in module torch.utils)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.rename_unbacked_to.html#torch.fx.experimental.symbolic_shapes.rename_unbacked_to">rename_unbacked_to() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint.html#torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint.render">render() (torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint method)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend">RendezvousBackend (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousClosedError">RendezvousClosedError (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousConnectionError">RendezvousConnectionError (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousError">RendezvousError (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousGracefulExitError">RendezvousGracefulExitError (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler">RendezvousHandler (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry">RendezvousHandlerRegistry (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousParameters">RendezvousParameters (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousStateError">RendezvousStateError (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout">RendezvousTimeout (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousTimeoutError">RendezvousTimeoutError (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="generated/torch.renorm.html#torch.renorm">renorm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.renorm.html#torch.Tensor.renorm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.renorm_.html#torch.Tensor.renorm_">renorm_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.repeat.html#torch.Tensor.repeat">repeat() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.repeat_interleave.html#torch.repeat_interleave">repeat_interleave() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.repeat_interleave.html#torch.Tensor.repeat_interleave">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.replace">replace() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.func.replace_all_batch_norm_modules_.html#torch.func.replace_all_batch_norm_modules_">replace_all_batch_norm_modules_() (in module torch.func)</a>
</li>
      <li><a href="export.html#torch.export.graph_signature.ExportGraphSignature.replace_all_uses">replace_all_uses() (torch.export.graph_signature.ExportGraphSignature method)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.replace_all_uses_with">replace_all_uses_with() (torch.fx.Node method)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.replace_input_with">replace_input_with() (torch.fx.Node method)</a>
</li>
      <li><a href="fx.html#torch.fx.replace_pattern">replace_pattern() (in module torch.fx)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.replay">replay() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="generated/torch.nn.ReplicationPad1d.html#torch.nn.ReplicationPad1d">ReplicationPad1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ReplicationPad2d.html#torch.nn.ReplicationPad2d">ReplicationPad2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ReplicationPad3d.html#torch.nn.ReplicationPad3d">ReplicationPad3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.Tensor.requires_grad.html#torch.Tensor.requires_grad">requires_grad (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.requires_grad_">requires_grad_() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.requires_grad_">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.requires_grad_.html#torch.Tensor.requires_grad_">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.compiler.reset.html#torch.compiler.reset">reset() (in module torch.compiler)</a>

      <ul>
        <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.reset">(torch.cuda.CUDAGraph method)</a>
</li>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.reset">(torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader method)</a>
</li>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.reset">(torch.distributed.checkpoint.StorageReader method)</a>
</li>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.reset">(torch.distributed.checkpoint.StorageWriter method)</a>
</li>
        <li><a href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine.reset">(torch.quasirandom.SobolEngine method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.reset_max_memory_allocated.html#torch.cuda.reset_max_memory_allocated">reset_max_memory_allocated() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.reset_max_memory_cached.html#torch.cuda.reset_max_memory_cached">reset_max_memory_cached() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.MinMaxObserver.html#torch.ao.quantization.observer.MinMaxObserver.reset_min_max_vals">reset_min_max_vals() (torch.ao.quantization.observer.MinMaxObserver method)</a>

      <ul>
        <li><a href="generated/torch.ao.quantization.observer.PerChannelMinMaxObserver.html#torch.ao.quantization.observer.PerChannelMinMaxObserver.reset_min_max_vals">(torch.ao.quantization.observer.PerChannelMinMaxObserver method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.reset_peak_memory_stats.html#torch.cuda.reset_peak_memory_stats">reset_peak_memory_stats() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.reshape.html#torch.reshape">reshape() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.reshape.html#torch.Tensor.reshape">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.reshape_as.html#torch.Tensor.reshape_as">reshape_as() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.ReshapeTransform">ReshapeTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.resizable">resizable() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.resizable">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.resize_.html#torch.Tensor.resize_">resize_() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.resize_">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.resize_">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.resize_as_.html#torch.Tensor.resize_as_">resize_as_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.resolve_conj.html#torch.resolve_conj">resolve_conj() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.resolve_conj.html#torch.Tensor.resolve_conj">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.resolve_data">resolve_data() (torch.distributed.checkpoint.SavePlanner method)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.resolve_name">resolve_name() (in module torch.overrides)</a>
</li>
      <li><a href="generated/torch.resolve_neg.html#torch.resolve_neg">resolve_neg() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.resolve_neg.html#torch.Tensor.resolve_neg">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.resolve_tensor">resolve_tensor() (torch.distributed.checkpoint.LoadPlanner method)</a>
</li>
      <li><a href="generated/torch.result_type.html#torch.result_type">result_type() (in module torch)</a>
</li>
      <li><a href="generated/torch.Tensor.retain_grad.html#torch.Tensor.retain_grad">retain_grad() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.retains_grad.html#torch.Tensor.retains_grad">retains_grad (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.DimConstraints.html#torch.fx.experimental.symbolic_shapes.DimConstraints.rewrite_with_congruences">rewrite_with_congruences() (torch.fx.experimental.symbolic_shapes.DimConstraints method)</a>
</li>
      <li><a href="generated/torch.fft.rfft.html#torch.fft.rfft">rfft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.rfft2.html#torch.fft.rfft2">rfft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.rfftfreq.html#torch.fft.rfftfreq">rfftfreq() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.rfftn.html#torch.fft.rfftn">rfftn() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.nn.utils.parametrize.ParametrizationList.html#torch.nn.utils.parametrize.ParametrizationList.right_inverse">right_inverse() (torch.nn.utils.parametrize.ParametrizationList method)</a>
</li>
      <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop">RMSprop (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.nn.RNN.html#torch.nn.RNN">RNN (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.RNNBase.html#torch.nn.RNNBase">RNNBase (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.dynamic.RNNCell.html#torch.ao.nn.quantized.dynamic.RNNCell">RNNCell (class in torch.ao.nn.quantized.dynamic)</a>

      <ul>
        <li><a href="generated/torch.nn.RNNCell.html#torch.nn.RNNCell">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.roll.html#torch.roll">roll() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.roll.html#torch.Tensor.roll">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.rot90.html#torch.rot90">rot90() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.rot90.html#torch.Tensor.rot90">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.round.html#torch.round">round() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.round">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.round.html#torch.Tensor.round">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.round_.html#torch.Tensor.round_">round_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.row_indices.html#torch.Tensor.row_indices">row_indices() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.row_stack.html#torch.row_stack">row_stack() (in module torch)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.RowwiseParallel">RowwiseParallel (class in torch.distributed.tensor.parallel)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.rpc_async">rpc_async() (in module torch.distributed.rpc)</a>

      <ul>
        <li><a href="rpc.html#torch.distributed.rpc.PyRRef.rpc_async">(torch.distributed.rpc.PyRRef method)</a>
</li>
      </ul></li>
      <li><a href="rpc.html#torch.distributed.rpc.rpc_sync">rpc_sync() (in module torch.distributed.rpc)</a>

      <ul>
        <li><a href="rpc.html#torch.distributed.rpc.PyRRef.rpc_sync">(torch.distributed.rpc.PyRRef method)</a>
</li>
      </ul></li>
      <li><a href="rpc.html#torch.distributed.rpc.RpcBackendOptions.rpc_timeout">rpc_timeout (torch.distributed.rpc.RpcBackendOptions property)</a>

      <ul>
        <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.rpc_timeout">(torch.distributed.rpc.TensorPipeRpcBackendOptions property)</a>
</li>
      </ul></li>
      <li><a href="rpc.html#torch.distributed.rpc.RpcBackendOptions">RpcBackendOptions (class in torch.distributed.rpc)</a>
</li>
      <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop">Rprop (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.nn.RReLU.html#torch.nn.RReLU">RReLU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.rrelu.html#torch.nn.functional.rrelu">rrelu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.rrelu_.html#torch.nn.functional.rrelu_">rrelu_() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.beta.Beta.rsample">rsample() (torch.distributions.beta.Beta method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.rsample">(torch.distributions.cauchy.Cauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.rsample">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.rsample">(torch.distributions.dirichlet.Dirichlet method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.rsample">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.rsample">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.rsample">(torch.distributions.fishersnedecor.FisherSnedecor method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.rsample">(torch.distributions.gamma.Gamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.rsample">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.rsample">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.rsample">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.rsample">(torch.distributions.multivariate_normal.MultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.rsample">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.rsample">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.rsample">(torch.distributions.studentT.StudentT method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.rsample">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.rsample">(torch.distributions.uniform.Uniform method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.rsample">(torch.distributions.wishart.Wishart method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.rsqrt.html#torch.rsqrt">rsqrt() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.rsqrt.html#torch.Tensor.rsqrt">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.rsqrt_.html#torch.Tensor.rsqrt_">rsqrt_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.ElasticAgent.run">run() (torch.distributed.elastic.agent.server.ElasticAgent method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.run">(torch.fx.Interpreter method)</a>
</li>
      </ul></li>
      <li><a href="export.html#torch.export.ExportedProgram.run_decompositions">run_decompositions() (torch.export.ExportedProgram method)</a>
</li>
      <li><a href="fx.html#torch.fx.Interpreter.run_node">run_node() (torch.fx.Interpreter method)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.RunProcsResult">RunProcsResult (class in torch.distributed.elastic.multiprocessing.api)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.api.RunResult">RunResult (class in torch.distributed.elastic.agent.server.api)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="S">S</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.sample">sample() (torch.distributions.bernoulli.Bernoulli method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.sample">(torch.distributions.binomial.Binomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.sample">(torch.distributions.categorical.Categorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.sample">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.sample">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.sample">(torch.distributions.geometric.Geometric method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.sample">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky.sample">(torch.distributions.lkj_cholesky.LKJCholesky method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.sample">(torch.distributions.mixture_same_family.MixtureSameFamily method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.sample">(torch.distributions.multinomial.Multinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.sample">(torch.distributions.negative_binomial.NegativeBinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.sample">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.sample">(torch.distributions.one_hot_categorical.OneHotCategorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.sample">(torch.distributions.poisson.Poisson method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.sample">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.sample">(torch.distributions.von_mises.VonMises method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution.sample_n">sample_n() (torch.distributions.distribution.Distribution method)</a>
</li>
      <li><a href="generated/torch.sparse.sampled_addmm.html#torch.sparse.sampled_addmm">sampled_addmm() (in module torch.sparse)</a>
</li>
      <li><a href="data.html#torch.utils.data.Sampler">Sampler (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.save.html#torch.save">save() (in module torch)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict_saver.save">(in module torch.distributed.checkpoint.state_dict_saver)</a>
</li>
        <li><a href="export.html#torch.export.save">(in module torch.export)</a>
</li>
        <li><a href="generated/torch.jit.save.html#torch.jit.save">(in module torch.jit)</a>
</li>
        <li><a href="generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction.save">(torch.jit.ScriptFunction method)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.save">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="onnx_dynamo.html#torch.onnx.ONNXProgram.save">(torch.onnx.ONNXProgram method)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.PackageExporter.save_binary">save_binary() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.ONNXProgram.save_diagnostics">save_diagnostics() (torch.onnx.ONNXProgram method)</a>
</li>
      <li><a href="generated/torch.autograd.function.BackwardCFunction.html#torch.autograd.function.BackwardCFunction.save_for_backward">save_for_backward() (torch.autograd.function.BackwardCFunction method)</a>

      <ul>
        <li><a href="generated/torch.autograd.function.FunctionCtx.save_for_backward.html#torch.autograd.function.FunctionCtx.save_for_backward">(torch.autograd.function.FunctionCtx method)</a>
</li>
        <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction.save_for_backward">(torch.autograd.function.InplaceFunction method)</a>
</li>
        <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.save_for_backward">(torch.autograd.function.NestedIOFunction method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.function.BackwardCFunction.html#torch.autograd.function.BackwardCFunction.save_for_forward">save_for_forward() (torch.autograd.function.BackwardCFunction method)</a>

      <ul>
        <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction.save_for_forward">(torch.autograd.function.InplaceFunction method)</a>
</li>
        <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.save_for_forward">(torch.autograd.function.NestedIOFunction method)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.PackageExporter.save_module">save_module() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.save_on_cpu">save_on_cpu (class in torch.autograd.graph)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.save_pickle">save_pickle() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.save_source_file">save_source_file() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.save_source_string">save_source_string() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict_saver.save_state_dict">save_state_dict() (in module torch.distributed.checkpoint.state_dict_saver)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.save_text">save_text() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction.save_to_buffer">save_to_buffer() (torch.jit.ScriptFunction method)</a>
</li>
      <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.saved_tensors">saved_tensors (torch.autograd.function.NestedIOFunction property)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.saved_tensors_hooks">saved_tensors_hooks (class in torch.autograd.graph)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlan">SavePlan (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner">SavePlanner (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.scalar_name">scalar_name() (torch.onnx.JitScalarType method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.scale">scale (torch.distributions.half_cauchy.HalfCauchy property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.scale">(torch.distributions.half_normal.HalfNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.scale">(torch.distributions.log_normal.LogNormal property)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.scale_tril">scale_tril (torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.scale_tril">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.scaled_dot_product_attention.html#torch.nn.functional.scaled_dot_product_attention">scaled_dot_product_attention() (in module torch.nn.functional)</a>
</li>
      <li><a href="special.html#torch.special.scaled_modified_bessel_k0">scaled_modified_bessel_k0() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.scaled_modified_bessel_k1">scaled_modified_bessel_k1() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.scatter.html#torch.scatter">scatter() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.comm.scatter.html#torch.cuda.comm.scatter">(in module torch.cuda.comm)</a>
</li>
        <li><a href="distributed.html#torch.distributed.scatter">(in module torch.distributed)</a>
</li>
        <li><a href="generated/torch.Tensor.scatter.html#torch.Tensor.scatter">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_">scatter_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.scatter_add.html#torch.scatter_add">scatter_add() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.scatter_add.html#torch.Tensor.scatter_add">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_">scatter_add_() (torch.Tensor method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.scatter_full_optim_state_dict">scatter_full_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.scatter_object_list">scatter_object_list() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.scatter_reduce.html#torch.scatter_reduce">scatter_reduce() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.scatter_reduce.html#torch.Tensor.scatter_reduce">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.scatter_reduce_.html#torch.Tensor.scatter_reduce_">scatter_reduce_() (torch.Tensor method)</a>
</li>
      <li><a href="profiler.html#torch.profiler.schedule">schedule() (in module torch.profiler)</a>
</li>
      <li><a href="generated/torch.jit.script.html#torch.jit.script">script() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.jit.script_if_tracing.html#torch.jit.script_if_tracing">script_if_tracing() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction">ScriptFunction (class in torch.jit)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule">ScriptModule (class in torch.jit)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.sdp_kernel">sdp_kernel() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.nn.attention.sdpa_kernel.html#torch.nn.attention.sdpa_kernel">sdpa_kernel() (in module torch.nn.attention)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.SDPAParams">SDPAParams (class in torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.nn.attention.SDPBackend.html#torch.nn.attention.SDPBackend">SDPBackend (class in torch.nn.attention)</a>
</li>
      <li><a href="generated/torch.searchsorted.html#torch.searchsorted">searchsorted() (in module torch)</a>
</li>
      <li><a href="generated/torch.autograd.profiler.EnforceUnique.html#torch.autograd.profiler.EnforceUnique.see">see() (torch.autograd.profiler.EnforceUnique method)</a>
</li>
      <li><a href="generated/torch.seed.html#torch.seed">seed() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.seed.html#torch.cuda.seed">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.mps.seed.html#torch.mps.seed">(in module torch.mps)</a>
</li>
        <li><a href="random.html#torch.random.seed">(in module torch.random)</a>
</li>
        <li><a href="generated/torch.xpu.seed.html#torch.xpu.seed">(in module torch.xpu)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.seed">(torch.Generator method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.seed_all.html#torch.cuda.seed_all">seed_all() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.xpu.seed_all.html#torch.xpu.seed_all">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.select.html#torch.select">select() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.select.html#torch.Tensor.select">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="onnx_torchscript.html#torch.onnx.select_model_mode_for_export">select_model_mode_for_export() (in module torch.onnx)</a>
</li>
      <li><a href="generated/torch.select_scatter.html#torch.select_scatter">select_scatter() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.select_scatter.html#torch.Tensor.select_scatter">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.profiler.profile.self_cpu_time_total.html#torch.autograd.profiler.profile.self_cpu_time_total">self_cpu_time_total (torch.autograd.profiler.profile property)</a>
</li>
      <li><a href="generated/torch.nn.SELU.html#torch.nn.SELU">SELU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.selu.html#torch.nn.functional.selu">selu() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributed.html#torch.distributed.send">send() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.SequenceParallel">SequenceParallel (class in torch.distributed.tensor.parallel)</a>
</li>
      <li><a href="generated/torch.nn.Sequential.html#torch.nn.Sequential">Sequential (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.SequentialLR.html#torch.optim.lr_scheduler.SequentialLR">SequentialLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="data.html#torch.utils.data.SequentialSampler">SequentialSampler (class in torch.utils.data)</a>
</li>
      <li><a href="onnx_dynamo.html#torch.onnx.ONNXProgramSerializer.serialize">serialize() (torch.onnx.ONNXProgramSerializer method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store.set">set() (in module torch.distributed.Store)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.set">(torch.distributed.elastic.rendezvous.etcd_store.EtcdStore method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.set_.html#torch.Tensor.set_">set_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.set_backend_pattern_config">set_backend_pattern_config() (torch.ao.quantization.backend_config.BackendConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.set_backend_pattern_configs">set_backend_pattern_configs() (torch.ao.quantization.backend_config.BackendConfig method)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.set_buffer">set_buffer() (in module torch.distributed.GradBucket)</a>
</li>
      <li><a href="checkpoint.html#torch.utils.checkpoint.set_checkpoint_debug_enabled">set_checkpoint_debug_enabled() (in module torch.utils.checkpoint)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.set_closed">set_closed() (torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.set_codegen">set_codegen() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.set_default_device.html#torch.set_default_device">set_default_device() (in module torch)</a>
</li>
      <li><a href="generated/torch.set_default_dtype.html#torch.set_default_dtype">set_default_dtype() (in module torch)</a>
</li>
      <li><a href="notes/serialization.html#torch.serialization.set_default_load_endianness">set_default_load_endianness() (in module torch.serialization)</a>
</li>
      <li><a href="generated/torch.set_default_tensor_type.html#torch.set_default_tensor_type">set_default_tensor_type() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution.set_default_validate_args">set_default_validate_args() (torch.distributions.distribution.Distribution static method)</a>
</li>
      <li><a href="autograd.html#torch.autograd.set_detect_anomaly">set_detect_anomaly (class in torch.autograd)</a>
</li>
      <li><a href="generated/torch.set_deterministic_debug_mode.html#torch.set_deterministic_debug_mode">set_deterministic_debug_mode() (in module torch)</a>
</li>
      <li><a href="generated/torch.cpu.set_device.html#torch.cpu.set_device">set_device() (in module torch.cpu)</a>

      <ul>
        <li><a href="generated/torch.cuda.set_device.html#torch.cuda.set_device">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.xpu.set_device.html#torch.xpu.set_device">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.set_device_map">set_device_map() (torch.distributed.rpc.TensorPipeRpcBackendOptions method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.set_devices">set_devices() (torch.distributed.rpc.TensorPipeRpcBackendOptions method)</a>
</li>
      <li><a href="hub.html#torch.hub.set_dir">set_dir() (in module torch.hub)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_dtype_configs">set_dtype_configs() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.set_exception">set_exception() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.set_extra_state">set_extra_state() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.set_extra_state">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="backends.html#torch.backends.mha.set_fastpath_enabled">set_fastpath_enabled() (in module torch.backends.mha)</a>
</li>
      <li><a href="backends.html#torch.backends.nnpack.set_flags">set_flags() (in module torch.backends.nnpack)</a>
</li>
      <li><a href="generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision">set_float32_matmul_precision() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_float_to_observed_mapping">set_float_to_observed_mapping() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="generated/torch.set_flush_denormal.html#torch.set_flush_denormal">set_flush_denormal() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_fused_module">set_fused_module() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_fuser_method">set_fuser_method() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="generated/torch.jit.set_fusion_strategy.html#torch.jit.set_fusion_strategy">set_fusion_strategy() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.set_global">set_global() (torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      <li><a href="generated/torch.autograd.grad_mode.set_grad_enabled.html#torch.autograd.grad_mode.set_grad_enabled">set_grad_enabled (class in torch.autograd.grad_mode)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_input_quantized_indexes">set_input_quantized_indexes() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="generated/torch._logging.set_logs.html#torch._logging.set_logs">set_logs() (in module torch._logging)</a>
</li>
      <li><a href="generated/torch.autograd.function.BackwardCFunction.html#torch.autograd.function.BackwardCFunction.set_materialize_grads">set_materialize_grads() (torch.autograd.function.BackwardCFunction method)</a>

      <ul>
        <li><a href="generated/torch.autograd.function.FunctionCtx.set_materialize_grads.html#torch.autograd.function.FunctionCtx.set_materialize_grads">(torch.autograd.function.FunctionCtx method)</a>
</li>
        <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction.set_materialize_grads">(torch.autograd.function.InplaceFunction method)</a>
</li>
        <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.set_materialize_grads">(torch.autograd.function.NestedIOFunction method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.set_model_state_dict">set_model_state_dict() (in module torch.distributed.checkpoint.state_dict)</a>
</li>
      <li><a href="generated/torch.utils.set_module.html#torch.utils.set_module">set_module() (in module torch.utils)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name">set_module_name() (torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name_object_type_order">set_module_name_object_type_order() (torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name_regex">set_module_name_regex() (torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      <li><a href="generated/torch.autograd.grad_mode.set_multithreading_enabled.html#torch.autograd.grad_mode.set_multithreading_enabled">set_multithreading_enabled (class in torch.autograd.grad_mode)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.set_name">set_name() (torch.ao.quantization.backend_config.BackendConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_non_traceable_module_classes">set_non_traceable_module_classes() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_non_traceable_module_names">set_non_traceable_module_names() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="generated/torch.set_num_interop_threads.html#torch.set_num_interop_threads">set_num_interop_threads() (in module torch)</a>
</li>
      <li><a href="generated/torch.set_num_threads.html#torch.set_num_threads">set_num_threads() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.set_object_type">set_object_type() (torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_observation_type">set_observation_type() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.html#torch.ao.quantization.fx.custom_config.ConvertCustomConfig.set_observed_to_quantized_mapping">set_observed_to_quantized_mapping() (torch.ao.quantization.fx.custom_config.ConvertCustomConfig method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.set_optimizer_state_dict">set_optimizer_state_dict() (in module torch.distributed.checkpoint.state_dict)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_output_quantized_indexes">set_output_quantized_indexes() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="future_mod.html#torch.__future__.set_overwrite_module_params_on_conversion">set_overwrite_module_params_on_conversion() (in module torch.__future__)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_pattern">set_pattern() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="generated/torch.cuda.set_per_process_memory_fraction.html#torch.cuda.set_per_process_memory_fraction">set_per_process_memory_fraction() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.mps.set_per_process_memory_fraction.html#torch.mps.set_per_process_memory_fraction">(in module torch.mps)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.html#torch.ao.quantization.fx.custom_config.ConvertCustomConfig.set_preserved_attributes">set_preserved_attributes() (torch.ao.quantization.fx.custom_config.ConvertCustomConfig method)</a>

      <ul>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig.html#torch.ao.quantization.fx.custom_config.FuseCustomConfig.set_preserved_attributes">(torch.ao.quantization.fx.custom_config.FuseCustomConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_preserved_attributes">(torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.set_printoptions.html#torch.set_printoptions">set_printoptions() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_qat_module">set_qat_module() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_reference_quantized_module">set_reference_quantized_module() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.set_result">set_result() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.set_rng_state.html#torch.set_rng_state">set_rng_state() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.set_rng_state.html#torch.cuda.set_rng_state">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.mps.set_rng_state.html#torch.mps.set_rng_state">(in module torch.mps)</a>
</li>
        <li><a href="random.html#torch.random.set_rng_state">(in module torch.random)</a>
</li>
        <li><a href="generated/torch.xpu.set_rng_state.html#torch.xpu.set_rng_state">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.set_rng_state_all.html#torch.cuda.set_rng_state_all">set_rng_state_all() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.xpu.set_rng_state_all.html#torch.xpu.set_rng_state_all">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_root_module">set_root_module() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="multiprocessing.html#torch.multiprocessing.set_sharing_strategy">set_sharing_strategy() (in module torch.multiprocessing)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_standalone_module_class">set_standalone_module_class() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_standalone_module_name">set_standalone_module_name() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.set_state">set_state() (torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend method)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.set_state">(torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend method)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend.set_state">(torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend method)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.set_state">(torch.Generator method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.set_state_dict">set_state_dict() (in module torch.distributed.checkpoint.state_dict)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.set_state_dict_type">set_state_dict_type() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="generated/torch.cuda.set_stream.html#torch.cuda.set_stream">set_stream() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.xpu.set_stream.html#torch.xpu.set_stream">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="future_mod.html#torch.__future__.set_swap_module_params_on_conversion">set_swap_module_params_on_conversion() (in module torch.__future__)</a>
</li>
      <li><a href="generated/torch.cuda.set_sync_debug_mode.html#torch.cuda.set_sync_debug_mode">set_sync_debug_mode() (in module torch.cuda)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store.set_timeout">set_timeout() (in module torch.distributed.Store)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.DynamicMetaLoadPlanner.set_up_planner">set_up_planner() (torch.distributed.checkpoint.format_utils.DynamicMetaLoadPlanner method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.set_up_planner">(torch.distributed.checkpoint.LoadPlanner method)</a>
</li>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.set_up_planner">(torch.distributed.checkpoint.SavePlanner method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.set_up_storage_reader">set_up_storage_reader() (torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.set_up_storage_reader">(torch.distributed.checkpoint.StorageReader method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.set_up_storage_writer">set_up_storage_writer() (torch.distributed.checkpoint.StorageWriter method)</a>
</li>
      <li><a href="generated/torch.set_warn_always.html#torch.set_warn_always">set_warn_always() (in module torch)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.setdefault">setdefault() (torch.autograd.profiler_util.StringTable method)</a>

      <ul>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.setdefault">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction.setup_context">setup_context() (torch.autograd.function.InplaceFunction static method)</a>

      <ul>
        <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.setup_context">(torch.autograd.function.NestedIOFunction static method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD">SGD (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.sgn.html#torch.sgn">sgn() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sgn.html#torch.Tensor.sgn">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sgn_.html#torch.Tensor.sgn_">sgn_() (torch.Tensor method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow">Shadow (class in torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.ShadowLogger">ShadowLogger (class in torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="generated/torch.Tensor.shape.html#torch.Tensor.shape">shape (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv">ShapeEnv (class in torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.shard_full_optim_state_dict">shard_full_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.sharded_optim_state_dict">sharded_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.ShardedOptimStateDictConfig">ShardedOptimStateDictConfig (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.ShardedStateDictConfig">ShardedStateDictConfig (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.ShardingStrategy">ShardingStrategy (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.share_memory">share_memory() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.share_memory">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.share_memory_.html#torch.Tensor.share_memory_">share_memory_() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.share_memory_">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.share_memory_">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.short.html#torch.Tensor.short">short() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.short">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.short">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.ShortStorage">ShortStorage (class in torch)</a>
</li>
      <li><a href="config_mod.html#torch.__config__.show">show() (in module torch.__config__)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.shutdown">shutdown() (in module torch.distributed.rpc)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.shutdown">(torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.Sigmoid.html#torch.ao.nn.quantized.Sigmoid">Sigmoid (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.sigmoid.html#torch.sigmoid">sigmoid() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.nn.functional.sigmoid.html#torch.nn.functional.sigmoid">(in module torch.nn.functional)</a>
</li>
        <li><a href="generated/torch.Tensor.sigmoid.html#torch.Tensor.sigmoid">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sigmoid_.html#torch.Tensor.sigmoid_">sigmoid_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.SigmoidTransform">SigmoidTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform.sign">sign (torch.distributions.transforms.Transform property)</a>
</li>
      <li><a href="generated/torch.sign.html#torch.sign">sign() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sign.html#torch.Tensor.sign">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sign_.html#torch.Tensor.sign_">sign_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.signbit.html#torch.signbit">signbit() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.signbit.html#torch.Tensor.signbit">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Measurement.significant_figures">significant_figures (torch.utils.benchmark.Measurement property)</a>
</li>
      <li><a href="generated/torch.nn.SiLU.html#torch.nn.SiLU">SiLU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.silu.html#torch.nn.functional.silu">silu() (in module torch.nn.functional)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent">SimpleElasticAgent (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.simplify">simplify() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.sin.html#torch.sin">sin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sin.html#torch.Tensor.sin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sin_.html#torch.Tensor.sin_">sin_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.sinc.html#torch.sinc">sinc() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.sinc">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.sinc.html#torch.Tensor.sinc">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sinc_.html#torch.Tensor.sinc_">sinc_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.sinh.html#torch.sinh">sinh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sinh.html#torch.Tensor.sinh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sinh_.html#torch.Tensor.sinh_">sinh_() (torch.Tensor method)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.cufft_plan_cache.size">size (in module torch.backends.cuda.cufft_plan_cache)</a>
</li>
      <li><a href="generated/torch.Tensor.size.html#torch.Tensor.size">size() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.size">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.size">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.size_hint">size_hint() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.nn.utils.skip_init.html#torch.nn.utils.skip_init">skip_init() (in module torch.nn.utils)</a>
</li>
      <li><a href="pipeline.html#torch.distributed.pipeline.sync.skip.skippable.skippable">skippable() (in module torch.distributed.pipeline.sync.skip.skippable)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.slice_scatter.html#torch.slice_scatter">slice_scatter() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.slice_scatter.html#torch.Tensor.slice_scatter">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.slogdet.html#torch.slogdet">slogdet() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.slogdet.html#torch.linalg.slogdet">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.slogdet.html#torch.Tensor.slogdet">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.smm.html#torch.smm">smm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.smm.html#torch.Tensor.smm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.smooth_l1_loss.html#torch.nn.functional.smooth_l1_loss">smooth_l1_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.SmoothL1Loss.html#torch.nn.SmoothL1Loss">SmoothL1Loss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine">SobolEngine (class in torch.quasirandom)</a>
</li>
      <li><a href="generated/torch.nn.functional.soft_margin_loss.html#torch.nn.functional.soft_margin_loss">soft_margin_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.SoftMarginLoss.html#torch.nn.SoftMarginLoss">SoftMarginLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.Softmax.html#torch.nn.Softmax">Softmax (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.softmax.html#torch.softmax">softmax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax">(in module torch.nn.functional)</a>
</li>
        <li><a href="generated/torch.sparse.softmax.html#torch.sparse.softmax">(in module torch.sparse)</a>
</li>
        <li><a href="special.html#torch.special.softmax">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.softmax.html#torch.Tensor.softmax">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.Softmax2d.html#torch.nn.Softmax2d">Softmax2d (class in torch.nn)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.SoftmaxTransform">SoftmaxTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.nn.Softmin.html#torch.nn.Softmin">Softmin (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.softmin.html#torch.nn.functional.softmin">softmin() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.Softplus.html#torch.nn.Softplus">Softplus (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.softplus.html#torch.nn.functional.softplus">softplus() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.SoftplusTransform">SoftplusTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.nn.Softshrink.html#torch.nn.Softshrink">Softshrink (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.softshrink.html#torch.nn.functional.softshrink">softshrink() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.Softsign.html#torch.nn.Softsign">Softsign (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.softsign.html#torch.nn.functional.softsign">softsign() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.linalg.solve.html#torch.linalg.solve">solve() (in module torch.linalg)</a>

      <ul>
        <li><a href="generated/torch.fx.experimental.symbolic_shapes.DimConstraints.html#torch.fx.experimental.symbolic_shapes.DimConstraints.solve">(torch.fx.experimental.symbolic_shapes.DimConstraints method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.solve_ex.html#torch.linalg.solve_ex">solve_ex() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.solve_triangular.html#torch.linalg.solve_triangular">solve_triangular() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.sort.html#torch.sort">sort() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sort.html#torch.Tensor.sort">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.sorted_indices">sorted_indices (torch.nn.utils.rnn.PackedSequence attribute)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.sparse_">sparse_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.sparse_bsc_tensor.html#torch.sparse_bsc_tensor">sparse_bsc_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.sparse_bsr_tensor.html#torch.sparse_bsr_tensor">sparse_bsr_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.sparse_compressed_tensor.html#torch.sparse_compressed_tensor">sparse_compressed_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.sparse_coo_tensor.html#torch.sparse_coo_tensor">sparse_coo_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.sparse_csc_tensor.html#torch.sparse_csc_tensor">sparse_csc_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.sparse_csr_tensor.html#torch.sparse_csr_tensor">sparse_csr_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.Tensor.sparse_dim.html#torch.Tensor.sparse_dim">sparse_dim() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.sparse_mask.html#torch.Tensor.sparse_mask">sparse_mask() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.sparse_resize_.html#torch.Tensor.sparse_resize_">sparse_resize_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.sparse_resize_and_clear_.html#torch.Tensor.sparse_resize_and_clear_">sparse_resize_and_clear_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam">SparseAdam (class in torch.optim)</a>
</li>
      <li><a href="multiprocessing.html#torch.multiprocessing.spawn.spawn">spawn() (in module torch.multiprocessing.spawn)</a>
</li>
      <li><a href="multiprocessing.html#torch.multiprocessing.SpawnContext">SpawnContext (class in torch.multiprocessing)</a>
</li>
      <li><a href="generated/torch.sparse.spdiags.html#torch.sparse.spdiags">spdiags() (in module torch.sparse)</a>
</li>
      <li><a href="generated/torch.nn.utils.spectral_norm.html#torch.nn.utils.spectral_norm">spectral_norm() (in module torch.nn.utils)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.parametrizations.spectral_norm.html#torch.nn.utils.parametrizations.spectral_norm">(in module torch.nn.utils.parametrizations)</a>
</li>
      </ul></li>
      <li><a href="special.html#torch.special.spherical_bessel_j0">spherical_bessel_j0() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.split.html#torch.split">split() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.split.html#torch.Tensor.split">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.sqrt.html#torch.sqrt">sqrt() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sqrt.html#torch.Tensor.sqrt">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sqrt_.html#torch.Tensor.sqrt_">sqrt_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.square.html#torch.square">square() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.square.html#torch.Tensor.square">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.square_.html#torch.Tensor.square_">square_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.squeeze.html#torch.squeeze">squeeze() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.squeeze.html#torch.Tensor.squeeze">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.squeeze_.html#torch.Tensor.squeeze_">squeeze_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.sspaddmm.html#torch.sspaddmm">sspaddmm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sspaddmm.html#torch.Tensor.sspaddmm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.constraints.stack">stack (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.stack.html#torch.stack">stack() (in module torch)</a>
</li>
      <li><a href="generated/torch.func.stack_module_state.html#torch.func.stack_module_state">stack_module_state() (in module torch.func)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.stack_trace">stack_trace (torch.fx.Node property)</a>
</li>
      <li><a href="data.html#torch.utils.data.StackDataset">StackDataset (class in torch.utils.data)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.StackTransform">StackTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry.html#torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry">StandaloneModuleConfigEntry (class in torch.ao.quantization.fx.custom_config)</a>
</li>
      <li><a href="generated/torch.mps.profiler.start.html#torch.mps.profiler.start">start() (in module torch.mps.profiler)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.start_processes">start_processes() (in module torch.distributed.elastic.multiprocessing)</a>
</li>
      <li><a href="pipeline.html#torch.distributed.pipeline.sync.skip.skippable.stash">stash (class in torch.distributed.pipeline.sync.skip.skippable)</a>
</li>
      <li><a href="monitor.html#torch.monitor.Stat">Stat (class in torch.monitor)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.stateful.Stateful.state_dict">state_dict() (torch.distributed.checkpoint.stateful.Stateful method)</a>

      <ul>
        <li><a href="distributed.optim.html#torch.distributed.optim.PostLocalSGDOptimizer.state_dict">(torch.distributed.optim.PostLocalSGDOptimizer method)</a>
</li>
        <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.state_dict">(torch.distributed.optim.ZeroRedundancyOptimizer method)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.state_dict">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.state_dict">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.state_dict">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.state_dict">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.state_dict">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.state_dict">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.state_dict">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.state_dict">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.state_dict">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ChainedScheduler.html#torch.optim.lr_scheduler.ChainedScheduler.state_dict">(torch.optim.lr_scheduler.ChainedScheduler method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ConstantLR.html#torch.optim.lr_scheduler.ConstantLR.state_dict">(torch.optim.lr_scheduler.ConstantLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR.state_dict">(torch.optim.lr_scheduler.CosineAnnealingLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.state_dict">(torch.optim.lr_scheduler.CosineAnnealingWarmRestarts method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR.state_dict">(torch.optim.lr_scheduler.ExponentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR.state_dict">(torch.optim.lr_scheduler.LambdaLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LinearLR.html#torch.optim.lr_scheduler.LinearLR.state_dict">(torch.optim.lr_scheduler.LinearLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR.state_dict">(torch.optim.lr_scheduler.MultiplicativeLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR.state_dict">(torch.optim.lr_scheduler.MultiStepLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR.state_dict">(torch.optim.lr_scheduler.OneCycleLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.PolynomialLR.html#torch.optim.lr_scheduler.PolynomialLR.state_dict">(torch.optim.lr_scheduler.PolynomialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.SequentialLR.html#torch.optim.lr_scheduler.SequentialLR.state_dict">(torch.optim.lr_scheduler.SequentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR.state_dict">(torch.optim.lr_scheduler.StepLR method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.state_dict">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.Optimizer.state_dict.html#torch.optim.Optimizer.state_dict">(torch.optim.Optimizer method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.state_dict">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.state_dict">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.state_dict">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.state_dict">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.state_dict">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.state_dict_type">state_dict_type() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.StateDictConfig">StateDictConfig (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.StateDictOptions">StateDictOptions (class in torch.distributed.checkpoint.state_dict)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.StateDictSettings">StateDictSettings (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.stateful.Stateful">Stateful (class in torch.distributed.checkpoint.stateful)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.StatefulSymbolicContext.html#torch.fx.experimental.symbolic_shapes.StatefulSymbolicContext">StatefulSymbolicContext (class in torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.StatelessSymbolicContext.html#torch.fx.experimental.symbolic_shapes.StatelessSymbolicContext">StatelessSymbolicContext (class in torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.statically_known_true.html#torch.fx.experimental.symbolic_shapes.statically_known_true">statically_known_true() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.CallgrindStats.stats">stats() (torch.utils.benchmark.CallgrindStats method)</a>
</li>
      <li><a href="generated/torch.std.html#torch.std">std() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.std.html#torch.Tensor.std">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.std_mean.html#torch.std_mean">std_mean() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.stddev">stddev (torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.stddev">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.stddev">(torch.distributions.exponential.Exponential property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.stddev">(torch.distributions.gumbel.Gumbel property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.stddev">(torch.distributions.laplace.Laplace property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.stddev">(torch.distributions.normal.Normal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.stddev">(torch.distributions.uniform.Uniform property)</a>
</li>
      </ul></li>
      <li><a href="distributed.optim.html#torch.distributed.optim.DistributedOptimizer.step">step() (torch.distributed.optim.DistributedOptimizer method)</a>

      <ul>
        <li><a href="distributed.optim.html#torch.distributed.optim.PostLocalSGDOptimizer.step">(torch.distributed.optim.PostLocalSGDOptimizer method)</a>
</li>
        <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.step">(torch.distributed.optim.ZeroRedundancyOptimizer method)</a>
</li>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.step">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.step">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.step">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.step">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.step">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.step">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.step">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.step">(torch.optim.lr_scheduler.CosineAnnealingWarmRestarts method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.step">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.Optimizer.step.html#torch.optim.Optimizer.step">(torch.optim.Optimizer method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.step">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.step">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.step">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.step">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.step">(torch.optim.SparseAdam method)</a>
</li>
        <li><a href="profiler.html#torch.profiler.profile.step">(torch.profiler.profile method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR">StepLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.stft.html#torch.stft">stft() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.stft.html#torch.Tensor.stft">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.transforms.StickBreakingTransform">StickBreakingTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.mps.profiler.stop.html#torch.mps.profiler.stop">stop() (in module torch.mps.profiler)</a>
</li>
      <li><a href="generated/torch.Tensor.storage.html#torch.Tensor.storage">storage() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.storage_offset.html#torch.Tensor.storage_offset">storage_offset() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.storage_type.html#torch.Tensor.storage_type">storage_type() (torch.Tensor method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader">StorageReader (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter">StorageWriter (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store">Store (class in torch.distributed)</a>
</li>
      <li><a href="backends.html#torch.backends.opt_einsum.strategy">strategy (in module torch.backends.opt_einsum)</a>
</li>
      <li><a href="generated/torch.cpu.Stream.html#torch.cpu.Stream">Stream (class in torch.cpu)</a>

      <ul>
        <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream">(class in torch.cuda)</a>
</li>
        <li><a href="generated/torch.xpu.Stream.html#torch.xpu.Stream">(class in torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cpu.stream.html#torch.cpu.stream">stream() (in module torch.cpu)</a>

      <ul>
        <li><a href="generated/torch.cuda.stream.html#torch.cuda.stream">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.xpu.stream.html#torch.xpu.stream">(in module torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cpu.StreamContext.html#torch.cpu.StreamContext">StreamContext (class in torch.cpu)</a>

      <ul>
        <li><a href="generated/torch.cuda.StreamContext.html#torch.cuda.StreamContext">(class in torch.cuda)</a>
</li>
        <li><a href="generated/torch.xpu.StreamContext.html#torch.xpu.StreamContext">(class in torch.xpu)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.strict_fusion.html#torch.jit.strict_fusion">strict_fusion (class in torch.jit)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint.html#torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint">StrictMinMaxConstraint (class in torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.Tensor.stride.html#torch.Tensor.stride">stride() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable">StringTable (class in torch.autograd.profiler_util)</a>
</li>
      <li><a href="distributions.html#torch.distributions.studentT.StudentT">StudentT (class in torch.distributions.studentT)</a>
</li>
      <li><a href="generated/torch.sub.html#torch.sub">sub() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sub.html#torch.Tensor.sub">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sub_.html#torch.Tensor.sub_">sub_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.SubclassSymbolicContext.html#torch.fx.experimental.symbolic_shapes.SubclassSymbolicContext">SubclassSymbolicContext (class in torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.SubprocessContext">SubprocessContext (class in torch.distributed.elastic.multiprocessing.api)</a>
</li>
      <li><a href="elastic/subprocess_handler.html#torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler.SubprocessHandler">SubprocessHandler (class in torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler)</a>
</li>
      <li><a href="data.html#torch.utils.data.Subset">Subset (class in torch.utils.data)</a>
</li>
      <li><a href="data.html#torch.utils.data.SubsetRandomSampler">SubsetRandomSampler (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.subtract.html#torch.subtract">subtract() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.subtract.html#torch.Tensor.subtract">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.subtract_.html#torch.Tensor.subtract_">subtract_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.sum.html#torch.sum">sum() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.sparse.sum.html#torch.sparse.sum">(in module torch.sparse)</a>
</li>
        <li><a href="generated/torch.Tensor.sum.html#torch.Tensor.sum">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sum_to_size.html#torch.Tensor.sum_to_size">sum_to_size() (torch.Tensor method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter">SummaryWriter (class in torch.utils.tensorboard.writer)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.summon_full_params">summon_full_params() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.support">support (torch.distributions.bernoulli.Bernoulli attribute)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.support">(torch.distributions.beta.Beta attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.support">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.support">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.support">(torch.distributions.cauchy.Cauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.support">(torch.distributions.continuous_bernoulli.ContinuousBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.support">(torch.distributions.dirichlet.Dirichlet attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.support">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.support">(torch.distributions.exponential.Exponential attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.support">(torch.distributions.fishersnedecor.FisherSnedecor attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.support">(torch.distributions.gamma.Gamma attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.support">(torch.distributions.geometric.Geometric attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.support">(torch.distributions.gumbel.Gumbel attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.support">(torch.distributions.half_cauchy.HalfCauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.support">(torch.distributions.half_normal.HalfNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.support">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.inverse_gamma.InverseGamma.support">(torch.distributions.inverse_gamma.InverseGamma attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.support">(torch.distributions.kumaraswamy.Kumaraswamy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.support">(torch.distributions.laplace.Laplace attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky.support">(torch.distributions.lkj_cholesky.LKJCholesky attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.support">(torch.distributions.log_normal.LogNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.support">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.support">(torch.distributions.mixture_same_family.MixtureSameFamily property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.support">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.support">(torch.distributions.multivariate_normal.MultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.support">(torch.distributions.negative_binomial.NegativeBinomial attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.support">(torch.distributions.normal.Normal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.support">(torch.distributions.one_hot_categorical.OneHotCategorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.support">(torch.distributions.pareto.Pareto property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.support">(torch.distributions.poisson.Poisson attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.support">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.support">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.support">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.support">(torch.distributions.studentT.StudentT attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.support">(torch.distributions.transformed_distribution.TransformedDistribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.support">(torch.distributions.uniform.Uniform property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.support">(torch.distributions.von_mises.VonMises attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.support">(torch.distributions.weibull.Weibull attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.support">(torch.distributions.wishart.Wishart attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.ShapeEnv.html#torch.fx.experimental.symbolic_shapes.ShapeEnv.suppress_guards">suppress_guards() (torch.fx.experimental.symbolic_shapes.ShapeEnv method)</a>
</li>
      <li><a href="generated/torch.svd.html#torch.svd">svd() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.svd.html#torch.linalg.svd">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.svd.html#torch.Tensor.svd">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.svd_lowrank.html#torch.svd_lowrank">svd_lowrank() (in module torch)</a>
</li>
      <li><a href="generated/torch.linalg.svdvals.html#torch.linalg.svdvals">svdvals() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.ao.quantization.swap_module.html#torch.ao.quantization.swap_module">swap_module (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.utils.swap_tensors.html#torch.utils.swap_tensors">swap_tensors() (in module torch.utils)</a>
</li>
      <li><a href="generated/torch.swapaxes.html#torch.swapaxes">swapaxes() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.swapaxes.html#torch.Tensor.swapaxes">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.swapdims.html#torch.swapdims">swapdims() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.swapdims.html#torch.Tensor.swapdims">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.sym_eq.html#torch.fx.experimental.symbolic_shapes.sym_eq">sym_eq() (in module torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="generated/torch.sym_float.html#torch.sym_float">sym_float() (in module torch)</a>
</li>
      <li><a href="generated/torch.sym_int.html#torch.sym_int">sym_int() (in module torch)</a>
</li>
      <li><a href="generated/torch.sym_ite.html#torch.sym_ite">sym_ite() (in module torch)</a>
</li>
      <li><a href="generated/torch.sym_max.html#torch.sym_max">sym_max() (in module torch)</a>
</li>
      <li><a href="generated/torch.sym_min.html#torch.sym_min">sym_min() (in module torch)</a>
</li>
      <li><a href="generated/torch.sym_not.html#torch.sym_not">sym_not() (in module torch)</a>
</li>
      <li><a href="fx.html#torch.fx.symbolic_trace">symbolic_trace() (in module torch.fx)</a>
</li>
      <li><a href="generated/torch.fx.experimental.symbolic_shapes.SymbolicContext.html#torch.fx.experimental.symbolic_shapes.SymbolicContext">SymbolicContext (class in torch.fx.experimental.symbolic_shapes)</a>
</li>
      <li><a href="torch.html#torch.SymBool">SymBool (class in torch)</a>
</li>
      <li><a href="torch.html#torch.SymFloat">SymFloat (class in torch)</a>
</li>
      <li><a href="torch.html#torch.SymInt">SymInt (class in torch)</a>
</li>
      <li><a href="generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm">SyncBatchNorm (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.cpu.synchronize.html#torch.cpu.synchronize">synchronize() (in module torch.cpu)</a>

      <ul>
        <li><a href="generated/torch.cuda.synchronize.html#torch.cuda.synchronize">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.mps.synchronize.html#torch.mps.synchronize">(in module torch.mps)</a>
</li>
        <li><a href="generated/torch.xpu.synchronize.html#torch.xpu.synchronize">(in module torch.xpu)</a>
</li>
        <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.synchronize">(torch.cuda.Event method)</a>
</li>
        <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream.synchronize">(torch.cuda.ExternalStream method)</a>
</li>
        <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream.synchronize">(torch.cuda.Stream method)</a>
</li>
        <li><a href="generated/torch.mps.event.Event.html#torch.mps.event.Event.synchronize">(torch.mps.event.Event method)</a>
</li>
        <li><a href="generated/torch.xpu.Event.html#torch.xpu.Event.synchronize">(torch.xpu.Event method)</a>
</li>
        <li><a href="generated/torch.xpu.Stream.html#torch.xpu.Stream.synchronize">(torch.xpu.Stream method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="T">T</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="tensors.html#torch.Tensor.T">T (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.t.html#torch.t">t() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.t.html#torch.Tensor.t">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.t_.html#torch.Tensor.t_">t_() (torch.Tensor method)</a>
</li>
      <li><a href="torch.html#torch.Tag">Tag (class in torch)</a>
</li>
      <li><a href="generated/torch.take.html#torch.take">take() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.take.html#torch.Tensor.take">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.take_along_dim.html#torch.take_along_dim">take_along_dim() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.take_along_dim.html#torch.Tensor.take_along_dim">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.tan.html#torch.tan">tan() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.tan.html#torch.Tensor.tan">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.tan_.html#torch.Tensor.tan_">tan_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.autograd.forward_ad.UnpackedDualTensor.html#torch.autograd.forward_ad.UnpackedDualTensor.tangent">tangent (torch.autograd.forward_ad.UnpackedDualTensor attribute)</a>
</li>
      <li><a href="generated/torch.nn.Tanh.html#torch.nn.Tanh">Tanh (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.tanh.html#torch.tanh">tanh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.nn.functional.tanh.html#torch.nn.functional.tanh">(in module torch.nn.functional)</a>
</li>
        <li><a href="generated/torch.Tensor.tanh.html#torch.Tensor.tanh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.tanh_.html#torch.Tensor.tanh_">tanh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.Tanhshrink.html#torch.nn.Tanhshrink">Tanhshrink (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.tanhshrink.html#torch.nn.functional.tanhshrink">tanhshrink() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.TanhTransform">TanhTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributed.html#torch.distributed.TCPStore">TCPStore (class in torch.distributed)</a>
</li>
      <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature">temperature (torch.distributions.relaxed_bernoulli.RelaxedBernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.temperature.html#torch.cuda.temperature">temperature() (in module torch.cuda)</a>
</li>
      <li><a href="tensors.html#torch.Tensor">Tensor (class in torch)</a>
</li>
      <li><a href="generated/torch.tensor.html#torch.tensor">tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.tensor_split.html#torch.tensor_split">tensor_split() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.tensor_split.html#torch.Tensor.tensor_split">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.planner.WriteItem.tensor_storage_size">tensor_storage_size() (torch.distributed.checkpoint.planner.WriteItem method)</a>
</li>
      <li><a href="profiler.html#torch.profiler.tensorboard_trace_handler">tensorboard_trace_handler() (in module torch.profiler)</a>
</li>
      <li><a href="monitor.html#torch.monitor.TensorboardEventHandler">TensorboardEventHandler (class in torch.monitor)</a>
</li>
      <li><a href="data.html#torch.utils.data.TensorDataset">TensorDataset (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.tensordot.html#torch.tensordot">tensordot() (in module torch)</a>
</li>
      <li><a href="generated/torch.linalg.tensorinv.html#torch.linalg.tensorinv">tensorinv() (in module torch.linalg)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions">TensorPipeRpcBackendOptions (class in torch.distributed.rpc)</a>
</li>
      <li><a href="generated/torch.linalg.tensorsolve.html#torch.linalg.tensorsolve">tensorsolve() (in module torch.linalg)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.then">then() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.threshold.html#torch.ao.nn.quantized.functional.threshold">threshold (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Threshold.html#torch.nn.Threshold">Threshold (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.threshold.html#torch.nn.functional.threshold">threshold() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.threshold_.html#torch.nn.functional.threshold_">threshold_() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.tile.html#torch.tile">tile() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.tile.html#torch.Tensor.tile">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Timer.timeit">timeit() (torch.utils.benchmark.Timer method)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Timer">Timer (class in torch.utils.benchmark)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerClient">TimerClient (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerRequest">TimerRequest (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerServer">TimerServer (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="monitor.html#torch.monitor.Event.timestamp">timestamp (torch.monitor.Event property)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.to">to() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.to">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.to">(torch.nn.utils.rnn.PackedSequence method)</a>
</li>
        <li><a href="generated/torch.Tensor.to.html#torch.Tensor.to">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Tracer.to_bool">to_bool() (torch.fx.Tracer method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_dense.html#torch.Tensor.to_dense">to_dense() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.to_dict">to_dict() (torch.ao.quantization.backend_config.BackendConfig method)</a>

      <ul>
        <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.to_dict">(torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.backend_config.DTypeConfig.html#torch.ao.quantization.backend_config.DTypeConfig.to_dict">(torch.ao.quantization.backend_config.DTypeConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.html#torch.ao.quantization.fx.custom_config.ConvertCustomConfig.to_dict">(torch.ao.quantization.fx.custom_config.ConvertCustomConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig.html#torch.ao.quantization.fx.custom_config.FuseCustomConfig.to_dict">(torch.ao.quantization.fx.custom_config.FuseCustomConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.to_dict">(torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.to_dict">(torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      </ul></li>
      <li><a href="dlpack.html#torch.utils.dlpack.to_dlpack">to_dlpack() (in module torch.utils.dlpack)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.to_empty">to_empty() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.to_empty">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.GraphModule.to_folder">to_folder() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.PyRRef.to_here">to_here() (torch.distributed.rpc.PyRRef method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_mkldnn.html#torch.Tensor.to_mkldnn">to_mkldnn() (torch.Tensor method)</a>
</li>
      <li><a href="nested.html#torch.nested.to_padded_tensor">to_padded_tensor() (in module torch.nested)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse.html#torch.Tensor.to_sparse">to_sparse() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse_bsc.html#torch.Tensor.to_sparse_bsc">to_sparse_bsc() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse_bsr.html#torch.Tensor.to_sparse_bsr">to_sparse_bsr() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse_coo.html#torch.Tensor.to_sparse_coo">to_sparse_coo() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse_csc.html#torch.Tensor.to_sparse_csc">to_sparse_csc() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse_csr.html#torch.Tensor.to_sparse_csr">to_sparse_csr() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.tolist.html#torch.Tensor.tolist">tolist() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.tolist">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.tolist">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.topk.html#torch.topk">topk() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.topk.html#torch.Tensor.topk">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li>
    torch

      <ul>
        <li><a href="torch.html#module-torch">module</a>
</li>
      </ul></li>
      <li>
    torch.__config__

      <ul>
        <li><a href="config_mod.html#module-torch.__config__">module</a>
</li>
      </ul></li>
      <li>
    torch.__future__

      <ul>
        <li><a href="future_mod.html#module-torch.__future__">module</a>
</li>
      </ul></li>
      <li>
    torch._logging

      <ul>
        <li><a href="logging.html#module-torch._logging">module</a>
</li>
      </ul></li>
      <li>
    torch.amp

      <ul>
        <li><a href="amp.html#module-torch.amp">module</a>
</li>
      </ul></li>
      <li>
    torch.amp.autocast_mode

      <ul>
        <li><a href="amp.html#module-torch.amp.autocast_mode">module</a>
</li>
      </ul></li>
      <li>
    torch.amp.grad_scaler

      <ul>
        <li><a href="amp.html#module-torch.amp.grad_scaler">module</a>
</li>
      </ul></li>
      <li>
    torch.ao

      <ul>
        <li><a href="quantization.html#module-torch.ao">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.modules.fused

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.modules.fused">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.qat

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.qat">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.qat.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.qat.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.qat.modules.conv_fused

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.qat.modules.conv_fused">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.qat.modules.linear_fused

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.qat.modules.linear_fused">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.qat.modules.linear_relu

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.qat.modules.linear_relu">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized.modules.bn_relu

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.quantized.modules.bn_relu">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized.modules.conv_add

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.quantized.modules.conv_add">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized.modules.conv_relu

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.quantized.modules.conv_relu">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized.modules.linear_relu

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.intrinsic.quantized.modules.linear_relu">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat.dynamic.modules.linear

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.qat.dynamic.modules.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat.modules.conv

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.qat.modules.conv">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat.modules.embedding_ops

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.qat.modules.embedding_ops">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat.modules.linear

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.qat.modules.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantizable

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantizable.modules

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantizable.modules.activation

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable.modules.activation">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantizable.modules.rnn

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable.modules.rnn">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.dynamic.modules.conv

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.dynamic.modules.conv">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.dynamic.modules.linear

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.dynamic.modules.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.dynamic.modules.rnn

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.dynamic.modules.rnn">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.functional

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.functional">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules.activation

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.activation">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules.batchnorm

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.batchnorm">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules.conv

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.conv">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules.dropout

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.dropout">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules.embedding_ops

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.embedding_ops">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules.functional_modules

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.functional_modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules.linear

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules.normalization

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.normalization">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules.rnn

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.rnn">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules.utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.modules.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.reference

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.reference.modules

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.reference.modules.conv

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules.conv">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.reference.modules.linear

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.reference.modules.rnn

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules.rnn">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.reference.modules.sparse

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules.sparse">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.reference.modules.utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.sparse

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.sparse">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.sparse.quantized

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.sparse.quantized.dynamic

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.sparse.quantized.dynamic.linear

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized.dynamic.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.sparse.quantized.linear

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.sparse.quantized.utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns._numeric_suite

      <ul>
        <li><a href="torch.ao.ns._numeric_suite.html#module-torch.ao.ns._numeric_suite">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns._numeric_suite_fx

      <ul>
        <li><a href="torch.ao.ns._numeric_suite_fx.html#module-torch.ao.ns._numeric_suite_fx">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns.fx

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns.fx">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns.fx.graph_matcher

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns.fx.graph_matcher">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns.fx.graph_passes

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns.fx.graph_passes">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns.fx.mappings

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns.fx.mappings">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns.fx.n_shadows_utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns.fx.n_shadows_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns.fx.ns_types

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns.fx.ns_types">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns.fx.pattern_utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns.fx.pattern_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns.fx.qconfig_multi_mapping

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns.fx.qconfig_multi_mapping">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns.fx.utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns.fx.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns.fx.weight_utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns.fx.weight_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning.scheduler

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning.scheduler">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning.scheduler.base_scheduler

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning.scheduler.base_scheduler">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning.scheduler.cubic_scheduler

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning.scheduler.cubic_scheduler">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning.scheduler.lambda_scheduler

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning.scheduler.lambda_scheduler">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning.sparsifier

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning.sparsifier.base_sparsifier

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier.base_sparsifier">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning.sparsifier.nearly_diagonal_sparsifier

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier.nearly_diagonal_sparsifier">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning.sparsifier.utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning.sparsifier.weight_norm_sparsifier

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier.weight_norm_sparsifier">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config.backend_config

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.backend_config">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config.executorch

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.executorch">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config.fbgemm

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.fbgemm">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config.native

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.native">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config.observation_type

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.observation_type">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config.onednn

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.onednn">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config.qnnpack

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.qnnpack">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config.tensorrt

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.tensorrt">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config.utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config.x86

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config.x86">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fake_quantize

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fake_quantize">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fuse_modules

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fuse_modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fuser_method_mappings

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fuser_method_mappings">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.convert

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.convert">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.custom_config

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.custom_config">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.fuse

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.fuse">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.fuse_handler

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.fuse_handler">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.graph_module

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.graph_module">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.lower_to_fbgemm

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.lower_to_fbgemm">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.lower_to_qnnpack

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.lower_to_qnnpack">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.lstm_utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.lstm_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.match_utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.match_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.pattern_utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.pattern_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.prepare

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.prepare">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.qconfig_mapping_utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.qconfig_mapping_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.quantize_handler

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.quantize_handler">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.tracer

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.tracer">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx.utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.observer

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.observer">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.pt2e

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.quantization.pt2e">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.pt2e.duplicate_dq_pass

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.duplicate_dq_pass">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.pt2e.export_utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.export_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.pt2e.generate_numeric_debug_handle

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.quantization.pt2e.generate_numeric_debug_handle">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.pt2e.graph_utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.graph_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.pt2e.port_metadata_pass

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.port_metadata_pass">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.pt2e.prepare

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.prepare">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.pt2e.qat_utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.qat_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.pt2e.representation

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.quantization.pt2e.representation">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.pt2e.representation.rewrite

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.representation.rewrite">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.pt2e.utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.pt2e.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.qconfig

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.qconfig">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.qconfig_mapping

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.qconfig_mapping">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quant_type

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quant_type">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantization_mappings

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantization_mappings">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantize

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantize">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantize_fx

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantize_fx">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantize_jit

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantize_jit">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantize_pt2e

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantize_pt2e">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantizer

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.quantization.quantizer">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantizer.composable_quantizer

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.composable_quantizer">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantizer.embedding_quantizer

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.embedding_quantizer">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantizer.quantizer

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.quantizer">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantizer.utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantizer.x86_inductor_quantizer

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.x86_inductor_quantizer">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantizer.xnnpack_quantizer

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.xnnpack_quantizer">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.quantizer.xnnpack_quantizer_utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.quantizer.xnnpack_quantizer_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.stubs

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.stubs">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.utils

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd

      <ul>
        <li><a href="autograd.html#module-torch.autograd">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd.anomaly_mode

      <ul>
        <li><a href="autograd.html#module-torch.autograd.anomaly_mode">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd.forward_ad

      <ul>
        <li><a href="autograd.html#module-torch.autograd.forward_ad">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd.function

      <ul>
        <li><a href="autograd.html#module-torch.autograd.function">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd.functional

      <ul>
        <li><a href="autograd.html#module-torch.autograd.functional">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd.grad_mode

      <ul>
        <li><a href="autograd.html#module-torch.autograd.grad_mode">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd.gradcheck

      <ul>
        <li><a href="autograd.html#module-torch.autograd.gradcheck">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd.graph

      <ul>
        <li><a href="autograd.html#module-torch.autograd.graph">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd.profiler

      <ul>
        <li><a href="autograd.html#module-torch.autograd.profiler">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd.profiler_legacy

      <ul>
        <li><a href="autograd.html#module-torch.autograd.profiler_legacy">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd.profiler_util

      <ul>
        <li><a href="autograd.html#module-torch.autograd.profiler_util">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd.variable

      <ul>
        <li><a href="autograd.html#module-torch.autograd.variable">module</a>
</li>
      </ul></li>
      <li>
    torch.backends

      <ul>
        <li><a href="backends.html#module-torch.backends">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.cpu

      <ul>
        <li><a href="backends.html#module-torch.backends.cpu">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.cuda

      <ul>
        <li><a href="backends.html#module-torch.backends.cuda">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.cudnn

      <ul>
        <li><a href="backends.html#module-torch.backends.cudnn">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.cudnn.rnn

      <ul>
        <li><a href="backends.html#module-torch.backends.cudnn.rnn">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.mha

      <ul>
        <li><a href="backends.html#module-torch.backends.mha">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.mkl

      <ul>
        <li><a href="backends.html#module-torch.backends.mkl">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.mkldnn

      <ul>
        <li><a href="backends.html#module-torch.backends.mkldnn">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.mps

      <ul>
        <li><a href="backends.html#module-torch.backends.mps">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.nnpack

      <ul>
        <li><a href="backends.html#module-torch.backends.nnpack">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.openmp

      <ul>
        <li><a href="backends.html#module-torch.backends.openmp">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.opt_einsum

      <ul>
        <li><a href="backends.html#module-torch.backends.opt_einsum">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.quantized

      <ul>
        <li><a href="backends.html#module-torch.backends.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.xeon

      <ul>
        <li><a href="backends.html#module-torch.backends.xeon">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.xeon.run_cpu

      <ul>
        <li><a href="backends.html#module-torch.backends.xeon.run_cpu">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.xnnpack

      <ul>
        <li><a href="backends.html#module-torch.backends.xnnpack">module</a>
</li>
      </ul></li>
      <li>
    torch.compiler

      <ul>
        <li><a href="torch.compiler_api.html#module-torch.compiler">module</a>
</li>
      </ul></li>
      <li>
    torch.contrib

      <ul>
        <li><a href="torch.html#module-torch.contrib">module</a>
</li>
      </ul></li>
      <li>
    torch.cpu

      <ul>
        <li><a href="cpu.html#module-torch.cpu">module</a>
</li>
      </ul></li>
      <li>
    torch.cpu.amp

      <ul>
        <li><a href="amp.html#module-torch.cpu.amp">module</a>
</li>
      </ul></li>
      <li>
    torch.cpu.amp.autocast_mode

      <ul>
        <li><a href="amp.html#module-torch.cpu.amp.autocast_mode">module</a>
</li>
      </ul></li>
      <li>
    torch.cpu.amp.grad_scaler

      <ul>
        <li><a href="amp.html#module-torch.cpu.amp.grad_scaler">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda

      <ul>
        <li><a href="cuda.html#module-torch.cuda">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda._sanitizer

      <ul>
        <li><a href="cuda._sanitizer.html#module-torch.cuda._sanitizer">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.amp

      <ul>
        <li><a href="amp.html#module-torch.cuda.amp">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.amp.autocast_mode

      <ul>
        <li><a href="amp.html#module-torch.cuda.amp.autocast_mode">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.amp.common

      <ul>
        <li><a href="amp.html#module-torch.cuda.amp.common">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.amp.grad_scaler

      <ul>
        <li><a href="amp.html#module-torch.cuda.amp.grad_scaler">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.comm

      <ul>
        <li><a href="cuda.html#module-torch.cuda.comm">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.error

      <ul>
        <li><a href="cuda.html#module-torch.cuda.error">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.graphs

      <ul>
        <li><a href="cuda.html#module-torch.cuda.graphs">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.jiterator

      <ul>
        <li><a href="cuda.html#module-torch.cuda.jiterator">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.memory

      <ul>
        <li><a href="cuda.html#module-torch.cuda.memory">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.nccl

      <ul>
        <li><a href="cuda.html#module-torch.cuda.nccl">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.nvtx

      <ul>
        <li><a href="cuda.html#module-torch.cuda.nvtx">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.profiler

      <ul>
        <li><a href="cuda.html#module-torch.cuda.profiler">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.random

      <ul>
        <li><a href="cuda.html#module-torch.cuda.random">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.sparse

      <ul>
        <li><a href="cuda.html#module-torch.cuda.sparse">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.streams

      <ul>
        <li><a href="cuda.html#module-torch.cuda.streams">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed

      <ul>
        <li><a href="distributed.html#module-torch.distributed">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.ddp_comm_hooks

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.ddp_comm_hooks.ddp_zero_hook

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.ddp_zero_hook">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.ddp_comm_hooks.default_hooks

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.default_hooks">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.ddp_comm_hooks.post_localSGD_hook

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.post_localSGD_hook">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.ddp_comm_hooks.quantization_hooks

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks.quantization_hooks">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.join

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.join">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.model_averaging

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.model_averaging">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.model_averaging.averagers

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.model_averaging.averagers">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.model_averaging.hierarchical_model_averager

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.model_averaging.hierarchical_model_averager">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.model_averaging.utils

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.model_averaging.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.argparse_util

      <ul>
        <li><a href="distributed.html#module-torch.distributed.argparse_util">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.autograd

      <ul>
        <li><a href="rpc.html#module-torch.distributed.autograd">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.c10d_logger

      <ul>
        <li><a href="distributed.html#module-torch.distributed.c10d_logger">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint

      <ul>
        <li><a href="distributed.checkpoint.html#module-torch.distributed.checkpoint">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.default_planner

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.default_planner">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.filesystem

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.filesystem">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.format_utils

      <ul>
        <li><a href="distributed.checkpoint.html#module-torch.distributed.checkpoint.format_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.metadata

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.metadata">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.optimizer

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.optimizer">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.planner

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.planner">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.planner_helpers

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.planner_helpers">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.resharding

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.resharding">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.state_dict

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.state_dict">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.state_dict_loader

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.state_dict_loader">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.state_dict_saver

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.state_dict_saver">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.stateful

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.stateful">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.storage

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.storage">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint.utils

      <ul>
        <li><a href="distributed.html#module-torch.distributed.checkpoint.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.collective_utils

      <ul>
        <li><a href="distributed.html#module-torch.distributed.collective_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.constants

      <ul>
        <li><a href="distributed.html#module-torch.distributed.constants">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.device_mesh

      <ul>
        <li><a href="distributed.html#module-torch.distributed.device_mesh">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.distributed_c10d

      <ul>
        <li><a href="distributed.html#module-torch.distributed.distributed_c10d">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.agent

      <ul>
        <li><a href="elastic/agent.html#module-torch.distributed.elastic.agent">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.agent.server

      <ul>
        <li><a href="elastic/agent.html#module-torch.distributed.elastic.agent.server">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.agent.server.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.agent.server.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.agent.server.local_elastic_agent

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.agent.server.local_elastic_agent">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.events

      <ul>
        <li><a href="elastic/events.html#module-torch.distributed.elastic.events">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.events.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.events.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.events.handlers

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.events.handlers">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.metrics

      <ul>
        <li><a href="elastic/metrics.html#module-torch.distributed.elastic.metrics">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.metrics.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.metrics.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing

      <ul>
        <li><a href="elastic/multiprocessing.html#module-torch.distributed.elastic.multiprocessing">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.multiprocessing.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing.errors

      <ul>
        <li><a href="elastic/errors.html#module-torch.distributed.elastic.multiprocessing.errors">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing.errors.error_handler

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.multiprocessing.errors.error_handler">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing.errors.handlers

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.multiprocessing.errors.handlers">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing.redirects

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.multiprocessing.redirects">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing.subprocess_handler

      <ul>
        <li><a href="elastic/subprocess_handler.html#module-torch.distributed.elastic.multiprocessing.subprocess_handler">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing.subprocess_handler.handlers

      <ul>
        <li><a href="elastic/subprocess_handler.html#module-torch.distributed.elastic.multiprocessing.subprocess_handler.handlers">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler

      <ul>
        <li><a href="elastic/subprocess_handler.html#module-torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing.tail_log

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.multiprocessing.tail_log">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous

      <ul>
        <li><a href="elastic/rendezvous.html#module-torch.distributed.elastic.rendezvous">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous.c10d_rendezvous_backend

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.c10d_rendezvous_backend">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous.dynamic_rendezvous

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.dynamic_rendezvous">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous.etcd_rendezvous

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.etcd_rendezvous">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous.etcd_rendezvous_backend

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.etcd_rendezvous_backend">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous.etcd_server

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.etcd_server">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous.etcd_store

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.etcd_store">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous.registry

      <ul>
        <li><a href="elastic/rendezvous.html#module-torch.distributed.elastic.rendezvous.registry">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous.static_tcp_rendezvous

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.static_tcp_rendezvous">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous.utils

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.rendezvous.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.timer

      <ul>
        <li><a href="elastic/timer.html#module-torch.distributed.elastic.timer">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.timer.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.timer.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.timer.file_based_local_timer

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.timer.file_based_local_timer">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.timer.local_timer

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.timer.local_timer">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.utils

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.utils.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.utils.data

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.data">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.utils.data.cycling_iterator

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.data.cycling_iterator">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.utils.data.elastic_distributed_sampler

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.data.elastic_distributed_sampler">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.utils.distributed

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.distributed">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.utils.log_level

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.log_level">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.utils.logging

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.logging">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.utils.store

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.store">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.fsdp

      <ul>
        <li><a href="fsdp.html#module-torch.distributed.fsdp">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.fsdp.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.fsdp.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.fsdp.fully_sharded_data_parallel

      <ul>
        <li><a href="distributed.html#module-torch.distributed.fsdp.fully_sharded_data_parallel">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.fsdp.sharded_grad_scaler

      <ul>
        <li><a href="distributed.html#module-torch.distributed.fsdp.sharded_grad_scaler">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.fsdp.wrap

      <ul>
        <li><a href="distributed.html#module-torch.distributed.fsdp.wrap">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.launch

      <ul>
        <li><a href="distributed.html#module-torch.distributed.launch">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.launcher

      <ul>
        <li><a href="distributed.html#module-torch.distributed.launcher">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.launcher.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.launcher.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.logging_handlers

      <ul>
        <li><a href="distributed.html#module-torch.distributed.logging_handlers">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn.api.remote_module

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn.api.remote_module">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn.functional

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn.functional">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn.jit

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn.jit">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn.jit.instantiator

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn.jit.instantiator">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn.jit.templates

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn.jit.templates">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn.jit.templates.remote_module_template

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn.jit.templates.remote_module_template">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim

      <ul>
        <li><a href="distributed.optim.html#module-torch.distributed.optim">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.apply_optimizer_in_backward

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.apply_optimizer_in_backward">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.functional_adadelta

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_adadelta">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.functional_adagrad

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_adagrad">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.functional_adam

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_adam">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.functional_adamax

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_adamax">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.functional_adamw

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_adamw">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.functional_rmsprop

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_rmsprop">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.functional_rprop

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_rprop">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.functional_sgd

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.functional_sgd">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.named_optimizer

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.named_optimizer">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.optimizer

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.optimizer">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.post_localSGD_optimizer

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.post_localSGD_optimizer">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.utils

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim.zero_redundancy_optimizer

      <ul>
        <li><a href="distributed.html#module-torch.distributed.optim.zero_redundancy_optimizer">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.batchnorm

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.batchnorm">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.checkpoint

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.checkpoint">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.copy

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.copy">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.dependency

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.dependency">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.microbatch

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.microbatch">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.phony

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.phony">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.pipe

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.pipe">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.pipeline

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.pipeline">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.skip

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.skip.layout

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip.layout">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.skip.namespace

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip.namespace">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.skip.portal

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip.portal">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.skip.skippable

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip.skippable">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.skip.tracker

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip.tracker">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.stream

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.stream">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.utils

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.worker

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.worker">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.remote_device

      <ul>
        <li><a href="distributed.html#module-torch.distributed.remote_device">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.rendezvous

      <ul>
        <li><a href="distributed.html#module-torch.distributed.rendezvous">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.rpc

      <ul>
        <li><a href="rpc.html#module-torch.distributed.rpc">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.rpc.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.rpc.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.rpc.backend_registry

      <ul>
        <li><a href="distributed.html#module-torch.distributed.rpc.backend_registry">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.rpc.constants

      <ul>
        <li><a href="distributed.html#module-torch.distributed.rpc.constants">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.rpc.functions

      <ul>
        <li><a href="distributed.html#module-torch.distributed.rpc.functions">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.rpc.internal

      <ul>
        <li><a href="distributed.html#module-torch.distributed.rpc.internal">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.rpc.options

      <ul>
        <li><a href="distributed.html#module-torch.distributed.rpc.options">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.rpc.rref_proxy

      <ul>
        <li><a href="distributed.html#module-torch.distributed.rpc.rref_proxy">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.rpc.server_process_global_profiler

      <ul>
        <li><a href="distributed.html#module-torch.distributed.rpc.server_process_global_profiler">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.run

      <ul>
        <li><a href="elastic/run.html#module-torch.distributed.run">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.tensor

      <ul>
        <li><a href="distributed.html#module-torch.distributed.tensor">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.tensor.parallel

      <ul>
        <li><a href="distributed.tensor.parallel.html#module-torch.distributed.tensor.parallel">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.tensor.parallel.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.tensor.parallel.ddp

      <ul>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.ddp">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.tensor.parallel.fsdp

      <ul>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.fsdp">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.tensor.parallel.input_reshard

      <ul>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.input_reshard">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.tensor.parallel.loss

      <ul>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.loss">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.tensor.parallel.style

      <ul>
        <li><a href="distributed.html#module-torch.distributed.tensor.parallel.style">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.utils

      <ul>
        <li><a href="distributed.html#module-torch.distributed.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions

      <ul>
        <li><a href="distributions.html#module-torch.distributions">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.bernoulli

      <ul>
        <li><a href="distributions.html#module-torch.distributions.bernoulli">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.beta

      <ul>
        <li><a href="distributions.html#module-torch.distributions.beta">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.binomial

      <ul>
        <li><a href="distributions.html#module-torch.distributions.binomial">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.categorical

      <ul>
        <li><a href="distributions.html#module-torch.distributions.categorical">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.cauchy

      <ul>
        <li><a href="distributions.html#module-torch.distributions.cauchy">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.chi2

      <ul>
        <li><a href="distributions.html#module-torch.distributions.chi2">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.constraint_registry

      <ul>
        <li><a href="distributions.html#module-torch.distributions.constraint_registry">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.constraints

      <ul>
        <li><a href="distributions.html#module-torch.distributions.constraints">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.continuous_bernoulli

      <ul>
        <li><a href="distributions.html#module-torch.distributions.continuous_bernoulli">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.dirichlet

      <ul>
        <li><a href="distributions.html#module-torch.distributions.dirichlet">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.distribution

      <ul>
        <li><a href="distributions.html#module-torch.distributions.distribution">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.exp_family

      <ul>
        <li><a href="distributions.html#module-torch.distributions.exp_family">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.exponential

      <ul>
        <li><a href="distributions.html#module-torch.distributions.exponential">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.fishersnedecor

      <ul>
        <li><a href="distributions.html#module-torch.distributions.fishersnedecor">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.gamma

      <ul>
        <li><a href="distributions.html#module-torch.distributions.gamma">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.geometric

      <ul>
        <li><a href="distributions.html#module-torch.distributions.geometric">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.gumbel

      <ul>
        <li><a href="distributions.html#module-torch.distributions.gumbel">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.half_cauchy

      <ul>
        <li><a href="distributions.html#module-torch.distributions.half_cauchy">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.half_normal

      <ul>
        <li><a href="distributions.html#module-torch.distributions.half_normal">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.independent

      <ul>
        <li><a href="distributions.html#module-torch.distributions.independent">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.inverse_gamma

      <ul>
        <li><a href="distributions.html#module-torch.distributions.inverse_gamma">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.kl

      <ul>
        <li><a href="distributions.html#module-torch.distributions.kl">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.kumaraswamy

      <ul>
        <li><a href="distributions.html#module-torch.distributions.kumaraswamy">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.laplace

      <ul>
        <li><a href="distributions.html#module-torch.distributions.laplace">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.lkj_cholesky

      <ul>
        <li><a href="distributions.html#module-torch.distributions.lkj_cholesky">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.log_normal

      <ul>
        <li><a href="distributions.html#module-torch.distributions.log_normal">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.logistic_normal

      <ul>
        <li><a href="distributions.html#module-torch.distributions.logistic_normal">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.lowrank_multivariate_normal

      <ul>
        <li><a href="distributions.html#module-torch.distributions.lowrank_multivariate_normal">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.mixture_same_family

      <ul>
        <li><a href="distributions.html#module-torch.distributions.mixture_same_family">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.multinomial

      <ul>
        <li><a href="distributions.html#module-torch.distributions.multinomial">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.multivariate_normal

      <ul>
        <li><a href="distributions.html#module-torch.distributions.multivariate_normal">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.negative_binomial

      <ul>
        <li><a href="distributions.html#module-torch.distributions.negative_binomial">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.normal

      <ul>
        <li><a href="distributions.html#module-torch.distributions.normal">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.one_hot_categorical

      <ul>
        <li><a href="distributions.html#module-torch.distributions.one_hot_categorical">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.pareto

      <ul>
        <li><a href="distributions.html#module-torch.distributions.pareto">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.poisson

      <ul>
        <li><a href="distributions.html#module-torch.distributions.poisson">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.relaxed_bernoulli

      <ul>
        <li><a href="distributions.html#module-torch.distributions.relaxed_bernoulli">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.relaxed_categorical

      <ul>
        <li><a href="distributions.html#module-torch.distributions.relaxed_categorical">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.studentT

      <ul>
        <li><a href="distributions.html#module-torch.distributions.studentT">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.transformed_distribution

      <ul>
        <li><a href="distributions.html#module-torch.distributions.transformed_distribution">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.transforms

      <ul>
        <li><a href="distributions.html#module-torch.distributions.transforms">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.uniform

      <ul>
        <li><a href="distributions.html#module-torch.distributions.uniform">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.utils

      <ul>
        <li><a href="distributions.html#module-torch.distributions.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.von_mises

      <ul>
        <li><a href="distributions.html#module-torch.distributions.von_mises">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.weibull

      <ul>
        <li><a href="distributions.html#module-torch.distributions.weibull">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.wishart

      <ul>
        <li><a href="distributions.html#module-torch.distributions.wishart">module</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li>
    torch.export

      <ul>
        <li><a href="export.html#module-torch.export">module</a>
</li>
      </ul></li>
      <li>
    torch.export.custom_obj

      <ul>
        <li><a href="export.html#module-torch.export.custom_obj">module</a>
</li>
      </ul></li>
      <li>
    torch.export.dynamic_shapes

      <ul>
        <li><a href="export.html#module-torch.export.dynamic_shapes">module</a>
</li>
      </ul></li>
      <li>
    torch.export.exported_program

      <ul>
        <li><a href="export.html#module-torch.export.exported_program">module</a>
</li>
      </ul></li>
      <li>
    torch.export.graph_signature

      <ul>
        <li><a href="export.html#module-torch.export.graph_signature">module</a>
</li>
      </ul></li>
      <li>
    torch.export.unflatten

      <ul>
        <li><a href="export.html#module-torch.export.unflatten">module</a>
</li>
      </ul></li>
      <li>
    torch.fft

      <ul>
        <li><a href="fft.html#module-torch.fft">module</a>
</li>
      </ul></li>
      <li><a href="type_info.html#torch.torch.finfo">torch.finfo (class in torch)</a>
</li>
      <li>
    torch.func

      <ul>
        <li><a href="func.api.html#module-torch.func">module</a>
</li>
      </ul></li>
      <li>
    torch.functional

      <ul>
        <li><a href="torch.html#module-torch.functional">module</a>
</li>
      </ul></li>
      <li>
    torch.futures

      <ul>
        <li><a href="futures.html#module-torch.futures">module</a>
</li>
      </ul></li>
      <li>
    torch.fx

      <ul>
        <li><a href="fx.html#module-torch.fx">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.annotate

      <ul>
        <li><a href="fx.html#module-torch.fx.annotate">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.config

      <ul>
        <li><a href="fx.html#module-torch.fx.config">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.accelerator_partitioner

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.accelerator_partitioner">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.const_fold

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.const_fold">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.debug

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.debug">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.graph_gradual_typechecker

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.graph_gradual_typechecker">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.merge_matmul

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.merge_matmul">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.meta_tracer

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.meta_tracer">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.migrate_gradual_types

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.migrate_gradual_types.constraint

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.constraint">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.migrate_gradual_types.constraint_generator

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.constraint_generator">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.migrate_gradual_types.constraint_transformation

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.constraint_transformation">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.migrate_gradual_types.operation

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.operation">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.migrate_gradual_types.transform_to_z3

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.transform_to_z3">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.migrate_gradual_types.util

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.util">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.migrate_gradual_types.z3_types

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types.z3_types">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.normalize

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.normalize">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.optimization

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.optimization">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.partitioner_utils

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.partitioner_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.proxy_tensor

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.proxy_tensor">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.recording

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.recording">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.refinement_types

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.refinement_types">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.rewriter

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.rewriter">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.schema_type_annotation

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.schema_type_annotation">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.sym_node

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.sym_node">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.symbolic_shapes

      <ul>
        <li><a href="fx.experimental.html#module-torch.fx.experimental.symbolic_shapes">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.core

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.core">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.dispatch

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.dispatch">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.match

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.match">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.more

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.more">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.multipledispatch

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.multipledispatch.conflict

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch.conflict">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.multipledispatch.core

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch.core">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.multipledispatch.dispatcher

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch.dispatcher">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.multipledispatch.utils

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.multipledispatch.variadic

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch.variadic">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.unification_tools

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.unification_tools">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.utils

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.variable

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.variable">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unify_refinements

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unify_refinements">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.validator

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.validator">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.graph

      <ul>
        <li><a href="fx.html#module-torch.fx.graph">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.graph_module

      <ul>
        <li><a href="fx.html#module-torch.fx.graph_module">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.immutable_collections

      <ul>
        <li><a href="fx.html#module-torch.fx.immutable_collections">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.interpreter

      <ul>
        <li><a href="fx.html#module-torch.fx.interpreter">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.node

      <ul>
        <li><a href="fx.html#module-torch.fx.node">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.operator_schemas

      <ul>
        <li><a href="fx.html#module-torch.fx.operator_schemas">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes

      <ul>
        <li><a href="fx.html#module-torch.fx.passes">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.annotate_getitem_nodes

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.annotate_getitem_nodes">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.backends

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.backends">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.backends.cudagraphs

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.backends.cudagraphs">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.dialect

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.dialect">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.dialect.common

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.dialect.common">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.dialect.common.cse_pass

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.dialect.common.cse_pass">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.fake_tensor_prop

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.fake_tensor_prop">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.graph_drawer

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.graph_drawer">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.graph_manipulation

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.graph_manipulation">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.infra

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.infra">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.infra.partitioner

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.infra.partitioner">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.infra.pass_base

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.infra.pass_base">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.infra.pass_manager

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.infra.pass_manager">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.net_min_base

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.net_min_base">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.operator_support

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.operator_support">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.param_fetch

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.param_fetch">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.pass_manager

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.pass_manager">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.reinplace

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.reinplace">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.shape_prop

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.shape_prop">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.split_module

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.split_module">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.split_utils

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.split_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.splitter_base

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.splitter_base">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.tests

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.tests">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.tests.test_pass_manager

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.tests.test_pass_manager">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.tools_common

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.tools_common">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.utils

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.utils.common

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.utils.common">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.utils.fuser_utils

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.utils.fuser_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.utils.matcher_utils

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.utils.matcher_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.utils.matcher_with_name_node_map_utils

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.utils.matcher_with_name_node_map_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.utils.source_matcher_utils

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.utils.source_matcher_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.proxy

      <ul>
        <li><a href="fx.html#module-torch.fx.proxy">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.subgraph_rewriter

      <ul>
        <li><a href="fx.html#module-torch.fx.subgraph_rewriter">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.tensor_type

      <ul>
        <li><a href="fx.html#module-torch.fx.tensor_type">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.traceback

      <ul>
        <li><a href="fx.html#module-torch.fx.traceback">module</a>
</li>
      </ul></li>
      <li>
    torch.hub

      <ul>
        <li><a href="hub.html#module-torch.hub">module</a>
</li>
      </ul></li>
      <li><a href="type_info.html#torch.torch.iinfo">torch.iinfo (class in torch)</a>
</li>
      <li>
    torch.jit

      <ul>
        <li><a href="jit.html#module-torch.jit">module</a>
</li>
      </ul></li>
      <li>
    torch.jit.annotations

      <ul>
        <li><a href="jit.html#module-torch.jit.annotations">module</a>
</li>
      </ul></li>
      <li>
    torch.jit.frontend

      <ul>
        <li><a href="jit.html#module-torch.jit.frontend">module</a>
</li>
      </ul></li>
      <li>
    torch.jit.generate_bytecode

      <ul>
        <li><a href="jit.html#module-torch.jit.generate_bytecode">module</a>
</li>
      </ul></li>
      <li>
    torch.jit.mobile

      <ul>
        <li><a href="jit.html#module-torch.jit.mobile">module</a>
</li>
      </ul></li>
      <li>
    torch.jit.quantized

      <ul>
        <li><a href="jit.html#module-torch.jit.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.jit.supported_ops

      <ul>
        <li><a href="jit_builtin_functions.html#module-torch.jit.supported_ops">module</a>
</li>
      </ul></li>
      <li>
    torch.jit.unsupported_tensor_ops

      <ul>
        <li><a href="jit_unsupported.html#module-torch.jit.unsupported_tensor_ops">module</a>
</li>
      </ul></li>
      <li>
    torch.library

      <ul>
        <li><a href="library.html#module-torch.library">module</a>
</li>
      </ul></li>
      <li>
    torch.linalg

      <ul>
        <li><a href="linalg.html#module-torch.linalg">module</a>
</li>
      </ul></li>
      <li>
    torch.masked

      <ul>
        <li><a href="masked.html#module-torch.masked">module</a>
</li>
      </ul></li>
      <li>
    torch.masked.maskedtensor

      <ul>
        <li><a href="masked.html#module-torch.masked.maskedtensor">module</a>
</li>
      </ul></li>
      <li>
    torch.masked.maskedtensor.binary

      <ul>
        <li><a href="masked.html#module-torch.masked.maskedtensor.binary">module</a>
</li>
      </ul></li>
      <li>
    torch.masked.maskedtensor.core

      <ul>
        <li><a href="masked.html#module-torch.masked.maskedtensor.core">module</a>
</li>
      </ul></li>
      <li>
    torch.masked.maskedtensor.creation

      <ul>
        <li><a href="masked.html#module-torch.masked.maskedtensor.creation">module</a>
</li>
      </ul></li>
      <li>
    torch.masked.maskedtensor.passthrough

      <ul>
        <li><a href="masked.html#module-torch.masked.maskedtensor.passthrough">module</a>
</li>
      </ul></li>
      <li>
    torch.masked.maskedtensor.reductions

      <ul>
        <li><a href="masked.html#module-torch.masked.maskedtensor.reductions">module</a>
</li>
      </ul></li>
      <li>
    torch.masked.maskedtensor.unary

      <ul>
        <li><a href="masked.html#module-torch.masked.maskedtensor.unary">module</a>
</li>
      </ul></li>
      <li>
    torch.monitor

      <ul>
        <li><a href="monitor.html#module-torch.monitor">module</a>
</li>
      </ul></li>
      <li>
    torch.mps

      <ul>
        <li><a href="mps.html#module-torch.mps">module</a>
</li>
      </ul></li>
      <li>
    torch.mps.event

      <ul>
        <li><a href="mps.html#module-torch.mps.event">module</a>
</li>
      </ul></li>
      <li>
    torch.mps.profiler

      <ul>
        <li><a href="mps.html#module-torch.mps.profiler">module</a>
</li>
      </ul></li>
      <li>
    torch.multiprocessing

      <ul>
        <li><a href="multiprocessing.html#module-torch.multiprocessing">module</a>
</li>
      </ul></li>
      <li>
    torch.multiprocessing.pool

      <ul>
        <li><a href="multiprocessing.html#module-torch.multiprocessing.pool">module</a>
</li>
      </ul></li>
      <li>
    torch.multiprocessing.queue

      <ul>
        <li><a href="multiprocessing.html#module-torch.multiprocessing.queue">module</a>
</li>
      </ul></li>
      <li>
    torch.multiprocessing.reductions

      <ul>
        <li><a href="multiprocessing.html#module-torch.multiprocessing.reductions">module</a>
</li>
      </ul></li>
      <li>
    torch.multiprocessing.spawn

      <ul>
        <li><a href="multiprocessing.html#module-torch.multiprocessing.spawn">module</a>
</li>
      </ul></li>
      <li>
    torch.nested

      <ul>
        <li><a href="nested.html#module-torch.nested">module</a>
</li>
      </ul></li>
      <li>
    torch.nn

      <ul>
        <li><a href="nn.html#module-torch.nn">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.attention

      <ul>
        <li><a href="nn.attention.html#module-torch.nn.attention">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.attention.bias

      <ul>
        <li><a href="nn.attention.bias.html#module-torch.nn.attention.bias">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.backends

      <ul>
        <li><a href="nn.html#module-torch.nn.backends">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.backends.thnn

      <ul>
        <li><a href="nn.html#module-torch.nn.backends.thnn">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.common_types

      <ul>
        <li><a href="nn.html#module-torch.nn.common_types">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.cpp

      <ul>
        <li><a href="nn.html#module-torch.nn.cpp">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.functional

      <ul>
        <li><a href="nn.html#module-torch.nn.functional">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.grad

      <ul>
        <li><a href="nn.html#module-torch.nn.grad">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.init

      <ul>
        <li><a href="nn.html#module-torch.nn.init">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.modules.fused

      <ul>
        <li><a href="quantization.html#module-torch.nn.intrinsic.modules.fused">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.qat

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.qat">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.qat.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.qat.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.qat.modules.conv_fused

      <ul>
        <li><a href="quantization.html#module-torch.nn.intrinsic.qat.modules.conv_fused">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.qat.modules.linear_fused

      <ul>
        <li><a href="quantization.html#module-torch.nn.intrinsic.qat.modules.linear_fused">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.qat.modules.linear_relu

      <ul>
        <li><a href="quantization.html#module-torch.nn.intrinsic.qat.modules.linear_relu">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized.dynamic.modules.linear_relu

      <ul>
        <li><a href="quantization.html#module-torch.nn.intrinsic.quantized.dynamic.modules.linear_relu">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized.modules.bn_relu

      <ul>
        <li><a href="quantization.html#module-torch.nn.intrinsic.quantized.modules.bn_relu">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized.modules.conv_relu

      <ul>
        <li><a href="quantization.html#module-torch.nn.intrinsic.quantized.modules.conv_relu">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized.modules.linear_relu

      <ul>
        <li><a href="quantization.html#module-torch.nn.intrinsic.quantized.modules.linear_relu">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules

      <ul>
        <li><a href="nn.html#module-torch.nn.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.activation

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.activation">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.adaptive

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.adaptive">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.batchnorm

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.batchnorm">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.channelshuffle

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.channelshuffle">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.container

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.container">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.conv

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.conv">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.distance

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.distance">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.dropout

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.dropout">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.flatten

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.flatten">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.fold

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.fold">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.instancenorm

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.instancenorm">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.lazy

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.lazy">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.linear

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.loss

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.loss">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.module

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.module">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.normalization

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.normalization">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.padding

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.padding">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.pixelshuffle

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.pixelshuffle">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.pooling

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.pooling">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.rnn

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.rnn">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.sparse

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.sparse">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.transformer

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.transformer">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.upsampling

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.upsampling">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules.utils

      <ul>
        <li><a href="nn.html#module-torch.nn.modules.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.parallel

      <ul>
        <li><a href="nn.html#module-torch.nn.parallel">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.parallel.comm

      <ul>
        <li><a href="nn.html#module-torch.nn.parallel.comm">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.parallel.data_parallel

      <ul>
        <li><a href="nn.html#module-torch.nn.parallel.data_parallel">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.parallel.distributed

      <ul>
        <li><a href="nn.html#module-torch.nn.parallel.distributed">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.parallel.parallel_apply

      <ul>
        <li><a href="nn.html#module-torch.nn.parallel.parallel_apply">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.parallel.replicate

      <ul>
        <li><a href="nn.html#module-torch.nn.parallel.replicate">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.parallel.scatter_gather

      <ul>
        <li><a href="nn.html#module-torch.nn.parallel.scatter_gather">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.parameter

      <ul>
        <li><a href="nn.html#module-torch.nn.parameter">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.qat">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.qat.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.qat.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat.dynamic.modules.linear

      <ul>
        <li><a href="quantization.html#module-torch.nn.qat.dynamic.modules.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.qat.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat.modules.conv

      <ul>
        <li><a href="quantization.html#module-torch.nn.qat.modules.conv">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat.modules.embedding_ops

      <ul>
        <li><a href="quantization.html#module-torch.nn.qat.modules.embedding_ops">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat.modules.linear

      <ul>
        <li><a href="quantization.html#module-torch.nn.qat.modules.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantizable

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantizable">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantizable.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantizable.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantizable.modules.activation

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantizable.modules.activation">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantizable.modules.rnn

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantizable.modules.rnn">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantized.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantized.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.dynamic.modules.conv

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.dynamic.modules.conv">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.dynamic.modules.linear

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.dynamic.modules.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.dynamic.modules.rnn

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.dynamic.modules.rnn">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.functional

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.functional">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantized.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules.activation

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.activation">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules.batchnorm

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.batchnorm">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules.conv

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.conv">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules.dropout

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.dropout">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules.embedding_ops

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.embedding_ops">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules.functional_modules

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.functional_modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules.linear

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.linear">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules.normalization

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.normalization">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules.rnn

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.rnn">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules.utils

      <ul>
        <li><a href="quantization.html#module-torch.nn.quantized.modules.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils

      <ul>
        <li><a href="nn.html#module-torch.nn.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.clip_grad

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.clip_grad">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.convert_parameters

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.convert_parameters">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.fusion

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.fusion">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.init

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.init">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.memory_format

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.memory_format">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.parametrizations

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.parametrizations">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.parametrize

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.parametrize">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.prune

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.prune">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.rnn

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.rnn">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.spectral_norm

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.spectral_norm">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.stateless

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.stateless">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.weight_norm

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.weight_norm">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx

      <ul>
        <li><a href="onnx_torchscript.html#module-torch.onnx">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.errors

      <ul>
        <li><a href="onnx.html#module-torch.onnx.errors">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.operators

      <ul>
        <li><a href="onnx.html#module-torch.onnx.operators">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_caffe2

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_caffe2">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_helper

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_helper">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset10

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset10">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset11

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset11">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset12

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset12">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset13

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset13">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset14

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset14">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset15

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset15">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset16

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset16">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset17

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset17">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset18

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset18">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset19

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset19">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset20

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset20">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset7

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset7">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset8

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset8">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.symbolic_opset9

      <ul>
        <li><a href="onnx.html#module-torch.onnx.symbolic_opset9">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.utils

      <ul>
        <li><a href="onnx.html#module-torch.onnx.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx.verification

      <ul>
        <li><a href="onnx.html#module-torch.onnx.verification">module</a>
</li>
      </ul></li>
      <li>
    torch.optim

      <ul>
        <li><a href="optim.html#module-torch.optim">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.adadelta

      <ul>
        <li><a href="optim.html#module-torch.optim.adadelta">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.adagrad

      <ul>
        <li><a href="optim.html#module-torch.optim.adagrad">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.adam

      <ul>
        <li><a href="optim.html#module-torch.optim.adam">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.adamax

      <ul>
        <li><a href="optim.html#module-torch.optim.adamax">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.adamw

      <ul>
        <li><a href="optim.html#module-torch.optim.adamw">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.asgd

      <ul>
        <li><a href="optim.html#module-torch.optim.asgd">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.lbfgs

      <ul>
        <li><a href="optim.html#module-torch.optim.lbfgs">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.lr_scheduler

      <ul>
        <li><a href="optim.html#module-torch.optim.lr_scheduler">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.nadam

      <ul>
        <li><a href="optim.html#module-torch.optim.nadam">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.optimizer

      <ul>
        <li><a href="optim.html#module-torch.optim.optimizer">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.radam

      <ul>
        <li><a href="optim.html#module-torch.optim.radam">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.rmsprop

      <ul>
        <li><a href="optim.html#module-torch.optim.rmsprop">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.rprop

      <ul>
        <li><a href="optim.html#module-torch.optim.rprop">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.sgd

      <ul>
        <li><a href="optim.html#module-torch.optim.sgd">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.sparse_adam

      <ul>
        <li><a href="optim.html#module-torch.optim.sparse_adam">module</a>
</li>
      </ul></li>
      <li>
    torch.optim.swa_utils

      <ul>
        <li><a href="optim.html#module-torch.optim.swa_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.overrides

      <ul>
        <li><a href="torch.overrides.html#module-torch.overrides">module</a>
</li>
      </ul></li>
      <li>
    torch.package

      <ul>
        <li><a href="package.html#module-torch.package">module</a>
</li>
      </ul></li>
      <li>
    torch.package.analyze

      <ul>
        <li><a href="package.html#module-torch.package.analyze">module</a>
</li>
      </ul></li>
      <li>
    torch.package.analyze.find_first_use_of_broken_modules

      <ul>
        <li><a href="package.html#module-torch.package.analyze.find_first_use_of_broken_modules">module</a>
</li>
      </ul></li>
      <li>
    torch.package.analyze.is_from_package

      <ul>
        <li><a href="package.html#module-torch.package.analyze.is_from_package">module</a>
</li>
      </ul></li>
      <li>
    torch.package.analyze.trace_dependencies

      <ul>
        <li><a href="package.html#module-torch.package.analyze.trace_dependencies">module</a>
</li>
      </ul></li>
      <li>
    torch.package.file_structure_representation

      <ul>
        <li><a href="package.html#module-torch.package.file_structure_representation">module</a>
</li>
      </ul></li>
      <li>
    torch.package.find_file_dependencies

      <ul>
        <li><a href="package.html#module-torch.package.find_file_dependencies">module</a>
</li>
      </ul></li>
      <li>
    torch.package.glob_group

      <ul>
        <li><a href="package.html#module-torch.package.glob_group">module</a>
</li>
      </ul></li>
      <li>
    torch.package.importer

      <ul>
        <li><a href="package.html#module-torch.package.importer">module</a>
</li>
      </ul></li>
      <li>
    torch.package.package_exporter

      <ul>
        <li><a href="package.html#module-torch.package.package_exporter">module</a>
</li>
      </ul></li>
      <li>
    torch.package.package_importer

      <ul>
        <li><a href="package.html#module-torch.package.package_importer">module</a>
</li>
      </ul></li>
      <li>
    torch.profiler

      <ul>
        <li><a href="profiler.html#module-torch.profiler">module</a>
</li>
      </ul></li>
      <li>
    torch.profiler.itt

      <ul>
        <li><a href="profiler.html#module-torch.profiler.itt">module</a>
</li>
      </ul></li>
      <li>
    torch.profiler.profiler

      <ul>
        <li><a href="profiler.html#module-torch.profiler.profiler">module</a>
</li>
      </ul></li>
      <li>
    torch.profiler.python_tracer

      <ul>
        <li><a href="profiler.html#module-torch.profiler.python_tracer">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization

      <ul>
        <li><a href="quantization-support.html#module-torch.quantization">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fake_quantize

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fake_quantize">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fuse_modules

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fuse_modules">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fuser_method_mappings

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fuser_method_mappings">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx

      <ul>
        <li><a href="quantization-support.html#module-torch.quantization.fx">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx.convert

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fx.convert">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx.fuse

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fx.fuse">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx.fusion_patterns

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fx.fusion_patterns">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx.graph_module

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fx.graph_module">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx.match_utils

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fx.match_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx.pattern_utils

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fx.pattern_utils">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx.prepare

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fx.prepare">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx.quantization_patterns

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fx.quantization_patterns">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx.quantization_types

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fx.quantization_types">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx.utils

      <ul>
        <li><a href="quantization.html#module-torch.quantization.fx.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.observer

      <ul>
        <li><a href="quantization.html#module-torch.quantization.observer">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.qconfig

      <ul>
        <li><a href="quantization.html#module-torch.quantization.qconfig">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.quant_type

      <ul>
        <li><a href="quantization.html#module-torch.quantization.quant_type">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.quantization_mappings

      <ul>
        <li><a href="quantization.html#module-torch.quantization.quantization_mappings">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.quantize

      <ul>
        <li><a href="quantization.html#module-torch.quantization.quantize">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.quantize_fx

      <ul>
        <li><a href="quantization.html#module-torch.quantization.quantize_fx">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.quantize_jit

      <ul>
        <li><a href="quantization.html#module-torch.quantization.quantize_jit">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.stubs

      <ul>
        <li><a href="quantization.html#module-torch.quantization.stubs">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.utils

      <ul>
        <li><a href="quantization.html#module-torch.quantization.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.quasirandom

      <ul>
        <li><a href="torch.html#module-torch.quasirandom">module</a>
</li>
      </ul></li>
      <li>
    torch.random

      <ul>
        <li><a href="random.html#module-torch.random">module</a>
</li>
      </ul></li>
      <li>
    torch.return_types

      <ul>
        <li><a href="torch.html#module-torch.return_types">module</a>
</li>
      </ul></li>
      <li>
    torch.serialization

      <ul>
        <li><a href="torch.html#module-torch.serialization">module</a>
</li>
      </ul></li>
      <li>
    torch.signal

      <ul>
        <li><a href="signal.html#module-torch.signal">module</a>
</li>
      </ul></li>
      <li>
    torch.signal.windows

      <ul>
        <li><a href="signal.html#module-torch.signal.windows">module</a>
</li>
      </ul></li>
      <li>
    torch.signal.windows.windows

      <ul>
        <li><a href="torch.html#module-torch.signal.windows.windows">module</a>
</li>
      </ul></li>
      <li>
    torch.sparse

      <ul>
        <li><a href="sparse.html#module-torch.sparse">module</a>
</li>
      </ul></li>
      <li>
    torch.sparse.semi_structured

      <ul>
        <li><a href="torch.html#module-torch.sparse.semi_structured">module</a>
</li>
      </ul></li>
      <li>
    torch.special

      <ul>
        <li><a href="special.html#module-torch.special">module</a>
</li>
      </ul></li>
      <li>
    torch.storage

      <ul>
        <li><a href="torch.html#module-torch.storage">module</a>
</li>
      </ul></li>
      <li>
    torch.testing

      <ul>
        <li><a href="testing.html#module-torch.testing">module</a>
</li>
      </ul></li>
      <li>
    torch.torch_version

      <ul>
        <li><a href="torch.html#module-torch.torch_version">module</a>
</li>
      </ul></li>
      <li>
    torch.types

      <ul>
        <li><a href="torch.html#module-torch.types">module</a>
</li>
      </ul></li>
      <li>
    torch.utils

      <ul>
        <li><a href="utils.html#module-torch.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.backcompat

      <ul>
        <li><a href="torch.html#module-torch.utils.backcompat">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.backend_registration

      <ul>
        <li><a href="utils.html#module-torch.utils.backend_registration">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark

      <ul>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.examples

      <ul>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.examples">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.examples.blas_compare_setup

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.blas_compare_setup">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.examples.compare

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.compare">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.examples.fuzzer

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.fuzzer">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.examples.op_benchmark

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.op_benchmark">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.examples.simple_timeit

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.simple_timeit">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.examples.spectral_ops_fuzz_test

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.examples.spectral_ops_fuzz_test">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.op_fuzzers

      <ul>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.op_fuzzers">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.op_fuzzers.binary

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.op_fuzzers.binary">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.op_fuzzers.sparse_binary

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.op_fuzzers.sparse_binary">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.op_fuzzers.sparse_unary

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.op_fuzzers.sparse_unary">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.op_fuzzers.spectral

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.op_fuzzers.spectral">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.op_fuzzers.unary

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.op_fuzzers.unary">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils

      <ul>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils.common

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.common">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils.compare

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.compare">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils.compile

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.compile">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils.cpp_jit

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.cpp_jit">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils.fuzzer

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.fuzzer">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils.sparse_fuzzer

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.sparse_fuzzer">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils.timer

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.timer">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils.valgrind_wrapper

      <ul>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.utils.valgrind_wrapper">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils.valgrind_wrapper.timer_interface

      <ul>
        <li><a href="utils.html#module-torch.utils.benchmark.utils.valgrind_wrapper.timer_interface">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.bottleneck

      <ul>
        <li><a href="bottleneck.html#module-torch.utils.bottleneck">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.bundled_inputs

      <ul>
        <li><a href="utils.html#module-torch.utils.bundled_inputs">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.checkpoint

      <ul>
        <li><a href="utils.html#module-torch.utils.checkpoint">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.collect_env

      <ul>
        <li><a href="utils.html#module-torch.utils.collect_env">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.cpp_backtrace

      <ul>
        <li><a href="utils.html#module-torch.utils.cpp_backtrace">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.cpp_extension

      <ul>
        <li><a href="utils.html#module-torch.utils.cpp_extension">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data

      <ul>
        <li><a href="data.html#module-torch.utils.data">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.backward_compatibility

      <ul>
        <li><a href="utils.html#module-torch.utils.data.backward_compatibility">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.dataloader

      <ul>
        <li><a href="utils.html#module-torch.utils.data.dataloader">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes

      <ul>
        <li><a href="data.html#module-torch.utils.data.datapipes">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.dataframe

      <ul>
        <li><a href="data.html#module-torch.utils.data.datapipes.dataframe">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.dataframe.dataframe_wrapper

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.dataframe.dataframe_wrapper">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.dataframe.dataframes

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.dataframe.dataframes">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.dataframe.datapipes

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.dataframe.datapipes">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.dataframe.structures

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.dataframe.structures">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.datapipe

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.datapipe">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.gen_pyi

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.gen_pyi">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter

      <ul>
        <li><a href="data.html#module-torch.utils.data.datapipes.iter">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter.callable

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.callable">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter.combinatorics

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.combinatorics">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter.combining

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.combining">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter.filelister

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.filelister">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter.fileopener

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.fileopener">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter.grouping

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.grouping">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter.routeddecoder

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.routeddecoder">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter.selecting

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.selecting">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter.sharding

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.sharding">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter.streamreader

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.streamreader">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter.utils

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.iter.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.map

      <ul>
        <li><a href="data.html#module-torch.utils.data.datapipes.map">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.map.callable

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.map.callable">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.map.combinatorics

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.map.combinatorics">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.map.combining

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.map.combining">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.map.grouping

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.map.grouping">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.map.utils

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.map.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.utils

      <ul>
        <li><a href="data.html#module-torch.utils.data.datapipes.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.utils.common

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.utils.common">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.utils.decoder

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.utils.decoder">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.utils.snapshot

      <ul>
        <li><a href="utils.html#module-torch.utils.data.datapipes.utils.snapshot">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.dataset

      <ul>
        <li><a href="utils.html#module-torch.utils.data.dataset">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.distributed

      <ul>
        <li><a href="utils.html#module-torch.utils.data.distributed">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.graph

      <ul>
        <li><a href="utils.html#module-torch.utils.data.graph">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.graph_settings

      <ul>
        <li><a href="utils.html#module-torch.utils.data.graph_settings">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.sampler

      <ul>
        <li><a href="utils.html#module-torch.utils.data.sampler">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.deterministic

      <ul>
        <li><a href="deterministic.html#module-torch.utils.deterministic">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.dlpack

      <ul>
        <li><a href="utils.html#module-torch.utils.dlpack">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.file_baton

      <ul>
        <li><a href="utils.html#module-torch.utils.file_baton">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.flop_counter

      <ul>
        <li><a href="utils.html#module-torch.utils.flop_counter">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.hipify

      <ul>
        <li><a href="torch.html#module-torch.utils.hipify">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.hipify.constants

      <ul>
        <li><a href="utils.html#module-torch.utils.hipify.constants">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.hipify.cuda_to_hip_mappings

      <ul>
        <li><a href="utils.html#module-torch.utils.hipify.cuda_to_hip_mappings">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.hipify.hipify_python

      <ul>
        <li><a href="utils.html#module-torch.utils.hipify.hipify_python">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.hipify.version

      <ul>
        <li><a href="utils.html#module-torch.utils.hipify.version">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.hooks

      <ul>
        <li><a href="utils.html#module-torch.utils.hooks">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.jit

      <ul>
        <li><a href="jit_utils.html#module-torch.utils.jit">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.jit.log_extract

      <ul>
        <li><a href="utils.html#module-torch.utils.jit.log_extract">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.mkldnn

      <ul>
        <li><a href="utils.html#module-torch.utils.mkldnn">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.mobile_optimizer

      <ul>
        <li><a href="utils.html#module-torch.utils.mobile_optimizer">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.model_dump

      <ul>
        <li><a href="torch.html#module-torch.utils.model_dump">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.model_zoo

      <ul>
        <li><a href="model_zoo.html#module-torch.utils.model_zoo">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.show_pickle

      <ul>
        <li><a href="utils.html#module-torch.utils.show_pickle">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.tensorboard

      <ul>
        <li><a href="tensorboard.html#module-torch.utils.tensorboard">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.tensorboard.summary

      <ul>
        <li><a href="utils.html#module-torch.utils.tensorboard.summary">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.tensorboard.writer

      <ul>
        <li><a href="utils.html#module-torch.utils.tensorboard.writer">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.throughput_benchmark

      <ul>
        <li><a href="utils.html#module-torch.utils.throughput_benchmark">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.viz

      <ul>
        <li><a href="torch.html#module-torch.utils.viz">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.weak

      <ul>
        <li><a href="utils.html#module-torch.utils.weak">module</a>
</li>
      </ul></li>
      <li>
    torch.version

      <ul>
        <li><a href="torch.html#module-torch.version">module</a>
</li>
      </ul></li>
      <li>
    torch.xpu

      <ul>
        <li><a href="xpu.html#module-torch.xpu">module</a>
</li>
      </ul></li>
      <li>
    torch.xpu.random

      <ul>
        <li><a href="xpu.html#module-torch.xpu.random">module</a>
</li>
      </ul></li>
      <li>
    torch.xpu.streams

      <ul>
        <li><a href="xpu.html#module-torch.xpu.streams">module</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.torch_name">torch_name() (torch.onnx.JitScalarType method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.torch_save_to_dcp">torch_save_to_dcp() (in module torch.distributed.checkpoint.format_utils)</a>
</li>
      <li><a href="generated/torch.autograd.profiler.profile.total_average.html#torch.autograd.profiler.profile.total_average">total_average() (torch.autograd.profiler.profile method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.total_count">total_count (torch.distributions.multinomial.Multinomial attribute)</a>
</li>
      <li><a href="generated/torch.trace.html#torch.trace">trace() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.jit.trace.html#torch.jit.trace">(in module torch.jit)</a>
</li>
        <li><a href="fx.html#torch.fx.Tracer.trace">(torch.fx.Tracer method)</a>
</li>
        <li><a href="generated/torch.Tensor.trace.html#torch.Tensor.trace">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.trace_module.html#torch.jit.trace_module">trace_module() (in module torch.jit)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer">Tracer (class in torch.fx)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.train">train() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.train">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform">Transform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="fx.html#torch.fx.Transformer.transform">transform() (torch.fx.Transformer method)</a>

      <ul>
        <li><a href="benchmark_utils.html#torch.utils.benchmark.FunctionCounts.transform">(torch.utils.benchmark.FunctionCounts method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultSavePlanner.transform_object">transform_object() (torch.distributed.checkpoint.DefaultSavePlanner method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultLoadPlanner.transform_tensor">transform_tensor() (torch.distributed.checkpoint.DefaultLoadPlanner method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution">TransformedDistribution (class in torch.distributions.transformed_distribution)</a>
</li>
      <li><a href="fx.html#torch.fx.Transformer">Transformer (class in torch.fx)</a>

      <ul>
        <li><a href="generated/torch.nn.Transformer.html#torch.nn.Transformer">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder">TransformerDecoder (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.TransformerDecoderLayer.html#torch.nn.TransformerDecoderLayer">TransformerDecoderLayer (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder">TransformerEncoder (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.TransformerEncoderLayer.html#torch.nn.TransformerEncoderLayer">TransformerEncoderLayer (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.transpose.html#torch.transpose">transpose() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.transpose.html#torch.Tensor.transpose">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.transpose_.html#torch.Tensor.transpose_">transpose_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.trapezoid.html#torch.trapezoid">trapezoid() (in module torch)</a>
</li>
      <li><a href="generated/torch.trapz.html#torch.trapz">trapz() (in module torch)</a>
</li>
      <li><a href="generated/torch.triangular_solve.html#torch.triangular_solve">triangular_solve() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.triangular_solve.html#torch.Tensor.triangular_solve">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.tril.html#torch.tril">tril() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.tril.html#torch.Tensor.tril">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.tril_.html#torch.Tensor.tril_">tril_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.tril_indices.html#torch.tril_indices">tril_indices() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.functional.triplet_margin_loss.html#torch.nn.functional.triplet_margin_loss">triplet_margin_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.triplet_margin_with_distance_loss.html#torch.nn.functional.triplet_margin_with_distance_loss">triplet_margin_with_distance_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.TripletMarginLoss.html#torch.nn.TripletMarginLoss">TripletMarginLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.TripletMarginWithDistanceLoss.html#torch.nn.TripletMarginWithDistanceLoss">TripletMarginWithDistanceLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.triu.html#torch.triu">triu() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.triu.html#torch.Tensor.triu">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.triu_.html#torch.Tensor.triu_">triu_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.triu_indices.html#torch.triu_indices">triu_indices() (in module torch)</a>
</li>
      <li><a href="generated/torch.true_divide.html#torch.true_divide">true_divide() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.true_divide.html#torch.Tensor.true_divide">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.true_divide_.html#torch.Tensor.true_divide_">true_divide_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.trunc.html#torch.trunc">trunc() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.trunc.html#torch.Tensor.trunc">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.trunc_.html#torch.Tensor.trunc_">trunc_() (torch.Tensor method)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.trunc_normal_">trunc_normal_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.jit.Attribute.html#torch.jit.Attribute.type">type (torch.jit.Attribute attribute)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.type">type() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.type">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.type.html#torch.Tensor.type">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.type">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.type">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.type_as.html#torch.Tensor.type_as">type_as() (torch.Tensor method)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage">TypedStorage (class in torch)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="U">U</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.unbind.html#torch.unbind">unbind() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.unbind.html#torch.Tensor.unbind">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.Unflatten.html#torch.nn.Unflatten">Unflatten (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.unflatten.html#torch.unflatten">unflatten() (in module torch)</a>

      <ul>
        <li><a href="export.html#torch.export.unflatten.unflatten">(in module torch.export.unflatten)</a>
</li>
        <li><a href="generated/torch.Tensor.unflatten.html#torch.Tensor.unflatten">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.Unfold.html#torch.nn.Unfold">Unfold (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.unfold.html#torch.nn.functional.unfold">unfold() (in module torch.nn.functional)</a>

      <ul>
        <li><a href="generated/torch.Tensor.unfold.html#torch.Tensor.unfold">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.uniform.Uniform">Uniform (class in torch.distributions.uniform)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.uniform_">uniform_() (in module torch.nn.init)</a>

      <ul>
        <li><a href="generated/torch.Tensor.uniform_.html#torch.Tensor.uniform_">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.parameter.UninitializedBuffer.html#torch.nn.parameter.UninitializedBuffer">UninitializedBuffer (class in torch.nn.parameter)</a>
</li>
      <li><a href="generated/torch.nn.parameter.UninitializedParameter.html#torch.nn.parameter.UninitializedParameter">UninitializedParameter (class in torch.nn.parameter)</a>
</li>
      <li><a href="generated/torch.unique.html#torch.unique">unique() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.unique.html#torch.Tensor.unique">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.unique_consecutive.html#torch.unique_consecutive">unique_consecutive() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.unique_consecutive.html#torch.Tensor.unique_consecutive">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.forward_ad.unpack_dual.html#torch.autograd.forward_ad.unpack_dual">unpack_dual() (in module torch.autograd.forward_ad)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.unpack_sequence.html#torch.nn.utils.rnn.unpack_sequence">unpack_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="generated/torch.autograd.forward_ad.UnpackedDualTensor.html#torch.autograd.forward_ad.UnpackedDualTensor">UnpackedDualTensor (class in torch.autograd.forward_ad)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.unpad_sequence.html#torch.nn.utils.rnn.unpad_sequence">unpad_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="generated/torch.unravel_index.html#torch.unravel_index">unravel_index() (in module torch)</a>
</li>
      <li><a href="onnx_torchscript.html#torch.onnx.unregister_custom_op_symbolic">unregister_custom_op_symbolic() (in module torch.onnx)</a>
</li>
      <li><a href="monitor.html#torch.monitor.unregister_event_handler">unregister_event_handler() (in module torch.monitor)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.unsorted_indices">unsorted_indices (torch.nn.utils.rnn.PackedSequence attribute)</a>
</li>
      <li><a href="generated/torch.unsqueeze.html#torch.unsqueeze">unsqueeze() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.unsqueeze.html#torch.Tensor.unsqueeze">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.unsqueeze_.html#torch.Tensor.unsqueeze_">unsqueeze_() (torch.Tensor method)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.untyped">untyped() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.untyped">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.untyped_storage.html#torch.Tensor.untyped_storage">untyped_storage() (torch.Tensor method)</a>
</li>
      <li><a href="storage.html#torch.UntypedStorage">UntypedStorage (class in torch)</a>
</li>
      <li><a href="generated/torch.jit.unused.html#torch.jit.unused">unused() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.update">update() (torch.autograd.profiler_util.StringTable method)</a>

      <ul>
        <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.update">(torch.nn.ModuleDict method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.update">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Node.update_arg">update_arg() (torch.fx.Node method)</a>
</li>
      <li><a href="generated/torch.ao.nn.intrinsic.qat.update_bn_stats.html#torch.ao.nn.intrinsic.qat.update_bn_stats">update_bn_stats (class in torch.ao.nn.intrinsic.qat)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.update_kwarg">update_kwarg() (torch.fx.Node method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.upsample.html#torch.ao.nn.quantized.functional.upsample">upsample (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Upsample.html#torch.nn.Upsample">Upsample (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.upsample.html#torch.nn.functional.upsample">upsample() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.upsample_bilinear.html#torch.ao.nn.quantized.functional.upsample_bilinear">upsample_bilinear (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.upsample_bilinear.html#torch.nn.functional.upsample_bilinear">upsample_bilinear() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.upsample_nearest.html#torch.ao.nn.quantized.functional.upsample_nearest">upsample_nearest (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.upsample_nearest.html#torch.nn.functional.upsample_nearest">upsample_nearest() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.UpsamplingBilinear2d.html#torch.nn.UpsamplingBilinear2d">UpsamplingBilinear2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.UpsamplingNearest2d.html#torch.nn.UpsamplingNearest2d">UpsamplingNearest2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms">use_deterministic_algorithms() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.utilization.html#torch.cuda.utilization">utilization() (in module torch.cuda)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="V">V</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader.validate_checkpoint_id">validate_checkpoint_id() (torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader class method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.validate_checkpoint_id">(torch.distributed.checkpoint.StorageReader class method)</a>
</li>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.validate_checkpoint_id">(torch.distributed.checkpoint.StorageWriter class method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.Attribute.html#torch.jit.Attribute.value">value (torch.jit.Attribute attribute)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.value">value() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.autograd.profiler_util.StringTable.html#torch.autograd.profiler_util.StringTable.values">values() (torch.autograd.profiler_util.StringTable method)</a>

      <ul>
        <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.values">(torch.nn.ModuleDict method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.values">(torch.nn.ParameterDict method)</a>
</li>
        <li><a href="generated/torch.Tensor.values.html#torch.Tensor.values">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.vander.html#torch.vander">vander() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.vander.html#torch.linalg.vander">(in module torch.linalg)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.var.html#torch.var">var() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.var.html#torch.Tensor.var">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.var_mean.html#torch.var_mean">var_mean() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.variance">variance (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.variance">(torch.distributions.beta.Beta property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.variance">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.variance">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.variance">(torch.distributions.cauchy.Cauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.variance">(torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.variance">(torch.distributions.dirichlet.Dirichlet property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.variance">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.variance">(torch.distributions.exponential.Exponential property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.variance">(torch.distributions.fishersnedecor.FisherSnedecor property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.variance">(torch.distributions.gamma.Gamma property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.variance">(torch.distributions.geometric.Geometric property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.variance">(torch.distributions.gumbel.Gumbel property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.variance">(torch.distributions.half_cauchy.HalfCauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.variance">(torch.distributions.half_normal.HalfNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.variance">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.inverse_gamma.InverseGamma.variance">(torch.distributions.inverse_gamma.InverseGamma property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.variance">(torch.distributions.kumaraswamy.Kumaraswamy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.variance">(torch.distributions.laplace.Laplace property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.variance">(torch.distributions.log_normal.LogNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.variance">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.variance">(torch.distributions.mixture_same_family.MixtureSameFamily property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.variance">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.variance">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.variance">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.variance">(torch.distributions.normal.Normal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.variance">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.variance">(torch.distributions.pareto.Pareto property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.variance">(torch.distributions.poisson.Poisson property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.variance">(torch.distributions.studentT.StudentT property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.variance">(torch.distributions.uniform.Uniform property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.variance">(torch.distributions.von_mises.VonMises property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.variance">(torch.distributions.weibull.Weibull property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.variance">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.vdot.html#torch.vdot">vdot() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.vdot.html#torch.Tensor.vdot">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.vecdot.html#torch.linalg.vecdot">vecdot() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.vector_norm.html#torch.linalg.vector_norm">vector_norm() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.nn.utils.vector_to_parameters.html#torch.nn.utils.vector_to_parameters">vector_to_parameters() (in module torch.nn.utils)</a>
</li>
      <li><a href="backends.html#torch.backends.mkl.verbose">verbose (class in torch.backends.mkl)</a>

      <ul>
        <li><a href="backends.html#torch.backends.mkldnn.verbose">(class in torch.backends.mkldnn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.verification.VerificationOptions.html#torch.onnx.verification.VerificationOptions">VerificationOptions (class in torch.onnx.verification)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.verify_export">verify_export() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.verify_ninja_availability">verify_ninja_availability() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="pipeline.html#torch.distributed.pipeline.sync.skip.skippable.verify_skippables">verify_skippables() (in module torch.distributed.pipeline.sync.skip.skippable)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.version">version() (in module torch.backends.cudnn)</a>
</li>
      <li><a href="generated/torch.autograd.functional.vhp.html#torch.autograd.functional.vhp">vhp() (in module torch.autograd.functional)</a>
</li>
      <li><a href="generated/torch.Tensor.view.html#torch.Tensor.view">view() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.view_as.html#torch.Tensor.view_as">view_as() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.view_as_complex.html#torch.view_as_complex">view_as_complex() (in module torch)</a>
</li>
      <li><a href="generated/torch.view_as_real.html#torch.view_as_real">view_as_real() (in module torch)</a>
</li>
      <li><a href="generated/torch.autograd.functional.vjp.html#torch.autograd.functional.vjp">vjp() (in module torch.autograd.functional)</a>

      <ul>
        <li><a href="generated/torch.func.vjp.html#torch.func.vjp">(in module torch.func)</a>
</li>
        <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction.vjp">(torch.autograd.function.InplaceFunction static method)</a>
</li>
        <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.vjp">(torch.autograd.function.NestedIOFunction static method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.vmap.html#torch.vmap">vmap() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.func.vmap.html#torch.func.vmap">(in module torch.func)</a>
</li>
        <li><a href="generated/torch.autograd.Function.vmap.html#torch.autograd.Function.vmap">(torch.autograd.Function static method)</a>
</li>
        <li><a href="generated/torch.autograd.function.InplaceFunction.html#torch.autograd.function.InplaceFunction.vmap">(torch.autograd.function.InplaceFunction static method)</a>
</li>
        <li><a href="generated/torch.autograd.function.NestedIOFunction.html#torch.autograd.function.NestedIOFunction.vmap">(torch.autograd.function.NestedIOFunction static method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.von_mises.VonMises">VonMises (class in torch.distributions.von_mises)</a>
</li>
      <li><a href="generated/torch.vsplit.html#torch.vsplit">vsplit() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.vsplit.html#torch.Tensor.vsplit">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.vstack.html#torch.vstack">vstack() (in module torch)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="W">W</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributed.html#torch.distributed.Store.wait">wait() (in module torch.distributed.Store)</a>

      <ul>
        <li><a href="generated/torch.jit.wait.html#torch.jit.wait">(in module torch.jit)</a>
</li>
        <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.wait">(torch.cuda.Event method)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.wait">(torch.distributed.elastic.rendezvous.etcd_store.EtcdStore method)</a>
</li>
        <li><a href="futures.html#torch.futures.Future.wait">(torch.futures.Future method)</a>
</li>
        <li><a href="generated/torch.mps.event.Event.html#torch.mps.event.Event.wait">(torch.mps.event.Event method)</a>
</li>
        <li><a href="generated/torch.xpu.Event.html#torch.xpu.Event.wait">(torch.xpu.Event method)</a>
</li>
      </ul></li>
      <li><a href="futures.html#torch.futures.wait_all">wait_all() (in module torch.futures)</a>
</li>
      <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream.wait_event">wait_event() (torch.cuda.ExternalStream method)</a>

      <ul>
        <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream.wait_event">(torch.cuda.Stream method)</a>
</li>
        <li><a href="generated/torch.xpu.Stream.html#torch.xpu.Stream.wait_event">(torch.xpu.Stream method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream.wait_stream">wait_stream() (torch.cuda.ExternalStream method)</a>

      <ul>
        <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream.wait_stream">(torch.cuda.Stream method)</a>
</li>
        <li><a href="generated/torch.xpu.Stream.html#torch.xpu.Stream.wait_stream">(torch.xpu.Stream method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.weibull.Weibull">Weibull (class in torch.distributions.weibull)</a>
</li>
      <li><a href="generated/torch.nn.utils.weight_norm.html#torch.nn.utils.weight_norm">weight_norm() (in module torch.nn.utils)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.parametrizations.weight_norm.html#torch.nn.utils.parametrizations.weight_norm">(in module torch.nn.utils.parametrizations)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="data.html#torch.utils.data.WeightedRandomSampler">WeightedRandomSampler (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.where.html#torch.where">where() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.where.html#torch.Tensor.where">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.wishart.Wishart">Wishart (class in torch.distributions.wishart)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.ObserverBase.html#torch.ao.quantization.observer.ObserverBase.with_args">with_args() (torch.ao.quantization.observer.ObserverBase class method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.ObserverBase.html#torch.ao.quantization.observer.ObserverBase.with_callable_args">with_callable_args() (torch.ao.quantization.observer.ObserverBase class method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Work">Work (class in torch.distributed)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.Worker">Worker (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.WorkerGroup">WorkerGroup (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.WorkerInfo">WorkerInfo (class in torch.distributed.rpc)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.WorkerSpec">WorkerSpec (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.WorkerState">WorkerState (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="fx.html#torch.fx.wrap">wrap() (in module torch.fx)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.wrap_torch_function">wrap_torch_function() (in module torch.overrides)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.write_data">write_data() (torch.distributed.checkpoint.StorageWriter method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.planner.WriteItem">WriteItem (class in torch.distributed.checkpoint.planner)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="X">X</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="nn.init.html#torch.nn.init.xavier_normal_">xavier_normal_() (in module torch.nn.init)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.xavier_uniform_">xavier_uniform_() (in module torch.nn.init)</a>
</li>
      <li><a href="special.html#torch.special.xlog1py">xlog1py() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.xlogy.html#torch.xlogy">xlogy() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.xlogy">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.xlogy.html#torch.Tensor.xlogy">(torch.Tensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.Tensor.xlogy_.html#torch.Tensor.xlogy_">xlogy_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.xpu">xpu() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.xpu">(torch.nn.Module method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="Z">Z</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.Tensor.zero_.html#torch.Tensor.zero_">zero_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.zero_grad">zero_grad() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.zero_grad">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.zero_grad">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.zero_grad">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.zero_grad">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.zero_grad">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.zero_grad">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.zero_grad">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.zero_grad">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.zero_grad">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.Optimizer.zero_grad.html#torch.optim.Optimizer.zero_grad">(torch.optim.Optimizer method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.zero_grad">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.zero_grad">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.zero_grad">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.zero_grad">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.zero_grad">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.nn.ZeroPad1d.html#torch.nn.ZeroPad1d">ZeroPad1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ZeroPad2d.html#torch.nn.ZeroPad2d">ZeroPad2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ZeroPad3d.html#torch.nn.ZeroPad3d">ZeroPad3d (class in torch.nn)</a>
</li>
      <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer">ZeroRedundancyOptimizer (class in torch.distributed.optim)</a>
</li>
      <li><a href="generated/torch.zeros.html#torch.zeros">zeros() (in module torch)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.zeros_">zeros_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.zeros_like.html#torch.zeros_like">zeros_like() (in module torch)</a>
</li>
      <li><a href="special.html#torch.special.zeta">zeta() (in module torch.special)</a>
</li>
  </ul></td>
</tr></table>



             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/sphinx_highlight.js"></script>
         <script src="_static/clipboard.min.js"></script>
         <script src="_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>