


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Index &mdash; PyTorch main documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/genindex.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="_static/sphinx-dropdown.css" type="text/css" />
  <link rel="stylesheet" href="_static/panels-bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="#" />
    <link rel="search" title="Search" href="search.html" />

<!--
  Search engines should not index the main version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>main (2.1.0a0+git707d265 ) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          

<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/genindex.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community/build_ci_governance.html">PyTorch Governance | Build + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/design.html">PyTorch Design Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/governance.html">PyTorch Governance | Mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/persons_of_interest.html">PyTorch Governance | Maintainers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/amp_examples.html">CUDA Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.func.html">Extending torch.func with autograd.Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">torch.compile</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="compile/index.html">torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/get-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/troubleshooting.html">PyTorch 2.0 Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/technical-overview.html">Technical Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/guards-overview.html">Guards Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/custom-backends.html">Custom Backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/fine_grained_apis.html">TorchDynamo APIs to control fine-grained tracing</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/profiling_torch_compile.html">Profiling to understand torch.compile performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/inductor_profiling.html">TorchInductor GPU Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/deep-dive.html">TorchDynamo Deeper Dive</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/cudagraph_trees.html">CUDAGraph Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/performance-dashboard.html">PyTorch 2.0 Performance Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/torchfunc-and-torchcompile.html">torch.func interaction with torch.compile</a></li>
<li class="toctree-l1"><a class="reference internal" href="ir.html">IRs</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/dynamic-shapes.html">Dynamic shapes</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/fake-tensor.html">Fake tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">torch._logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="compile/transformations.html">Writing Graph Transformations on ATen IR</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="export.html">torch._export.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx_diagnostics.html">torch.onnx diagnostics</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="logging.html">torch._logging</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>Index</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              

<h1 id="index">Index</h1>

<div class="genindex-jumpbox">
 <a href="#_"><strong>_</strong></a>
 | <a href="#A"><strong>A</strong></a>
 | <a href="#B"><strong>B</strong></a>
 | <a href="#C"><strong>C</strong></a>
 | <a href="#D"><strong>D</strong></a>
 | <a href="#E"><strong>E</strong></a>
 | <a href="#F"><strong>F</strong></a>
 | <a href="#G"><strong>G</strong></a>
 | <a href="#H"><strong>H</strong></a>
 | <a href="#I"><strong>I</strong></a>
 | <a href="#J"><strong>J</strong></a>
 | <a href="#K"><strong>K</strong></a>
 | <a href="#L"><strong>L</strong></a>
 | <a href="#M"><strong>M</strong></a>
 | <a href="#N"><strong>N</strong></a>
 | <a href="#O"><strong>O</strong></a>
 | <a href="#P"><strong>P</strong></a>
 | <a href="#Q"><strong>Q</strong></a>
 | <a href="#R"><strong>R</strong></a>
 | <a href="#S"><strong>S</strong></a>
 | <a href="#T"><strong>T</strong></a>
 | <a href="#U"><strong>U</strong></a>
 | <a href="#V"><strong>V</strong></a>
 | <a href="#W"><strong>W</strong></a>
 | <a href="#X"><strong>X</strong></a>
 | <a href="#Z"><strong>Z</strong></a>
 
</div>
<h2 id="_">_</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState.__getstate__">__getstate__() (torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.__init__">__init__() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.GraphModule.__init__">(torch.fx.GraphModule method)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Event.__init__">(torch.monitor.Event method)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Stat.__init__">(torch.monitor.Stat method)</a>
</li>
        <li><a href="monitor.html#torch.monitor.TensorboardEventHandler.__init__">(torch.monitor.TensorboardEventHandler method)</a>
</li>
        <li><a href="package.html#torch.package.PackageExporter.__init__">(torch.package.PackageExporter method)</a>
</li>
        <li><a href="package.html#torch.package.PackageImporter.__init__">(torch.package.PackageImporter method)</a>
</li>
        <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.__init__">(torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      </ul></li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState.__setstate__">__setstate__() (torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState method)</a>
</li>
      <li><a href="generated/torch._assert.html#torch._assert">_assert() (in module torch)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._assign_worker_ranks">_assign_worker_ranks() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="generated/torch.cuda.jiterator._create_jit_fn.html#torch.cuda.jiterator._create_jit_fn">_create_jit_fn() (in module torch.cuda.jiterator)</a>
</li>
      <li><a href="generated/torch.cuda.jiterator._create_multi_output_jit_fn.html#torch.cuda.jiterator._create_multi_output_jit_fn">_create_multi_output_jit_fn() (in module torch.cuda.jiterator)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._exit_barrier">_exit_barrier() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="generated/torch._foreach_abs.html#torch._foreach_abs">_foreach_abs() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_abs_.html#torch._foreach_abs_">_foreach_abs_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_acos.html#torch._foreach_acos">_foreach_acos() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_acos_.html#torch._foreach_acos_">_foreach_acos_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_asin.html#torch._foreach_asin">_foreach_asin() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_asin_.html#torch._foreach_asin_">_foreach_asin_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_atan.html#torch._foreach_atan">_foreach_atan() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_atan_.html#torch._foreach_atan_">_foreach_atan_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_ceil.html#torch._foreach_ceil">_foreach_ceil() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_ceil_.html#torch._foreach_ceil_">_foreach_ceil_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_cos.html#torch._foreach_cos">_foreach_cos() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_cos_.html#torch._foreach_cos_">_foreach_cos_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_cosh.html#torch._foreach_cosh">_foreach_cosh() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_cosh_.html#torch._foreach_cosh_">_foreach_cosh_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_erf.html#torch._foreach_erf">_foreach_erf() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_erf_.html#torch._foreach_erf_">_foreach_erf_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_erfc.html#torch._foreach_erfc">_foreach_erfc() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_erfc_.html#torch._foreach_erfc_">_foreach_erfc_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_exp.html#torch._foreach_exp">_foreach_exp() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_exp_.html#torch._foreach_exp_">_foreach_exp_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_expm1.html#torch._foreach_expm1">_foreach_expm1() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_expm1_.html#torch._foreach_expm1_">_foreach_expm1_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_floor.html#torch._foreach_floor">_foreach_floor() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_floor_.html#torch._foreach_floor_">_foreach_floor_() (in module torch)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch._foreach_frac.html#torch._foreach_frac">_foreach_frac() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_frac_.html#torch._foreach_frac_">_foreach_frac_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_lgamma.html#torch._foreach_lgamma">_foreach_lgamma() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_lgamma_.html#torch._foreach_lgamma_">_foreach_lgamma_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log.html#torch._foreach_log">_foreach_log() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log10.html#torch._foreach_log10">_foreach_log10() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log10_.html#torch._foreach_log10_">_foreach_log10_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log1p.html#torch._foreach_log1p">_foreach_log1p() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log1p_.html#torch._foreach_log1p_">_foreach_log1p_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log2.html#torch._foreach_log2">_foreach_log2() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log2_.html#torch._foreach_log2_">_foreach_log2_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_log_.html#torch._foreach_log_">_foreach_log_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_neg.html#torch._foreach_neg">_foreach_neg() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_neg_.html#torch._foreach_neg_">_foreach_neg_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_reciprocal.html#torch._foreach_reciprocal">_foreach_reciprocal() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_reciprocal_.html#torch._foreach_reciprocal_">_foreach_reciprocal_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_round.html#torch._foreach_round">_foreach_round() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_round_.html#torch._foreach_round_">_foreach_round_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sigmoid.html#torch._foreach_sigmoid">_foreach_sigmoid() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sigmoid_.html#torch._foreach_sigmoid_">_foreach_sigmoid_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sin.html#torch._foreach_sin">_foreach_sin() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sin_.html#torch._foreach_sin_">_foreach_sin_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sinh.html#torch._foreach_sinh">_foreach_sinh() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sinh_.html#torch._foreach_sinh_">_foreach_sinh_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sqrt.html#torch._foreach_sqrt">_foreach_sqrt() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_sqrt_.html#torch._foreach_sqrt_">_foreach_sqrt_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_tan.html#torch._foreach_tan">_foreach_tan() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_tan_.html#torch._foreach_tan_">_foreach_tan_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_trunc.html#torch._foreach_trunc">_foreach_trunc() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_trunc_.html#torch._foreach_trunc_">_foreach_trunc_() (in module torch)</a>
</li>
      <li><a href="generated/torch._foreach_zero_.html#torch._foreach_zero_">_foreach_zero_() (in module torch)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._initialize_workers">_initialize_workers() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile">_KinetoProfile (class in torch.profiler)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._monitor_workers">_monitor_workers() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._rendezvous">_rendezvous() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._restart_workers">_restart_workers() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._shutdown">_shutdown() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._start_workers">_start_workers() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent._stop_workers">_stop_workers() (torch.distributed.elastic.agent.server.SimpleElasticAgent method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="A">A</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.abs.html#torch.abs">abs() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.abs.html#torch.Tensor.abs">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.abs_.html#torch.Tensor.abs_">abs_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.absolute.html#torch.absolute">absolute() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.absolute.html#torch.Tensor.absolute">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.absolute_.html#torch.Tensor.absolute_">absolute_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.AbsTransform">AbsTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.acos.html#torch.acos">acos() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.acos.html#torch.Tensor.acos">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.acos_.html#torch.Tensor.acos_">acos_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.acosh.html#torch.acosh">acosh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.acosh.html#torch.Tensor.acosh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.acosh_.html#torch.Tensor.acosh_">acosh_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerClient.acquire">acquire() (torch.distributed.elastic.timer.TimerClient method)</a>
</li>
      <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta">Adadelta (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad">Adagrad (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam">Adam (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax">Adamax (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW">AdamW (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.onnx.ExportOutput.html#torch.onnx.ExportOutput.adapt_torch_inputs_to_onnx">adapt_torch_inputs_to_onnx() (torch.onnx.ExportOutput method)</a>
</li>
      <li><a href="generated/torch.onnx.ExportOutput.html#torch.onnx.ExportOutput.adapt_torch_outputs_to_onnx">adapt_torch_outputs_to_onnx() (torch.onnx.ExportOutput method)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_avg_pool1d.html#torch.nn.functional.adaptive_avg_pool1d">adaptive_avg_pool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.adaptive_avg_pool2d.html#torch.ao.nn.quantized.functional.adaptive_avg_pool2d">adaptive_avg_pool2d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_avg_pool2d.html#torch.nn.functional.adaptive_avg_pool2d">adaptive_avg_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.adaptive_avg_pool3d.html#torch.ao.nn.quantized.functional.adaptive_avg_pool3d">adaptive_avg_pool3d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_avg_pool3d.html#torch.nn.functional.adaptive_avg_pool3d">adaptive_avg_pool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_max_pool1d.html#torch.nn.functional.adaptive_max_pool1d">adaptive_max_pool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_max_pool2d.html#torch.nn.functional.adaptive_max_pool2d">adaptive_max_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.adaptive_max_pool3d.html#torch.nn.functional.adaptive_max_pool3d">adaptive_max_pool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveAvgPool1d.html#torch.nn.AdaptiveAvgPool1d">AdaptiveAvgPool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveAvgPool2d.html#torch.nn.AdaptiveAvgPool2d">AdaptiveAvgPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveAvgPool3d.html#torch.nn.AdaptiveAvgPool3d">AdaptiveAvgPool3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html#torch.nn.AdaptiveLogSoftmaxWithLoss">AdaptiveLogSoftmaxWithLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveMaxPool1d.html#torch.nn.AdaptiveMaxPool1d">AdaptiveMaxPool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveMaxPool2d.html#torch.nn.AdaptiveMaxPool2d">AdaptiveMaxPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AdaptiveMaxPool3d.html#torch.nn.AdaptiveMaxPool3d">AdaptiveMaxPool3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.add.html#torch.add">add() (in module torch)</a>

      <ul>
        <li><a href="distributed.html#torch.distributed.Store.add">(in module torch.distributed.Store)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.add">(torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.add">(torch.distributed.elastic.rendezvous.etcd_store.EtcdStore method)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Stat.add">(torch.monitor.Stat method)</a>
</li>
        <li><a href="generated/torch.Tensor.add.html#torch.Tensor.add">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.add_.html#torch.Tensor.add_">add_() (torch.Tensor method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_audio">add_audio() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars">add_custom_scalars() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.add_dependency">add_dependency() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.add_done_callback">add_done_callback() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.add_dtype_config">add_dtype_config() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_embedding">add_embedding() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_figure">add_figure() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_graph">add_graph() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_histogram">add_histogram() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_hparams">add_hparams() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_image">add_image() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_images">add_images() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.add_loggers">add_loggers() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_mesh">add_mesh() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile.add_metadata">add_metadata() (torch.profiler._KinetoProfile method)</a>
</li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile.add_metadata_json">add_metadata_json() (torch.profiler._KinetoProfile method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.add_module">add_module() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.add_module">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.add_param_group">add_param_group() (torch.distributed.optim.ZeroRedundancyOptimizer method)</a>

      <ul>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.add_param_group">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.add_param_group">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.add_param_group">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.add_param_group">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.add_param_group">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.add_param_group">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.add_param_group">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.add_param_group">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.Optimizer.add_param_group.html#torch.optim.Optimizer.add_param_group">(torch.optim.Optimizer method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.add_param_group">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.add_param_group">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.add_param_group">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.add_param_group">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.add_param_group">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve">add_pr_curve() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.add_pruning_method">add_pruning_method() (torch.nn.utils.prune.PruningContainer method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.add_quant_dequant.html#torch.ao.quantization.add_quant_dequant">add_quant_dequant (class in torch.ao.quantization)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.add_relu">add_relu() (torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.add_scalar">add_scalar() (torch.ao.ns._numeric_suite.Shadow method)</a>

      <ul>
        <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalar">(torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      </ul></li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_scalars">add_scalars() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.add_shadow_loggers">add_shadow_loggers() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule.add_submodule">add_submodule() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_text">add_text() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_video">add_video() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="generated/torch.addbmm.html#torch.addbmm">addbmm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.addbmm.html#torch.Tensor.addbmm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addbmm_.html#torch.Tensor.addbmm_">addbmm_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.addcdiv.html#torch.addcdiv">addcdiv() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.addcdiv.html#torch.Tensor.addcdiv">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addcdiv_.html#torch.Tensor.addcdiv_">addcdiv_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.addcmul.html#torch.addcmul">addcmul() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.addcmul.html#torch.Tensor.addcmul">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addcmul_.html#torch.Tensor.addcmul_">addcmul_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.addmm.html#torch.addmm">addmm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.sparse.addmm.html#torch.sparse.addmm">(in module torch.sparse)</a>
</li>
        <li><a href="generated/torch.Tensor.addmm.html#torch.Tensor.addmm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addmm_.html#torch.Tensor.addmm_">addmm_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.addmv.html#torch.addmv">addmv() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.addmv.html#torch.Tensor.addmv">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addmv_.html#torch.Tensor.addmv_">addmv_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.addr.html#torch.addr">addr() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.addr.html#torch.Tensor.addr">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.addr_.html#torch.Tensor.addr_">addr_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.adjoint.html#torch.adjoint">adjoint() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.adjoint.html#torch.Tensor.adjoint">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.affine_grid.html#torch.nn.functional.affine_grid">affine_grid() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.AffineTransform">AffineTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="monitor.html#torch.monitor.Aggregation">Aggregation (class in torch.monitor)</a>
</li>
      <li><a href="special.html#torch.special.airy_ai">airy_ai() (in module torch.special)</a>
</li>
      <li><a href="named_tensor.html#torch.Tensor.align_as">align_as() (torch.Tensor method)</a>
</li>
      <li><a href="named_tensor.html#torch.Tensor.align_to">align_to() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.all.html#torch.all">all() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.all.html#torch.Tensor.all">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.all_gather">all_gather() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_gather_into_tensor">all_gather_into_tensor() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_gather_multigpu">all_gather_multigpu() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_gather_object">all_gather_object() (in module torch.distributed)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.all_input_nodes">all_input_nodes (torch.fx.Node property)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.all_mismatch_leaf_graph_info">all_mismatch_leaf_graph_info() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.all_paths">all_paths() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_reduce">all_reduce() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_reduce_multigpu">all_reduce_multigpu() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_to_all">all_to_all() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.all_to_all_single">all_to_all_single() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.allclose.html#torch.allclose">allclose() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.allclose.html#torch.Tensor.allclose">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="backends.html#torch.backends.cuda.matmul.allow_bf16_reduced_precision_reduction">allow_bf16_reduced_precision_reduction (in module torch.backends.cuda.matmul)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction">allow_fp16_reduced_precision_reduction (in module torch.backends.cuda.matmul)</a>
</li>
      <li><a href="generated/torch.compiler.allow_in_graph.html#torch.compiler.allow_in_graph">allow_in_graph() (in module torch.compiler)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.allow_mutation_on_saved_tensors">allow_mutation_on_saved_tensors (class in torch.autograd.graph)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.matmul.allow_tf32">allow_tf32 (in module torch.backends.cuda.matmul)</a>

      <ul>
        <li><a href="backends.html#torch.backends.cudnn.allow_tf32">(in module torch.backends.cudnn)</a>
</li>
      </ul></li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.default_hooks.allreduce_hook">allreduce_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)</a>
</li>
      <li><a href="generated/torch.nn.functional.alpha_dropout.html#torch.nn.functional.alpha_dropout">alpha_dropout() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.AlphaDropout.html#torch.nn.AlphaDropout">AlphaDropout (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.amax.html#torch.amax">amax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.amax.html#torch.Tensor.amax">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.amin.html#torch.amin">amin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.amin.html#torch.Tensor.amin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.aminmax.html#torch.aminmax">aminmax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.aminmax.html#torch.Tensor.aminmax">(torch.Tensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.angle.html#torch.angle">angle() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.angle.html#torch.Tensor.angle">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.annotate.html#torch.jit.annotate">annotate() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.any.html#torch.any">any() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.any.html#torch.Tensor.any">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Node.append">append() (torch.fx.Node method)</a>

      <ul>
        <li><a href="generated/torch.nn.ModuleList.html#torch.nn.ModuleList.append">(torch.nn.ModuleList method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterList.html#torch.nn.ParameterList.append">(torch.nn.ParameterList method)</a>
</li>
        <li><a href="generated/torch.nn.Sequential.html#torch.nn.Sequential.append">(torch.nn.Sequential method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.apply">apply() (torch.distributed.fsdp.FullyShardedDataParallel method)</a>

      <ul>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.apply">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.apply">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.apply">(torch.nn.utils.prune.BasePruningMethod class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.apply">(torch.nn.utils.prune.CustomFromMask class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.apply">(torch.nn.utils.prune.Identity class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.apply">(torch.nn.utils.prune.L1Unstructured class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.apply">(torch.nn.utils.prune.LnStructured class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.apply">(torch.nn.utils.prune.PruningContainer class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.apply">(torch.nn.utils.prune.RandomStructured class method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.apply">(torch.nn.utils.prune.RandomUnstructured class method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.apply_.html#torch.Tensor.apply_">apply_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.apply_mask">apply_mask() (torch.nn.utils.prune.BasePruningMethod method)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.apply_mask">(torch.nn.utils.prune.CustomFromMask method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.apply_mask">(torch.nn.utils.prune.Identity method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.apply_mask">(torch.nn.utils.prune.L1Unstructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.apply_mask">(torch.nn.utils.prune.LnStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.apply_mask">(torch.nn.utils.prune.PruningContainer method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.apply_mask">(torch.nn.utils.prune.RandomStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.apply_mask">(torch.nn.utils.prune.RandomUnstructured method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.arange.html#torch.arange">arange() (in module torch)</a>
</li>
      <li><a href="generated/torch.arccos.html#torch.arccos">arccos() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arccos.html#torch.Tensor.arccos">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arccos_.html#torch.Tensor.arccos_">arccos_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.arccosh.html#torch.arccosh">arccosh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arccosh.html#torch.Tensor.arccosh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arccosh_.html#torch.Tensor.arccosh_">arccosh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.arcsin.html#torch.arcsin">arcsin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arcsin.html#torch.Tensor.arcsin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arcsin_.html#torch.Tensor.arcsin_">arcsin_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.arcsinh.html#torch.arcsinh">arcsinh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arcsinh.html#torch.Tensor.arcsinh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arcsinh_.html#torch.Tensor.arcsinh_">arcsinh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.arctan.html#torch.arctan">arctan() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arctan.html#torch.Tensor.arctan">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.arctan2.html#torch.arctan2">arctan2() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arctan2.html#torch.Tensor.arctan2">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arctan2_.html#torch.Tensor.arctan2_">arctan2_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.arctan_.html#torch.Tensor.arctan_">arctan_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.arctanh.html#torch.arctanh">arctanh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.arctanh.html#torch.Tensor.arctanh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.arctanh_.html#torch.Tensor.arctanh_">arctanh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.are_deterministic_algorithms_enabled.html#torch.are_deterministic_algorithms_enabled">are_deterministic_algorithms_enabled() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.arg_constraints">arg_constraints (torch.distributions.bernoulli.Bernoulli attribute)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.arg_constraints">(torch.distributions.beta.Beta attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.arg_constraints">(torch.distributions.binomial.Binomial attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.arg_constraints">(torch.distributions.categorical.Categorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.arg_constraints">(torch.distributions.cauchy.Cauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.chi2.Chi2.arg_constraints">(torch.distributions.chi2.Chi2 attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.arg_constraints">(torch.distributions.continuous_bernoulli.ContinuousBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.arg_constraints">(torch.distributions.dirichlet.Dirichlet attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.arg_constraints">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.arg_constraints">(torch.distributions.exponential.Exponential attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.arg_constraints">(torch.distributions.fishersnedecor.FisherSnedecor attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.arg_constraints">(torch.distributions.gamma.Gamma attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.arg_constraints">(torch.distributions.geometric.Geometric attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.arg_constraints">(torch.distributions.gumbel.Gumbel attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.arg_constraints">(torch.distributions.half_cauchy.HalfCauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.arg_constraints">(torch.distributions.half_normal.HalfNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.arg_constraints">(torch.distributions.independent.Independent attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.arg_constraints">(torch.distributions.kumaraswamy.Kumaraswamy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.arg_constraints">(torch.distributions.laplace.Laplace attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky.arg_constraints">(torch.distributions.lkj_cholesky.LKJCholesky attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.arg_constraints">(torch.distributions.log_normal.LogNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.arg_constraints">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.arg_constraints">(torch.distributions.mixture_same_family.MixtureSameFamily attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.arg_constraints">(torch.distributions.multinomial.Multinomial attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.arg_constraints">(torch.distributions.multivariate_normal.MultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.arg_constraints">(torch.distributions.negative_binomial.NegativeBinomial attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.arg_constraints">(torch.distributions.normal.Normal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.arg_constraints">(torch.distributions.one_hot_categorical.OneHotCategorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.arg_constraints">(torch.distributions.pareto.Pareto attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.arg_constraints">(torch.distributions.poisson.Poisson attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.arg_constraints">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.arg_constraints">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.arg_constraints">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.arg_constraints">(torch.distributions.studentT.StudentT attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.arg_constraints">(torch.distributions.transformed_distribution.TransformedDistribution attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.arg_constraints">(torch.distributions.uniform.Uniform attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.arg_constraints">(torch.distributions.von_mises.VonMises attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.arg_constraints">(torch.distributions.weibull.Weibull attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.arg_constraints">(torch.distributions.wishart.Wishart attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.argmax.html#torch.argmax">argmax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.argmax.html#torch.Tensor.argmax">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.argmin.html#torch.argmin">argmin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.argmin.html#torch.Tensor.argmin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Node.args">args (torch.fx.Node property)</a>
</li>
      <li><a href="generated/torch.argsort.html#torch.argsort">argsort() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.argsort.html#torch.Tensor.argsort">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.argwhere.html#torch.argwhere">argwhere() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.argwhere.html#torch.Tensor.argwhere">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="nested.html#torch.nested.as_nested_tensor">as_nested_tensor() (in module torch.nested)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.CallgrindStats.as_standardized">as_standardized() (torch.utils.benchmark.CallgrindStats method)</a>
</li>
      <li><a href="generated/torch.as_strided.html#torch.as_strided">as_strided() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.as_strided.html#torch.Tensor.as_strided">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.as_subclass.html#torch.Tensor.as_subclass">as_subclass() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.as_tensor.html#torch.as_tensor">as_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.asarray.html#torch.asarray">asarray() (in module torch)</a>
</li>
      <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD">ASGD (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.asin.html#torch.asin">asin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.asin.html#torch.Tensor.asin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.asin_.html#torch.Tensor.asin_">asin_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.asinh.html#torch.asinh">asinh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.asinh.html#torch.Tensor.asinh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.asinh_.html#torch.Tensor.asinh_">asinh_() (torch.Tensor method)</a>
</li>
      <li><a href="testing.html#torch.testing.assert_allclose">assert_allclose() (in module torch.testing)</a>
</li>
      <li><a href="testing.html#torch.testing.assert_close">assert_close() (in module torch.testing)</a>
</li>
      <li><a href="generated/torch.compiler.assume_constant_result.html#torch.compiler.assume_constant_result">assume_constant_result() (in module torch.compiler)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.functions.async_execution">async_execution() (in module torch.distributed.rpc.functions)</a>
</li>
      <li><a href="generated/torch.atan.html#torch.atan">atan() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.atan.html#torch.Tensor.atan">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.atan2.html#torch.atan2">atan2() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.atan2.html#torch.Tensor.atan2">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.atan2_.html#torch.Tensor.atan2_">atan2_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.atan_.html#torch.Tensor.atan_">atan_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.atanh.html#torch.atanh">atanh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.atanh.html#torch.Tensor.atanh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.atanh_.html#torch.Tensor.atanh_">atanh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.atleast_1d.html#torch.atleast_1d">atleast_1d() (in module torch)</a>
</li>
      <li><a href="generated/torch.atleast_2d.html#torch.atleast_2d">atleast_2d() (in module torch)</a>
</li>
      <li><a href="generated/torch.atleast_3d.html#torch.atleast_3d">atleast_3d() (in module torch)</a>
</li>
      <li><a href="generated/torch.jit.Attribute.html#torch.jit.Attribute">Attribute (class in torch.jit)</a>
</li>
      <li><a href="amp.html#torch.autocast">autocast (class in torch)</a>

      <ul>
        <li><a href="amp.html#torch.cpu.amp.autocast">(class in torch.cpu.amp)</a>
</li>
        <li><a href="amp.html#torch.cuda.amp.autocast">(class in torch.cuda.amp)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.avg_pool1d.html#torch.nn.functional.avg_pool1d">avg_pool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.avg_pool2d.html#torch.ao.nn.quantized.functional.avg_pool2d">avg_pool2d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.avg_pool2d.html#torch.nn.functional.avg_pool2d">avg_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.avg_pool3d.html#torch.ao.nn.quantized.functional.avg_pool3d">avg_pool3d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.avg_pool3d.html#torch.nn.functional.avg_pool3d">avg_pool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.AvgPool1d.html#torch.nn.AvgPool1d">AvgPool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AvgPool2d.html#torch.nn.AvgPool2d">AvgPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.AvgPool3d.html#torch.nn.AvgPool3d">AvgPool3d (class in torch.nn)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="B">B</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributed.html#torch.distributed.Backend">Backend (class in torch.distributed)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig">BackendConfig (class in torch.ao.quantization.backend_config)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig">BackendPatternConfig (class in torch.ao.quantization.backend_config)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.BackendType">BackendType (class in torch.distributed.rpc)</a>
</li>
      <li><a href="generated/torch.autograd.backward.html#torch.autograd.backward">backward() (in module torch.autograd)</a>

      <ul>
        <li><a href="rpc.html#torch.distributed.autograd.backward">(in module torch.distributed.autograd)</a>
</li>
        <li><a href="generated/torch.autograd.Function.backward.html#torch.autograd.Function.backward">(torch.autograd.Function static method)</a>
</li>
        <li><a href="generated/torch.Tensor.backward.html#torch.Tensor.backward">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.BackwardPrefetch">BackwardPrefetch (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="generated/torch.baddbmm.html#torch.baddbmm">baddbmm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.baddbmm.html#torch.Tensor.baddbmm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.baddbmm_.html#torch.Tensor.baddbmm_">baddbmm_() (torch.Tensor method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.barrier">barrier() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.signal.windows.bartlett.html#torch.signal.windows.bartlett">bartlett() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.bartlett_window.html#torch.bartlett_window">bartlett_window() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod">BasePruningMethod (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="distributed.html#torch.distributed.batch_isend_irecv">batch_isend_irecv() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.nn.functional.batch_norm.html#torch.nn.functional.batch_norm">batch_norm() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution.batch_shape">batch_shape (torch.distributions.distribution.Distribution property)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.batch_sizes">batch_sizes (torch.nn.utils.rnn.PackedSequence attribute)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.batched_powerSGD_hook">batched_powerSGD_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook)</a>
</li>
      <li><a href="generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d">BatchNorm1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.BatchNorm2d.html#torch.ao.nn.quantized.BatchNorm2d">BatchNorm2d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.BatchNorm3d.html#torch.ao.nn.quantized.BatchNorm3d">BatchNorm3d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.BatchNorm3d.html#torch.nn.BatchNorm3d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="data.html#torch.utils.data.BatchSampler">BatchSampler (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.nn.BCELoss.html#torch.nn.BCELoss">BCELoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss">BCEWithLogitsLoss (class in torch.nn)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.benchmark">benchmark (in module torch.backends.cudnn)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.benchmark_limit">benchmark_limit (in module torch.backends.cudnn)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli">Bernoulli (class in torch.distributions.bernoulli)</a>
</li>
      <li><a href="generated/torch.bernoulli.html#torch.bernoulli">bernoulli() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bernoulli.html#torch.Tensor.bernoulli">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bernoulli_.html#torch.Tensor.bernoulli_">bernoulli_() (torch.Tensor method)</a>
</li>
      <li><a href="special.html#torch.special.bessel_j0">bessel_j0() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.bessel_j1">bessel_j1() (in module torch.special)</a>
</li>
      <li><a href="distributions.html#torch.distributions.beta.Beta">Beta (class in torch.distributions.beta)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.default_hooks.bf16_compress_hook">bf16_compress_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.default_hooks.bf16_compress_wrapper">bf16_compress_wrapper() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.bfloat16">bfloat16() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.bfloat16">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.bfloat16.html#torch.Tensor.bfloat16">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.bfloat16">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.bfloat16">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.BFloat16Storage">BFloat16Storage (class in torch)</a>
</li>
      <li><a href="generated/torch.nn.Bilinear.html#torch.nn.Bilinear">Bilinear (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.bilinear.html#torch.nn.functional.bilinear">bilinear() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.binary_cross_entropy.html#torch.nn.functional.binary_cross_entropy">binary_cross_entropy() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.binary_cross_entropy_with_logits.html#torch.nn.functional.binary_cross_entropy_with_logits">binary_cross_entropy_with_logits() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.bincount.html#torch.bincount">bincount() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bincount.html#torch.Tensor.bincount">(torch.Tensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributions.html#torch.distributions.binomial.Binomial">Binomial (class in torch.distributions.binomial)</a>
</li>
      <li><a href="generated/torch.bitwise_and.html#torch.bitwise_and">bitwise_and() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_and.html#torch.Tensor.bitwise_and">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_and_.html#torch.Tensor.bitwise_and_">bitwise_and_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.bitwise_left_shift.html#torch.bitwise_left_shift">bitwise_left_shift() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_left_shift.html#torch.Tensor.bitwise_left_shift">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_left_shift_.html#torch.Tensor.bitwise_left_shift_">bitwise_left_shift_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.bitwise_not.html#torch.bitwise_not">bitwise_not() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_not.html#torch.Tensor.bitwise_not">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_not_.html#torch.Tensor.bitwise_not_">bitwise_not_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.bitwise_or.html#torch.bitwise_or">bitwise_or() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_or.html#torch.Tensor.bitwise_or">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_or_.html#torch.Tensor.bitwise_or_">bitwise_or_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.bitwise_right_shift.html#torch.bitwise_right_shift">bitwise_right_shift() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_right_shift.html#torch.Tensor.bitwise_right_shift">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_right_shift_.html#torch.Tensor.bitwise_right_shift_">bitwise_right_shift_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.bitwise_xor.html#torch.bitwise_xor">bitwise_xor() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bitwise_xor.html#torch.Tensor.bitwise_xor">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bitwise_xor_.html#torch.Tensor.bitwise_xor_">bitwise_xor_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.signal.windows.blackman.html#torch.signal.windows.blackman">blackman() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.blackman_window.html#torch.blackman_window">blackman_window() (in module torch)</a>
</li>
      <li><a href="generated/torch.block_diag.html#torch.block_diag">block_diag() (in module torch)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Timer.blocked_autorange">blocked_autorange() (torch.utils.benchmark.Timer method)</a>
</li>
      <li><a href="generated/torch.bmm.html#torch.bmm">bmm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.bmm.html#torch.Tensor.bmm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.BNReLU2d.html#torch.ao.nn.intrinsic.BNReLU2d">BNReLU2d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.BNReLU2d.html#torch.ao.nn.intrinsic.quantized.BNReLU2d">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.BNReLU3d.html#torch.ao.nn.intrinsic.BNReLU3d">BNReLU3d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.BNReLU3d.html#torch.ao.nn.intrinsic.quantized.BNReLU3d">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.bool.html#torch.Tensor.bool">bool() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.bool">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.bool">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.BoolStorage">BoolStorage (class in torch)</a>
</li>
      <li><a href="fx.html#torch.fx.Interpreter.boxed_run">boxed_run() (torch.fx.Interpreter method)</a>
</li>
      <li><a href="generated/torch.cuda.comm.broadcast.html#torch.cuda.comm.broadcast">broadcast() (in module torch.cuda.comm)</a>

      <ul>
        <li><a href="distributed.html#torch.distributed.broadcast">(in module torch.distributed)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.comm.broadcast_coalesced.html#torch.cuda.comm.broadcast_coalesced">broadcast_coalesced() (in module torch.cuda.comm)</a>
</li>
      <li><a href="distributed.html#torch.distributed.broadcast_multigpu">broadcast_multigpu() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.broadcast_object_list">broadcast_object_list() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.broadcast_shapes.html#torch.broadcast_shapes">broadcast_shapes() (in module torch)</a>
</li>
      <li><a href="generated/torch.broadcast_tensors.html#torch.broadcast_tensors">broadcast_tensors() (in module torch)</a>
</li>
      <li><a href="generated/torch.broadcast_to.html#torch.broadcast_to">broadcast_to() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.broadcast_to.html#torch.Tensor.broadcast_to">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.bucketize.html#torch.bucketize">bucketize() (in module torch)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.buffer">buffer() (in module torch.distributed.GradBucket)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.buffers">buffers() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.buffers">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.BuildExtension">BuildExtension() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.Tensor.byte.html#torch.Tensor.byte">byte() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.byte">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.byte">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.ByteStorage">ByteStorage (class in torch)</a>
</li>
      <li><a href="storage.html#torch.UntypedStorage.byteswap">byteswap() (torch.UntypedStorage method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="C">C</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend">C10dRendezvousBackend (class in torch.distributed.elastic.rendezvous.c10d_rendezvous_backend)</a>
</li>
      <li><a href="generated/torch.nn.utils.parametrize.cached.html#torch.nn.utils.parametrize.cached">cached() (in module torch.nn.utils.parametrize)</a>
</li>
      <li><a href="generated/torch.cuda.caching_allocator_alloc.html#torch.cuda.caching_allocator_alloc">caching_allocator_alloc() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.caching_allocator_delete.html#torch.cuda.caching_allocator_delete">caching_allocator_delete() (in module torch.cuda)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.calculate_gain">calculate_gain() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.MinMaxObserver.html#torch.ao.quantization.observer.MinMaxObserver.calculate_qparams">calculate_qparams() (torch.ao.quantization.observer.MinMaxObserver method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.call_function">call_function() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.call_function">(torch.fx.Interpreter method)</a>
</li>
        <li><a href="fx.html#torch.fx.Transformer.call_function">(torch.fx.Transformer method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.call_method">call_method() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.call_method">(torch.fx.Interpreter method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.call_module">call_module() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.call_module">(torch.fx.Interpreter method)</a>
</li>
        <li><a href="fx.html#torch.fx.Tracer.call_module">(torch.fx.Tracer method)</a>
</li>
        <li><a href="fx.html#torch.fx.Transformer.call_module">(torch.fx.Transformer method)</a>
</li>
      </ul></li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.CallgrindStats">CallgrindStats (class in torch.utils.benchmark)</a>
</li>
      <li><a href="generated/torch.can_cast.html#torch.can_cast">can_cast() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.can_device_access_peer.html#torch.cuda.can_device_access_peer">can_device_access_peer() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.capture_begin">capture_begin() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.capture_end">capture_end() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="generated/torch.cartesian_prod.html#torch.cartesian_prod">cartesian_prod() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.cat">cat (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.cat.html#torch.cat">cat() (in module torch)</a>

      <ul>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.cat">(torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.categorical.Categorical">Categorical (class in torch.distributions.categorical)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.CatTransform">CatTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributions.html#torch.distributions.cauchy.Cauchy">Cauchy (class in torch.distributions.cauchy)</a>
</li>
      <li><a href="generated/torch.Tensor.cauchy_.html#torch.Tensor.cauchy_">cauchy_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.ccol_indices.html#torch.Tensor.ccol_indices">ccol_indices() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.cdf">cdf() (torch.distributions.cauchy.Cauchy method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.cdf">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.cdf">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.cdf">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.cdf">(torch.distributions.gamma.Gamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.cdf">(torch.distributions.half_cauchy.HalfCauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.cdf">(torch.distributions.half_normal.HalfNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.cdf">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.cdf">(torch.distributions.mixture_same_family.MixtureSameFamily method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.cdf">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.cdf">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.cdf">(torch.distributions.uniform.Uniform method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cdist.html#torch.cdist">cdist() (in module torch)</a>
</li>
      <li><a href="generated/torch.Tensor.cdouble.html#torch.Tensor.cdouble">cdouble() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ceil.html#torch.ceil">ceil() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ceil.html#torch.Tensor.ceil">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.ceil_.html#torch.Tensor.ceil_">ceil_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.celu.html#torch.ao.nn.quantized.functional.celu">celu (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.CELU.html#torch.nn.CELU">CELU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.celu.html#torch.nn.functional.celu">celu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.Tensor.cfloat.html#torch.Tensor.cfloat">cfloat() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.chain_matmul.html#torch.chain_matmul">chain_matmul() (in module torch)</a>
</li>
      <li><a href="data.html#torch.utils.data.ChainDataset">ChainDataset (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ChainedScheduler.html#torch.optim.lr_scheduler.ChainedScheduler">ChainedScheduler (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.Tensor.chalf.html#torch.Tensor.chalf">chalf() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.cuda.change_current_allocator.html#torch.cuda.change_current_allocator">change_current_allocator() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.nn.ChannelShuffle.html#torch.nn.ChannelShuffle">ChannelShuffle (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.Tensor.char.html#torch.Tensor.char">char() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.char">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.char">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.CharStorage">CharStorage (class in torch)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.check">check() (torch.distributed.elastic.rendezvous.etcd_store.EtcdStore method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.constraints.Constraint.check">(torch.distributions.constraints.Constraint method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.sparse.check_sparse_tensor_invariants.html#torch.sparse.check_sparse_tensor_invariants">check_sparse_tensor_invariants (class in torch.sparse)</a>
</li>
      <li><a href="checkpoint.html#torch.utils.checkpoint.checkpoint">checkpoint() (in module torch.utils.checkpoint)</a>
</li>
      <li><a href="checkpoint.html#torch.utils.checkpoint.checkpoint_sequential">checkpoint_sequential() (in module torch.utils.checkpoint)</a>
</li>
      <li><a href="distributions.html#torch.distributions.chi2.Chi2">Chi2 (class in torch.distributions.chi2)</a>
</li>
      <li><a href="elastic/errors.html#torch.distributed.elastic.multiprocessing.errors.ChildFailedError">ChildFailedError (class in torch.distributed.elastic.multiprocessing.errors)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.children">children() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.children">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cholesky.html#torch.cholesky">cholesky() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.cholesky.html#torch.linalg.cholesky">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.cholesky.html#torch.Tensor.cholesky">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.cholesky_ex.html#torch.linalg.cholesky_ex">cholesky_ex() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.cholesky_inverse.html#torch.cholesky_inverse">cholesky_inverse() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cholesky_inverse.html#torch.Tensor.cholesky_inverse">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cholesky_solve.html#torch.cholesky_solve">cholesky_solve() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cholesky_solve.html#torch.Tensor.cholesky_solve">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.chunk.html#torch.chunk">chunk() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.chunk.html#torch.Tensor.chunk">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.functional.clamp.html#torch.ao.nn.quantized.functional.clamp">clamp (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.clamp.html#torch.clamp">clamp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.clamp.html#torch.Tensor.clamp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.clamp_.html#torch.Tensor.clamp_">clamp_() (torch.Tensor method)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.cufft_plan_cache.clear">clear() (in module torch.backends.cuda.cufft_plan_cache)</a>

      <ul>
        <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.clear">(torch.nn.ModuleDict method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.clear">(torch.nn.ParameterDict method)</a>
</li>
        <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.clear">(torch.onnx.verification.GraphInfo method)</a>
</li>
      </ul></li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerServer.clear_timers">clear_timers() (torch.distributed.elastic.timer.TimerServer method)</a>
</li>
      <li><a href="generated/torch.clip.html#torch.clip">clip() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.clip.html#torch.Tensor.clip">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.clip_.html#torch.Tensor.clip_">clip_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.utils.clip_grad_norm_.html#torch.nn.utils.clip_grad_norm_">clip_grad_norm_() (in module torch.nn.utils)</a>

      <ul>
        <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.clip_grad_norm_">(torch.distributed.fsdp.FullyShardedDataParallel method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.clip_grad_value_.html#torch.nn.utils.clip_grad_value_">clip_grad_value_() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.cuda.clock_rate.html#torch.cuda.clock_rate">clock_rate() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.clone.html#torch.clone">clone() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.clone.html#torch.Tensor.clone">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.clone">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.clone">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.close">close (torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout property)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.close">close() (torch.package.PackageExporter method)</a>

      <ul>
        <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.close">(torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.LazyBatchNorm1d.html#torch.nn.LazyBatchNorm1d.cls_to_become">cls_to_become (torch.nn.LazyBatchNorm1d attribute)</a>

      <ul>
        <li><a href="generated/torch.nn.LazyBatchNorm2d.html#torch.nn.LazyBatchNorm2d.cls_to_become">(torch.nn.LazyBatchNorm2d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyBatchNorm3d.html#torch.nn.LazyBatchNorm3d.cls_to_become">(torch.nn.LazyBatchNorm3d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConv1d.html#torch.nn.LazyConv1d.cls_to_become">(torch.nn.LazyConv1d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConv2d.html#torch.nn.LazyConv2d.cls_to_become">(torch.nn.LazyConv2d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConv3d.html#torch.nn.LazyConv3d.cls_to_become">(torch.nn.LazyConv3d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConvTranspose1d.html#torch.nn.LazyConvTranspose1d.cls_to_become">(torch.nn.LazyConvTranspose1d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConvTranspose2d.html#torch.nn.LazyConvTranspose2d.cls_to_become">(torch.nn.LazyConvTranspose2d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyConvTranspose3d.html#torch.nn.LazyConvTranspose3d.cls_to_become">(torch.nn.LazyConvTranspose3d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyInstanceNorm1d.html#torch.nn.LazyInstanceNorm1d.cls_to_become">(torch.nn.LazyInstanceNorm1d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyInstanceNorm2d.html#torch.nn.LazyInstanceNorm2d.cls_to_become">(torch.nn.LazyInstanceNorm2d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyInstanceNorm3d.html#torch.nn.LazyInstanceNorm3d.cls_to_become">(torch.nn.LazyInstanceNorm3d attribute)</a>
</li>
        <li><a href="generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear.cls_to_become">(torch.nn.LazyLinear attribute)</a>
</li>
        <li><a href="generated/torch.nn.parameter.UninitializedParameter.html#torch.nn.parameter.UninitializedParameter.cls_to_become">(torch.nn.parameter.UninitializedParameter attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.coalesce.html#torch.Tensor.coalesce">coalesce() (torch.Tensor method)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule.code">code (torch.fx.GraphModule property)</a>

      <ul>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.code">(torch.jit.ScriptModule property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.code_with_constants">code_with_constants (torch.jit.ScriptModule property)</a>
</li>
      <li><a href="generated/torch.Tensor.col_indices.html#torch.Tensor.col_indices">col_indices() (torch.Tensor method)</a>
</li>
      <li><a href="data.html#torch.utils.data._utils.collate.collate">collate() (in module torch.utils.data._utils.collate)</a>
</li>
      <li><a href="futures.html#torch.futures.collect_all">collect_all() (in module torch.futures)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Timer.collect_callgrind">collect_callgrind() (torch.utils.benchmark.Timer method)</a>
</li>
      <li><a href="generated/torch.column_stack.html#torch.column_stack">column_stack() (in module torch)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.ColwiseParallel">ColwiseParallel (class in torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="generated/torch.combinations.html#torch.combinations">combinations() (in module torch)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.commit_tensor">commit_tensor() (torch.distributed.checkpoint.LoadPlanner method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.compare_model_outputs">compare_model_outputs() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.compare_model_stub">compare_model_stub() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store.compare_set">compare_set() (in module torch.distributed.Store)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.compare_weights">compare_weights() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="compile/generated/torch.compile.html#torch.compile">compile() (in module torch)</a>, <a href="generated/torch.compile.html#torch.compile">[1]</a>

      <ul>
        <li><a href="generated/torch.compiler.compile.html#torch.compiler.compile">(in module torch.compiler)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.compile">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.compile">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.compiled_with_cxx11_abi.html#torch.compiled_with_cxx11_abi">compiled_with_cxx11_abi() (in module torch)</a>
</li>
      <li><a href="generated/torch.complex.html#torch.complex">complex() (in module torch)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.complex_double">complex_double() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.complex_double">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.TypedStorage.complex_float">complex_float() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.complex_float">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.ComplexDoubleStorage">ComplexDoubleStorage (class in torch)</a>
</li>
      <li><a href="storage.html#torch.ComplexFloatStorage">ComplexFloatStorage (class in torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.component_distribution">component_distribution (torch.distributions.mixture_same_family.MixtureSameFamily property)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.ComposeTransform">ComposeTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns.fx.utils.compute_cosine_similarity">compute_cosine_similarity() (in module torch.ao.ns.fx.utils)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.compute_mask">compute_mask() (torch.nn.utils.prune.BasePruningMethod method)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.compute_mask">(torch.nn.utils.prune.LnStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.compute_mask">(torch.nn.utils.prune.PruningContainer method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.compute_mask">(torch.nn.utils.prune.RandomStructured method)</a>
</li>
      </ul></li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns.fx.utils.compute_normalized_l2_error">compute_normalized_l2_error() (in module torch.ao.ns.fx.utils)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns.fx.utils.compute_sqnr">compute_sqnr() (in module torch.ao.ns.fx.utils)</a>
</li>
      <li><a href="generated/torch.concat.html#torch.concat">concat() (in module torch)</a>
</li>
      <li><a href="data.html#torch.utils.data.ConcatDataset">ConcatDataset (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.concatenate.html#torch.concatenate">concatenate() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.beta.Beta.concentration0">concentration0 (torch.distributions.beta.Beta property)</a>
</li>
      <li><a href="distributions.html#torch.distributions.beta.Beta.concentration1">concentration1 (torch.distributions.beta.Beta property)</a>
</li>
      <li><a href="generated/torch.linalg.cond.html#torch.linalg.cond">cond() (in module torch.linalg)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.configs">configs (torch.ao.quantization.backend_config.BackendConfig property)</a>
</li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.configure">configure() (in module torch.distributed.elastic.metrics)</a>

      <ul>
        <li><a href="elastic/timer.html#torch.distributed.elastic.timer.configure">(in module torch.distributed.elastic.timer)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.conj.html#torch.conj">conj() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.conj.html#torch.Tensor.conj">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.conj_physical.html#torch.conj_physical">conj_physical() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.conj_physical.html#torch.Tensor.conj_physical">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.conj_physical_.html#torch.Tensor.conj_physical_">conj_physical_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.api.ConsoleMetricHandler">ConsoleMetricHandler (class in torch.distributed.elastic.metrics.api)</a>
</li>
      <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.consolidate_state_dict">consolidate_state_dict() (torch.distributed.optim.ZeroRedundancyOptimizer method)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.constant_">constant_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ConstantLR.html#torch.optim.lr_scheduler.ConstantLR">ConstantLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.nn.ConstantPad1d.html#torch.nn.ConstantPad1d">ConstantPad1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ConstantPad2d.html#torch.nn.ConstantPad2d">ConstantPad2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ConstantPad3d.html#torch.nn.ConstantPad3d">ConstantPad3d (class in torch.nn)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.Constraint">Constraint (class in torch.distributions.constraints)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraint_registry.ConstraintRegistry">ConstraintRegistry (class in torch.distributions.constraint_registry)</a>
</li>
      <li><a href="rpc.html#torch.distributed.autograd.context">context (class in torch.distributed.autograd)</a>
</li>
      <li><a href="generated/torch.Tensor.contiguous.html#torch.Tensor.contiguous">contiguous() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli">ContinuousBernoulli (class in torch.distributions.continuous_bernoulli)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.Conv1d.html#torch.ao.nn.quantized.Conv1d">Conv1d (class in torch.ao.nn.quantized)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.conv1d.html#torch.ao.nn.quantized.functional.conv1d">conv1d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Conv1d.html#torch.nn.Conv1d">Conv1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv1d.html#torch.nn.functional.conv1d">conv1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.qat.Conv2d.html#torch.ao.nn.qat.Conv2d">Conv2d (class in torch.ao.nn.qat)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantized.Conv2d.html#torch.ao.nn.quantized.Conv2d">(class in torch.ao.nn.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.functional.conv2d.html#torch.ao.nn.quantized.functional.conv2d">conv2d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Conv2d.html#torch.nn.Conv2d">Conv2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv2d.html#torch.nn.functional.conv2d">conv2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.qat.Conv3d.html#torch.ao.nn.qat.Conv3d">Conv3d (class in torch.ao.nn.qat)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantized.Conv3d.html#torch.ao.nn.quantized.Conv3d">(class in torch.ao.nn.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.functional.conv3d.html#torch.ao.nn.quantized.functional.conv3d">conv3d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Conv3d.html#torch.nn.Conv3d">Conv3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv3d.html#torch.nn.functional.conv3d">conv3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv_transpose1d.html#torch.nn.functional.conv_transpose1d">conv_transpose1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv_transpose2d.html#torch.nn.functional.conv_transpose2d">conv_transpose2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.conv_transpose3d.html#torch.nn.functional.conv_transpose3d">conv_transpose3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBn1d.html#torch.ao.nn.intrinsic.ConvBn1d">ConvBn1d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBn1d.html#torch.ao.nn.intrinsic.qat.ConvBn1d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBn2d.html#torch.ao.nn.intrinsic.ConvBn2d">ConvBn2d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBn2d.html#torch.ao.nn.intrinsic.qat.ConvBn2d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBn3d.html#torch.ao.nn.intrinsic.ConvBn3d">ConvBn3d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBn3d.html#torch.ao.nn.intrinsic.qat.ConvBn3d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBnReLU1d.html#torch.ao.nn.intrinsic.ConvBnReLU1d">ConvBnReLU1d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBnReLU1d.html#torch.ao.nn.intrinsic.qat.ConvBnReLU1d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBnReLU2d.html#torch.ao.nn.intrinsic.ConvBnReLU2d">ConvBnReLU2d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBnReLU2d.html#torch.ao.nn.intrinsic.qat.ConvBnReLU2d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvBnReLU3d.html#torch.ao.nn.intrinsic.ConvBnReLU3d">ConvBnReLU3d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvBnReLU3d.html#torch.ao.nn.intrinsic.qat.ConvBnReLU3d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.convert.html#torch.ao.quantization.convert">convert (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.ao.quantization.quantize_fx.convert_fx.html#torch.ao.quantization.quantize_fx.convert_fx">convert_fx (class in torch.ao.quantization.quantize_fx)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.convert_n_shadows_model">convert_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm.convert_sync_batchnorm">convert_sync_batchnorm() (torch.nn.SyncBatchNorm class method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.html#torch.ao.quantization.fx.custom_config.ConvertCustomConfig">ConvertCustomConfig (class in torch.ao.quantization.fx.custom_config)</a>
</li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvReLU1d.html#torch.ao.nn.intrinsic.ConvReLU1d">ConvReLU1d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.ConvReLU1d.html#torch.ao.nn.intrinsic.quantized.ConvReLU1d">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvReLU2d.html#torch.ao.nn.intrinsic.ConvReLU2d">ConvReLU2d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvReLU2d.html#torch.ao.nn.intrinsic.qat.ConvReLU2d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.ConvReLU2d.html#torch.ao.nn.intrinsic.quantized.ConvReLU2d">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.intrinsic.ConvReLU3d.html#torch.ao.nn.intrinsic.ConvReLU3d">ConvReLU3d (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.ConvReLU3d.html#torch.ao.nn.intrinsic.qat.ConvReLU3d">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.ConvReLU3d.html#torch.ao.nn.intrinsic.quantized.ConvReLU3d">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.ConvTranspose1d.html#torch.ao.nn.quantized.ConvTranspose1d">ConvTranspose1d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.ConvTranspose1d.html#torch.nn.ConvTranspose1d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.ConvTranspose2d.html#torch.ao.nn.quantized.ConvTranspose2d">ConvTranspose2d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.ConvTranspose2d.html#torch.nn.ConvTranspose2d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.ConvTranspose3d.html#torch.ao.nn.quantized.ConvTranspose3d">ConvTranspose3d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.ConvTranspose3d.html#torch.nn.ConvTranspose3d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.copy">copy() (torch.nn.ParameterDict method)</a>
</li>
      <li><a href="generated/torch.Tensor.copy_.html#torch.Tensor.copy_">copy_() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.copy_">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.copy_">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.copysign.html#torch.copysign">copysign() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.copysign.html#torch.Tensor.copysign">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.copysign_.html#torch.Tensor.copysign_">copysign_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.CorrCholeskyTransform">CorrCholeskyTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.corrcoef.html#torch.corrcoef">corrcoef() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.corrcoef.html#torch.Tensor.corrcoef">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cos.html#torch.cos">cos() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cos.html#torch.Tensor.cos">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.cos_.html#torch.Tensor.cos_">cos_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.cosh.html#torch.cosh">cosh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cosh.html#torch.Tensor.cosh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.cosh_.html#torch.Tensor.cosh_">cosh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.signal.windows.cosine.html#torch.signal.windows.cosine">cosine() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.nn.functional.cosine_embedding_loss.html#torch.nn.functional.cosine_embedding_loss">cosine_embedding_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.cosine_similarity.html#torch.nn.functional.cosine_similarity">cosine_similarity() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR">CosineAnnealingLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts">CosineAnnealingWarmRestarts (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.nn.CosineEmbeddingLoss.html#torch.nn.CosineEmbeddingLoss">CosineEmbeddingLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.CosineSimilarity.html#torch.nn.CosineSimilarity">CosineSimilarity (class in torch.nn)</a>
</li>
      <li><a href="monitor.html#torch.monitor.Stat.count">count (torch.monitor.Stat property)</a>
</li>
      <li><a href="generated/torch.jit.Attribute.html#torch.jit.Attribute.count">count() (torch.jit.Attribute method)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.count">(torch.nn.utils.rnn.PackedSequence method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.count_nonzero.html#torch.count_nonzero">count_nonzero() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.count_nonzero.html#torch.Tensor.count_nonzero">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.CallgrindStats.counts">counts() (torch.utils.benchmark.CallgrindStats method)</a>
</li>
      <li><a href="generated/torch.cov.html#torch.cov">cov() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cov.html#torch.Tensor.cov">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.covariance_matrix">covariance_matrix (torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.covariance_matrix">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.CppExtension">CppExtension() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.cpu">cpu() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.cpu">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.cpu.html#torch.Tensor.cpu">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.cpu">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.cpu">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.CPUOffload">CPUOffload (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.create_arg">create_arg() (torch.fx.Tracer method)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.create_args_for_root">create_args_for_root() (torch.fx.Tracer method)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.create_backend">create_backend() (in module torch.distributed.elastic.rendezvous.c10d_rendezvous_backend)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.create_backend">(in module torch.distributed.elastic.rendezvous.etcd_rendezvous_backend)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.create_global_plan">create_global_plan() (torch.distributed.checkpoint.LoadPlanner method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.create_global_plan">(torch.distributed.checkpoint.SavePlanner method)</a>
</li>
      </ul></li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.create_handler">create_handler() (in module torch.distributed.elastic.rendezvous.dynamic_rendezvous)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry.create_handler">(torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.create_local_plan">create_local_plan() (torch.distributed.checkpoint.LoadPlanner method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.create_local_plan">(torch.distributed.checkpoint.SavePlanner method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.create_node">create_node() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Tracer.create_node">(torch.fx.Tracer method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Tracer.create_proxy">create_proxy() (torch.fx.Tracer method)</a>
</li>
      <li><a href="generated/torch.cross.html#torch.cross">cross() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.cross.html#torch.linalg.cross">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.cross.html#torch.Tensor.cross">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.cross_entropy.html#torch.nn.functional.cross_entropy">cross_entropy() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss">CrossEntropyLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.Tensor.crow_indices.html#torch.Tensor.crow_indices">crow_indices() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.functional.ctc_loss.html#torch.nn.functional.ctc_loss">ctc_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.CTCLoss.html#torch.nn.CTCLoss">CTCLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.cuda">cuda() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.cuda">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.cuda.html#torch.Tensor.cuda">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.cuda">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.cuda">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.CUDAExtension">CUDAExtension() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph">CUDAGraph (class in torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAPluggableAllocator.html#torch.cuda.CUDAPluggableAllocator">CUDAPluggableAllocator (class in torch.cuda)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.cufft_plan_cache">cufft_plan_cache (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.cummax.html#torch.cummax">cummax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cummax.html#torch.Tensor.cummax">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cummin.html#torch.cummin">cummin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cummin.html#torch.Tensor.cummin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cumprod.html#torch.cumprod">cumprod() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cumprod.html#torch.Tensor.cumprod">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.cumprod_.html#torch.Tensor.cumprod_">cumprod_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.cumsum.html#torch.cumsum">cumsum() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.cumsum.html#torch.Tensor.cumsum">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.cumsum_.html#torch.Tensor.cumsum_">cumsum_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.cumulative_trapezoid.html#torch.cumulative_trapezoid">cumulative_trapezoid() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.CumulativeDistributionTransform">CumulativeDistributionTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.mps.current_allocated_memory.html#torch.mps.current_allocated_memory">current_allocated_memory() (in module torch.mps)</a>
</li>
      <li><a href="generated/torch.cuda.current_blas_handle.html#torch.cuda.current_blas_handle">current_blas_handle() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.current_device.html#torch.cuda.current_device">current_device() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.current_stream.html#torch.cuda.current_stream">current_stream() (in module torch.cuda)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.custom_bwd">custom_bwd() (in module torch.cuda.amp)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.custom_from_mask.html#torch.nn.utils.prune.custom_from_mask">custom_from_mask() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.custom_fwd">custom_fwd() (in module torch.cuda.amp)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask">CustomFromMask (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.CyclicLR.html#torch.optim.lr_scheduler.CyclicLR">CyclicLR (class in torch.optim.lr_scheduler)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="D">D</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="monitor.html#torch.monitor.Event.data">data (torch.monitor.Event property)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.data">(torch.nn.utils.rnn.PackedSequence attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.torch.nn.parallel.data_parallel.html#torch.nn.parallel.data_parallel">data_parallel() (in module torch.nn.parallel)</a>
</li>
      <li><a href="generated/torch.Tensor.data_ptr.html#torch.Tensor.data_ptr">data_ptr() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.data_ptr">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.data_ptr">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="monitor.html#torch.monitor.data_value_t">data_value_t (class in torch.monitor)</a>
</li>
      <li><a href="data.html#torch.utils.data.DataLoader">DataLoader (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.nn.DataParallel.html#torch.nn.DataParallel">DataParallel (class in torch.nn)</a>
</li>
      <li><a href="data.html#torch.utils.data.Dataset">Dataset (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.debug_dump">debug_dump() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_activation_only_qconfig.html#torch.ao.quantization.qconfig.default_activation_only_qconfig">default_activation_only_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="data.html#torch.utils.data.default_collate">default_collate() (in module torch.utils.data)</a>
</li>
      <li><a href="data.html#torch.utils.data.default_convert">default_convert() (in module torch.utils.data)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_debug_observer.html#torch.ao.quantization.observer.default_debug_observer">default_debug_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_debug_qconfig.html#torch.ao.quantization.qconfig.default_debug_qconfig">default_debug_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_dynamic_qconfig.html#torch.ao.quantization.qconfig.default_dynamic_qconfig">default_dynamic_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_dynamic_quant_observer.html#torch.ao.quantization.observer.default_dynamic_quant_observer">default_dynamic_quant_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.default_eval_fn.html#torch.ao.quantization.default_eval_fn">default_eval_fn (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_fake_quant.html#torch.ao.quantization.fake_quantize.default_fake_quant">default_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_float_qparams_observer.html#torch.ao.quantization.observer.default_float_qparams_observer">default_float_qparams_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_fused_act_fake_quant.html#torch.ao.quantization.fake_quantize.default_fused_act_fake_quant">default_fused_act_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant.html#torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant">default_fused_per_channel_wt_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant.html#torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant">default_fused_wt_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="torch.html#torch.torch.default_generator">default_generator (torch.torch attribute)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_histogram_fake_quant.html#torch.ao.quantization.fake_quantize.default_histogram_fake_quant">default_histogram_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_histogram_observer.html#torch.ao.quantization.observer.default_histogram_observer">default_histogram_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_observer.html#torch.ao.quantization.observer.default_observer">default_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_per_channel_qconfig.html#torch.ao.quantization.qconfig.default_per_channel_qconfig">default_per_channel_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant.html#torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant">default_per_channel_weight_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_per_channel_weight_observer.html#torch.ao.quantization.observer.default_per_channel_weight_observer">default_per_channel_weight_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_placeholder_observer.html#torch.ao.quantization.observer.default_placeholder_observer">default_placeholder_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_qat_qconfig.html#torch.ao.quantization.qconfig.default_qat_qconfig">default_qat_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_qat_qconfig_v2.html#torch.ao.quantization.qconfig.default_qat_qconfig_v2">default_qat_qconfig_v2 (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_qconfig.html#torch.ao.quantization.qconfig.default_qconfig">default_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.cuda.default_stream.html#torch.cuda.default_stream">default_stream() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.default_weight_fake_quant.html#torch.ao.quantization.fake_quantize.default_weight_fake_quant">default_weight_fake_quant (in module torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.default_weight_observer.html#torch.ao.quantization.observer.default_weight_observer">default_weight_observer (in module torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.default_weight_only_qconfig.html#torch.ao.quantization.qconfig.default_weight_only_qconfig">default_weight_only_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultLoadPlanner">DefaultLoadPlanner (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultSavePlanner">DefaultSavePlanner (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="library.html#torch.library.Library.define">define() (torch.library.Library method)</a>
</li>
      <li><a href="generated/torch.deg2rad.html#torch.deg2rad">deg2rad() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.deg2rad.html#torch.Tensor.deg2rad">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.GraphModule.delete_all_unused_submodules">delete_all_unused_submodules() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store.delete_key">delete_key() (in module torch.distributed.Store)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule.delete_submodule">delete_submodule() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.CallgrindStats.delta">delta() (torch.utils.benchmark.CallgrindStats method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.denied_modules">denied_modules() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.FunctionCounts.denoise">denoise() (torch.utils.benchmark.FunctionCounts method)</a>
</li>
      <li><a href="generated/torch.Tensor.dense_dim.html#torch.Tensor.dense_dim">dense_dim() (torch.Tensor method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.deny">deny() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.dependency_graph_string">dependency_graph_string() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.dependent_property">dependent_property (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.dequantize.html#torch.dequantize">dequantize() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantizable.MultiheadAttention.html#torch.ao.nn.quantizable.MultiheadAttention.dequantize">(torch.ao.nn.quantizable.MultiheadAttention method)</a>
</li>
        <li><a href="generated/torch.Tensor.dequantize.html#torch.Tensor.dequantize">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.DeQuantStub.html#torch.ao.quantization.DeQuantStub">DeQuantStub (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.det.html#torch.det">det() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.det.html#torch.linalg.det">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.det.html#torch.Tensor.det">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.detach.html#torch.Tensor.detach">detach() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.detach_.html#torch.Tensor.detach_">detach_() (torch.Tensor method)</a>
</li>
      <li><a href="autograd.html#torch.autograd.detect_anomaly">detect_anomaly (class in torch.autograd)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.deterministic">deterministic (in module torch.backends.cudnn)</a>
</li>
      <li><a href="tensor_attributes.html#torch.device">device (class in torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.device.html#torch.cuda.device">(class in torch.cuda)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.device">(torch.Generator attribute)</a>
</li>
        <li><a href="generated/torch.Tensor.device.html#torch.Tensor.device">(torch.Tensor attribute)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.device">(torch.TypedStorage property)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.device">(torch.UntypedStorage attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.device_count.html#torch.cuda.device_count">device_count() (in module torch.cuda)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.device_maps">device_maps (torch.distributed.rpc.TensorPipeRpcBackendOptions property)</a>
</li>
      <li><a href="generated/torch.cuda.device_of.html#torch.cuda.device_of">device_of (class in torch.cuda)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.devices">devices (torch.distributed.rpc.TensorPipeRpcBackendOptions property)</a>
</li>
      <li><a href="distributions.html#torch.distributions.chi2.Chi2.df">df (torch.distributions.chi2.Chi2 property)</a>
</li>
      <li><a href="generated/torch.diag.html#torch.diag">diag() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.diag.html#torch.Tensor.diag">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.diag_embed.html#torch.diag_embed">diag_embed() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.diag_embed.html#torch.Tensor.diag_embed">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.diagflat.html#torch.diagflat">diagflat() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.diagflat.html#torch.Tensor.diagflat">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.ExportOutput.html#torch.onnx.ExportOutput.diagnostic_context">diagnostic_context (torch.onnx.ExportOutput property)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.diagonal.html#torch.diagonal">diagonal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.diagonal.html#torch.linalg.diagonal">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.diagonal.html#torch.Tensor.diagonal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.diagonal_scatter.html#torch.diagonal_scatter">diagonal_scatter() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.diagonal_scatter.html#torch.Tensor.diagonal_scatter">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.diff.html#torch.diff">diff() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.diff.html#torch.Tensor.diff">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.digamma.html#torch.digamma">digamma() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.digamma">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.digamma.html#torch.Tensor.digamma">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.digamma_.html#torch.Tensor.digamma_">digamma_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.dim.html#torch.Tensor.dim">dim() (torch.Tensor method)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.dirac_">dirac_() (in module torch.nn.init)</a>
</li>
      <li><a href="package.html#torch.package.Directory">Directory (class in torch.package)</a>
</li>
      <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet">Dirichlet (class in torch.distributions.dirichlet)</a>
</li>
      <li><a href="generated/torch.compiler.disable.html#torch.compiler.disable">disable() (in module torch.compiler)</a>

      <ul>
        <li><a href="generated/torch.sparse.check_sparse_tensor_invariants.html#torch.sparse.check_sparse_tensor_invariants.disable">(torch.sparse.check_sparse_tensor_invariants static method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.disable_fake_quant.html#torch.ao.quantization.fake_quantize.disable_fake_quant">disable_fake_quant (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="onnx.html#torch.onnx.disable_log">disable_log() (in module torch.onnx)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.disable_observer.html#torch.ao.quantization.fake_quantize.disable_observer">disable_observer (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.disable_saved_tensors_hooks">disable_saved_tensors_hooks (class in torch.autograd.graph)</a>
</li>
      <li><a href="generated/torch.dist.html#torch.dist">dist() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.dist.html#torch.Tensor.dist">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.DistBackendError">DistBackendError (class in torch.distributed)</a>
</li>
      <li><a href="generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel">DistributedDataParallel (class in torch.nn.parallel)</a>
</li>
      <li><a href="distributed.optim.html#torch.distributed.optim.DistributedOptimizer">DistributedOptimizer (class in torch.distributed.optim)</a>
</li>
      <li><a href="data.html#torch.utils.data.distributed.DistributedSampler">DistributedSampler (class in torch.utils.data.distributed)</a>
</li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution">Distribution (class in torch.distributions.distribution)</a>
</li>
      <li><a href="generated/torch.div.html#torch.div">div() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.div.html#torch.Tensor.div">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.div_.html#torch.Tensor.div_">div_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.divide.html#torch.divide">divide() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.divide.html#torch.Tensor.divide">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.divide_.html#torch.Tensor.divide_">divide_() (torch.Tensor method)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.done">done() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.dot.html#torch.dot">dot() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.dot.html#torch.Tensor.dot">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.double">double() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.double">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.double.html#torch.Tensor.double">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.double">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.double">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.DoubleStorage">DoubleStorage (class in torch)</a>
</li>
      <li><a href="hub.html#torch.hub.download_url_to_file">download_url_to_file() (in module torch.hub)</a>
</li>
      <li><a href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine.draw">draw() (torch.quasirandom.SobolEngine method)</a>
</li>
      <li><a href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine.draw_base2">draw_base2() (torch.quasirandom.SobolEngine method)</a>
</li>
      <li><a href="generated/torch.mps.driver_allocated_memory.html#torch.mps.driver_allocated_memory">driver_allocated_memory() (in module torch.mps)</a>
</li>
      <li><a href="generated/torch.nn.Dropout.html#torch.nn.Dropout">Dropout (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.dropout.html#torch.nn.functional.dropout">dropout() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.Dropout1d.html#torch.nn.Dropout1d">Dropout1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.dropout1d.html#torch.nn.functional.dropout1d">dropout1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.Dropout2d.html#torch.nn.Dropout2d">Dropout2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.dropout2d.html#torch.nn.functional.dropout2d">dropout2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.Dropout3d.html#torch.nn.Dropout3d">Dropout3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.dropout3d.html#torch.nn.functional.dropout3d">dropout3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.dsplit.html#torch.dsplit">dsplit() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.dsplit.html#torch.Tensor.dsplit">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.dstack.html#torch.dstack">dstack() (in module torch)</a>
</li>
      <li><a href="tensor_attributes.html#torch.dtype">dtype (class in torch)</a>

      <ul>
        <li><a href="storage.html#torch.BFloat16Storage.dtype">(torch.BFloat16Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.BoolStorage.dtype">(torch.BoolStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.ByteStorage.dtype">(torch.ByteStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.CharStorage.dtype">(torch.CharStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.ComplexDoubleStorage.dtype">(torch.ComplexDoubleStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.ComplexFloatStorage.dtype">(torch.ComplexFloatStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.DoubleStorage.dtype">(torch.DoubleStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.FloatStorage.dtype">(torch.FloatStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.HalfStorage.dtype">(torch.HalfStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.IntStorage.dtype">(torch.IntStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.LongStorage.dtype">(torch.LongStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.QInt32Storage.dtype">(torch.QInt32Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.QInt8Storage.dtype">(torch.QInt8Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.QUInt2x4Storage.dtype">(torch.QUInt2x4Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.QUInt4x2Storage.dtype">(torch.QUInt4x2Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.QUInt8Storage.dtype">(torch.QUInt8Storage attribute)</a>
</li>
        <li><a href="storage.html#torch.ShortStorage.dtype">(torch.ShortStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.dtype">(torch.TypedStorage attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.dtype">dtype() (torch.onnx.JitScalarType method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.DTypeConfig.html#torch.ao.quantization.backend_config.DTypeConfig">DTypeConfig (class in torch.ao.quantization.backend_config)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.DTypeWithConstraints.html#torch.ao.quantization.backend_config.DTypeWithConstraints">DTypeWithConstraints (class in torch.ao.quantization.backend_config)</a>
</li>
      <li><a href="generated/torch.autograd.forward_ad.dual_level.html#torch.autograd.forward_ad.dual_level">dual_level (class in torch.autograd.forward_ad)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler">DynamicRendezvousHandler (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)</a>
</li>
      <li><a href="onnx.html#torch.onnx.dynamo_export">dynamo_export() (in module torch.onnx)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="E">E</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.linalg.eig.html#torch.linalg.eig">eig() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.eigh.html#torch.linalg.eigh">eigh() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.eigvals.html#torch.linalg.eigvals">eigvals() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.eigvalsh.html#torch.linalg.eigvalsh">eigvalsh() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.einsum.html#torch.einsum">einsum() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.elapsed_time">elapsed_time() (torch.cuda.Event method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.ElasticAgent">ElasticAgent (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="generated/torch.Tensor.element_size.html#torch.Tensor.element_size">element_size() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.element_size">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.element_size">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.eliminate_dead_code">eliminate_dead_code() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.ELU.html#torch.ao.nn.quantized.ELU">ELU (class in torch.ao.nn.quantized)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.elu.html#torch.ao.nn.quantized.functional.elu">elu (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.ELU.html#torch.nn.ELU">ELU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.elu.html#torch.nn.functional.elu">elu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.elu_.html#torch.nn.functional.elu_">elu_() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.Embedding.html#torch.ao.nn.quantized.Embedding">Embedding (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.Embedding.html#torch.nn.Embedding">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.embedding.html#torch.nn.functional.embedding">embedding() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.embedding_bag.html#torch.nn.functional.embedding_bag">embedding_bag() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.EmbeddingBag.html#torch.ao.nn.quantized.EmbeddingBag">EmbeddingBag (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="autograd.html#torch.autograd.profiler.emit_itt">emit_itt (class in torch.autograd.profiler)</a>
</li>
      <li><a href="autograd.html#torch.autograd.profiler.emit_nvtx">emit_nvtx (class in torch.autograd.profiler)</a>
</li>
      <li><a href="generated/torch.empty.html#torch.empty">empty() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.empty_cache.html#torch.cuda.empty_cache">empty_cache() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.mps.empty_cache.html#torch.mps.empty_cache">(in module torch.mps)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.empty_like.html#torch.empty_like">empty_like() (in module torch)</a>
</li>
      <li><a href="generated/torch.empty_strided.html#torch.empty_strided">empty_strided() (in module torch)</a>
</li>
      <li><a href="package.html#torch.package.EmptyMatchError">EmptyMatchError (class in torch.package)</a>
</li>
      <li><a href="generated/torch.sparse.check_sparse_tensor_invariants.html#torch.sparse.check_sparse_tensor_invariants.enable">enable() (torch.sparse.check_sparse_tensor_invariants static method)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.fsdp.enable_2d_with_fsdp">enable_2d_with_fsdp() (in module torch.distributed.tensor.parallel.fsdp)</a>
</li>
      <li><a href="cuda._sanitizer.html#torch.cuda._sanitizer.enable_cuda_sanitizer">enable_cuda_sanitizer() (in module torch.cuda._sanitizer)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.enable_debug_mode">enable_debug_mode() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.enable_fake_quant.html#torch.ao.quantization.fake_quantize.enable_fake_quant">enable_fake_quant (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.enable_flash_sdp">enable_flash_sdp() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.enable_grad.html#torch.enable_grad">enable_grad (class in torch)</a>
</li>
      <li><a href="onnx.html#torch.onnx.enable_log">enable_log() (in module torch.onnx)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.enable_math_sdp">enable_math_sdp() (in module torch.backends.cuda)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.enable_mem_efficient_sdp">enable_mem_efficient_sdp() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.enable_observer.html#torch.ao.quantization.fake_quantize.enable_observer">enable_observer (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.jit.enable_onednn_fusion.html#torch.jit.enable_onednn_fusion">enable_onednn_fusion() (in module torch.jit)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.enabled">enabled (in module torch.backends.cudnn)</a>

      <ul>
        <li><a href="backends.html#torch.backends.opt_einsum.enabled">(in module torch.backends.opt_einsum)</a>
</li>
      </ul></li>
      <li><a href="special.html#torch.special.entr">entr() (in module torch.special)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.entropy">entropy() (torch.distributions.bernoulli.Bernoulli method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.entropy">(torch.distributions.beta.Beta method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.entropy">(torch.distributions.binomial.Binomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.entropy">(torch.distributions.categorical.Categorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.entropy">(torch.distributions.cauchy.Cauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.entropy">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.entropy">(torch.distributions.dirichlet.Dirichlet method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.entropy">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exp_family.ExponentialFamily.entropy">(torch.distributions.exp_family.ExponentialFamily method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.entropy">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.entropy">(torch.distributions.gamma.Gamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.entropy">(torch.distributions.geometric.Geometric method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.entropy">(torch.distributions.gumbel.Gumbel method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.entropy">(torch.distributions.half_cauchy.HalfCauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.entropy">(torch.distributions.half_normal.HalfNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.entropy">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.entropy">(torch.distributions.kumaraswamy.Kumaraswamy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.entropy">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.entropy">(torch.distributions.log_normal.LogNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.entropy">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.entropy">(torch.distributions.multinomial.Multinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.entropy">(torch.distributions.multivariate_normal.MultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.entropy">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.entropy">(torch.distributions.one_hot_categorical.OneHotCategorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.entropy">(torch.distributions.pareto.Pareto method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.entropy">(torch.distributions.studentT.StudentT method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.entropy">(torch.distributions.uniform.Uniform method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.entropy">(torch.distributions.weibull.Weibull method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.entropy">(torch.distributions.wishart.Wishart method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.enumerate_support">enumerate_support() (torch.distributions.bernoulli.Bernoulli method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.enumerate_support">(torch.distributions.binomial.Binomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.enumerate_support">(torch.distributions.categorical.Categorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.enumerate_support">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.enumerate_support">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support">(torch.distributions.one_hot_categorical.OneHotCategorical method)</a>
</li>
      </ul></li>
      <li>
    environment variable

      <ul>
        <li><a href="jit.html#envvar-PYTORCH_JIT">PYTORCH_JIT</a>
</li>
      </ul></li>
      <li><a href="generated/torch.eq.html#torch.eq">eq() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.eq.html#torch.Tensor.eq">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.eq_.html#torch.Tensor.eq_">eq_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.equal.html#torch.equal">equal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.equal.html#torch.Tensor.equal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.erase_node">erase_node() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.erf.html#torch.erf">erf() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.erf">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.erf.html#torch.Tensor.erf">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.erf_.html#torch.Tensor.erf_">erf_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.erfc.html#torch.erfc">erfc() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.erfc">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.erfc.html#torch.Tensor.erfc">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.erfc_.html#torch.Tensor.erfc_">erfc_() (torch.Tensor method)</a>
</li>
      <li><a href="special.html#torch.special.erfcx">erfcx() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.erfinv.html#torch.erfinv">erfinv() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.erfinv">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.erfinv.html#torch.Tensor.erfinv">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.erfinv_.html#torch.Tensor.erfinv_">erfinv_() (torch.Tensor method)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="elastic/errors.html#torch.distributed.elastic.multiprocessing.errors.ErrorHandler">ErrorHandler (class in torch.distributed.elastic.multiprocessing.errors)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.essential_node_count">essential_node_count() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.essential_node_kinds">essential_node_kinds() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend">EtcdRendezvousBackend (class in torch.distributed.elastic.rendezvous.etcd_rendezvous_backend)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous.EtcdRendezvousHandler">EtcdRendezvousHandler (class in torch.distributed.elastic.rendezvous.etcd_rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_server.EtcdServer">EtcdServer (class in torch.distributed.elastic.rendezvous.etcd_server)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore">EtcdStore (class in torch.distributed.elastic.rendezvous.etcd_store)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.eval">eval() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.eval">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event">Event (class in torch.cuda)</a>

      <ul>
        <li><a href="elastic/events.html#torch.distributed.elastic.events.api.Event">(class in torch.distributed.elastic.events.api)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Event">(class in torch.monitor)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution.event_shape">event_shape (torch.distributions.distribution.Distribution property)</a>
</li>
      <li><a href="monitor.html#torch.monitor.EventHandlerHandle">EventHandlerHandle (class in torch.monitor)</a>
</li>
      <li><a href="elastic/events.html#torch.distributed.elastic.events.api.EventMetadataValue">EventMetadataValue (in module torch.distributed.elastic.events.api)</a>
</li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile.events">events() (torch.profiler._KinetoProfile method)</a>
</li>
      <li><a href="elastic/events.html#torch.distributed.elastic.events.api.EventSource">EventSource (class in torch.distributed.elastic.events.api)</a>
</li>
      <li><a href="generated/torch.exp.html#torch.exp">exp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.exp.html#torch.Tensor.exp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.exp2.html#torch.exp2">exp2() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.exp2">(in module torch.special)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.exp_.html#torch.Tensor.exp_">exp_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.expand">expand() (torch.distributions.bernoulli.Bernoulli method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.expand">(torch.distributions.beta.Beta method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.expand">(torch.distributions.binomial.Binomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.expand">(torch.distributions.categorical.Categorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.expand">(torch.distributions.cauchy.Cauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.chi2.Chi2.expand">(torch.distributions.chi2.Chi2 method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.expand">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.expand">(torch.distributions.dirichlet.Dirichlet method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.expand">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.expand">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.expand">(torch.distributions.fishersnedecor.FisherSnedecor method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.expand">(torch.distributions.gamma.Gamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.expand">(torch.distributions.geometric.Geometric method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.expand">(torch.distributions.gumbel.Gumbel method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.expand">(torch.distributions.half_cauchy.HalfCauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.expand">(torch.distributions.half_normal.HalfNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.expand">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.expand">(torch.distributions.kumaraswamy.Kumaraswamy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.expand">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky.expand">(torch.distributions.lkj_cholesky.LKJCholesky method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.expand">(torch.distributions.log_normal.LogNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.expand">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.expand">(torch.distributions.mixture_same_family.MixtureSameFamily method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.expand">(torch.distributions.multinomial.Multinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.expand">(torch.distributions.multivariate_normal.MultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.expand">(torch.distributions.negative_binomial.NegativeBinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.expand">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.expand">(torch.distributions.one_hot_categorical.OneHotCategorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.expand">(torch.distributions.pareto.Pareto method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.expand">(torch.distributions.poisson.Poisson method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.expand">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.expand">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.expand">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.expand">(torch.distributions.studentT.StudentT method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.expand">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.expand">(torch.distributions.uniform.Uniform method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.expand">(torch.distributions.von_mises.VonMises method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.expand">(torch.distributions.weibull.Weibull method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.expand">(torch.distributions.wishart.Wishart method)</a>
</li>
        <li><a href="generated/torch.Tensor.expand.html#torch.Tensor.expand">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.expand_as.html#torch.Tensor.expand_as">expand_as() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.expires">expires() (in module torch.distributed.elastic.timer)</a>
</li>
      <li><a href="special.html#torch.special.expit">expit() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.expm1.html#torch.expm1">expm1() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.expm1">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.expm1.html#torch.Tensor.expm1">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.expm1_.html#torch.Tensor.expm1_">expm1_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.exponential.Exponential">Exponential (class in torch.distributions.exponential)</a>
</li>
      <li><a href="generated/torch.signal.windows.exponential.html#torch.signal.windows.exponential">exponential() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.Tensor.exponential_.html#torch.Tensor.exponential_">exponential_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.exp_family.ExponentialFamily">ExponentialFamily (class in torch.distributions.exp_family)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR">ExponentialLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="jit.html#torch.jit.export">export() (in module torch.jit)</a>

      <ul>
        <li><a href="onnx.html#torch.onnx.export">(in module torch.onnx)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.profiler.profile.export_chrome_trace.html#torch.autograd.profiler.profile.export_chrome_trace">export_chrome_trace() (torch.autograd.profiler.profile method)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler._KinetoProfile.export_chrome_trace">(torch.profiler._KinetoProfile method)</a>
</li>
      </ul></li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile.export_memory_timeline">export_memory_timeline() (torch.profiler._KinetoProfile method)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.export_repro">export_repro() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="profiler.html#torch.profiler._KinetoProfile.export_stacks">export_stacks() (torch.profiler._KinetoProfile method)</a>
</li>
      <li><a href="onnx.html#torch.onnx.export_to_pretty_string">export_to_pretty_string() (in module torch.onnx)</a>
</li>
      <li><a href="onnx_diagnostics.html#torch.onnx._internal.diagnostics.ExportDiagnostic">ExportDiagnostic (class in torch.onnx._internal.diagnostics)</a>
</li>
      <li><a href="generated/torch.onnx.ExportOptions.html#torch.onnx.ExportOptions">ExportOptions (class in torch.onnx)</a>
</li>
      <li><a href="generated/torch.onnx.ExportOutput.html#torch.onnx.ExportOutput">ExportOutput (class in torch.onnx)</a>
</li>
      <li><a href="generated/torch.onnx.ExportOutputSerializer.html#torch.onnx.ExportOutputSerializer">ExportOutputSerializer (class in torch.onnx)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.ExpTransform">ExpTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.nn.ModuleList.html#torch.nn.ModuleList.extend">extend() (torch.nn.ModuleList method)</a>

      <ul>
        <li><a href="generated/torch.nn.ParameterList.html#torch.nn.ParameterList.extend">(torch.nn.ParameterList method)</a>
</li>
      </ul></li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extend_logger_results_with_comparison">extend_logger_results_with_comparison() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.extern">extern() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream">ExternalStream (class in torch.cuda)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.externed_modules">externed_modules() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.extra_repr">extra_repr() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.extra_repr">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_logger_info">extract_logger_info() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_results_n_shadows_model">extract_results_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_shadow_logger_info">extract_shadow_logger_info() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.extract_weights">extract_weights() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="generated/torch.eye.html#torch.eye">eye() (in module torch)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.eye_">eye_() (in module torch.nn.init)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="F">F</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.fake_quantize_per_channel_affine.html#torch.fake_quantize_per_channel_affine">fake_quantize_per_channel_affine() (in module torch)</a>
</li>
      <li><a href="generated/torch.fake_quantize_per_tensor_affine.html#torch.fake_quantize_per_tensor_affine">fake_quantize_per_tensor_affine() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.FakeQuantize.html#torch.ao.quantization.fake_quantize.FakeQuantize">FakeQuantize (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.FakeQuantizeBase.html#torch.ao.quantization.fake_quantize.FakeQuantizeBase">FakeQuantizeBase (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine.fast_forward">fast_forward() (torch.quasirandom.SobolEngine method)</a>
</li>
      <li><a href="generated/torch.nn.functional.feature_alpha_dropout.html#torch.nn.functional.feature_alpha_dropout">feature_alpha_dropout() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.FeatureAlphaDropout.html#torch.nn.FeatureAlphaDropout">FeatureAlphaDropout (class in torch.nn)</a>
</li>
      <li><a href="fx.html#torch.fx.Interpreter.fetch_args_kwargs_from_env">fetch_args_kwargs_from_env() (torch.fx.Interpreter method)</a>
</li>
      <li><a href="fx.html#torch.fx.Interpreter.fetch_attr">fetch_attr() (torch.fx.Interpreter method)</a>
</li>
      <li><a href="generated/torch.fft.fft.html#torch.fft.fft">fft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.fft2.html#torch.fft.fft2">fft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.fftfreq.html#torch.fft.fftfreq">fftfreq() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.fftn.html#torch.fft.fftn">fftn() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.fftshift.html#torch.fft.fftshift">fftshift() (in module torch.fft)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.file_structure">file_structure() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.FileStore">FileStore (class in torch.distributed)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.FileSystemReader">FileSystemReader (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.FileSystemWriter">FileSystemWriter (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.FileTimerClient">FileTimerClient (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.FileTimerServer">FileTimerServer (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="generated/torch.Tensor.fill_.html#torch.Tensor.fill_">fill_() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.fill_">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.fill_">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.fill_diagonal_.html#torch.Tensor.fill_diagonal_">fill_diagonal_() (torch.Tensor method)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.FunctionCounts.filter">filter() (torch.utils.benchmark.FunctionCounts method)</a>
</li>
      <li><a href="onnx.html#torch.onnx.verification.find_mismatch">find_mismatch() (in module torch.onnx.verification)</a>

      <ul>
        <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.find_mismatch">(torch.onnx.verification.GraphInfo method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.find_partition">find_partition() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.finish">finish() (torch.distributed.checkpoint.StorageWriter method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.finish_plan">finish_plan() (torch.distributed.checkpoint.LoadPlanner method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.finish_plan">(torch.distributed.checkpoint.SavePlanner method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor">FisherSnedecor (class in torch.distributions.fishersnedecor)</a>
</li>
      <li><a href="generated/torch.fix.html#torch.fix">fix() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.fix.html#torch.Tensor.fix">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.fix_.html#torch.Tensor.fix_">fix_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize.html#torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize">FixedQParamsFakeQuantize (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.flash_sdp_enabled">flash_sdp_enabled() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.nn.Flatten.html#torch.nn.Flatten">Flatten (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.flatten.html#torch.flatten">flatten() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.flatten.html#torch.Tensor.flatten">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.RNNBase.html#torch.nn.RNNBase.flatten_parameters">flatten_parameters() (torch.nn.RNNBase method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.flatten_sharded_optim_state_dict">flatten_sharded_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="generated/torch.flip.html#torch.flip">flip() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.flip.html#torch.Tensor.flip">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fliplr.html#torch.fliplr">fliplr() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.fliplr.html#torch.Tensor.fliplr">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.flipud.html#torch.flipud">flipud() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.flipud.html#torch.Tensor.flipud">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.float">float() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.float">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.float.html#torch.Tensor.float">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.float">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.float">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.qconfig.float16_dynamic_qconfig.html#torch.ao.quantization.qconfig.float16_dynamic_qconfig">float16_dynamic_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.float16_static_qconfig.html#torch.ao.quantization.qconfig.float16_static_qconfig">float16_static_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.float_power.html#torch.float_power">float_power() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.float_power.html#torch.Tensor.float_power">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.float_power_.html#torch.Tensor.float_power_">float_power_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.float_qparams_weight_only_qconfig.html#torch.ao.quantization.qconfig.float_qparams_weight_only_qconfig">float_qparams_weight_only_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.FloatFunctional.html#torch.ao.nn.quantized.FloatFunctional">FloatFunctional (class in torch.ao.nn.quantized)</a>
</li>
      <li><a href="storage.html#torch.FloatStorage">FloatStorage (class in torch)</a>
</li>
      <li><a href="generated/torch.floor.html#torch.floor">floor() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.floor.html#torch.Tensor.floor">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.floor_.html#torch.Tensor.floor_">floor_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.floor_divide.html#torch.floor_divide">floor_divide() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.floor_divide.html#torch.Tensor.floor_divide">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.floor_divide_.html#torch.Tensor.floor_divide_">floor_divide_() (torch.Tensor method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.flush">flush() (torch.utils.tensorboard.writer.SummaryWriter method)</a>
</li>
      <li><a href="generated/torch.fmax.html#torch.fmax">fmax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.fmax.html#torch.Tensor.fmax">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fmin.html#torch.fmin">fmin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.fmin.html#torch.Tensor.fmin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fmod.html#torch.fmod">fmod() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.fmod.html#torch.Tensor.fmod">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.fmod_.html#torch.Tensor.fmod_">fmod_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.Fold.html#torch.nn.Fold">Fold (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.fold.html#torch.nn.functional.fold">fold() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.jit.fork.html#torch.jit.fork">fork() (in module torch.jit)</a>
</li>
      <li><a href="random.html#torch.random.fork_rng">fork_rng() (in module torch.random)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.format_node">format_node() (torch.fx.Node method)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.ao.nn.quantizable.MultiheadAttention.html#torch.ao.nn.quantizable.MultiheadAttention.forward">forward() (torch.ao.nn.quantizable.MultiheadAttention method)</a>

      <ul>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Logger.forward">(torch.ao.ns._numeric_suite.Logger method)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.OutputLogger.forward">(torch.ao.ns._numeric_suite.OutputLogger method)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.forward">(torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.ShadowLogger.forward">(torch.ao.ns._numeric_suite.ShadowLogger method)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputComparisonLogger.forward">(torch.ao.ns._numeric_suite_fx.OutputComparisonLogger method)</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputLogger.forward">(torch.ao.ns._numeric_suite_fx.OutputLogger method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.observer.MinMaxObserver.html#torch.ao.quantization.observer.MinMaxObserver.forward">(torch.ao.quantization.observer.MinMaxObserver method)</a>
</li>
        <li><a href="generated/torch.autograd.Function.forward.html#torch.autograd.Function.forward">(torch.autograd.Function static method)</a>
</li>
        <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.forward">(torch.distributed.fsdp.FullyShardedDataParallel method)</a>
</li>
        <li><a href="pipeline.html#torch.distributed.pipeline.sync.Pipe.forward">(torch.distributed.pipeline.sync.Pipe method)</a>
</li>
        <li><a href="generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag.forward">(torch.nn.EmbeddingBag method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.forward">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention.forward">(torch.nn.MultiheadAttention method)</a>
</li>
        <li><a href="generated/torch.nn.Transformer.html#torch.nn.Transformer.forward">(torch.nn.Transformer method)</a>
</li>
        <li><a href="generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder.forward">(torch.nn.TransformerDecoder method)</a>
</li>
        <li><a href="generated/torch.nn.TransformerDecoderLayer.html#torch.nn.TransformerDecoderLayer.forward">(torch.nn.TransformerDecoderLayer method)</a>
</li>
        <li><a href="generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder.forward">(torch.nn.TransformerEncoder method)</a>
</li>
        <li><a href="generated/torch.nn.TransformerEncoderLayer.html#torch.nn.TransformerEncoderLayer.forward">(torch.nn.TransformerEncoderLayer method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform.forward_shape">forward_shape() (torch.distributions.transforms.Transform method)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.default_hooks.fp16_compress_hook">fp16_compress_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.default_hooks.fp16_compress_wrapper">fp16_compress_wrapper() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)</a>
</li>
      <li><a href="generated/torch.frac.html#torch.frac">frac() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.frac.html#torch.Tensor.frac">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.frac_.html#torch.Tensor.frac_">frac_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.functional.fractional_max_pool2d.html#torch.nn.functional.fractional_max_pool2d">fractional_max_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.fractional_max_pool3d.html#torch.nn.functional.fractional_max_pool3d">fractional_max_pool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.FractionalMaxPool2d.html#torch.nn.FractionalMaxPool2d">FractionalMaxPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.FractionalMaxPool3d.html#torch.nn.FractionalMaxPool3d">FractionalMaxPool3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.jit.freeze.html#torch.jit.freeze">freeze() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.ao.nn.intrinsic.qat.freeze_bn_stats.html#torch.ao.nn.intrinsic.qat.freeze_bn_stats">freeze_bn_stats (class in torch.ao.nn.intrinsic.qat)</a>
</li>
      <li><a href="generated/torch.frexp.html#torch.frexp">frexp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.frexp.html#torch.Tensor.frexp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler.from_backend">from_backend() (torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler class method)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.from_buffer">from_buffer() (torch.TypedStorage class method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.from_buffer">(torch.UntypedStorage static method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.from_dict">from_dict() (torch.ao.quantization.backend_config.BackendConfig class method)</a>

      <ul>
        <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.from_dict">(torch.ao.quantization.backend_config.BackendPatternConfig class method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.backend_config.DTypeConfig.html#torch.ao.quantization.backend_config.DTypeConfig.from_dict">(torch.ao.quantization.backend_config.DTypeConfig class method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.html#torch.ao.quantization.fx.custom_config.ConvertCustomConfig.from_dict">(torch.ao.quantization.fx.custom_config.ConvertCustomConfig class method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig.html#torch.ao.quantization.fx.custom_config.FuseCustomConfig.from_dict">(torch.ao.quantization.fx.custom_config.FuseCustomConfig class method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.from_dict">(torch.ao.quantization.fx.custom_config.PrepareCustomConfig class method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.from_dict">(torch.ao.quantization.qconfig_mapping.QConfigMapping class method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.from_dlpack.html#torch.from_dlpack">from_dlpack() (in module torch)</a>

      <ul>
        <li><a href="dlpack.html#torch.utils.dlpack.from_dlpack">(in module torch.utils.dlpack)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.from_dtype">from_dtype() (torch.onnx.JitScalarType class method)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.from_file">from_file() (torch.TypedStorage class method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.from_file">(torch.UntypedStorage static method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.qat.Linear.html#torch.ao.nn.qat.Linear.from_float">from_float() (torch.ao.nn.qat.Linear class method)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantized.Conv1d.html#torch.ao.nn.quantized.Conv1d.from_float">(torch.ao.nn.quantized.Conv1d class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.Conv2d.html#torch.ao.nn.quantized.Conv2d.from_float">(torch.ao.nn.quantized.Conv2d class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.Conv3d.html#torch.ao.nn.quantized.Conv3d.from_float">(torch.ao.nn.quantized.Conv3d class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.dynamic.Linear.html#torch.ao.nn.quantized.dynamic.Linear.from_float">(torch.ao.nn.quantized.dynamic.Linear class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.Embedding.html#torch.ao.nn.quantized.Embedding.from_float">(torch.ao.nn.quantized.Embedding class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.EmbeddingBag.html#torch.ao.nn.quantized.EmbeddingBag.from_float">(torch.ao.nn.quantized.EmbeddingBag class method)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.Linear.html#torch.ao.nn.quantized.Linear.from_float">(torch.ao.nn.quantized.Linear class method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.from_ipc_handle">from_ipc_handle() (torch.cuda.Event class method)</a>
</li>
      <li><a href="generated/torch.from_numpy.html#torch.from_numpy">from_numpy() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.Embedding.html#torch.nn.Embedding.from_pretrained">from_pretrained() (torch.nn.Embedding class method)</a>

      <ul>
        <li><a href="generated/torch.nn.EmbeddingBag.html#torch.nn.EmbeddingBag.from_pretrained">(torch.nn.EmbeddingBag class method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.dynamic.Linear.html#torch.ao.nn.quantized.dynamic.Linear.from_reference">from_reference() (torch.ao.nn.quantized.dynamic.Linear class method)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantized.Linear.html#torch.ao.nn.quantized.Linear.from_reference">(torch.ao.nn.quantized.Linear class method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.from_value">from_value() (torch.onnx.JitScalarType class method)</a>
</li>
      <li><a href="generated/torch.frombuffer.html#torch.frombuffer">frombuffer() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.fromkeys">fromkeys() (torch.nn.ParameterDict method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.fsdp_modules">fsdp_modules() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="generated/torch.full.html#torch.full">full() (in module torch)</a>
</li>
      <li><a href="generated/torch.full_like.html#torch.full_like">full_like() (in module torch)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.full_optim_state_dict">full_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel">FullyShardedDataParallel (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="autograd.html#torch.autograd.Function">Function (class in torch.autograd)</a>
</li>
      <li><a href="generated/torch.func.functional_call.html#torch.func.functional_call">functional_call() (in module torch.func)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.stateless.functional_call.html#torch.nn.utils.stateless.functional_call">(in module torch.nn.utils.stateless)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.func.functionalize.html#torch.func.functionalize">functionalize() (in module torch.func)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.FunctionCounts">FunctionCounts (class in torch.utils.benchmark)</a>
</li>
      <li><a href="generated/torch.ao.quantization.quantize_fx.fuse_fx.html#torch.ao.quantization.quantize_fx.fuse_fx">fuse_fx (class in torch.ao.quantization.quantize_fx)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fuse_modules.html#torch.ao.quantization.fuse_modules">fuse_modules (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig.html#torch.ao.quantization.fx.custom_config.FuseCustomConfig">FuseCustomConfig (class in torch.ao.quantization.fx.custom_config)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize.html#torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize">FusedMovingAvgObsFakeQuantize (class in torch.ao.quantization.fake_quantize)</a>
</li>
      <li><a href="futures.html#torch.futures.Future">Future (class in torch.futures)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.FXFloatFunctional.html#torch.ao.nn.quantized.FXFloatFunctional">FXFloatFunctional (class in torch.ao.nn.quantized)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="G">G</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributions.html#torch.distributions.gamma.Gamma">Gamma (class in torch.distributions.gamma)</a>
</li>
      <li><a href="special.html#torch.special.gammainc">gammainc() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.gammaincc">gammaincc() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.gammaln">gammaln() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.gather.html#torch.gather">gather() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.comm.gather.html#torch.cuda.comm.gather">(in module torch.cuda.comm)</a>
</li>
        <li><a href="distributed.html#torch.distributed.gather">(in module torch.distributed)</a>
</li>
        <li><a href="generated/torch.Tensor.gather.html#torch.Tensor.gather">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.gather_object">gather_object() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.signal.windows.gaussian.html#torch.signal.windows.gaussian">gaussian() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.nn.functional.gaussian_nll_loss.html#torch.nn.functional.gaussian_nll_loss">gaussian_nll_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.GaussianNLLLoss.html#torch.nn.GaussianNLLLoss">GaussianNLLLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.gcd.html#torch.gcd">gcd() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.gcd.html#torch.Tensor.gcd">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.gcd_.html#torch.Tensor.gcd_">gcd_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ge.html#torch.ge">ge() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ge.html#torch.Tensor.ge">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.ge_.html#torch.Tensor.ge_">ge_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.GELU.html#torch.nn.GELU">GELU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.gelu.html#torch.nn.functional.gelu">gelu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.signal.windows.general_cosine.html#torch.signal.windows.general_cosine">general_cosine() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.signal.windows.general_hamming.html#torch.signal.windows.general_hamming">general_hamming() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.nn.Transformer.html#torch.nn.Transformer.generate_square_subsequent_mask">generate_square_subsequent_mask() (torch.nn.Transformer static method)</a>
</li>
      <li><a href="generated/torch.Generator.html#torch.Generator">Generator (class in torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.geometric.Geometric">Geometric (class in torch.distributions.geometric)</a>
</li>
      <li><a href="generated/torch.Tensor.geometric_.html#torch.Tensor.geometric_">geometric_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.geqrf.html#torch.geqrf">geqrf() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.geqrf.html#torch.Tensor.geqrf">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ger.html#torch.ger">ger() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ger.html#torch.Tensor.ger">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.Store.get">get() (in module torch.distributed.Store)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.get">(torch.distributed.elastic.rendezvous.etcd_store.EtcdStore method)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousParameters.get">(torch.distributed.elastic.rendezvous.RendezvousParameters method)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Stat.get">(torch.monitor.Stat method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.get">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="multiprocessing.html#torch.multiprocessing.get_all_sharing_strategies">get_all_sharing_strategies() (in module torch.multiprocessing)</a>
</li>
      <li><a href="generated/torch.cuda.get_allocator_backend.html#torch.cuda.get_allocator_backend">get_allocator_backend() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.get_arch_list.html#torch.cuda.get_arch_list">get_arch_list() (in module torch.cuda)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousParameters.get_as_bool">get_as_bool() (torch.distributed.elastic.rendezvous.RendezvousParameters method)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousParameters.get_as_int">get_as_int() (torch.distributed.elastic.rendezvous.RendezvousParameters method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.get_attr">get_attr() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.get_attr">(torch.fx.Interpreter method)</a>
</li>
        <li><a href="fx.html#torch.fx.Transformer.get_attr">(torch.fx.Transformer method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.get_backend">get_backend() (in module torch.distributed)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.get_backend">(torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      </ul></li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.get_backoff_factor">get_backoff_factor() (torch.cuda.amp.GradScaler method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.get_buffer">get_buffer() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.get_buffer">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.get_compiler_abi_compatibility_and_version">get_compiler_abi_compatibility_and_version() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="backends.html#torch.backends.cpu.get_cpu_capability">get_cpu_capability() (in module torch.backends.cpu)</a>
</li>
      <li><a href="generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction.get_debug_state">get_debug_state() (torch.jit.ScriptFunction method)</a>
</li>
      <li><a href="generated/torch.get_default_dtype.html#torch.get_default_dtype">get_default_dtype() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping.html#torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping">get_default_qat_qconfig_mapping (class in torch.ao.quantization.qconfig_mapping)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping.html#torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping">get_default_qconfig_mapping (class in torch.ao.quantization.qconfig_mapping)</a>
</li>
      <li><a href="generated/torch.get_deterministic_debug_mode.html#torch.get_deterministic_debug_mode">get_deterministic_debug_mode() (in module torch)</a>
</li>
      <li><a href="generated/torch.Tensor.get_device.html#torch.Tensor.get_device">get_device() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.get_device">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.get_device">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.get_device_capability.html#torch.cuda.get_device_capability">get_device_capability() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.get_device_name.html#torch.cuda.get_device_name">get_device_name() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.get_device_properties.html#torch.cuda.get_device_properties">get_device_properties() (in module torch.cuda)</a>
</li>
      <li><a href="hub.html#torch.hub.get_dir">get_dir() (in module torch.hub)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.WorkerSpec.get_entrypoint_name">get_entrypoint_name() (torch.distributed.elastic.agent.server.WorkerSpec method)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerServer.get_expired_timers">get_expired_timers() (torch.distributed.elastic.timer.TimerServer method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.get_extra_state">get_extra_state() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.get_extra_state">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.get_float32_matmul_precision.html#torch.get_float32_matmul_precision">get_float32_matmul_precision() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.get_gencode_flags.html#torch.cuda.get_gencode_flags">get_gencode_flags() (in module torch.cuda)</a>
</li>
      <li><a href="distributed.html#torch.distributed.get_global_rank">get_global_rank() (in module torch.distributed)</a>
</li>
      <li><a href="rpc.html#torch.distributed.autograd.get_gradients">get_gradients() (in module torch.distributed.autograd)</a>
</li>
      <li><a href="distributed.html#torch.distributed.get_group_rank">get_group_rank() (in module torch.distributed)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.get_growth_factor">get_growth_factor() (torch.cuda.amp.GradScaler method)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.get_growth_interval">get_growth_interval() (torch.cuda.amp.GradScaler method)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.get_ignored_functions">get_ignored_functions() (in module torch.overrides)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ChainedScheduler.html#torch.optim.lr_scheduler.ChainedScheduler.get_last_lr">get_last_lr() (torch.optim.lr_scheduler.ChainedScheduler method)</a>

      <ul>
        <li><a href="generated/torch.optim.lr_scheduler.ConstantLR.html#torch.optim.lr_scheduler.ConstantLR.get_last_lr">(torch.optim.lr_scheduler.ConstantLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR.get_last_lr">(torch.optim.lr_scheduler.CosineAnnealingLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.get_last_lr">(torch.optim.lr_scheduler.CosineAnnealingWarmRestarts method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CyclicLR.html#torch.optim.lr_scheduler.CyclicLR.get_last_lr">(torch.optim.lr_scheduler.CyclicLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR.get_last_lr">(torch.optim.lr_scheduler.ExponentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR.get_last_lr">(torch.optim.lr_scheduler.LambdaLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LinearLR.html#torch.optim.lr_scheduler.LinearLR.get_last_lr">(torch.optim.lr_scheduler.LinearLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR.get_last_lr">(torch.optim.lr_scheduler.MultiplicativeLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR.get_last_lr">(torch.optim.lr_scheduler.MultiStepLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR.get_last_lr">(torch.optim.lr_scheduler.OneCycleLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.PolynomialLR.html#torch.optim.lr_scheduler.PolynomialLR.get_last_lr">(torch.optim.lr_scheduler.PolynomialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.SequentialLR.html#torch.optim.lr_scheduler.SequentialLR.get_last_lr">(torch.optim.lr_scheduler.SequentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR.get_last_lr">(torch.optim.lr_scheduler.StepLR method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.get_logger_dict">get_logger_dict() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="elastic/events.html#torch.distributed.elastic.events.get_logging_handler">get_logging_handler() (in module torch.distributed.elastic.events)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.CyclicLR.html#torch.optim.lr_scheduler.CyclicLR.get_lr">get_lr() (torch.optim.lr_scheduler.CyclicLR method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.get_matching_activations">get_matching_activations() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="rpc.html#torch.distributed.nn.api.remote_module.RemoteModule.get_module_rref">get_module_rref() (torch.distributed.nn.api.remote_module.RemoteModule method)</a>
</li>
      <li><a href="generated/torch.get_num_interop_threads.html#torch.get_num_interop_threads">get_num_interop_threads() (in module torch)</a>
</li>
      <li><a href="generated/torch.get_num_threads.html#torch.get_num_threads">get_num_threads() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.get_observer_state_dict.html#torch.ao.quantization.observer.get_observer_state_dict">get_observer_state_dict (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="backends.html#torch.backends.opt_einsum.get_opt_einsum">get_opt_einsum() (in module torch.backends.opt_einsum)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.get_overridable_functions">get_overridable_functions() (in module torch.overrides)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.get_parameter">get_parameter() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.get_parameter">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.get_process_group_ranks">get_process_group_ranks() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.get_rank">get_rank() (in module torch.distributed)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.get_rdeps">get_rdeps() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.get_rng_state.html#torch.get_rng_state">get_rng_state() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.get_rng_state.html#torch.cuda.get_rng_state">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.mps.get_rng_state.html#torch.mps.get_rng_state">(in module torch.mps)</a>
</li>
        <li><a href="random.html#torch.random.get_rng_state">(in module torch.random)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.get_rng_state_all.html#torch.cuda.get_rng_state_all">get_rng_state_all() (in module torch.cuda)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.get_run_id">get_run_id() (torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.get_scale">get_scale() (torch.cuda.amp.GradScaler method)</a>
</li>
      <li><a href="multiprocessing.html#torch.multiprocessing.get_sharing_strategy">get_sharing_strategy() (in module torch.multiprocessing)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.get_state">get_state() (torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend method)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.get_state">(torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend method)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend.get_state">(torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend method)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.get_state">(torch.Generator method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.get_state_dict_type">get_state_dict_type() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.get_submodule">get_submodule() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.get_submodule">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.get_sync_debug_mode.html#torch.cuda.get_sync_debug_mode">get_sync_debug_mode() (in module torch.cuda)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.get_testing_overrides">get_testing_overrides() (in module torch.overrides)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.get_unique_id">get_unique_id() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.ElasticAgent.get_worker_group">get_worker_group() (torch.distributed.elastic.agent.server.ElasticAgent method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.get_worker_info">get_worker_info() (in module torch.distributed.rpc)</a>

      <ul>
        <li><a href="data.html#torch.utils.data.get_worker_info">(in module torch.utils.data)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.get_world_size">get_world_size() (in module torch.distributed)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.getattr">getattr() (torch.fx.Tracer method)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.global_unstructured.html#torch.nn.utils.prune.global_unstructured">global_unstructured() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.nn.GLU.html#torch.nn.GLU">GLU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.glu.html#torch.nn.functional.glu">glu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.Tensor.grad.html#torch.Tensor.grad">grad (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.autograd.grad.html#torch.autograd.grad">grad() (in module torch.autograd)</a>

      <ul>
        <li><a href="generated/torch.func.grad.html#torch.func.grad">(in module torch.func)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.func.grad_and_value.html#torch.func.grad_and_value">grad_and_value() (in module torch.func)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket">GradBucket (class in torch.distributed)</a>
</li>
      <li><a href="generated/torch.autograd.gradcheck.html#torch.autograd.gradcheck">gradcheck() (in module torch.autograd)</a>
</li>
      <li><a href="generated/torch.autograd.gradgradcheck.html#torch.autograd.gradgradcheck">gradgradcheck() (in module torch.autograd)</a>
</li>
      <li><a href="generated/torch.gradient.html#torch.gradient">gradient() (in module torch)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.gradients">gradients() (in module torch.distributed.GradBucket)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler">GradScaler (class in torch.cuda.amp)</a>
</li>
      <li><a href="generated/torch.cuda.graph.html#torch.cuda.graph">graph (class in torch.cuda)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph">Graph (class in torch.fx)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule.graph">graph (torch.fx.GraphModule property)</a>

      <ul>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.graph">(torch.jit.ScriptModule property)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.graph_copy">graph_copy() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.cuda.graph_pool_handle.html#torch.cuda.graph_pool_handle">graph_pool_handle() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo">GraphInfo (class in torch.onnx.verification)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule">GraphModule (class in torch.fx)</a>
</li>
      <li><a href="generated/torch.greater.html#torch.greater">greater() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.greater.html#torch.Tensor.greater">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.greater_.html#torch.Tensor.greater_">greater_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.greater_equal.html#torch.greater_equal">greater_equal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.greater_equal.html#torch.Tensor.greater_equal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.greater_equal_.html#torch.Tensor.greater_equal_">greater_equal_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.greater_than">greater_than (in module torch.distributions.constraints)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.greater_than_eq">greater_than_eq (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.nn.functional.grid_sample.html#torch.nn.functional.grid_sample">grid_sample() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.group_norm.html#torch.nn.functional.group_norm">group_norm() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.GroupNorm.html#torch.ao.nn.quantized.GroupNorm">GroupNorm (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.GroupNorm.html#torch.nn.GroupNorm">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.dynamic.GRU.html#torch.ao.nn.quantized.dynamic.GRU">GRU (class in torch.ao.nn.quantized.dynamic)</a>

      <ul>
        <li><a href="generated/torch.nn.GRU.html#torch.nn.GRU">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.dynamic.GRUCell.html#torch.ao.nn.quantized.dynamic.GRUCell">GRUCell (class in torch.ao.nn.quantized.dynamic)</a>

      <ul>
        <li><a href="generated/torch.nn.GRUCell.html#torch.nn.GRUCell">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.gt.html#torch.gt">gt() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.gt.html#torch.Tensor.gt">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.gt_.html#torch.Tensor.gt_">gt_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.gumbel.Gumbel">Gumbel (class in torch.distributions.gumbel)</a>
</li>
      <li><a href="generated/torch.nn.functional.gumbel_softmax.html#torch.nn.functional.gumbel_softmax">gumbel_softmax() (in module torch.nn.functional)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="H">H</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="tensors.html#torch.Tensor.H">H (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.half">half() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.half">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.half.html#torch.Tensor.half">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.half">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.half">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.constraints.half_open_interval">half_open_interval (in module torch.distributions.constraints)</a>
</li>
      <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy">HalfCauchy (class in torch.distributions.half_cauchy)</a>
</li>
      <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal">HalfNormal (class in torch.distributions.half_normal)</a>
</li>
      <li><a href="storage.html#torch.HalfStorage">HalfStorage (class in torch)</a>
</li>
      <li><a href="generated/torch.signal.windows.hamming.html#torch.signal.windows.hamming">hamming() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.hamming_window.html#torch.hamming_window">hamming_window() (in module torch)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.handle_torch_function">handle_torch_function() (in module torch.overrides)</a>
</li>
      <li><a href="generated/torch.signal.windows.hann.html#torch.signal.windows.hann">hann() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.hann_window.html#torch.hann_window">hann_window() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.Hardshrink.html#torch.nn.Hardshrink">Hardshrink (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.hardshrink.html#torch.nn.functional.hardshrink">hardshrink() (in module torch.nn.functional)</a>

      <ul>
        <li><a href="generated/torch.Tensor.hardshrink.html#torch.Tensor.hardshrink">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.functional.hardsigmoid.html#torch.ao.nn.quantized.functional.hardsigmoid">hardsigmoid (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Hardsigmoid.html#torch.nn.Hardsigmoid">Hardsigmoid (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.hardsigmoid.html#torch.nn.functional.hardsigmoid">hardsigmoid() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.Hardswish.html#torch.ao.nn.quantized.Hardswish">Hardswish (class in torch.ao.nn.quantized)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.hardswish.html#torch.ao.nn.quantized.functional.hardswish">hardswish (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Hardswish.html#torch.nn.Hardswish">Hardswish (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.hardswish.html#torch.nn.functional.hardswish">hardswish() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.hardtanh.html#torch.ao.nn.quantized.functional.hardtanh">hardtanh (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Hardtanh.html#torch.nn.Hardtanh">Hardtanh (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.hardtanh.html#torch.nn.functional.hardtanh">hardtanh() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.hardtanh_.html#torch.nn.functional.hardtanh_">hardtanh_() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.has_enumerate_support">has_enumerate_support (torch.distributions.bernoulli.Bernoulli attribute)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.has_enumerate_support">(torch.distributions.binomial.Binomial attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.has_enumerate_support">(torch.distributions.categorical.Categorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.has_enumerate_support">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.has_enumerate_support">(torch.distributions.one_hot_categorical.OneHotCategorical attribute)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.Directory.has_file">has_file() (torch.package.Directory method)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.has_mismatch">has_mismatch() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.beta.Beta.has_rsample">has_rsample (torch.distributions.beta.Beta attribute)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.has_rsample">(torch.distributions.cauchy.Cauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.has_rsample">(torch.distributions.continuous_bernoulli.ContinuousBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.has_rsample">(torch.distributions.dirichlet.Dirichlet attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.has_rsample">(torch.distributions.exponential.Exponential attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.has_rsample">(torch.distributions.fishersnedecor.FisherSnedecor attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.has_rsample">(torch.distributions.gamma.Gamma attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.has_rsample">(torch.distributions.half_cauchy.HalfCauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.has_rsample">(torch.distributions.half_normal.HalfNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.has_rsample">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.has_rsample">(torch.distributions.kumaraswamy.Kumaraswamy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.has_rsample">(torch.distributions.laplace.Laplace attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.has_rsample">(torch.distributions.log_normal.LogNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.has_rsample">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.has_rsample">(torch.distributions.mixture_same_family.MixtureSameFamily attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.has_rsample">(torch.distributions.multivariate_normal.MultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.has_rsample">(torch.distributions.normal.Normal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.has_rsample">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.has_rsample">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.has_rsample">(torch.distributions.studentT.StudentT attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.has_rsample">(torch.distributions.transformed_distribution.TransformedDistribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.has_rsample">(torch.distributions.uniform.Uniform attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.has_rsample">(torch.distributions.von_mises.VonMises attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.has_rsample">(torch.distributions.wishart.Wishart attribute)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="torch.overrides.html#torch.overrides.has_torch_function">has_torch_function() (in module torch.overrides)</a>
</li>
      <li><a href="generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin.has_uninitialized_params">has_uninitialized_params() (torch.nn.modules.lazy.LazyModuleMixin method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.HashStore">HashStore (class in torch.distributed)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.heartbeat">heartbeat (torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout property)</a>
</li>
      <li><a href="generated/torch.heaviside.html#torch.heaviside">heaviside() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.heaviside.html#torch.Tensor.heaviside">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="hub.html#torch.hub.help">help() (in module torch.hub)</a>
</li>
      <li><a href="generated/torch.autograd.functional.hessian.html#torch.autograd.functional.hessian">hessian() (in module torch.autograd.functional)</a>

      <ul>
        <li><a href="generated/torch.func.hessian.html#torch.func.hessian">(in module torch.func)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.fft.hfft.html#torch.fft.hfft">hfft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.hfft2.html#torch.fft.hfft2">hfft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.hfftn.html#torch.fft.hfftn">hfftn() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.nn.functional.hinge_embedding_loss.html#torch.nn.functional.hinge_embedding_loss">hinge_embedding_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.HingeEmbeddingLoss.html#torch.nn.HingeEmbeddingLoss">HingeEmbeddingLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.histc.html#torch.histc">histc() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.histc.html#torch.Tensor.histc">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.histogram.html#torch.histogram">histogram() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.histogram.html#torch.Tensor.histogram">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.histogramdd.html#torch.histogramdd">histogramdd() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.HistogramObserver.html#torch.ao.quantization.observer.HistogramObserver">HistogramObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.linalg.householder_product.html#torch.linalg.householder_product">householder_product() (in module torch.linalg)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.hpu">hpu() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.hpu">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.hsplit.html#torch.hsplit">hsplit() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.hsplit.html#torch.Tensor.hsplit">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.hspmm.html#torch.hspmm">hspmm() (in module torch)</a>
</li>
      <li><a href="generated/torch.hstack.html#torch.hstack">hstack() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.functional.huber_loss.html#torch.nn.functional.huber_loss">huber_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.HuberLoss.html#torch.nn.HuberLoss">HuberLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.autograd.functional.hvp.html#torch.autograd.functional.hvp">hvp() (in module torch.autograd.functional)</a>
</li>
      <li><a href="generated/torch.hypot.html#torch.hypot">hypot() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.hypot.html#torch.Tensor.hypot">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.hypot_.html#torch.Tensor.hypot_">hypot_() (torch.Tensor method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="I">I</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.i0.html#torch.i0">i0() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.i0">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.i0.html#torch.Tensor.i0">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.i0_.html#torch.Tensor.i0_">i0_() (torch.Tensor method)</a>
</li>
      <li><a href="special.html#torch.special.i0e">i0e() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.i1">i1() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.i1e">i1e() (in module torch.special)</a>
</li>
      <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.icdf">icdf() (torch.distributions.cauchy.Cauchy method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.icdf">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.icdf">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.icdf">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.icdf">(torch.distributions.half_cauchy.HalfCauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.icdf">(torch.distributions.half_normal.HalfNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.icdf">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.icdf">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.icdf">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.icdf">(torch.distributions.uniform.Uniform method)</a>
</li>
      </ul></li>
      <li><a href="rpc.html#torch.distributed.rpc.WorkerInfo.id">id (torch.distributed.rpc.WorkerInfo property)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.id">id() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="generated/torch.nn.Identity.html#torch.nn.Identity">Identity (class in torch.nn)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity">(class in torch.nn.utils.prune)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.prune.identity.html#torch.nn.utils.prune.identity">identity() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.fft.ifft.html#torch.fft.ifft">ifft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.ifft2.html#torch.fft.ifft2">ifft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.ifftn.html#torch.fft.ifftn">ifftn() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.ifftshift.html#torch.fft.ifftshift">ifftshift() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.igamma.html#torch.igamma">igamma() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.igamma.html#torch.Tensor.igamma">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.igamma_.html#torch.Tensor.igamma_">igamma_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.igammac.html#torch.igammac">igammac() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.igammac.html#torch.Tensor.igammac">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.igammac_.html#torch.Tensor.igammac_">igammac_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.jit.ignore.html#torch.jit.ignore">ignore() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.fft.ihfft.html#torch.fft.ihfft">ihfft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.ihfft2.html#torch.fft.ihfft2">ihfft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.ihfftn.html#torch.fft.ihfftn">ihfftn() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.Tensor.imag.html#torch.Tensor.imag">imag (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.imag.html#torch.imag">imag() (in module torch)</a>
</li>
      <li><a href="library.html#torch.library.Library.impl">impl() (torch.library.Library method)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.import_module">import_module() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.include_paths">include_paths() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="distributions.html#torch.distributions.independent.Independent">Independent (class in torch.distributions.independent)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.independent">independent (in module torch.distributions.constraints)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.IndependentTransform">IndependentTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.index">index() (in module torch.distributed.GradBucket)</a>

      <ul>
        <li><a href="generated/torch.jit.Attribute.html#torch.jit.Attribute.index">(torch.jit.Attribute method)</a>
</li>
        <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.index">(torch.nn.utils.rnn.PackedSequence method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.index_add.html#torch.index_add">index_add() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.index_add.html#torch.Tensor.index_add">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.index_add_.html#torch.Tensor.index_add_">index_add_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.index_copy.html#torch.index_copy">index_copy() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.index_copy.html#torch.Tensor.index_copy">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.index_copy_.html#torch.Tensor.index_copy_">index_copy_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.index_fill.html#torch.Tensor.index_fill">index_fill() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.index_fill_.html#torch.Tensor.index_fill_">index_fill_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.index_put.html#torch.Tensor.index_put">index_put() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.index_put_.html#torch.Tensor.index_put_">index_put_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.index_reduce.html#torch.index_reduce">index_reduce() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.index_reduce.html#torch.Tensor.index_reduce">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.index_reduce_.html#torch.Tensor.index_reduce_">index_reduce_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.index_select.html#torch.index_select">index_select() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.index_select.html#torch.Tensor.index_select">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.indices.html#torch.Tensor.indices">indices() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.inference_mode.html#torch.inference_mode">inference_mode (class in torch)</a>
</li>
      <li><a href="generated/torch.cuda.init.html#torch.cuda.init">init() (in module torch.cuda)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.RpcBackendOptions.init_method">init_method (torch.distributed.rpc.RpcBackendOptions property)</a>

      <ul>
        <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.init_method">(torch.distributed.rpc.TensorPipeRpcBackendOptions property)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.init_process_group">init_process_group() (in module torch.distributed)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.init_rpc">init_rpc() (in module torch.distributed.rpc)</a>
</li>
      <li><a href="generated/torch.initial_seed.html#torch.initial_seed">initial_seed() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.initial_seed.html#torch.cuda.initial_seed">(in module torch.cuda)</a>
</li>
        <li><a href="random.html#torch.random.initial_seed">(in module torch.random)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.initial_seed">(torch.Generator method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin.initialize_parameters">initialize_parameters() (torch.nn.modules.lazy.LazyModuleMixin method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.inlined_graph">inlined_graph (torch.jit.ScriptModule property)</a>
</li>
      <li><a href="generated/torch.inner.html#torch.inner">inner() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.inner.html#torch.Tensor.inner">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.backend_config.ObservationType.html#torch.ao.quantization.backend_config.ObservationType.INPUT_OUTPUT_NOT_OBSERVED">INPUT_OUTPUT_NOT_OBSERVED (torch.ao.quantization.backend_config.ObservationType attribute)</a>
</li>
      <li><a href="generated/torch.nn.ModuleList.html#torch.nn.ModuleList.insert">insert() (torch.nn.ModuleList method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.inserting_after">inserting_after() (torch.fx.Graph method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.inserting_before">inserting_before() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.nn.functional.instance_norm.html#torch.nn.functional.instance_norm">instance_norm() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.InstanceNorm1d.html#torch.ao.nn.quantized.InstanceNorm1d">InstanceNorm1d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.InstanceNorm1d.html#torch.nn.InstanceNorm1d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.InstanceNorm2d.html#torch.ao.nn.quantized.InstanceNorm2d">InstanceNorm2d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.InstanceNorm2d.html#torch.nn.InstanceNorm2d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.InstanceNorm3d.html#torch.ao.nn.quantized.InstanceNorm3d">InstanceNorm3d (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.InstanceNorm3d.html#torch.nn.InstanceNorm3d">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.int.html#torch.Tensor.int">int() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.int">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.int">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.int_repr.html#torch.Tensor.int_repr">int_repr() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.integer_interval">integer_interval (in module torch.distributions.constraints)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.intern">intern() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.interned_modules">interned_modules() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.interpolate.html#torch.ao.nn.quantized.functional.interpolate">interpolate (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.interpolate.html#torch.nn.functional.interpolate">interpolate() (in module torch.nn.functional)</a>
</li>
      <li><a href="fx.html#torch.fx.Interpreter">Interpreter (class in torch.fx)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.interval">interval (in module torch.distributions.constraints)</a>
</li>
      <li><a href="storage.html#torch.IntStorage">IntStorage (class in torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform.inv">inv (torch.distributions.transforms.Transform property)</a>
</li>
      <li><a href="generated/torch.linalg.inv.html#torch.linalg.inv">inv() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.inv_ex.html#torch.linalg.inv_ex">inv_ex() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.inverse.html#torch.inverse">inverse() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.inverse.html#torch.Tensor.inverse">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform.inverse_shape">inverse_shape() (torch.distributions.transforms.Transform method)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.cuda.ipc_collect.html#torch.cuda.ipc_collect">ipc_collect() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.ipc_handle">ipc_handle() (torch.cuda.Event method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.ipu">ipu() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.ipu">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.irecv">irecv() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.fft.irfft.html#torch.fft.irfft">irfft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.irfft2.html#torch.fft.irfft2">irfft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.irfftn.html#torch.fft.irfftn">irfftn() (in module torch.fft)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.is_available">is_available() (in module torch.backends.cudnn)</a>

      <ul>
        <li><a href="backends.html#torch.backends.mkl.is_available">(in module torch.backends.mkl)</a>
</li>
        <li><a href="backends.html#torch.backends.mkldnn.is_available">(in module torch.backends.mkldnn)</a>
</li>
        <li><a href="backends.html#torch.backends.mps.is_available">(in module torch.backends.mps)</a>
</li>
        <li><a href="backends.html#torch.backends.openmp.is_available">(in module torch.backends.openmp)</a>
</li>
        <li><a href="backends.html#torch.backends.opt_einsum.is_available">(in module torch.backends.opt_einsum)</a>
</li>
        <li><a href="generated/torch.cuda.is_available.html#torch.cuda.is_available">(in module torch.cuda)</a>
</li>
        <li><a href="distributed.html#torch.distributed.is_available">(in module torch.distributed)</a>
</li>
        <li><a href="profiler.html#torch.profiler.itt.is_available">(in module torch.profiler.itt)</a>
</li>
      </ul></li>
      <li><a href="backends.html#torch.backends.cuda.is_built">is_built() (in module torch.backends.cuda)</a>

      <ul>
        <li><a href="backends.html#torch.backends.mps.is_built">(in module torch.backends.mps)</a>
</li>
      </ul></li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.is_closed">is_closed() (torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      <li><a href="generated/torch.Tensor.is_coalesced.html#torch.Tensor.is_coalesced">is_coalesced() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.is_complex.html#torch.is_complex">is_complex() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.is_complex.html#torch.Tensor.is_complex">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.is_conj.html#torch.is_conj">is_conj() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.is_conj.html#torch.Tensor.is_conj">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.is_contiguous.html#torch.Tensor.is_contiguous">is_contiguous() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.is_cuda">is_cuda (torch.nn.utils.rnn.PackedSequence property)</a>

      <ul>
        <li><a href="generated/torch.Tensor.is_cuda.html#torch.Tensor.is_cuda">(torch.Tensor attribute)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.is_cuda">(torch.TypedStorage property)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.is_cuda">(torch.UntypedStorage property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.is_current_stream_capturing.html#torch.cuda.is_current_stream_capturing">is_current_stream_capturing() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.is_deterministic_algorithms_warn_only_enabled.html#torch.is_deterministic_algorithms_warn_only_enabled">is_deterministic_algorithms_warn_only_enabled() (in module torch)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.is_enabled">is_enabled() (torch.cuda.amp.GradScaler method)</a>

      <ul>
        <li><a href="generated/torch.sparse.check_sparse_tensor_invariants.html#torch.sparse.check_sparse_tensor_invariants.is_enabled">(torch.sparse.check_sparse_tensor_invariants static method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.is_floating_point.html#torch.is_floating_point">is_floating_point() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.is_floating_point.html#torch.Tensor.is_floating_point">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.is_gloo_available">is_gloo_available() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.is_grad_enabled.html#torch.is_grad_enabled">is_grad_enabled() (in module torch)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.is_hpu">is_hpu (torch.TypedStorage property)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.is_hpu">(torch.UntypedStorage property)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Node.is_impure">is_impure() (torch.fx.Node method)</a>
</li>
      <li><a href="onnx.html#torch.onnx.is_in_onnx_export">is_in_onnx_export() (in module torch.onnx)</a>
</li>
      <li><a href="generated/torch.Tensor.is_inference.html#torch.Tensor.is_inference">is_inference() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.is_inference_mode_enabled.html#torch.is_inference_mode_enabled">is_inference_mode_enabled() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.is_initialized.html#torch.cuda.is_initialized">is_initialized() (in module torch.cuda)</a>

      <ul>
        <li><a href="distributed.html#torch.distributed.is_initialized">(in module torch.distributed)</a>
</li>
      </ul></li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.is_last">is_last() (in module torch.distributed.GradBucket)</a>
</li>
      <li><a href="generated/torch.Tensor.is_leaf.html#torch.Tensor.is_leaf">is_leaf (torch.Tensor attribute)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.NSTracer.is_leaf_module">is_leaf_module() (torch.ao.ns._numeric_suite_fx.NSTracer method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Tracer.is_leaf_module">(torch.fx.Tracer method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.is_meta.html#torch.Tensor.is_meta">is_meta (torch.Tensor attribute)</a>
</li>
      <li><a href="distributed.html#torch.distributed.is_mpi_available">is_mpi_available() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.is_nccl_available">is_nccl_available() (in module torch.distributed)</a>
</li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.is_ninja_available">is_ninja_available() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.is_nonzero.html#torch.is_nonzero">is_nonzero() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.utils.parametrize.is_parametrized.html#torch.nn.utils.parametrize.is_parametrized">is_parametrized() (in module torch.nn.utils.parametrize)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.is_pinned">is_pinned() (torch.nn.utils.rnn.PackedSequence method)</a>

      <ul>
        <li><a href="generated/torch.Tensor.is_pinned.html#torch.Tensor.is_pinned">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.is_pinned">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.is_pinned">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.prune.is_pruned.html#torch.nn.utils.prune.is_pruned">is_pruned() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.Tensor.is_quantized.html#torch.Tensor.is_quantized">is_quantized (torch.Tensor attribute)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.WorkerState.is_running">is_running() (torch.distributed.elastic.agent.server.WorkerState static method)</a>
</li>
      <li><a href="jit_language_reference.html#torch.jit.is_scripting">is_scripting() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.Tensor.is_set_to.html#torch.Tensor.is_set_to">is_set_to() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.is_shared.html#torch.Tensor.is_shared">is_shared() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.is_shared">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.is_shared">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.is_signed.html#torch.Tensor.is_signed">is_signed() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.is_sparse.html#torch.Tensor.is_sparse">is_sparse (torch.Tensor attribute)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.is_sparse">(torch.TypedStorage attribute)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.is_sparse">(torch.UntypedStorage attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.is_sparse_csr.html#torch.Tensor.is_sparse_csr">is_sparse_csr (torch.Tensor attribute)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.is_sparse_csr">(torch.UntypedStorage attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.is_storage.html#torch.is_storage">is_storage() (in module torch)</a>
</li>
      <li><a href="generated/torch.is_tensor.html#torch.is_tensor">is_tensor() (in module torch)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.is_tensor_like">is_tensor_like() (in module torch.overrides)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.is_tensor_method_or_property">is_tensor_method_or_property() (in module torch.overrides)</a>
</li>
      <li><a href="distributed.html#torch.distributed.is_torchelastic_launched">is_torchelastic_launched() (in module torch.distributed)</a>
</li>
      <li><a href="jit_language_reference.html#torch.jit.is_tracing">is_tracing() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.is_warn_always_enabled.html#torch.is_warn_always_enabled">is_warn_always_enabled() (in module torch)</a>
</li>
      <li><a href="generated/torch.isclose.html#torch.isclose">isclose() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isclose.html#torch.Tensor.isclose">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.isend">isend() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.isfinite.html#torch.isfinite">isfinite() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isfinite.html#torch.Tensor.isfinite">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.isin.html#torch.isin">isin() (in module torch)</a>
</li>
      <li><a href="generated/torch.isinf.html#torch.isinf">isinf() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isinf.html#torch.Tensor.isinf">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.isinstance.html#torch.jit.isinstance">isinstance() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.isnan.html#torch.isnan">isnan() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isnan.html#torch.Tensor.isnan">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.isneginf.html#torch.isneginf">isneginf() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isneginf.html#torch.Tensor.isneginf">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.isposinf.html#torch.isposinf">isposinf() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isposinf.html#torch.Tensor.isposinf">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.isreal.html#torch.isreal">isreal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.isreal.html#torch.Tensor.isreal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.istft.html#torch.istft">istft() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.istft.html#torch.Tensor.istft">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.item.html#torch.Tensor.item">item() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.items">items() (torch.nn.ModuleDict method)</a>

      <ul>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.items">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.itemsize.html#torch.Tensor.itemsize">itemsize (torch.Tensor attribute)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.iter">iter() (torch.fx.Tracer method)</a>
</li>
      <li><a href="data.html#torch.utils.data.IterableDataset">IterableDataset (class in torch.utils.data)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="J">J</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.func.jacfwd.html#torch.func.jacfwd">jacfwd() (in module torch.func)</a>
</li>
      <li><a href="generated/torch.autograd.functional.jacobian.html#torch.autograd.functional.jacobian">jacobian() (in module torch.autograd.functional)</a>
</li>
      <li><a href="generated/torch.func.jacrev.html#torch.func.jacrev">jacrev() (in module torch.func)</a>
</li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType">JitScalarType (class in torch.onnx)</a>
</li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Join">Join (class in torch.distributed.algorithms)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.join">join (torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout property)</a>
</li>
      <li><a href="multiprocessing.html#torch.multiprocessing.SpawnContext.join">join() (torch.multiprocessing.SpawnContext method)</a>

      <ul>
        <li><a href="generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.join">(torch.nn.parallel.DistributedDataParallel method)</a>
</li>
      </ul></li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Joinable.join_device">join_device (torch.distributed.algorithms.Joinable property)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Joinable.join_hook">join_hook() (torch.distributed.algorithms.Joinable method)</a>

      <ul>
        <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.join_hook">(torch.distributed.optim.ZeroRedundancyOptimizer method)</a>
</li>
        <li><a href="generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.join_hook">(torch.nn.parallel.DistributedDataParallel method)</a>
</li>
      </ul></li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Joinable.join_process_group">join_process_group (torch.distributed.algorithms.Joinable property)</a>
</li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Joinable">Joinable (class in torch.distributed.algorithms)</a>
</li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.JoinHook">JoinHook (class in torch.distributed.algorithms)</a>
</li>
      <li><a href="generated/torch.autograd.functional.jvp.html#torch.autograd.functional.jvp">jvp() (in module torch.autograd.functional)</a>

      <ul>
        <li><a href="generated/torch.func.jvp.html#torch.func.jvp">(in module torch.func)</a>
</li>
        <li><a href="generated/torch.autograd.Function.jvp.html#torch.autograd.Function.jvp">(torch.autograd.Function static method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="K">K</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="nn.init.html#torch.nn.init.kaiming_normal_">kaiming_normal_() (in module torch.nn.init)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.kaiming_uniform_">kaiming_uniform_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.signal.windows.kaiser.html#torch.signal.windows.kaiser">kaiser() (in module torch.signal.windows)</a>
</li>
      <li><a href="generated/torch.kaiser_window.html#torch.kaiser_window">kaiser_window() (in module torch)</a>
</li>
      <li><a href="generated/torch.autograd.profiler.profile.key_averages.html#torch.autograd.profiler.profile.key_averages">key_averages() (torch.autograd.profiler.profile method)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler._KinetoProfile.key_averages">(torch.profiler._KinetoProfile method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Tracer.keys">keys() (torch.fx.Tracer method)</a>

      <ul>
        <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.keys">(torch.nn.ModuleDict method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.keys">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.nn.functional.kl_div.html#torch.nn.functional.kl_div">kl_div() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.kl.kl_divergence">kl_divergence() (in module torch.distributions.kl)</a>
</li>
      <li><a href="generated/torch.nn.KLDivLoss.html#torch.nn.KLDivLoss">KLDivLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.kron.html#torch.kron">kron() (in module torch)</a>
</li>
      <li><a href="generated/torch.kthvalue.html#torch.kthvalue">kthvalue() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.kthvalue.html#torch.Tensor.kthvalue">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy">Kumaraswamy (class in torch.distributions.kumaraswamy)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.kwargs">kwargs (torch.fx.Node property)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="L">L</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.nn.functional.l1_loss.html#torch.nn.functional.l1_loss">l1_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.l1_unstructured.html#torch.nn.utils.prune.l1_unstructured">l1_unstructured() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.nn.L1Loss.html#torch.nn.L1Loss">L1Loss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured">L1Unstructured (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR">LambdaLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="distributions.html#torch.distributions.laplace.Laplace">Laplace (class in torch.distributions.laplace)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.last_call">last_call (torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout property)</a>
</li>
      <li><a href="generated/torch.nn.functional.layer_norm.html#torch.nn.functional.layer_norm">layer_norm() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.LayerNorm.html#torch.ao.nn.quantized.LayerNorm">LayerNorm (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="tensor_attributes.html#torch.layout">layout (class in torch)</a>
</li>
      <li><a href="generated/torch.nn.LazyBatchNorm1d.html#torch.nn.LazyBatchNorm1d">LazyBatchNorm1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyBatchNorm2d.html#torch.nn.LazyBatchNorm2d">LazyBatchNorm2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyBatchNorm3d.html#torch.nn.LazyBatchNorm3d">LazyBatchNorm3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConv1d.html#torch.nn.LazyConv1d">LazyConv1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConv2d.html#torch.nn.LazyConv2d">LazyConv2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConv3d.html#torch.nn.LazyConv3d">LazyConv3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConvTranspose1d.html#torch.nn.LazyConvTranspose1d">LazyConvTranspose1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConvTranspose2d.html#torch.nn.LazyConvTranspose2d">LazyConvTranspose2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyConvTranspose3d.html#torch.nn.LazyConvTranspose3d">LazyConvTranspose3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyInstanceNorm1d.html#torch.nn.LazyInstanceNorm1d">LazyInstanceNorm1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyInstanceNorm2d.html#torch.nn.LazyInstanceNorm2d">LazyInstanceNorm2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyInstanceNorm3d.html#torch.nn.LazyInstanceNorm3d">LazyInstanceNorm3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LazyLinear.html#torch.nn.LazyLinear">LazyLinear (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.modules.lazy.LazyModuleMixin.html#torch.nn.modules.lazy.LazyModuleMixin">LazyModuleMixin (class in torch.nn.modules.lazy)</a>
</li>
      <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS">LBFGS (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.lcm.html#torch.lcm">lcm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.lcm.html#torch.Tensor.lcm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.lcm_.html#torch.Tensor.lcm_">lcm_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ldexp.html#torch.ldexp">ldexp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ldexp.html#torch.Tensor.ldexp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.ldexp_.html#torch.Tensor.ldexp_">ldexp_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.linalg.ldl_factor.html#torch.linalg.ldl_factor">ldl_factor() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.ldl_factor_ex.html#torch.linalg.ldl_factor_ex">ldl_factor_ex() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.ldl_solve.html#torch.linalg.ldl_solve">ldl_solve() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.le.html#torch.le">le() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.le.html#torch.Tensor.le">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.le_.html#torch.Tensor.le_">le_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.leaky_relu.html#torch.ao.nn.quantized.functional.leaky_relu">leaky_relu (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.leaky_relu.html#torch.nn.functional.leaky_relu">leaky_relu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.leaky_relu_.html#torch.nn.functional.leaky_relu_">leaky_relu_() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.LeakyReLU.html#torch.ao.nn.quantized.LeakyReLU">LeakyReLU (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.LeakyReLU.html#torch.nn.LeakyReLU">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.lerp.html#torch.lerp">lerp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.lerp.html#torch.Tensor.lerp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.lerp_.html#torch.Tensor.lerp_">lerp_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.less.html#torch.less">less() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.less.html#torch.Tensor.less">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.less_.html#torch.Tensor.less_">less_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.less_equal.html#torch.less_equal">less_equal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.less_equal.html#torch.Tensor.less_equal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.less_equal_.html#torch.Tensor.less_equal_">less_equal_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.less_than">less_than (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.lgamma.html#torch.lgamma">lgamma() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.lgamma.html#torch.Tensor.lgamma">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.lgamma_.html#torch.Tensor.lgamma_">lgamma_() (torch.Tensor method)</a>
</li>
      <li><a href="library.html#torch.library.Library">Library (class in torch.library)</a>
</li>
      <li><a href="generated/torch.ao.nn.qat.Linear.html#torch.ao.nn.qat.Linear">Linear (class in torch.ao.nn.qat)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.qat.dynamic.Linear.html#torch.ao.nn.qat.dynamic.Linear">(class in torch.ao.nn.qat.dynamic)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.Linear.html#torch.ao.nn.quantized.Linear">(class in torch.ao.nn.quantized)</a>
</li>
        <li><a href="generated/torch.ao.nn.quantized.dynamic.Linear.html#torch.ao.nn.quantized.dynamic.Linear">(class in torch.ao.nn.quantized.dynamic)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.functional.linear.html#torch.ao.nn.quantized.functional.linear">linear (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Linear.html#torch.nn.Linear">Linear (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.linear.html#torch.nn.functional.linear">linear() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.func.linearize.html#torch.func.linearize">linearize() (in module torch.func)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.LinearLR.html#torch.optim.lr_scheduler.LinearLR">LinearLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.ao.nn.intrinsic.LinearReLU.html#torch.ao.nn.intrinsic.LinearReLU">LinearReLU (class in torch.ao.nn.intrinsic)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.intrinsic.qat.LinearReLU.html#torch.ao.nn.intrinsic.qat.LinearReLU">(class in torch.ao.nn.intrinsic.qat)</a>
</li>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.LinearReLU.html#torch.ao.nn.intrinsic.quantized.LinearReLU">(class in torch.ao.nn.intrinsic.quantized)</a>
</li>
        <li><a href="generated/torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU.html#torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU">(class in torch.ao.nn.intrinsic.quantized.dynamic)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linspace.html#torch.linspace">linspace() (in module torch)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.lint">lint() (torch.fx.Graph method)</a>
</li>
      <li><a href="hub.html#torch.hub.list">list() (in module torch.hub)</a>
</li>
      <li><a href="generated/torch.compiler.list_backends.html#torch.compiler.list_backends">list_backends() (in module torch.compiler)</a>
</li>
      <li><a href="generated/torch.cuda.list_gpu_processes.html#torch.cuda.list_gpu_processes">list_gpu_processes() (in module torch.cuda)</a>
</li>
      <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky">LKJCholesky (class in torch.distributions.lkj_cholesky)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.ln_structured.html#torch.nn.utils.prune.ln_structured">ln_structured() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured">LnStructured (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.load.html#torch.load">load() (in module torch)</a>

      <ul>
        <li><a href="hub.html#torch.hub.load">(in module torch.hub)</a>
</li>
        <li><a href="generated/torch.jit.load.html#torch.jit.load">(in module torch.jit)</a>
</li>
        <li><a href="cpp_extension.html#torch.utils.cpp_extension.load">(in module torch.utils.cpp_extension)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.PackageImporter.load_binary">load_binary() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.load_bytes">load_bytes() (torch.distributed.checkpoint.LoadPlanner method)</a>
</li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.load_inline">load_inline() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="generated/torch.autograd.profiler.load_nvprof.html#torch.autograd.profiler.load_nvprof">load_nvprof() (in module torch.autograd.profiler)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.load_observer_state_dict.html#torch.ao.quantization.observer.load_observer_state_dict">load_observer_state_dict (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.load_pickle">load_pickle() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.load_state_dict">load_state_dict() (in module torch.distributed.checkpoint)</a>

      <ul>
        <li><a href="amp.html#torch.cuda.amp.GradScaler.load_state_dict">(torch.cuda.amp.GradScaler method)</a>
</li>
        <li><a href="distributed.optim.html#torch.distributed.optim.PostLocalSGDOptimizer.load_state_dict">(torch.distributed.optim.PostLocalSGDOptimizer method)</a>
</li>
        <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.load_state_dict">(torch.distributed.optim.ZeroRedundancyOptimizer method)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.load_state_dict">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.load_state_dict">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.load_state_dict">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.load_state_dict">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.load_state_dict">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.load_state_dict">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.load_state_dict">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.load_state_dict">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.load_state_dict">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ChainedScheduler.html#torch.optim.lr_scheduler.ChainedScheduler.load_state_dict">(torch.optim.lr_scheduler.ChainedScheduler method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ConstantLR.html#torch.optim.lr_scheduler.ConstantLR.load_state_dict">(torch.optim.lr_scheduler.ConstantLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR.load_state_dict">(torch.optim.lr_scheduler.CosineAnnealingLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.load_state_dict">(torch.optim.lr_scheduler.CosineAnnealingWarmRestarts method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR.load_state_dict">(torch.optim.lr_scheduler.ExponentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR.load_state_dict">(torch.optim.lr_scheduler.LambdaLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LinearLR.html#torch.optim.lr_scheduler.LinearLR.load_state_dict">(torch.optim.lr_scheduler.LinearLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict">(torch.optim.lr_scheduler.MultiplicativeLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR.load_state_dict">(torch.optim.lr_scheduler.MultiStepLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR.load_state_dict">(torch.optim.lr_scheduler.OneCycleLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.PolynomialLR.html#torch.optim.lr_scheduler.PolynomialLR.load_state_dict">(torch.optim.lr_scheduler.PolynomialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.SequentialLR.html#torch.optim.lr_scheduler.SequentialLR.load_state_dict">(torch.optim.lr_scheduler.SequentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR.load_state_dict">(torch.optim.lr_scheduler.StepLR method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.load_state_dict">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.Optimizer.load_state_dict.html#torch.optim.Optimizer.load_state_dict">(torch.optim.Optimizer method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.load_state_dict">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.load_state_dict">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.load_state_dict">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.load_state_dict">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.load_state_dict">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="hub.html#torch.hub.load_state_dict_from_url">load_state_dict_from_url() (in module torch.hub)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.load_text">load_text() (torch.package.PackageImporter method)</a>
</li>
      <li><a href="model_zoo.html#torch.utils.model_zoo.load_url">load_url() (in module torch.utils.model_zoo)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlan">LoadPlan (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner">LoadPlanner (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="generated/torch.lobpcg.html#torch.lobpcg">lobpcg() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.loc">loc (torch.distributions.log_normal.LogNormal property)</a>
</li>
      <li><a href="generated/torch.nn.functional.local_response_norm.html#torch.nn.functional.local_response_norm">local_response_norm() (in module torch.nn.functional)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent">LocalElasticAgent (class in torch.distributed.elastic.agent.server.local_elastic_agent)</a>
</li>
      <li><a href="generated/torch.nn.LocalResponseNorm.html#torch.nn.LocalResponseNorm">LocalResponseNorm (class in torch.nn)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.LocalTimerClient">LocalTimerClient (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.LocalTimerServer">LocalTimerServer (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="generated/torch.log.html#torch.log">log() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.log.html#torch.Tensor.log">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.log10.html#torch.log10">log10() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.log10.html#torch.Tensor.log10">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.log10_.html#torch.Tensor.log10_">log10_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.log1p.html#torch.log1p">log1p() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.log1p">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.log1p.html#torch.Tensor.log1p">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.log1p_.html#torch.Tensor.log1p_">log1p_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.log2.html#torch.log2">log2() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.log2.html#torch.Tensor.log2">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.log2_.html#torch.Tensor.log2_">log2_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.log_.html#torch.Tensor.log_">log_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform.log_abs_det_jacobian">log_abs_det_jacobian() (torch.distributions.transforms.Transform method)</a>
</li>
      <li><a href="monitor.html#torch.monitor.log_event">log_event() (in module torch.monitor)</a>
</li>
      <li><a href="special.html#torch.special.log_ndtr">log_ndtr() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.Tensor.log_normal_.html#torch.Tensor.log_normal_">log_normal_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.log_prob">log_prob() (torch.distributions.bernoulli.Bernoulli method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.log_prob">(torch.distributions.beta.Beta method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.log_prob">(torch.distributions.binomial.Binomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.log_prob">(torch.distributions.categorical.Categorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.log_prob">(torch.distributions.cauchy.Cauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.log_prob">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.log_prob">(torch.distributions.dirichlet.Dirichlet method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.log_prob">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.log_prob">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.log_prob">(torch.distributions.fishersnedecor.FisherSnedecor method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.log_prob">(torch.distributions.gamma.Gamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.log_prob">(torch.distributions.geometric.Geometric method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.log_prob">(torch.distributions.gumbel.Gumbel method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.log_prob">(torch.distributions.half_cauchy.HalfCauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.log_prob">(torch.distributions.half_normal.HalfNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.log_prob">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.log_prob">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky.log_prob">(torch.distributions.lkj_cholesky.LKJCholesky method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.log_prob">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.log_prob">(torch.distributions.mixture_same_family.MixtureSameFamily method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.log_prob">(torch.distributions.multinomial.Multinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.log_prob">(torch.distributions.multivariate_normal.MultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.log_prob">(torch.distributions.negative_binomial.NegativeBinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.log_prob">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.log_prob">(torch.distributions.one_hot_categorical.OneHotCategorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.log_prob">(torch.distributions.poisson.Poisson method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.log_prob">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.log_prob">(torch.distributions.studentT.StudentT method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.log_prob">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.log_prob">(torch.distributions.uniform.Uniform method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.log_prob">(torch.distributions.von_mises.VonMises method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.log_prob">(torch.distributions.wishart.Wishart method)</a>
</li>
        <li><a href="generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html#torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob">(torch.nn.AdaptiveLogSoftmaxWithLoss method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.log_softmax.html#torch.nn.functional.log_softmax">log_softmax() (in module torch.nn.functional)</a>

      <ul>
        <li><a href="generated/torch.sparse.log_softmax.html#torch.sparse.log_softmax">(in module torch.sparse)</a>
</li>
        <li><a href="special.html#torch.special.log_softmax">(in module torch.special)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.logaddexp.html#torch.logaddexp">logaddexp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logaddexp.html#torch.Tensor.logaddexp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.logaddexp2.html#torch.logaddexp2">logaddexp2() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logaddexp2.html#torch.Tensor.logaddexp2">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.logcumsumexp.html#torch.logcumsumexp">logcumsumexp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logcumsumexp.html#torch.Tensor.logcumsumexp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.logdet.html#torch.logdet">logdet() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logdet.html#torch.Tensor.logdet">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Logger">Logger (class in torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.loggers_set_enabled">loggers_set_enabled() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.loggers_set_save_activations">loggers_set_save_activations() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="generated/torch.logical_and.html#torch.logical_and">logical_and() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logical_and.html#torch.Tensor.logical_and">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.logical_and_.html#torch.Tensor.logical_and_">logical_and_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.logical_not.html#torch.logical_not">logical_not() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logical_not.html#torch.Tensor.logical_not">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.logical_not_.html#torch.Tensor.logical_not_">logical_not_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.logical_or.html#torch.logical_or">logical_or() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logical_or.html#torch.Tensor.logical_or">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.logical_or_.html#torch.Tensor.logical_or_">logical_or_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.logical_xor.html#torch.logical_xor">logical_xor() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.logical_xor.html#torch.Tensor.logical_xor">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.logical_xor_.html#torch.Tensor.logical_xor_">logical_xor_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.logit.html#torch.logit">logit() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.logit">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.logit.html#torch.Tensor.logit">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.logit_.html#torch.Tensor.logit_">logit_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli">LogitRelaxedBernoulli (class in torch.distributions.relaxed_bernoulli)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.logits">logits (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.logits">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.logits">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.logits">(torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.logits">(torch.distributions.geometric.Geometric property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.logits">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.logits">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.logits">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.logits">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical property)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.log_normal.LogNormal">LogNormal (class in torch.distributions.log_normal)</a>
</li>
      <li><a href="generated/torch.nn.LogSigmoid.html#torch.nn.LogSigmoid">LogSigmoid (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.logsigmoid.html#torch.nn.functional.logsigmoid">logsigmoid() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax">LogSoftmax (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.logspace.html#torch.logspace">logspace() (in module torch)</a>
</li>
      <li><a href="generated/torch.logsumexp.html#torch.logsumexp">logsumexp() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.logsumexp">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.logsumexp.html#torch.Tensor.logsumexp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.long.html#torch.Tensor.long">long() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.long">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.long">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.LongStorage">LongStorage (class in torch)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultSavePlanner.lookup_object">lookup_object() (torch.distributed.checkpoint.DefaultSavePlanner method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultLoadPlanner.lookup_tensor">lookup_tensor() (torch.distributed.checkpoint.DefaultLoadPlanner method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.LowerCholeskyTransform">LowerCholeskyTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal">LowRankMultivariateNormal (class in torch.distributions.lowrank_multivariate_normal)</a>
</li>
      <li><a href="generated/torch.nn.functional.lp_pool1d.html#torch.nn.functional.lp_pool1d">lp_pool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.lp_pool2d.html#torch.nn.functional.lp_pool2d">lp_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.LPPool1d.html#torch.nn.LPPool1d">LPPool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.LPPool2d.html#torch.nn.LPPool2d">LPPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantizable.LSTM.html#torch.ao.nn.quantizable.LSTM">LSTM (class in torch.ao.nn.quantizable)</a>

      <ul>
        <li><a href="generated/torch.ao.nn.quantized.dynamic.LSTM.html#torch.ao.nn.quantized.dynamic.LSTM">(class in torch.ao.nn.quantized.dynamic)</a>
</li>
        <li><a href="generated/torch.nn.LSTM.html#torch.nn.LSTM">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.dynamic.LSTMCell.html#torch.ao.nn.quantized.dynamic.LSTMCell">LSTMCell (class in torch.ao.nn.quantized.dynamic)</a>

      <ul>
        <li><a href="generated/torch.nn.LSTMCell.html#torch.nn.LSTMCell">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.lstsq.html#torch.linalg.lstsq">lstsq() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.lt.html#torch.lt">lt() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.lt.html#torch.Tensor.lt">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.lt_.html#torch.Tensor.lt_">lt_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.lu.html#torch.lu">lu() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.lu.html#torch.linalg.lu">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.lu.html#torch.Tensor.lu">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.lu_factor.html#torch.linalg.lu_factor">lu_factor() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.lu_factor_ex.html#torch.linalg.lu_factor_ex">lu_factor_ex() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.lu_solve.html#torch.lu_solve">lu_solve() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.lu_solve.html#torch.linalg.lu_solve">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.lu_solve.html#torch.Tensor.lu_solve">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.lu_unpack.html#torch.lu_unpack">lu_unpack() (in module torch)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="M">M</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.JoinHook.main_hook">main_hook() (torch.distributed.algorithms.JoinHook method)</a>
</li>
      <li><a href="generated/torch.autograd.forward_ad.make_dual.html#torch.autograd.forward_ad.make_dual">make_dual() (in module torch.autograd.forward_ad)</a>
</li>
      <li><a href="generated/torch.cuda.make_graphed_callables.html#torch.cuda.make_graphed_callables">make_graphed_callables() (in module torch.cuda)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.make_input_replicate_1d">make_input_replicate_1d() (in module torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.make_input_reshard_replicate">make_input_reshard_replicate() (in module torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.make_input_shard_1d">make_input_shard_1d() (in module torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.make_input_shard_1d_last_dim">make_input_shard_1d_last_dim() (in module torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.make_output_replicate_1d">make_output_replicate_1d() (in module torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.make_output_reshard_tensor">make_output_reshard_tensor() (in module torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.make_output_shard_1d">make_output_shard_1d() (in module torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.make_output_tensor">make_output_tensor() (in module torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="testing.html#torch.testing.make_tensor">make_tensor() (in module torch.testing)</a>
</li>
      <li><a href="generated/torch.manual_seed.html#torch.manual_seed">manual_seed() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.manual_seed.html#torch.cuda.manual_seed">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.mps.manual_seed.html#torch.mps.manual_seed">(in module torch.mps)</a>
</li>
        <li><a href="random.html#torch.random.manual_seed">(in module torch.random)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.manual_seed">(torch.Generator method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.manual_seed_all.html#torch.cuda.manual_seed_all">manual_seed_all() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.Tensor.map_.html#torch.Tensor.map_">map_() (torch.Tensor method)</a>
</li>
      <li><a href="fx.html#torch.fx.Interpreter.map_nodes_to_values">map_nodes_to_values() (torch.fx.Interpreter method)</a>
</li>
      <li><a href="generated/torch.nn.functional.margin_ranking_loss.html#torch.nn.functional.margin_ranking_loss">margin_ranking_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.MarginRankingLoss.html#torch.nn.MarginRankingLoss">MarginRankingLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.cuda.nvtx.mark.html#torch.cuda.nvtx.mark">mark() (in module torch.cuda.nvtx)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler.itt.mark">(in module torch.profiler.itt)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.function.FunctionCtx.mark_dirty.html#torch.autograd.function.FunctionCtx.mark_dirty">mark_dirty() (torch.autograd.function.FunctionCtx method)</a>
</li>
      <li><a href="generated/torch.autograd.function.FunctionCtx.mark_non_differentiable.html#torch.autograd.function.FunctionCtx.mark_non_differentiable">mark_non_differentiable() (torch.autograd.function.FunctionCtx method)</a>
</li>
      <li><a href="generated/torch.Tensor.masked_fill.html#torch.Tensor.masked_fill">masked_fill() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.masked_fill_.html#torch.Tensor.masked_fill_">masked_fill_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.masked_scatter.html#torch.Tensor.masked_scatter">masked_scatter() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.masked_scatter_.html#torch.Tensor.masked_scatter_">masked_scatter_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.masked_select.html#torch.masked_select">masked_select() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.masked_select.html#torch.Tensor.masked_select">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="backends.html#torch.backends.cuda.math_sdp_enabled">math_sdp_enabled() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.matmul.html#torch.matmul">matmul() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.matmul.html#torch.linalg.matmul">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.matmul.html#torch.Tensor.matmul">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.matrix_exp.html#torch.matrix_exp">matrix_exp() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.matrix_exp.html#torch.linalg.matrix_exp">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.matrix_exp.html#torch.Tensor.matrix_exp">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.matrix_norm.html#torch.linalg.matrix_norm">matrix_norm() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.matrix_power.html#torch.matrix_power">matrix_power() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.matrix_power.html#torch.linalg.matrix_power">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.matrix_power.html#torch.Tensor.matrix_power">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.matrix_rank.html#torch.linalg.matrix_rank">matrix_rank() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.max.html#torch.max">max() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.max.html#torch.Tensor.max">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.max_memory_allocated.html#torch.cuda.max_memory_allocated">max_memory_allocated() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.max_memory_cached.html#torch.cuda.max_memory_cached">max_memory_cached() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.max_memory_reserved.html#torch.cuda.max_memory_reserved">max_memory_reserved() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.max_pool1d.html#torch.ao.nn.quantized.functional.max_pool1d">max_pool1d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_pool1d.html#torch.nn.functional.max_pool1d">max_pool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.max_pool2d.html#torch.ao.nn.quantized.functional.max_pool2d">max_pool2d (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_pool2d.html#torch.nn.functional.max_pool2d">max_pool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_pool3d.html#torch.nn.functional.max_pool3d">max_pool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.cufft_plan_cache.max_size">max_size (in module torch.backends.cuda.cufft_plan_cache)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_unpool1d.html#torch.nn.functional.max_unpool1d">max_unpool1d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_unpool2d.html#torch.nn.functional.max_unpool2d">max_unpool2d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.max_unpool3d.html#torch.nn.functional.max_unpool3d">max_unpool3d() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.maximum.html#torch.maximum">maximum() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.maximum.html#torch.Tensor.maximum">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.MaxPool1d.html#torch.nn.MaxPool1d">MaxPool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d">MaxPool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MaxPool3d.html#torch.nn.MaxPool3d">MaxPool3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MaxUnpool1d.html#torch.nn.MaxUnpool1d">MaxUnpool1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MaxUnpool2d.html#torch.nn.MaxUnpool2d">MaxUnpool2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MaxUnpool3d.html#torch.nn.MaxUnpool3d">MaxUnpool3d (class in torch.nn)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.mean">mean (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.mean">(torch.distributions.beta.Beta property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.mean">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.mean">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.mean">(torch.distributions.cauchy.Cauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.mean">(torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.mean">(torch.distributions.dirichlet.Dirichlet property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.mean">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.mean">(torch.distributions.exponential.Exponential property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.mean">(torch.distributions.fishersnedecor.FisherSnedecor property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.mean">(torch.distributions.gamma.Gamma property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.mean">(torch.distributions.geometric.Geometric property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.mean">(torch.distributions.gumbel.Gumbel property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.mean">(torch.distributions.half_cauchy.HalfCauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.mean">(torch.distributions.half_normal.HalfNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.mean">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.mean">(torch.distributions.kumaraswamy.Kumaraswamy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.mean">(torch.distributions.laplace.Laplace property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.mean">(torch.distributions.log_normal.LogNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mean">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.mean">(torch.distributions.mixture_same_family.MixtureSameFamily property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.mean">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.mean">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.mean">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.mean">(torch.distributions.normal.Normal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.mean">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.mean">(torch.distributions.pareto.Pareto property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.mean">(torch.distributions.poisson.Poisson property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.mean">(torch.distributions.studentT.StudentT property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.mean">(torch.distributions.uniform.Uniform property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.mean">(torch.distributions.von_mises.VonMises property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.mean">(torch.distributions.weibull.Weibull property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.mean">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.mean.html#torch.mean">mean() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.mean.html#torch.Tensor.mean">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Measurement">Measurement (class in torch.utils.benchmark)</a>
</li>
      <li><a href="generated/torch.median.html#torch.median">median() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.median.html#torch.Tensor.median">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="backends.html#torch.backends.cuda.mem_efficient_sdp_enabled">mem_efficient_sdp_enabled() (in module torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.mem_get_info.html#torch.cuda.mem_get_info">mem_get_info() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_allocated.html#torch.cuda.memory_allocated">memory_allocated() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_cached.html#torch.cuda.memory_cached">memory_cached() (in module torch.cuda)</a>
</li>
      <li><a href="tensor_attributes.html#torch.memory_format">memory_format (class in torch)</a>
</li>
      <li><a href="generated/torch.cuda.memory_reserved.html#torch.cuda.memory_reserved">memory_reserved() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_snapshot.html#torch.cuda.memory_snapshot">memory_snapshot() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_stats.html#torch.cuda.memory_stats">memory_stats() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_summary.html#torch.cuda.memory_summary">memory_summary() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.memory_usage.html#torch.cuda.memory_usage">memory_usage() (in module torch.cuda)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Measurement.merge">merge() (torch.utils.benchmark.Measurement static method)</a>
</li>
      <li><a href="generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention.merge_masks">merge_masks() (torch.nn.MultiheadAttention method)</a>
</li>
      <li><a href="generated/torch.meshgrid.html#torch.meshgrid">meshgrid() (in module torch)</a>
</li>
      <li><a href="generated/torch.autograd.graph.Node.metadata.html#torch.autograd.graph.Node.metadata">metadata() (torch.autograd.graph.Node method)</a>
</li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.api.MetricHandler">MetricHandler (class in torch.distributed.elastic.metrics.api)</a>
</li>
      <li><a href="tensors.html#torch.Tensor.mH">mH (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.min.html#torch.min">min() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.min.html#torch.Tensor.min">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.minimum.html#torch.minimum">minimum() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.minimum.html#torch.Tensor.minimum">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.observer.MinMaxObserver.html#torch.ao.quantization.observer.MinMaxObserver">MinMaxObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.nn.Mish.html#torch.nn.Mish">Mish (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.mish.html#torch.nn.functional.mish">mish() (in module torch.nn.functional)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.MixedPrecision">MixedPrecision (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.mixture_distribution">mixture_distribution (torch.distributions.mixture_same_family.MixtureSameFamily property)</a>
</li>
      <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily">MixtureSameFamily (class in torch.distributions.mixture_same_family)</a>
</li>
      <li><a href="generated/torch.mm.html#torch.mm">mm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.sparse.mm.html#torch.sparse.mm">(in module torch.sparse)</a>
</li>
        <li><a href="generated/torch.Tensor.mm.html#torch.Tensor.mm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.PackageExporter.mock">mock() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.mocked_modules">mocked_modules() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.mode">mode (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.mode">(torch.distributions.beta.Beta property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.mode">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.mode">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.mode">(torch.distributions.cauchy.Cauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.mode">(torch.distributions.dirichlet.Dirichlet property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.mode">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.mode">(torch.distributions.exponential.Exponential property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.mode">(torch.distributions.fishersnedecor.FisherSnedecor property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.mode">(torch.distributions.gamma.Gamma property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.mode">(torch.distributions.geometric.Geometric property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.mode">(torch.distributions.gumbel.Gumbel property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.mode">(torch.distributions.half_cauchy.HalfCauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.mode">(torch.distributions.half_normal.HalfNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.mode">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.mode">(torch.distributions.kumaraswamy.Kumaraswamy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.mode">(torch.distributions.laplace.Laplace property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.mode">(torch.distributions.log_normal.LogNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mode">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.mode">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.mode">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.mode">(torch.distributions.normal.Normal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.mode">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.mode">(torch.distributions.pareto.Pareto property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.mode">(torch.distributions.poisson.Poisson property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.mode">(torch.distributions.studentT.StudentT property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.mode">(torch.distributions.uniform.Uniform property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.mode">(torch.distributions.von_mises.VonMises property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.mode">(torch.distributions.weibull.Weibull property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.mode">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.mode.html#torch.mode">mode() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.mode.html#torch.Tensor.mode">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.ExportOutput.html#torch.onnx.ExportOutput.model_proto">model_proto (torch.onnx.ExportOutput property)</a>
</li>
      <li>
    module

      <ul>
        <li><a href="torch.html#module-torch">torch</a>
</li>
        <li><a href="config_mod.html#module-torch.__config__">torch.__config__</a>
</li>
        <li><a href="logging.html#module-torch._logging">torch._logging</a>
</li>
        <li><a href="amp.html#module-torch.amp">torch.amp</a>
</li>
        <li><a href="quantization.html#module-torch.ao">torch.ao</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn">torch.ao.nn</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic">torch.ao.nn.intrinsic</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.modules">torch.ao.nn.intrinsic.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.qat">torch.ao.nn.intrinsic.qat</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.qat.modules">torch.ao.nn.intrinsic.qat.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized">torch.ao.nn.intrinsic.quantized</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.dynamic">torch.ao.nn.intrinsic.quantized.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.dynamic.modules">torch.ao.nn.intrinsic.quantized.dynamic.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.modules">torch.ao.nn.intrinsic.quantized.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat">torch.ao.nn.qat</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.dynamic">torch.ao.nn.qat.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.dynamic.modules">torch.ao.nn.qat.dynamic.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.modules">torch.ao.nn.qat.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable">torch.ao.nn.quantizable</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable.modules">torch.ao.nn.quantizable.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized">torch.ao.nn.quantized</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.dynamic">torch.ao.nn.quantized.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.dynamic.modules">torch.ao.nn.quantized.dynamic.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.functional">torch.ao.nn.quantized.functional</a>
</li>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.modules">torch.ao.nn.quantized.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference">torch.ao.nn.quantized.reference</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules">torch.ao.nn.quantized.reference.modules</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.sparse">torch.ao.nn.sparse</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized">torch.ao.nn.sparse.quantized</a>
</li>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized.dynamic">torch.ao.nn.sparse.quantized.dynamic</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns">torch.ao.ns</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite.html#module-torch.ao.ns._numeric_suite">torch.ao.ns._numeric_suite</a>
</li>
        <li><a href="torch.ao.ns._numeric_suite_fx.html#module-torch.ao.ns._numeric_suite_fx">torch.ao.ns._numeric_suite_fx</a>
</li>
        <li><a href="quantization.html#module-torch.ao.ns.fx">torch.ao.ns.fx</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning">torch.ao.pruning</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning.scheduler">torch.ao.pruning.scheduler</a>
</li>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier">torch.ao.pruning.sparsifier</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization">torch.ao.quantization</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config">torch.ao.quantization.backend_config</a>
</li>
        <li><a href="quantization.html#module-torch.ao.quantization.fx">torch.ao.quantization.fx</a>
</li>
        <li><a href="autograd.html#module-torch.autograd">torch.autograd</a>, <a href="torch.html#module-torch.autograd">[1]</a>
</li>
        <li><a href="backends.html#module-torch.backends">torch.backends</a>
</li>
        <li><a href="backends.html#module-torch.backends.cpu">torch.backends.cpu</a>
</li>
        <li><a href="backends.html#module-torch.backends.cuda">torch.backends.cuda</a>
</li>
        <li><a href="backends.html#module-torch.backends.cudnn">torch.backends.cudnn</a>
</li>
        <li><a href="backends.html#module-torch.backends.mkl">torch.backends.mkl</a>
</li>
        <li><a href="backends.html#module-torch.backends.mkldnn">torch.backends.mkldnn</a>
</li>
        <li><a href="backends.html#module-torch.backends.mps">torch.backends.mps</a>
</li>
        <li><a href="backends.html#module-torch.backends.openmp">torch.backends.openmp</a>
</li>
        <li><a href="backends.html#module-torch.backends.opt_einsum">torch.backends.opt_einsum</a>
</li>
        <li><a href="backends.html#module-torch.backends.quantized">torch.backends.quantized</a>
</li>
        <li><a href="backends.html#module-torch.backends.xeon">torch.backends.xeon</a>
</li>
        <li><a href="backends.html#module-torch.backends.xnnpack">torch.backends.xnnpack</a>
</li>
        <li><a href="compiler.html#module-torch.compiler">torch.compiler</a>
</li>
        <li><a href="torch.html#module-torch.contrib">torch.contrib</a>
</li>
        <li><a href="amp.html#module-torch.cpu">torch.cpu</a>
</li>
        <li><a href="amp.html#module-torch.cpu.amp">torch.cpu.amp</a>
</li>
        <li><a href="cuda.html#module-torch.cuda">torch.cuda</a>
</li>
        <li><a href="cuda._sanitizer.html#module-torch.cuda._sanitizer">torch.cuda._sanitizer</a>
</li>
        <li><a href="amp.html#module-torch.cuda.amp">torch.cuda.amp</a>
</li>
        <li><a href="distributed.html#module-torch.distributed">torch.distributed</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms">torch.distributed.algorithms</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks">torch.distributed.algorithms.ddp_comm_hooks</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.algorithms.model_averaging">torch.distributed.algorithms.model_averaging</a>
</li>
        <li><a href="rpc.html#module-torch.distributed.autograd">torch.distributed.autograd</a>
</li>
        <li><a href="distributed.checkpoint.html#module-torch.distributed.checkpoint">torch.distributed.checkpoint</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic">torch.distributed.elastic</a>
</li>
        <li><a href="elastic/agent.html#module-torch.distributed.elastic.agent">torch.distributed.elastic.agent</a>
</li>
        <li><a href="elastic/agent.html#module-torch.distributed.elastic.agent.server">torch.distributed.elastic.agent.server</a>
</li>
        <li><a href="elastic/events.html#module-torch.distributed.elastic.events">torch.distributed.elastic.events</a>
</li>
        <li><a href="elastic/metrics.html#module-torch.distributed.elastic.metrics">torch.distributed.elastic.metrics</a>
</li>
        <li><a href="elastic/multiprocessing.html#module-torch.distributed.elastic.multiprocessing">torch.distributed.elastic.multiprocessing</a>
</li>
        <li><a href="elastic/errors.html#module-torch.distributed.elastic.multiprocessing.errors">torch.distributed.elastic.multiprocessing.errors</a>
</li>
        <li><a href="elastic/rendezvous.html#module-torch.distributed.elastic.rendezvous">torch.distributed.elastic.rendezvous</a>
</li>
        <li><a href="elastic/rendezvous.html#module-torch.distributed.elastic.rendezvous.registry">torch.distributed.elastic.rendezvous.registry</a>
</li>
        <li><a href="elastic/timer.html#module-torch.distributed.elastic.timer">torch.distributed.elastic.timer</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils">torch.distributed.elastic.utils</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.data">torch.distributed.elastic.utils.data</a>
</li>
        <li><a href="fsdp.html#module-torch.distributed.fsdp">torch.distributed.fsdp</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.launch">torch.distributed.launch</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.launcher">torch.distributed.launcher</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn">torch.distributed.nn</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn.api">torch.distributed.nn.api</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn.jit">torch.distributed.nn.jit</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.nn.jit.templates">torch.distributed.nn.jit.templates</a>
</li>
        <li><a href="distributed.optim.html#module-torch.distributed.optim">torch.distributed.optim</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline">torch.distributed.pipeline</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync">torch.distributed.pipeline.sync</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip">torch.distributed.pipeline.sync.skip</a>
</li>
        <li><a href="rpc.html#module-torch.distributed.rpc">torch.distributed.rpc</a>
</li>
        <li><a href="elastic/run.html#module-torch.distributed.run">torch.distributed.run</a>
</li>
        <li><a href="distributed.html#module-torch.distributed.tensor">torch.distributed.tensor</a>
</li>
        <li><a href="distributed.tensor.parallel.html#module-torch.distributed.tensor.parallel">torch.distributed.tensor.parallel</a>
</li>
        <li><a href="distributions.html#module-torch.distributions">torch.distributions</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.constraint_registry">torch.distributions.constraint_registry</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.constraints">torch.distributions.constraints</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.kl">torch.distributions.kl</a>
</li>
        <li><a href="distributions.html#module-torch.distributions.transforms">torch.distributions.transforms</a>
</li>
        <li><a href="fft.html#module-torch.fft">torch.fft</a>
</li>
        <li><a href="func.api.html#module-torch.func">torch.func</a>
</li>
        <li><a href="futures.html#module-torch.futures">torch.futures</a>
</li>
        <li><a href="fx.html#module-torch.fx">torch.fx</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental">torch.fx.experimental</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types">torch.fx.experimental.migrate_gradual_types</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification">torch.fx.experimental.unification</a>
</li>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch">torch.fx.experimental.unification.multipledispatch</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes">torch.fx.passes</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.backends">torch.fx.passes.backends</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.dialect">torch.fx.passes.dialect</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.dialect.common">torch.fx.passes.dialect.common</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.infra">torch.fx.passes.infra</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.tests">torch.fx.passes.tests</a>
</li>
        <li><a href="fx.html#module-torch.fx.passes.utils">torch.fx.passes.utils</a>
</li>
        <li><a href="hub.html#module-torch.hub">torch.hub</a>
</li>
        <li><a href="jit.html#module-torch.jit">torch.jit</a>
</li>
        <li><a href="jit.html#module-torch.jit.mobile">torch.jit.mobile</a>
</li>
        <li><a href="jit_builtin_functions.html#module-torch.jit.supported_ops">torch.jit.supported_ops</a>
</li>
        <li><a href="jit_unsupported.html#module-torch.jit.unsupported_tensor_ops">torch.jit.unsupported_tensor_ops</a>
</li>
        <li><a href="linalg.html#module-torch.linalg">torch.linalg</a>
</li>
        <li><a href="masked.html#module-torch.masked">torch.masked</a>
</li>
        <li><a href="masked.html#module-torch.masked.maskedtensor">torch.masked.maskedtensor</a>
</li>
        <li><a href="monitor.html#module-torch.monitor">torch.monitor</a>
</li>
        <li><a href="mps.html#module-torch.mps">torch.mps</a>
</li>
        <li><a href="multiprocessing.html#module-torch.multiprocessing">torch.multiprocessing</a>
</li>
        <li><a href="nested.html#module-torch.nested">torch.nested</a>
</li>
        <li><a href="nn.html#module-torch.nn">torch.nn</a>
</li>
        <li><a href="nn.html#module-torch.nn.backends">torch.nn.backends</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic">torch.nn.intrinsic</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.modules">torch.nn.intrinsic.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.qat">torch.nn.intrinsic.qat</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.qat.modules">torch.nn.intrinsic.qat.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized">torch.nn.intrinsic.quantized</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.dynamic">torch.nn.intrinsic.quantized.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.dynamic.modules">torch.nn.intrinsic.quantized.dynamic.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.modules">torch.nn.intrinsic.quantized.modules</a>
</li>
        <li><a href="nn.html#module-torch.nn.modules">torch.nn.modules</a>
</li>
        <li><a href="nn.html#module-torch.nn.parallel">torch.nn.parallel</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.qat">torch.nn.qat</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.qat.dynamic">torch.nn.qat.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.qat.dynamic.modules">torch.nn.qat.dynamic.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.qat.modules">torch.nn.qat.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantizable">torch.nn.quantizable</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantizable.modules">torch.nn.quantizable.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantized">torch.nn.quantized</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantized.dynamic">torch.nn.quantized.dynamic</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantized.dynamic.modules">torch.nn.quantized.dynamic.modules</a>
</li>
        <li><a href="quantization-support.html#module-torch.nn.quantized.modules">torch.nn.quantized.modules</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils">torch.nn.utils</a>
</li>
        <li><a href="nn.html#module-torch.nn.utils.stateless">torch.nn.utils.stateless</a>
</li>
        <li><a href="onnx.html#module-torch.onnx">torch.onnx</a>
</li>
        <li><a href="onnx_diagnostics.html#module-torch.onnx._internal.diagnostics">torch.onnx._internal.diagnostics</a>
</li>
        <li><a href="optim.html#module-torch.optim">torch.optim</a>
</li>
        <li><a href="package.html#module-torch.package">torch.package</a>
</li>
        <li><a href="package.html#module-torch.package.analyze">torch.package.analyze</a>
</li>
        <li><a href="profiler.html#module-torch.profiler">torch.profiler</a>
</li>
        <li><a href="quantization-support.html#module-torch.quantization">torch.quantization</a>
</li>
        <li><a href="quantization-support.html#module-torch.quantization.fx">torch.quantization.fx</a>
</li>
        <li><a href="random.html#module-torch.random">torch.random</a>
</li>
        <li><a href="signal.html#module-torch.signal">torch.signal</a>
</li>
        <li><a href="signal.html#module-torch.signal.windows">torch.signal.windows</a>
</li>
        <li><a href="sparse.html#module-torch.sparse">torch.sparse</a>
</li>
        <li><a href="special.html#module-torch.special">torch.special</a>
</li>
        <li><a href="testing.html#module-torch.testing">torch.testing</a>
</li>
        <li><a href="torch.html#module-torch.utils">torch.utils</a>
</li>
        <li><a href="torch.html#module-torch.utils.backcompat">torch.utils.backcompat</a>
</li>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark">torch.utils.benchmark</a>
</li>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.examples">torch.utils.benchmark.examples</a>
</li>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.op_fuzzers">torch.utils.benchmark.op_fuzzers</a>
</li>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.utils">torch.utils.benchmark.utils</a>
</li>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.utils.valgrind_wrapper">torch.utils.benchmark.utils.valgrind_wrapper</a>
</li>
        <li><a href="bottleneck.html#module-torch.utils.bottleneck">torch.utils.bottleneck</a>
</li>
        <li><a href="data.html#module-torch.utils.data">torch.utils.data</a>
</li>
        <li><a href="data.html#module-torch.utils.data.datapipes">torch.utils.data.datapipes</a>
</li>
        <li><a href="data.html#module-torch.utils.data.datapipes.dataframe">torch.utils.data.datapipes.dataframe</a>
</li>
        <li><a href="data.html#module-torch.utils.data.datapipes.iter">torch.utils.data.datapipes.iter</a>
</li>
        <li><a href="data.html#module-torch.utils.data.datapipes.map">torch.utils.data.datapipes.map</a>
</li>
        <li><a href="data.html#module-torch.utils.data.datapipes.utils">torch.utils.data.datapipes.utils</a>
</li>
        <li><a href="torch.html#module-torch.utils.hipify">torch.utils.hipify</a>
</li>
        <li><a href="jit_utils.html#module-torch.utils.jit">torch.utils.jit</a>
</li>
        <li><a href="torch.html#module-torch.utils.model_dump">torch.utils.model_dump</a>
</li>
        <li><a href="model_zoo.html#module-torch.utils.model_zoo">torch.utils.model_zoo</a>
</li>
        <li><a href="tensorboard.html#module-torch.utils.tensorboard">torch.utils.tensorboard</a>
</li>
        <li><a href="torch.html#module-torch.utils.viz">torch.utils.viz</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.nn.Module.html#torch.nn.Module">Module (class in torch.nn)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.module">module (torch.distributed.fsdp.FullyShardedDataParallel property)</a>
</li>
      <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict">ModuleDict (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ModuleList.html#torch.nn.ModuleList">ModuleList (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.modules">modules() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.modules">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.monitored_barrier">monitored_barrier() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.moveaxis.html#torch.moveaxis">moveaxis() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.moveaxis.html#torch.Tensor.moveaxis">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.movedim.html#torch.movedim">movedim() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.movedim.html#torch.Tensor.movedim">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.observer.MovingAverageMinMaxObserver.html#torch.ao.quantization.observer.MovingAverageMinMaxObserver">MovingAverageMinMaxObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver.html#torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver">MovingAveragePerChannelMinMaxObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="storage.html#torch.UntypedStorage.mps">mps() (torch.UntypedStorage method)</a>
</li>
      <li><a href="generated/torch.nn.functional.mse_loss.html#torch.nn.functional.mse_loss">mse_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.MSELoss.html#torch.nn.MSELoss">MSELoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.msort.html#torch.msort">msort() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.msort.html#torch.Tensor.msort">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="tensors.html#torch.Tensor.mT">mT (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.mul.html#torch.mul">mul() (in module torch)</a>

      <ul>
        <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.mul">(torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
        <li><a href="generated/torch.Tensor.mul.html#torch.Tensor.mul">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.mul_.html#torch.Tensor.mul_">mul_() (torch.Tensor method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow.mul_scalar">mul_scalar() (torch.ao.ns._numeric_suite.Shadow method)</a>
</li>
      <li><a href="generated/torch.linalg.multi_dot.html#torch.linalg.multi_dot">multi_dot() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.nn.functional.multi_margin_loss.html#torch.nn.functional.multi_margin_loss">multi_margin_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="special.html#torch.special.multigammaln">multigammaln() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantizable.MultiheadAttention.html#torch.ao.nn.quantizable.MultiheadAttention">MultiheadAttention (class in torch.ao.nn.quantizable)</a>

      <ul>
        <li><a href="generated/torch.nn.MultiheadAttention.html#torch.nn.MultiheadAttention">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.multilabel_margin_loss.html#torch.nn.functional.multilabel_margin_loss">multilabel_margin_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.multilabel_soft_margin_loss.html#torch.nn.functional.multilabel_soft_margin_loss">multilabel_soft_margin_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.MultiLabelMarginLoss.html#torch.nn.MultiLabelMarginLoss">MultiLabelMarginLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MultiLabelSoftMarginLoss.html#torch.nn.MultiLabelSoftMarginLoss">MultiLabelSoftMarginLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.MultiMarginLoss.html#torch.nn.MultiMarginLoss">MultiMarginLoss (class in torch.nn)</a>
</li>
      <li><a href="distributions.html#torch.distributions.multinomial.Multinomial">Multinomial (class in torch.distributions.multinomial)</a>
</li>
      <li><a href="distributions.html#torch.distributions.constraints.multinomial">multinomial (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.multinomial.html#torch.multinomial">multinomial() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.multinomial.html#torch.Tensor.multinomial">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR">MultiplicativeLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.multiply.html#torch.multiply">multiply() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.multiply.html#torch.Tensor.multiply">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.multiply_.html#torch.Tensor.multiply_">multiply_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.MultiprocessContext">MultiprocessContext (class in torch.distributed.elastic.multiprocessing.api)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR">MultiStepLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal">MultivariateNormal (class in torch.distributions.multivariate_normal)</a>
</li>
      <li><a href="generated/torch.mv.html#torch.mv">mv() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.mv.html#torch.Tensor.mv">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.mvlgamma.html#torch.mvlgamma">mvlgamma() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.mvlgamma.html#torch.Tensor.mvlgamma">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.mvlgamma_.html#torch.Tensor.mvlgamma_">mvlgamma_() (torch.Tensor method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="N">N</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam">NAdam (class in torch.optim)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.name">name (torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend property)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.name">(torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend property)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend.name">(torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend property)</a>
</li>
        <li><a href="rpc.html#torch.distributed.rpc.WorkerInfo.name">(torch.distributed.rpc.WorkerInfo property)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Aggregation.name">(torch.monitor.Aggregation property)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Event.name">(torch.monitor.Event property)</a>
</li>
        <li><a href="monitor.html#torch.monitor.Stat.name">(torch.monitor.Stat property)</a>
</li>
        <li><a href="profiler.html#torch.profiler.ProfilerActivity.name">(torch.profiler.ProfilerActivity property)</a>
</li>
        <li><a href="torch.html#torch.Tag.name">(torch.Tag property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.graph.Node.name.html#torch.autograd.graph.Node.name">name() (torch.autograd.graph.Node method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.named_buffers">named_buffers() (torch.distributed.fsdp.FullyShardedDataParallel method)</a>

      <ul>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.named_buffers">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.named_buffers">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.named_children">named_children() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.named_children">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.named_modules">named_modules() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.named_modules">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.named_parameters">named_parameters() (torch.distributed.fsdp.FullyShardedDataParallel method)</a>

      <ul>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.named_parameters">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.named_parameters">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="named_tensor.html#torch.Tensor.names">names (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.nan_to_num.html#torch.nan_to_num">nan_to_num() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nan_to_num.html#torch.Tensor.nan_to_num">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.nan_to_num_.html#torch.Tensor.nan_to_num_">nan_to_num_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nanmean.html#torch.nanmean">nanmean() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nanmean.html#torch.Tensor.nanmean">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nanmedian.html#torch.nanmedian">nanmedian() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nanmedian.html#torch.Tensor.nanmedian">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nanquantile.html#torch.nanquantile">nanquantile() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nanquantile.html#torch.Tensor.nanquantile">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nansum.html#torch.nansum">nansum() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nansum.html#torch.Tensor.nansum">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.narrow.html#torch.narrow">narrow() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.narrow.html#torch.Tensor.narrow">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.narrow_copy.html#torch.narrow_copy">narrow_copy() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.narrow_copy.html#torch.Tensor.narrow_copy">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.nbytes.html#torch.Tensor.nbytes">nbytes (torch.Tensor attribute)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.nbytes">nbytes() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.nbytes">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.ndim.html#torch.Tensor.ndim">ndim (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.Tensor.ndimension.html#torch.Tensor.ndimension">ndimension() (torch.Tensor method)</a>
</li>
      <li><a href="special.html#torch.special.ndtr">ndtr() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.ndtri">ndtri() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.ne.html#torch.ne">ne() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ne.html#torch.Tensor.ne">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.ne_.html#torch.Tensor.ne_">ne_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.neg.html#torch.neg">neg() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.neg.html#torch.Tensor.neg">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.neg_.html#torch.Tensor.neg_">neg_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.negative.html#torch.negative">negative() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.negative.html#torch.Tensor.negative">(torch.Tensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.Tensor.negative_.html#torch.Tensor.negative_">negative_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial">NegativeBinomial (class in torch.distributions.negative_binomial)</a>
</li>
      <li><a href="generated/torch.Tensor.nelement.html#torch.Tensor.nelement">nelement() (torch.Tensor method)</a>
</li>
      <li><a href="nested.html#torch.nested.nested_tensor">nested_tensor() (in module torch.nested)</a>
</li>
      <li><a href="storage.html#torch.UntypedStorage.new">new() (torch.UntypedStorage method)</a>
</li>
      <li><a href="generated/torch.Tensor.new_empty.html#torch.Tensor.new_empty">new_empty() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.new_full.html#torch.Tensor.new_full">new_full() (torch.Tensor method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.new_group">new_group() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.Tensor.new_ones.html#torch.Tensor.new_ones">new_ones() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.new_tensor.html#torch.Tensor.new_tensor">new_tensor() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.new_zeros.html#torch.Tensor.new_zeros">new_zeros() (torch.Tensor method)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.next">next (torch.fx.Node property)</a>
</li>
      <li><a href="generated/torch.autograd.graph.Node.next_functions.html#torch.autograd.graph.Node.next_functions">next_functions (torch.autograd.graph.Node property)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.next_rendezvous">next_rendezvous() (torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      <li><a href="generated/torch.nextafter.html#torch.nextafter">nextafter() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nextafter.html#torch.Tensor.nextafter">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.nextafter_.html#torch.Tensor.nextafter_">nextafter_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.functional.nll_loss.html#torch.nn.functional.nll_loss">nll_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss">NLLLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.no_grad.html#torch.no_grad">no_grad (class in torch)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.no_sync">no_sync() (torch.distributed.fsdp.FullyShardedDataParallel method)</a>

      <ul>
        <li><a href="generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.no_sync">(torch.nn.parallel.DistributedDataParallel method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Node">Node (class in torch.fx)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.node_copy">node_copy() (torch.fx.Graph method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.nodes">nodes (torch.fx.Graph property)</a>
</li>
      <li><a href="generated/torch.nonzero.html#torch.nonzero">nonzero() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.nonzero.html#torch.Tensor.nonzero">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks.noop_hook">noop_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.NoopObserver.html#torch.ao.quantization.observer.NoopObserver">NoopObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.norm.html#torch.norm">norm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.norm.html#torch.linalg.norm">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.norm.html#torch.Tensor.norm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.normal.Normal">Normal (class in torch.distributions.normal)</a>
</li>
      <li><a href="generated/torch.normal.html#torch.normal">normal() (in module torch)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.normal_">normal_() (in module torch.nn.init)</a>

      <ul>
        <li><a href="generated/torch.Tensor.normal_.html#torch.Tensor.normal_">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.normalize.html#torch.nn.functional.normalize">normalize() (in module torch.nn.functional)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.normalized_arguments">normalized_arguments() (torch.fx.Node method)</a>
</li>
      <li><a href="generated/torch.not_equal.html#torch.not_equal">not_equal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.not_equal.html#torch.Tensor.not_equal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.not_equal_.html#torch.Tensor.not_equal_">not_equal_() (torch.Tensor method)</a>
</li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.Join.notify_join_context">notify_join_context() (torch.distributed.algorithms.Join static method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.NSTracer">NSTracer (class in torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.api.NullMetricHandler">NullMetricHandler (class in torch.distributed.elastic.metrics.api)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store.num_keys">num_keys() (in module torch.distributed.Store)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.num_nodes_waiting">num_nodes_waiting() (torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.num_worker_threads">num_worker_threads (torch.distributed.rpc.TensorPipeRpcBackendOptions property)</a>
</li>
      <li><a href="generated/torch.numel.html#torch.numel">numel() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.numel.html#torch.Tensor.numel">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.numpy.html#torch.Tensor.numpy">numpy() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.signal.windows.nuttall.html#torch.signal.windows.nuttall">nuttall() (in module torch.signal.windows)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="O">O</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.ao.quantization.backend_config.ObservationType.html#torch.ao.quantization.backend_config.ObservationType">ObservationType (class in torch.ao.quantization.backend_config)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.ObserverBase.html#torch.ao.quantization.observer.ObserverBase">ObserverBase (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.on_generate_code">on_generate_code() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.nn.functional.one_hot.html#torch.nn.functional.one_hot">one_hot() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR">OneCycleLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.jit.onednn_fusion_enabled.html#torch.jit.onednn_fusion_enabled">onednn_fusion_enabled() (in module torch.jit)</a>
</li>
      <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical">OneHotCategorical (class in torch.distributions.one_hot_categorical)</a>
</li>
      <li><a href="generated/torch.ones.html#torch.ones">ones() (in module torch)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.ones_">ones_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.ones_like.html#torch.ones_like">ones_like() (in module torch)</a>
</li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.onnx_compatible">onnx_compatible() (torch.onnx.JitScalarType method)</a>
</li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.onnx_type">onnx_type() (torch.onnx.JitScalarType method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.optim_state_dict">optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.optim_state_dict_to_load">optim_state_dict_to_load() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="generated/torch.jit.optimize_for_inference.html#torch.jit.optimize_for_inference">optimize_for_inference() (in module torch.jit)</a>
</li>
      <li><a href="mobile_optimizer.html#torch.utils.mobile_optimizer.optimize_for_mobile">optimize_for_mobile() (in module torch.utils.mobile_optimizer)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="optim.html#torch.optim.Optimizer">Optimizer (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.orgqr.html#torch.orgqr">orgqr() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.orgqr.html#torch.Tensor.orgqr">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ormqr.html#torch.ormqr">ormqr() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ormqr.html#torch.Tensor.ormqr">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.parametrizations.orthogonal.html#torch.nn.utils.parametrizations.orthogonal">orthogonal() (in module torch.nn.utils.parametrizations)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.orthogonal_">orthogonal_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.outer.html#torch.outer">outer() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.outer.html#torch.Tensor.outer">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.OutOfMemoryError.html#torch.cuda.OutOfMemoryError">OutOfMemoryError</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.output">output() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.output">(torch.fx.Interpreter method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.backend_config.ObservationType.html#torch.ao.quantization.backend_config.ObservationType.OUTPUT_SHARE_OBSERVER_WITH_INPUT">OUTPUT_SHARE_OBSERVER_WITH_INPUT (torch.ao.quantization.backend_config.ObservationType attribute)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.ObservationType.html#torch.ao.quantization.backend_config.ObservationType.OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT">OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT (torch.ao.quantization.backend_config.ObservationType attribute)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputComparisonLogger">OutputComparisonLogger (class in torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.OutputLogger">OutputLogger (class in torch.ao.ns._numeric_suite)</a>

      <ul>
        <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.OutputLogger">(class in torch.ao.ns._numeric_suite_fx)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="P">P</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributed.html#torch.distributed.P2POp">P2POp (class in torch.distributed)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.pack_padded_sequence.html#torch.nn.utils.rnn.pack_padded_sequence">pack_padded_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.pack_sequence.html#torch.nn.utils.rnn.pack_sequence">pack_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter">PackageExporter (class in torch.package)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter">PackageImporter (class in torch.package)</a>
</li>
      <li><a href="package.html#torch.package.PackagingError">PackagingError (class in torch.package)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence">PackedSequence (class in torch.nn.utils.rnn)</a>
</li>
      <li><a href="generated/torch.nn.functional.pad.html#torch.nn.functional.pad">pad() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.pad_packed_sequence.html#torch.nn.utils.rnn.pad_packed_sequence">pad_packed_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.pad_sequence.html#torch.nn.utils.rnn.pad_sequence">pad_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="generated/torch.nn.functional.pairwise_distance.html#torch.nn.functional.pairwise_distance">pairwise_distance() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.PairwiseDistance.html#torch.nn.PairwiseDistance">PairwiseDistance (class in torch.nn)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.PairwiseParallel">PairwiseParallel (class in torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="config_mod.html#torch.__config__.parallel_info">parallel_info() (in module torch.__config__)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.parallelize_module">parallelize_module() (in module torch.distributed.tensor.parallel)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.param_shape">param_shape (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.param_shape">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.param_shape">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.param_shape">(torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.param_shape">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.param_shape">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.param_shape">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.param_shape">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter">Parameter (class in torch.nn.parameter)</a>
</li>
      <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict">ParameterDict (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ParameterList.html#torch.nn.ParameterList">ParameterList (class in torch.nn)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.parameters">parameters() (in module torch.distributed.GradBucket)</a>

      <ul>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.parameters">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.parameters">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.parameters_to_vector.html#torch.nn.utils.parameters_to_vector">parameters_to_vector() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.nn.utils.parametrize.ParametrizationList.html#torch.nn.utils.parametrize.ParametrizationList">ParametrizationList (class in torch.nn.utils.parametrize)</a>
</li>
      <li><a href="distributions.html#torch.distributions.pareto.Pareto">Pareto (class in torch.distributions.pareto)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.path_of_module">path_of_module() (torch.fx.Tracer method)</a>
</li>
      <li><a href="generated/torch.pca_lowrank.html#torch.pca_lowrank">pca_lowrank() (in module torch)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.PContext">PContext (class in torch.distributed.elastic.multiprocessing.api)</a>
</li>
      <li><a href="generated/torch.nn.functional.pdist.html#torch.nn.functional.pdist">pdist() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.per_channel_dynamic_qconfig.html#torch.ao.quantization.qconfig.per_channel_dynamic_qconfig">per_channel_dynamic_qconfig (in module torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.PerChannelMinMaxObserver.html#torch.ao.quantization.observer.PerChannelMinMaxObserver">PerChannelMinMaxObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="generated/torch.permute.html#torch.permute">permute() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.permute.html#torch.Tensor.permute">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution.perplexity">perplexity() (torch.distributions.distribution.Distribution method)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.pickle_storage_type">pickle_storage_type() (torch.TypedStorage method)</a>
</li>
      <li><a href="generated/torch.Tensor.pin_memory.html#torch.Tensor.pin_memory">pin_memory() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.pin_memory">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.pin_memory">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.pinv.html#torch.linalg.pinv">pinv() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.pinverse.html#torch.pinverse">pinverse() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.pinverse.html#torch.Tensor.pinverse">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="pipeline.html#torch.distributed.pipeline.sync.Pipe">Pipe (class in torch.distributed.pipeline.sync)</a>
</li>
      <li><a href="generated/torch.nn.functional.pixel_shuffle.html#torch.nn.functional.pixel_shuffle">pixel_shuffle() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.pixel_unshuffle.html#torch.nn.functional.pixel_unshuffle">pixel_unshuffle() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.PixelShuffle.html#torch.nn.PixelShuffle">PixelShuffle (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.PixelUnshuffle.html#torch.nn.PixelUnshuffle">PixelUnshuffle (class in torch.nn)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.placeholder">placeholder() (torch.fx.Graph method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.placeholder">(torch.fx.Interpreter method)</a>
</li>
        <li><a href="fx.html#torch.fx.Transformer.placeholder">(torch.fx.Transformer method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.observer.PlaceholderObserver.html#torch.ao.quantization.observer.PlaceholderObserver">PlaceholderObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="distributions.html#torch.distributions.poisson.Poisson">Poisson (class in torch.distributions.poisson)</a>
</li>
      <li><a href="generated/torch.poisson.html#torch.poisson">poisson() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.functional.poisson_nll_loss.html#torch.nn.functional.poisson_nll_loss">poisson_nll_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.PoissonNLLLoss.html#torch.nn.PoissonNLLLoss">PoissonNLLLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.polar.html#torch.polar">polar() (in module torch)</a>
</li>
      <li><a href="generated/torch.polygamma.html#torch.polygamma">polygamma() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.polygamma">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.polygamma.html#torch.Tensor.polygamma">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.polygamma_.html#torch.Tensor.polygamma_">polygamma_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.PolynomialLR.html#torch.optim.lr_scheduler.PolynomialLR">PolynomialLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.pool">pool() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="pipeline.html#torch.distributed.pipeline.sync.skip.skippable.pop">pop (class in torch.distributed.pipeline.sync.skip.skippable)</a>
</li>
      <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.pop">pop() (torch.nn.ModuleDict method)</a>

      <ul>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.pop">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.popitem">popitem() (torch.nn.ParameterDict method)</a>
</li>
      <li><a href="generated/torch.positive.html#torch.positive">positive() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.positive.html#torch.Tensor.positive">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.transforms.PositiveDefiniteTransform">PositiveDefiniteTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributed.algorithms.join.html#torch.distributed.algorithms.JoinHook.post_hook">post_hook() (torch.distributed.algorithms.JoinHook method)</a>
</li>
      <li><a href="distributed.optim.html#torch.distributed.optim.PostLocalSGDOptimizer">PostLocalSGDOptimizer (class in torch.distributed.optim)</a>
</li>
      <li><a href="generated/torch.pow.html#torch.pow">pow() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.pow.html#torch.Tensor.pow">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.pow_.html#torch.Tensor.pow_">pow_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.cuda.power_draw.html#torch.cuda.power_draw">power_draw() (in module torch.cuda)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.powerSGD_hook">powerSGD_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="ddp_comm_hooks.html#torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState">PowerSGDState (class in torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.PowerTransform">PowerTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.precision_matrix">precision_matrix (torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.precision_matrix">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.AdaptiveLogSoftmaxWithLoss.html#torch.nn.AdaptiveLogSoftmaxWithLoss.predict">predict() (torch.nn.AdaptiveLogSoftmaxWithLoss method)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.preferred_linalg_library">preferred_linalg_library() (in module torch.backends.cuda)</a>
</li>
      <li><a href="distributed.html#torch.distributed.PrefixStore">PrefixStore (class in torch.distributed)</a>
</li>
      <li><a href="generated/torch.nn.PReLU.html#torch.nn.PReLU">PReLU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.prelu.html#torch.nn.functional.prelu">prelu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.quantization.prepare.html#torch.ao.quantization.prepare">prepare (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.ao.quantization.quantize_fx.prepare_fx.html#torch.ao.quantization.quantize_fx.prepare_fx">prepare_fx (class in torch.ao.quantization.quantize_fx)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.prepare_global_plan">prepare_global_plan() (torch.distributed.checkpoint.StorageReader method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.prepare_global_plan">(torch.distributed.checkpoint.StorageWriter method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.prepare_local_plan">prepare_local_plan() (torch.distributed.checkpoint.StorageReader method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.prepare_local_plan">(torch.distributed.checkpoint.StorageWriter method)</a>
</li>
      </ul></li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.prepare_model_outputs">prepare_model_outputs() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.prepare_model_with_stubs">prepare_model_with_stubs() (in module torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.prepare_n_shadows_model">prepare_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="generated/torch.ao.quantization.prepare_qat.html#torch.ao.quantization.prepare_qat">prepare_qat (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.ao.quantization.quantize_fx.prepare_qat_fx.html#torch.ao.quantization.quantize_fx.prepare_qat_fx">prepare_qat_fx (class in torch.ao.quantization.quantize_fx)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig">PrepareCustomConfig (class in torch.ao.quantization.fx.custom_config)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.prepend">prepend() (torch.fx.Node method)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.pretty_print_mismatch">pretty_print_mismatch() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.pretty_print_tree">pretty_print_tree() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.prev">prev (torch.fx.Node property)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite_fx.html#torch.ao.ns._numeric_suite_fx.print_comparisons_n_shadows_model">print_comparisons_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ChainedScheduler.html#torch.optim.lr_scheduler.ChainedScheduler.print_lr">print_lr() (torch.optim.lr_scheduler.ChainedScheduler method)</a>

      <ul>
        <li><a href="generated/torch.optim.lr_scheduler.ConstantLR.html#torch.optim.lr_scheduler.ConstantLR.print_lr">(torch.optim.lr_scheduler.ConstantLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR.print_lr">(torch.optim.lr_scheduler.CosineAnnealingLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.print_lr">(torch.optim.lr_scheduler.CosineAnnealingWarmRestarts method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CyclicLR.html#torch.optim.lr_scheduler.CyclicLR.print_lr">(torch.optim.lr_scheduler.CyclicLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR.print_lr">(torch.optim.lr_scheduler.ExponentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR.print_lr">(torch.optim.lr_scheduler.LambdaLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LinearLR.html#torch.optim.lr_scheduler.LinearLR.print_lr">(torch.optim.lr_scheduler.LinearLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR.print_lr">(torch.optim.lr_scheduler.MultiplicativeLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR.print_lr">(torch.optim.lr_scheduler.MultiStepLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR.print_lr">(torch.optim.lr_scheduler.OneCycleLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.PolynomialLR.html#torch.optim.lr_scheduler.PolynomialLR.print_lr">(torch.optim.lr_scheduler.PolynomialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.SequentialLR.html#torch.optim.lr_scheduler.SequentialLR.print_lr">(torch.optim.lr_scheduler.SequentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR.print_lr">(torch.optim.lr_scheduler.StepLR method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.GraphModule.print_readable">print_readable() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.print_tabular">print_tabular() (torch.fx.Graph method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.probs">probs (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.probs">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.probs">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.probs">(torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.probs">(torch.distributions.geometric.Geometric property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.probs">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.probs">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.probs">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.probs">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical property)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Graph.process_inputs">process_inputs() (torch.fx.Graph method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.process_outputs">process_outputs() (torch.fx.Graph method)</a>
</li>
      <li><a href="elastic/errors.html#torch.distributed.elastic.multiprocessing.errors.ProcessFailure">ProcessFailure (class in torch.distributed.elastic.multiprocessing.errors)</a>
</li>
      <li><a href="generated/torch.prod.html#torch.prod">prod() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.prod.html#torch.Tensor.prod">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.prof">prof() (in module torch.distributed.elastic.metrics)</a>
</li>
      <li><a href="autograd.html#torch.autograd.profiler.profile">profile (class in torch.autograd.profiler)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler.profile">(class in torch.profiler)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.mps.profiler.profile.html#torch.mps.profiler.profile">profile() (in module torch.mps.profiler)</a>
</li>
      <li><a href="profiler.html#torch.profiler.ProfilerAction">ProfilerAction (class in torch.profiler)</a>
</li>
      <li><a href="profiler.html#torch.profiler.ProfilerActivity">ProfilerActivity (class in torch.profiler)</a>
</li>
      <li><a href="generated/torch.promote_types.html#torch.promote_types">promote_types() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.propagate_qconfig_.html#torch.ao.quantization.propagate_qconfig_">propagate_qconfig_ (class in torch.ao.quantization)</a>
</li>
      <li><a href="fx.html#torch.fx.Proxy">Proxy (class in torch.fx)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer.proxy">proxy() (torch.fx.Tracer method)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.prune">prune() (torch.nn.utils.prune.BasePruningMethod method)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.prune">(torch.nn.utils.prune.CustomFromMask method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.prune">(torch.nn.utils.prune.Identity method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.prune">(torch.nn.utils.prune.L1Unstructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.prune">(torch.nn.utils.prune.LnStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.prune">(torch.nn.utils.prune.PruningContainer method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.prune">(torch.nn.utils.prune.RandomStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.prune">(torch.nn.utils.prune.RandomUnstructured method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer">PruningContainer (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="special.html#torch.special.psi">psi() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.Tensor.put_.html#torch.Tensor.put_">put_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/metrics.html#torch.distributed.elastic.metrics.put_metric">put_metric() (in module torch.distributed.elastic.metrics)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.python_code">python_code() (torch.fx.Graph method)</a>
</li>
      <li><a href="package.html#torch.package.PackageImporter.python_version">python_version() (torch.package.PackageImporter method)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="Q">Q</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.Tensor.q_per_channel_axis.html#torch.Tensor.q_per_channel_axis">q_per_channel_axis() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.q_per_channel_scales.html#torch.Tensor.q_per_channel_scales">q_per_channel_scales() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.q_per_channel_zero_points.html#torch.Tensor.q_per_channel_zero_points">q_per_channel_zero_points() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.q_scale.html#torch.Tensor.q_scale">q_scale() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.q_zero_point.html#torch.Tensor.q_zero_point">q_zero_point() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig.QConfig.html#torch.ao.quantization.qconfig.QConfig">QConfig (class in torch.ao.quantization.qconfig)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping">QConfigMapping (class in torch.ao.quantization.qconfig_mapping)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.QFunctional.html#torch.ao.nn.quantized.QFunctional">QFunctional (class in torch.ao.nn.quantized)</a>
</li>
      <li><a href="storage.html#torch.QInt32Storage">QInt32Storage (class in torch)</a>
</li>
      <li><a href="storage.html#torch.QInt8Storage">QInt8Storage (class in torch)</a>
</li>
      <li><a href="generated/torch.qr.html#torch.qr">qr() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.qr.html#torch.linalg.qr">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.qr.html#torch.Tensor.qr">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.qscheme.html#torch.Tensor.qscheme">qscheme() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.quantile.html#torch.quantile">quantile() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.quantile.html#torch.Tensor.quantile">(torch.Tensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.ao.quantization.quantize.html#torch.ao.quantization.quantize">quantize (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.ao.quantization.quantize_dynamic.html#torch.ao.quantization.quantize_dynamic">quantize_dynamic (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.quantize_per_channel.html#torch.quantize_per_channel">quantize_per_channel() (in module torch)</a>
</li>
      <li><a href="generated/torch.quantize_per_tensor.html#torch.quantize_per_tensor">quantize_per_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.quantize_qat.html#torch.ao.quantization.quantize_qat">quantize_qat (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.quantized_batch_norm.html#torch.quantized_batch_norm">quantized_batch_norm() (in module torch)</a>
</li>
      <li><a href="generated/torch.quantized_max_pool1d.html#torch.quantized_max_pool1d">quantized_max_pool1d() (in module torch)</a>
</li>
      <li><a href="generated/torch.quantized_max_pool2d.html#torch.quantized_max_pool2d">quantized_max_pool2d() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.QuantStub.html#torch.ao.quantization.QuantStub">QuantStub (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.ao.quantization.QuantWrapper.html#torch.ao.quantization.QuantWrapper">QuantWrapper (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.query">query() (torch.cuda.Event method)</a>

      <ul>
        <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream.query">(torch.cuda.ExternalStream method)</a>
</li>
        <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream.query">(torch.cuda.Stream method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.QUInt2x4Storage">QUInt2x4Storage (class in torch)</a>
</li>
      <li><a href="storage.html#torch.QUInt4x2Storage">QUInt4x2Storage (class in torch)</a>
</li>
      <li><a href="storage.html#torch.QUInt8Storage">QUInt8Storage (class in torch)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="R">R</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.rad2deg.html#torch.rad2deg">rad2deg() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.rad2deg.html#torch.Tensor.rad2deg">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam">RAdam (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.rand.html#torch.rand">rand() (in module torch)</a>
</li>
      <li><a href="generated/torch.rand_like.html#torch.rand_like">rand_like() (in module torch)</a>
</li>
      <li><a href="generated/torch.randint.html#torch.randint">randint() (in module torch)</a>
</li>
      <li><a href="generated/torch.randint_like.html#torch.randint_like">randint_like() (in module torch)</a>
</li>
      <li><a href="generated/torch.randn.html#torch.randn">randn() (in module torch)</a>
</li>
      <li><a href="generated/torch.randn_like.html#torch.randn_like">randn_like() (in module torch)</a>
</li>
      <li><a href="generated/torch.Tensor.random_.html#torch.Tensor.random_">random_() (torch.Tensor method)</a>
</li>
      <li><a href="data.html#torch.utils.data.random_split">random_split() (in module torch.utils.data)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.random_structured.html#torch.nn.utils.prune.random_structured">random_structured() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.random_unstructured.html#torch.nn.utils.prune.random_unstructured">random_unstructured() (in module torch.nn.utils.prune)</a>
</li>
      <li><a href="data.html#torch.utils.data.RandomSampler">RandomSampler (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured">RandomStructured (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured">RandomUnstructured (class in torch.nn.utils.prune)</a>
</li>
      <li><a href="generated/torch.randperm.html#torch.randperm">randperm() (in module torch)</a>
</li>
      <li><a href="generated/torch.range.html#torch.range">range() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.nvtx.range_pop.html#torch.cuda.nvtx.range_pop">range_pop() (in module torch.cuda.nvtx)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler.itt.range_pop">(in module torch.profiler.itt)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.nvtx.range_push.html#torch.cuda.nvtx.range_push">range_push() (in module torch.cuda.nvtx)</a>

      <ul>
        <li><a href="profiler.html#torch.profiler.itt.range_push">(in module torch.profiler.itt)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ravel.html#torch.ravel">ravel() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.ravel.html#torch.Tensor.ravel">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.read_data">read_data() (torch.distributed.checkpoint.StorageReader method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.read_metadata">read_metadata() (torch.distributed.checkpoint.StorageReader method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.ReadItem">ReadItem (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="generated/torch.Tensor.real.html#torch.Tensor.real">real (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.real.html#torch.real">real() (in module torch)</a>
</li>
      <li><a href="generated/torch.reciprocal.html#torch.reciprocal">reciprocal() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.reciprocal.html#torch.Tensor.reciprocal">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.reciprocal_.html#torch.Tensor.reciprocal_">reciprocal_() (torch.Tensor method)</a>
</li>
      <li><a href="fx.html#torch.fx.GraphModule.recompile">recompile() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="elastic/events.html#torch.distributed.elastic.events.record">record() (in module torch.distributed.elastic.events)</a>

      <ul>
        <li><a href="elastic/errors.html#torch.distributed.elastic.multiprocessing.errors.record">(in module torch.distributed.elastic.multiprocessing.errors)</a>
</li>
        <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.record">(torch.cuda.Event method)</a>
</li>
      </ul></li>
      <li><a href="onnx_diagnostics.html#torch.onnx._internal.diagnostics.ExportDiagnostic.record_cpp_call_stack">record_cpp_call_stack() (torch.onnx._internal.diagnostics.ExportDiagnostic method)</a>
</li>
      <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream.record_event">record_event() (torch.cuda.ExternalStream method)</a>

      <ul>
        <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream.record_event">(torch.cuda.Stream method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.record_stream.html#torch.Tensor.record_stream">record_stream() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.RecordingObserver.html#torch.ao.quantization.observer.RecordingObserver">RecordingObserver (class in torch.ao.quantization.observer)</a>
</li>
      <li><a href="distributed.html#torch.distributed.recv">recv() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.reduce">reduce() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.cuda.comm.reduce_add.html#torch.cuda.comm.reduce_add">reduce_add() (in module torch.cuda.comm)</a>
</li>
      <li><a href="distributed.html#torch.distributed.reduce_multigpu">reduce_multigpu() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.reduce_op">reduce_op (class in torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.reduce_scatter">reduce_scatter() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.reduce_scatter_multigpu">reduce_scatter_multigpu() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.html#torch.distributed.reduce_scatter_tensor">reduce_scatter_tensor() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html#torch.optim.lr_scheduler.ReduceLROnPlateau">ReduceLROnPlateau (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="distributed.html#torch.distributed.ReduceOp">ReduceOp (class in torch.distributed)</a>
</li>
      <li><a href="named_tensor.html#torch.Tensor.refine_names">refine_names() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.ReflectionPad1d.html#torch.nn.ReflectionPad1d">ReflectionPad1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ReflectionPad2d.html#torch.nn.ReflectionPad2d">ReflectionPad2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ReflectionPad3d.html#torch.nn.ReflectionPad3d">ReflectionPad3d (class in torch.nn)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry.register">register() (torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.constraint_registry.ConstraintRegistry.register">(torch.distributions.constraint_registry.ConstraintRegistry method)</a>
</li>
      </ul></li>
      <li><a href="distributed.html#torch.distributed.Backend.register_backend">register_backend() (torch.distributed.Backend class method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_backward_hook">register_backward_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_backward_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_buffer">register_buffer() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_buffer">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.register_comm_hook">register_comm_hook() (torch.distributed.fsdp.FullyShardedDataParallel method)</a>

      <ul>
        <li><a href="generated/torch.nn.parallel.DistributedDataParallel.html#torch.nn.parallel.DistributedDataParallel.register_comm_hook">(torch.nn.parallel.DistributedDataParallel method)</a>
</li>
      </ul></li>
      <li><a href="onnx.html#torch.onnx.register_custom_op_symbolic">register_custom_op_symbolic() (in module torch.onnx)</a>
</li>
      <li><a href="monitor.html#torch.monitor.register_event_handler">register_event_handler() (in module torch.monitor)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.register_extern_hook">register_extern_hook() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_forward_hook">register_forward_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_forward_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_forward_pre_hook">register_forward_pre_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_forward_pre_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_full_backward_hook">register_full_backward_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_full_backward_pre_hook">register_full_backward_pre_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_pre_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.graph.Node.register_hook.html#torch.autograd.graph.Node.register_hook">register_hook() (torch.autograd.graph.Node method)</a>

      <ul>
        <li><a href="generated/torch.Tensor.register_hook.html#torch.Tensor.register_hook">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.PackageExporter.register_intern_hook">register_intern_hook() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.kl.register_kl">register_kl() (in module torch.distributions.kl)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_load_state_dict_post_hook">register_load_state_dict_post_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_load_state_dict_post_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.PackageExporter.register_mock_hook">register_mock_hook() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_module">register_module() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_module">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.modules.module.register_module_backward_hook.html#torch.nn.modules.module.register_module_backward_hook">register_module_backward_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_buffer_registration_hook.html#torch.nn.modules.module.register_module_buffer_registration_hook">register_module_buffer_registration_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_forward_hook.html#torch.nn.modules.module.register_module_forward_hook">register_module_forward_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_forward_pre_hook.html#torch.nn.modules.module.register_module_forward_pre_hook">register_module_forward_pre_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_full_backward_hook.html#torch.nn.modules.module.register_module_full_backward_hook">register_module_full_backward_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_full_backward_pre_hook.html#torch.nn.modules.module.register_module_full_backward_pre_hook">register_module_full_backward_pre_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_module_registration_hook.html#torch.nn.modules.module.register_module_module_registration_hook">register_module_module_registration_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="generated/torch.nn.modules.module.register_module_parameter_registration_hook.html#torch.nn.modules.module.register_module_parameter_registration_hook">register_module_parameter_registration_hook() (in module torch.nn.modules.module)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.register_multi_grad_hook">register_multi_grad_hook (class in torch.autograd.graph)</a>
</li>
      <li><a href="notes/serialization.html#torch.serialization.register_package">register_package() (in module torch.serialization)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_parameter">register_parameter() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_parameter">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.parametrize.register_parametrization.html#torch.nn.utils.parametrize.register_parametrization">register_parametrization() (in module torch.nn.utils.parametrize)</a>
</li>
      <li><a href="generated/torch.autograd.graph.Node.register_prehook.html#torch.autograd.graph.Node.register_prehook">register_prehook() (torch.autograd.graph.Node method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.register_state_dict_pre_hook">register_state_dict_pre_hook() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.register_state_dict_pre_hook">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.register_step_post_hook">register_step_post_hook() (torch.optim.Adadelta method)</a>

      <ul>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.register_step_post_hook">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.register_step_post_hook">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.register_step_post_hook">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.register_step_post_hook">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.register_step_post_hook">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.register_step_post_hook">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.register_step_post_hook">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.register_step_post_hook">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.register_step_post_hook">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.register_step_post_hook">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.register_step_post_hook">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.register_step_post_hook">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.register_step_pre_hook">register_step_pre_hook() (torch.optim.Adadelta method)</a>

      <ul>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.register_step_pre_hook">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.register_step_pre_hook">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.register_step_pre_hook">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.register_step_pre_hook">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.register_step_pre_hook">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.register_step_pre_hook">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.register_step_pre_hook">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.register_step_pre_hook">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.register_step_pre_hook">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.register_step_pre_hook">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.register_step_pre_hook">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.register_step_pre_hook">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerServer.register_timers">register_timers() (torch.distributed.elastic.timer.TimerServer method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.rekey_optim_state_dict">rekey_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli">RelaxedBernoulli (class in torch.distributions.relaxed_bernoulli)</a>
</li>
      <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical">RelaxedOneHotCategorical (class in torch.distributions.relaxed_categorical)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerClient.release">release() (torch.distributed.elastic.timer.TimerClient method)</a>
</li>
      <li><a href="generated/torch.nn.ReLU.html#torch.nn.ReLU">ReLU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.relu.html#torch.nn.functional.relu">relu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.ReLU6.html#torch.ao.nn.quantized.ReLU6">ReLU6 (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.ReLU6.html#torch.nn.ReLU6">(class in torch.nn)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.nn.functional.relu6.html#torch.nn.functional.relu6">relu6() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.relu_.html#torch.nn.functional.relu_">relu_() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.remainder.html#torch.remainder">remainder() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.remainder.html#torch.Tensor.remainder">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.remainder_.html#torch.Tensor.remainder_">remainder_() (torch.Tensor method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.remote">remote() (in module torch.distributed.rpc)</a>
</li>
      <li><a href="rpc.html#torch.distributed.nn.api.remote_module.RemoteModule.remote_parameters">remote_parameters() (torch.distributed.nn.api.remote_module.RemoteModule method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.nn.api.remote_module.RemoteModule">RemoteModule (class in torch.distributed.nn.api.remote_module)</a>
</li>
      <li><a href="generated/torch.nn.utils.prune.remove.html#torch.nn.utils.prune.remove">remove() (in module torch.nn.utils.prune)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.prune.BasePruningMethod.html#torch.nn.utils.prune.BasePruningMethod.remove">(torch.nn.utils.prune.BasePruningMethod method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.CustomFromMask.html#torch.nn.utils.prune.CustomFromMask.remove">(torch.nn.utils.prune.CustomFromMask method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.Identity.html#torch.nn.utils.prune.Identity.remove">(torch.nn.utils.prune.Identity method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.L1Unstructured.html#torch.nn.utils.prune.L1Unstructured.remove">(torch.nn.utils.prune.L1Unstructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.LnStructured.html#torch.nn.utils.prune.LnStructured.remove">(torch.nn.utils.prune.LnStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.PruningContainer.html#torch.nn.utils.prune.PruningContainer.remove">(torch.nn.utils.prune.PruningContainer method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomStructured.html#torch.nn.utils.prune.RandomStructured.remove">(torch.nn.utils.prune.RandomStructured method)</a>
</li>
        <li><a href="generated/torch.nn.utils.prune.RandomUnstructured.html#torch.nn.utils.prune.RandomUnstructured.remove">(torch.nn.utils.prune.RandomUnstructured method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.parametrize.remove_parametrizations.html#torch.nn.utils.parametrize.remove_parametrizations">remove_parametrizations() (in module torch.nn.utils.parametrize)</a>
</li>
      <li><a href="generated/torch.nn.utils.remove_spectral_norm.html#torch.nn.utils.remove_spectral_norm">remove_spectral_norm() (in module torch.nn.utils)</a>
</li>
      <li><a href="generated/torch.nn.utils.remove_weight_norm.html#torch.nn.utils.remove_weight_norm">remove_weight_norm() (in module torch.nn.utils)</a>
</li>
      <li><a href="named_tensor.html#torch.Tensor.rename">rename() (torch.Tensor method)</a>
</li>
      <li><a href="named_tensor.html#torch.Tensor.rename_">rename_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend">RendezvousBackend (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousClosedError">RendezvousClosedError (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousConnectionError">RendezvousConnectionError (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousError">RendezvousError (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler">RendezvousHandler (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry">RendezvousHandlerRegistry (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousParameters">RendezvousParameters (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousStateError">RendezvousStateError (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout">RendezvousTimeout (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousTimeoutError">RendezvousTimeoutError (class in torch.distributed.elastic.rendezvous)</a>
</li>
      <li><a href="generated/torch.renorm.html#torch.renorm">renorm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.renorm.html#torch.Tensor.renorm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.renorm_.html#torch.Tensor.renorm_">renorm_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.repeat.html#torch.Tensor.repeat">repeat() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.repeat_interleave.html#torch.repeat_interleave">repeat_interleave() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.repeat_interleave.html#torch.Tensor.repeat_interleave">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.func.replace_all_batch_norm_modules_.html#torch.func.replace_all_batch_norm_modules_">replace_all_batch_norm_modules_() (in module torch.func)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.replace_all_uses_with">replace_all_uses_with() (torch.fx.Node method)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.replace_input_with">replace_input_with() (torch.fx.Node method)</a>
</li>
      <li><a href="fx.html#torch.fx.replace_pattern">replace_pattern() (in module torch.fx)</a>
</li>
      <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.replay">replay() (torch.cuda.CUDAGraph method)</a>
</li>
      <li><a href="generated/torch.nn.ReplicationPad1d.html#torch.nn.ReplicationPad1d">ReplicationPad1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ReplicationPad2d.html#torch.nn.ReplicationPad2d">ReplicationPad2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ReplicationPad3d.html#torch.nn.ReplicationPad3d">ReplicationPad3d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.Tensor.requires_grad.html#torch.Tensor.requires_grad">requires_grad (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.requires_grad_">requires_grad_() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.requires_grad_">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.requires_grad_.html#torch.Tensor.requires_grad_">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.compiler.reset.html#torch.compiler.reset">reset() (in module torch.compiler)</a>

      <ul>
        <li><a href="generated/torch.cuda.CUDAGraph.html#torch.cuda.CUDAGraph.reset">(torch.cuda.CUDAGraph method)</a>
</li>
        <li><a href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine.reset">(torch.quasirandom.SobolEngine method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.reset_max_memory_allocated.html#torch.cuda.reset_max_memory_allocated">reset_max_memory_allocated() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.reset_max_memory_cached.html#torch.cuda.reset_max_memory_cached">reset_max_memory_cached() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.MinMaxObserver.html#torch.ao.quantization.observer.MinMaxObserver.reset_min_max_vals">reset_min_max_vals() (torch.ao.quantization.observer.MinMaxObserver method)</a>

      <ul>
        <li><a href="generated/torch.ao.quantization.observer.PerChannelMinMaxObserver.html#torch.ao.quantization.observer.PerChannelMinMaxObserver.reset_min_max_vals">(torch.ao.quantization.observer.PerChannelMinMaxObserver method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.reset_peak_memory_stats.html#torch.cuda.reset_peak_memory_stats">reset_peak_memory_stats() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.reshape.html#torch.reshape">reshape() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.reshape.html#torch.Tensor.reshape">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.reshape_as.html#torch.Tensor.reshape_as">reshape_as() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.ReshapeTransform">ReshapeTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.Tensor.resize_.html#torch.Tensor.resize_">resize_() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.resize_">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.resize_">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.resize_as_.html#torch.Tensor.resize_as_">resize_as_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.resolve_conj.html#torch.resolve_conj">resolve_conj() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.resolve_conj.html#torch.Tensor.resolve_conj">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.resolve_data">resolve_data() (torch.distributed.checkpoint.SavePlanner method)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.resolve_name">resolve_name() (in module torch.overrides)</a>
</li>
      <li><a href="generated/torch.resolve_neg.html#torch.resolve_neg">resolve_neg() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.resolve_neg.html#torch.Tensor.resolve_neg">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.resolve_tensor">resolve_tensor() (torch.distributed.checkpoint.LoadPlanner method)</a>
</li>
      <li><a href="generated/torch.result_type.html#torch.result_type">result_type() (in module torch)</a>
</li>
      <li><a href="generated/torch.Tensor.retain_grad.html#torch.Tensor.retain_grad">retain_grad() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.retains_grad.html#torch.Tensor.retains_grad">retains_grad (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.fft.rfft.html#torch.fft.rfft">rfft() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.rfft2.html#torch.fft.rfft2">rfft2() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.rfftfreq.html#torch.fft.rfftfreq">rfftfreq() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.fft.rfftn.html#torch.fft.rfftn">rfftn() (in module torch.fft)</a>
</li>
      <li><a href="generated/torch.nn.utils.parametrize.ParametrizationList.html#torch.nn.utils.parametrize.ParametrizationList.right_inverse">right_inverse() (torch.nn.utils.parametrize.ParametrizationList method)</a>
</li>
      <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop">RMSprop (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.nn.RNN.html#torch.nn.RNN">RNN (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.RNNBase.html#torch.nn.RNNBase">RNNBase (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.dynamic.RNNCell.html#torch.ao.nn.quantized.dynamic.RNNCell">RNNCell (class in torch.ao.nn.quantized.dynamic)</a>

      <ul>
        <li><a href="generated/torch.nn.RNNCell.html#torch.nn.RNNCell">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.roll.html#torch.roll">roll() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.roll.html#torch.Tensor.roll">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.rot90.html#torch.rot90">rot90() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.rot90.html#torch.Tensor.rot90">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.round.html#torch.round">round() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.round">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.round.html#torch.Tensor.round">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.round_.html#torch.Tensor.round_">round_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.row_indices.html#torch.Tensor.row_indices">row_indices() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.row_stack.html#torch.row_stack">row_stack() (in module torch)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.RowwiseParallel">RowwiseParallel (class in torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.rpc_async">rpc_async() (in module torch.distributed.rpc)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.rpc_sync">rpc_sync() (in module torch.distributed.rpc)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.RpcBackendOptions.rpc_timeout">rpc_timeout (torch.distributed.rpc.RpcBackendOptions property)</a>

      <ul>
        <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.rpc_timeout">(torch.distributed.rpc.TensorPipeRpcBackendOptions property)</a>
</li>
      </ul></li>
      <li><a href="rpc.html#torch.distributed.rpc.RpcBackendOptions">RpcBackendOptions (class in torch.distributed.rpc)</a>
</li>
      <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop">Rprop (class in torch.optim)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.RRef">RRef (class in torch.distributed.rpc)</a>
</li>
      <li><a href="generated/torch.nn.RReLU.html#torch.nn.RReLU">RReLU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.rrelu.html#torch.nn.functional.rrelu">rrelu() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.rrelu_.html#torch.nn.functional.rrelu_">rrelu_() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.beta.Beta.rsample">rsample() (torch.distributions.beta.Beta method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.rsample">(torch.distributions.cauchy.Cauchy method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.rsample">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.rsample">(torch.distributions.dirichlet.Dirichlet method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.rsample">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.rsample">(torch.distributions.exponential.Exponential method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.rsample">(torch.distributions.fishersnedecor.FisherSnedecor method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.rsample">(torch.distributions.gamma.Gamma method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.rsample">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.rsample">(torch.distributions.laplace.Laplace method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.rsample">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.rsample">(torch.distributions.multivariate_normal.MultivariateNormal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.rsample">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.rsample">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.rsample">(torch.distributions.studentT.StudentT method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.rsample">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.rsample">(torch.distributions.uniform.Uniform method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.rsample">(torch.distributions.wishart.Wishart method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.rsqrt.html#torch.rsqrt">rsqrt() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.rsqrt.html#torch.Tensor.rsqrt">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.rsqrt_.html#torch.Tensor.rsqrt_">rsqrt_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.ElasticAgent.run">run() (torch.distributed.elastic.agent.server.ElasticAgent method)</a>

      <ul>
        <li><a href="fx.html#torch.fx.Interpreter.run">(torch.fx.Interpreter method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Interpreter.run_node">run_node() (torch.fx.Interpreter method)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.RunProcsResult">RunProcsResult (class in torch.distributed.elastic.multiprocessing.api)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.api.RunResult">RunResult (class in torch.distributed.elastic.agent.server.api)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="S">S</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.sample">sample() (torch.distributions.bernoulli.Bernoulli method)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.sample">(torch.distributions.binomial.Binomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.sample">(torch.distributions.categorical.Categorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.sample">(torch.distributions.continuous_bernoulli.ContinuousBernoulli method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.sample">(torch.distributions.distribution.Distribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.sample">(torch.distributions.geometric.Geometric method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.sample">(torch.distributions.independent.Independent method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky.sample">(torch.distributions.lkj_cholesky.LKJCholesky method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.sample">(torch.distributions.mixture_same_family.MixtureSameFamily method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.sample">(torch.distributions.multinomial.Multinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.sample">(torch.distributions.negative_binomial.NegativeBinomial method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.sample">(torch.distributions.normal.Normal method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.sample">(torch.distributions.one_hot_categorical.OneHotCategorical method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.sample">(torch.distributions.poisson.Poisson method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.sample">(torch.distributions.transformed_distribution.TransformedDistribution method)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.sample">(torch.distributions.von_mises.VonMises method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution.sample_n">sample_n() (torch.distributions.distribution.Distribution method)</a>
</li>
      <li><a href="generated/torch.sparse.sampled_addmm.html#torch.sparse.sampled_addmm">sampled_addmm() (in module torch.sparse)</a>
</li>
      <li><a href="data.html#torch.utils.data.Sampler">Sampler (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.save.html#torch.save">save() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.jit.save.html#torch.jit.save">(in module torch.jit)</a>
</li>
        <li><a href="generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction.save">(torch.jit.ScriptFunction method)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.save">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.onnx.ExportOutput.html#torch.onnx.ExportOutput.save">(torch.onnx.ExportOutput method)</a>
</li>
      </ul></li>
      <li><a href="package.html#torch.package.PackageExporter.save_binary">save_binary() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.autograd.function.FunctionCtx.save_for_backward.html#torch.autograd.function.FunctionCtx.save_for_backward">save_for_backward() (torch.autograd.function.FunctionCtx method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.save_module">save_module() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.save_on_cpu">save_on_cpu (class in torch.autograd.graph)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.save_pickle">save_pickle() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.save_source_file">save_source_file() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.save_source_string">save_source_string() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.save_state_dict">save_state_dict() (in module torch.distributed.checkpoint)</a>
</li>
      <li><a href="package.html#torch.package.PackageExporter.save_text">save_text() (torch.package.PackageExporter method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction.save_to_buffer">save_to_buffer() (torch.jit.ScriptFunction method)</a>
</li>
      <li><a href="autograd.html#torch.autograd.graph.saved_tensors_hooks">saved_tensors_hooks (class in torch.autograd.graph)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlan">SavePlan (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner">SavePlanner (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.scalar_name">scalar_name() (torch.onnx.JitScalarType method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.scale">scale (torch.distributions.half_cauchy.HalfCauchy property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.scale">(torch.distributions.half_normal.HalfNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.scale">(torch.distributions.log_normal.LogNormal property)</a>
</li>
      </ul></li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.scale">scale() (torch.cuda.amp.GradScaler method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.scale_tril">scale_tril (torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.scale_tril">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.functional.scaled_dot_product_attention.html#torch.nn.functional.scaled_dot_product_attention">scaled_dot_product_attention() (in module torch.nn.functional)</a>
</li>
      <li><a href="special.html#torch.special.scaled_modified_bessel_k0">scaled_modified_bessel_k0() (in module torch.special)</a>
</li>
      <li><a href="special.html#torch.special.scaled_modified_bessel_k1">scaled_modified_bessel_k1() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.scatter.html#torch.scatter">scatter() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.comm.scatter.html#torch.cuda.comm.scatter">(in module torch.cuda.comm)</a>
</li>
        <li><a href="distributed.html#torch.distributed.scatter">(in module torch.distributed)</a>
</li>
        <li><a href="generated/torch.Tensor.scatter.html#torch.Tensor.scatter">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_">scatter_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.scatter_add.html#torch.scatter_add">scatter_add() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.scatter_add.html#torch.Tensor.scatter_add">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_">scatter_add_() (torch.Tensor method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.scatter_full_optim_state_dict">scatter_full_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.scatter_object_list">scatter_object_list() (in module torch.distributed)</a>
</li>
      <li><a href="generated/torch.scatter_reduce.html#torch.scatter_reduce">scatter_reduce() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.scatter_reduce.html#torch.Tensor.scatter_reduce">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.scatter_reduce_.html#torch.Tensor.scatter_reduce_">scatter_reduce_() (torch.Tensor method)</a>
</li>
      <li><a href="profiler.html#torch.profiler.schedule">schedule() (in module torch.profiler)</a>
</li>
      <li><a href="generated/torch.jit.script.html#torch.jit.script">script() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.jit.script_if_tracing.html#torch.jit.script_if_tracing">script_if_tracing() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.jit.ScriptFunction.html#torch.jit.ScriptFunction">ScriptFunction (class in torch.jit)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule">ScriptModule (class in torch.jit)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.sdp_kernel">sdp_kernel() (in module torch.backends.cuda)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.SDPBackend">SDPBackend (class in torch.backends.cuda)</a>
</li>
      <li><a href="generated/torch.searchsorted.html#torch.searchsorted">searchsorted() (in module torch)</a>
</li>
      <li><a href="generated/torch.seed.html#torch.seed">seed() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.seed.html#torch.cuda.seed">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.mps.seed.html#torch.mps.seed">(in module torch.mps)</a>
</li>
        <li><a href="random.html#torch.random.seed">(in module torch.random)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.seed">(torch.Generator method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.seed_all.html#torch.cuda.seed_all">seed_all() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.select.html#torch.select">select() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.select.html#torch.Tensor.select">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="onnx.html#torch.onnx.select_model_mode_for_export">select_model_mode_for_export() (in module torch.onnx)</a>
</li>
      <li><a href="generated/torch.select_scatter.html#torch.select_scatter">select_scatter() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.select_scatter.html#torch.Tensor.select_scatter">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.profiler.profile.self_cpu_time_total.html#torch.autograd.profiler.profile.self_cpu_time_total">self_cpu_time_total (torch.autograd.profiler.profile property)</a>
</li>
      <li><a href="generated/torch.nn.SELU.html#torch.nn.SELU">SELU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.selu.html#torch.nn.functional.selu">selu() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributed.html#torch.distributed.send">send() (in module torch.distributed)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.style.SequenceParallel">SequenceParallel (class in torch.distributed.tensor.parallel.style)</a>
</li>
      <li><a href="generated/torch.nn.Sequential.html#torch.nn.Sequential">Sequential (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.optim.lr_scheduler.SequentialLR.html#torch.optim.lr_scheduler.SequentialLR">SequentialLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="data.html#torch.utils.data.SequentialSampler">SequentialSampler (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.onnx.ExportOutputSerializer.html#torch.onnx.ExportOutputSerializer.serialize">serialize() (torch.onnx.ExportOutputSerializer method)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store.set">set() (in module torch.distributed.Store)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.set">(torch.distributed.elastic.rendezvous.etcd_store.EtcdStore method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.set_.html#torch.Tensor.set_">set_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.set_backend_pattern_config">set_backend_pattern_config() (torch.ao.quantization.backend_config.BackendConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.set_backend_pattern_configs">set_backend_pattern_configs() (torch.ao.quantization.backend_config.BackendConfig method)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.set_backoff_factor">set_backoff_factor() (torch.cuda.amp.GradScaler method)</a>
</li>
      <li><a href="ddp_comm_hooks.html#torch.distributed.GradBucket.set_buffer">set_buffer() (in module torch.distributed.GradBucket)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.set_closed">set_closed() (torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      <li><a href="fx.html#torch.fx.Graph.set_codegen">set_codegen() (torch.fx.Graph method)</a>
</li>
      <li><a href="generated/torch.set_default_device.html#torch.set_default_device">set_default_device() (in module torch)</a>
</li>
      <li><a href="generated/torch.set_default_dtype.html#torch.set_default_dtype">set_default_dtype() (in module torch)</a>
</li>
      <li><a href="generated/torch.set_default_tensor_type.html#torch.set_default_tensor_type">set_default_tensor_type() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.distribution.Distribution.set_default_validate_args">set_default_validate_args() (torch.distributions.distribution.Distribution static method)</a>
</li>
      <li><a href="autograd.html#torch.autograd.set_detect_anomaly">set_detect_anomaly (class in torch.autograd)</a>
</li>
      <li><a href="generated/torch.set_deterministic_debug_mode.html#torch.set_deterministic_debug_mode">set_deterministic_debug_mode() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.set_device.html#torch.cuda.set_device">set_device() (in module torch.cuda)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.set_device_map">set_device_map() (torch.distributed.rpc.TensorPipeRpcBackendOptions method)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions.set_devices">set_devices() (torch.distributed.rpc.TensorPipeRpcBackendOptions method)</a>
</li>
      <li><a href="hub.html#torch.hub.set_dir">set_dir() (in module torch.hub)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_dtype_configs">set_dtype_configs() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.set_exception">set_exception() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.set_extra_state">set_extra_state() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.set_extra_state">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision">set_float32_matmul_precision() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_float_to_observed_mapping">set_float_to_observed_mapping() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="generated/torch.set_flush_denormal.html#torch.set_flush_denormal">set_flush_denormal() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_fused_module">set_fused_module() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_fuser_method">set_fuser_method() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="generated/torch.jit.set_fusion_strategy.html#torch.jit.set_fusion_strategy">set_fusion_strategy() (in module torch.jit)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.set_global">set_global() (torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      <li><a href="generated/torch.set_grad_enabled.html#torch.set_grad_enabled">set_grad_enabled (class in torch)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.set_growth_factor">set_growth_factor() (torch.cuda.amp.GradScaler method)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.set_growth_interval">set_growth_interval() (torch.cuda.amp.GradScaler method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_input_quantized_indexes">set_input_quantized_indexes() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="generated/torch._logging.set_logs.html#torch._logging.set_logs">set_logs() (in module torch._logging)</a>
</li>
      <li><a href="generated/torch.autograd.function.FunctionCtx.set_materialize_grads.html#torch.autograd.function.FunctionCtx.set_materialize_grads">set_materialize_grads() (torch.autograd.function.FunctionCtx method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name">set_module_name() (torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name_object_type_order">set_module_name_object_type_order() (torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name_regex">set_module_name_regex() (torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      <li><a href="generated/torch.autograd.set_multithreading_enabled.html#torch.autograd.set_multithreading_enabled">set_multithreading_enabled (class in torch.autograd)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.set_name">set_name() (torch.ao.quantization.backend_config.BackendConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_non_traceable_module_classes">set_non_traceable_module_classes() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_non_traceable_module_names">set_non_traceable_module_names() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="generated/torch.set_num_interop_threads.html#torch.set_num_interop_threads">set_num_interop_threads() (in module torch)</a>
</li>
      <li><a href="generated/torch.set_num_threads.html#torch.set_num_threads">set_num_threads() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.set_object_type">set_object_type() (torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_observation_type">set_observation_type() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.html#torch.ao.quantization.fx.custom_config.ConvertCustomConfig.set_observed_to_quantized_mapping">set_observed_to_quantized_mapping() (torch.ao.quantization.fx.custom_config.ConvertCustomConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_output_quantized_indexes">set_output_quantized_indexes() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_pattern">set_pattern() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="generated/torch.cuda.set_per_process_memory_fraction.html#torch.cuda.set_per_process_memory_fraction">set_per_process_memory_fraction() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.mps.set_per_process_memory_fraction.html#torch.mps.set_per_process_memory_fraction">(in module torch.mps)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.html#torch.ao.quantization.fx.custom_config.ConvertCustomConfig.set_preserved_attributes">set_preserved_attributes() (torch.ao.quantization.fx.custom_config.ConvertCustomConfig method)</a>

      <ul>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig.html#torch.ao.quantization.fx.custom_config.FuseCustomConfig.set_preserved_attributes">(torch.ao.quantization.fx.custom_config.FuseCustomConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_preserved_attributes">(torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.set_printoptions.html#torch.set_printoptions">set_printoptions() (in module torch)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_qat_module">set_qat_module() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_reference_quantized_module">set_reference_quantized_module() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.set_result">set_result() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.set_rng_state.html#torch.set_rng_state">set_rng_state() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.cuda.set_rng_state.html#torch.cuda.set_rng_state">(in module torch.cuda)</a>
</li>
        <li><a href="generated/torch.mps.set_rng_state.html#torch.mps.set_rng_state">(in module torch.mps)</a>
</li>
        <li><a href="random.html#torch.random.set_rng_state">(in module torch.random)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.set_rng_state_all.html#torch.cuda.set_rng_state_all">set_rng_state_all() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.set_root_module">set_root_module() (torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
      <li><a href="multiprocessing.html#torch.multiprocessing.set_sharing_strategy">set_sharing_strategy() (in module torch.multiprocessing)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_standalone_module_class">set_standalone_module_class() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_standalone_module_name">set_standalone_module_name() (torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
      <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.set_state">set_state() (torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend method)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.set_state">(torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend method)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend.set_state">(torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend method)</a>
</li>
        <li><a href="generated/torch.Generator.html#torch.Generator.set_state">(torch.Generator method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.set_state_dict_type">set_state_dict_type() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="generated/torch.cuda.set_stream.html#torch.cuda.set_stream">set_stream() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.set_sync_debug_mode.html#torch.cuda.set_sync_debug_mode">set_sync_debug_mode() (in module torch.cuda)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store.set_timeout">set_timeout() (in module torch.distributed.Store)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.LoadPlanner.set_up_planner">set_up_planner() (torch.distributed.checkpoint.LoadPlanner method)</a>

      <ul>
        <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.SavePlanner.set_up_planner">(torch.distributed.checkpoint.SavePlanner method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader.set_up_storage_reader">set_up_storage_reader() (torch.distributed.checkpoint.StorageReader method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.set_up_storage_writer">set_up_storage_writer() (torch.distributed.checkpoint.StorageWriter method)</a>
</li>
      <li><a href="generated/torch.set_warn_always.html#torch.set_warn_always">set_warn_always() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.setdefault">setdefault() (torch.nn.ParameterDict method)</a>
</li>
      <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD">SGD (class in torch.optim)</a>
</li>
      <li><a href="generated/torch.sgn.html#torch.sgn">sgn() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sgn.html#torch.Tensor.sgn">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sgn_.html#torch.Tensor.sgn_">sgn_() (torch.Tensor method)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.Shadow">Shadow (class in torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="torch.ao.ns._numeric_suite.html#torch.ao.ns._numeric_suite.ShadowLogger">ShadowLogger (class in torch.ao.ns._numeric_suite)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.shard_full_optim_state_dict">shard_full_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.sharded_optim_state_dict">sharded_optim_state_dict() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.ShardingStrategy">ShardingStrategy (class in torch.distributed.fsdp)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.share_memory">share_memory() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.share_memory">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.share_memory_.html#torch.Tensor.share_memory_">share_memory_() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.share_memory_">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.share_memory_">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.short.html#torch.Tensor.short">short() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.short">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.short">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="storage.html#torch.ShortStorage">ShortStorage (class in torch)</a>
</li>
      <li><a href="config_mod.html#torch.__config__.show">show() (in module torch.__config__)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.shutdown">shutdown() (in module torch.distributed.rpc)</a>

      <ul>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.RendezvousHandler.shutdown">(torch.distributed.elastic.rendezvous.RendezvousHandler method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.ao.nn.quantized.Sigmoid.html#torch.ao.nn.quantized.Sigmoid">Sigmoid (class in torch.ao.nn.quantized)</a>

      <ul>
        <li><a href="generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.sigmoid.html#torch.sigmoid">sigmoid() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.nn.functional.sigmoid.html#torch.nn.functional.sigmoid">(in module torch.nn.functional)</a>
</li>
        <li><a href="generated/torch.Tensor.sigmoid.html#torch.Tensor.sigmoid">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sigmoid_.html#torch.Tensor.sigmoid_">sigmoid_() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.SigmoidTransform">SigmoidTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform.sign">sign (torch.distributions.transforms.Transform property)</a>
</li>
      <li><a href="generated/torch.sign.html#torch.sign">sign() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sign.html#torch.Tensor.sign">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sign_.html#torch.Tensor.sign_">sign_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.signbit.html#torch.signbit">signbit() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.signbit.html#torch.Tensor.signbit">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Measurement.significant_figures">significant_figures (torch.utils.benchmark.Measurement property)</a>
</li>
      <li><a href="generated/torch.nn.SiLU.html#torch.nn.SiLU">SiLU (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.silu.html#torch.nn.functional.silu">silu() (in module torch.nn.functional)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.SimpleElasticAgent">SimpleElasticAgent (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="generated/torch.sin.html#torch.sin">sin() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sin.html#torch.Tensor.sin">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sin_.html#torch.Tensor.sin_">sin_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.sinc.html#torch.sinc">sinc() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.sinc">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.sinc.html#torch.Tensor.sinc">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sinc_.html#torch.Tensor.sinc_">sinc_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.sinh.html#torch.sinh">sinh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sinh.html#torch.Tensor.sinh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sinh_.html#torch.Tensor.sinh_">sinh_() (torch.Tensor method)</a>
</li>
      <li><a href="backends.html#torch.backends.cuda.cufft_plan_cache.size">size (in module torch.backends.cuda.cufft_plan_cache)</a>
</li>
      <li><a href="generated/torch.Tensor.size.html#torch.Tensor.size">size() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.size">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.size">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.skip_init.html#torch.nn.utils.skip_init">skip_init() (in module torch.nn.utils)</a>
</li>
      <li><a href="pipeline.html#torch.distributed.pipeline.sync.skip.skippable.skippable">skippable() (in module torch.distributed.pipeline.sync.skip.skippable)</a>
</li>
      <li><a href="generated/torch.slice_scatter.html#torch.slice_scatter">slice_scatter() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.slice_scatter.html#torch.Tensor.slice_scatter">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.slogdet.html#torch.slogdet">slogdet() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.slogdet.html#torch.linalg.slogdet">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.slogdet.html#torch.Tensor.slogdet">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.smm.html#torch.smm">smm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.smm.html#torch.Tensor.smm">(torch.Tensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.nn.functional.smooth_l1_loss.html#torch.nn.functional.smooth_l1_loss">smooth_l1_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.SmoothL1Loss.html#torch.nn.SmoothL1Loss">SmoothL1Loss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine">SobolEngine (class in torch.quasirandom)</a>
</li>
      <li><a href="generated/torch.nn.functional.soft_margin_loss.html#torch.nn.functional.soft_margin_loss">soft_margin_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.SoftMarginLoss.html#torch.nn.SoftMarginLoss">SoftMarginLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.Softmax.html#torch.nn.Softmax">Softmax (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.softmax.html#torch.softmax">softmax() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.nn.functional.softmax.html#torch.nn.functional.softmax">(in module torch.nn.functional)</a>
</li>
        <li><a href="generated/torch.sparse.softmax.html#torch.sparse.softmax">(in module torch.sparse)</a>
</li>
        <li><a href="special.html#torch.special.softmax">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.softmax.html#torch.Tensor.softmax">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.Softmax2d.html#torch.nn.Softmax2d">Softmax2d (class in torch.nn)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.SoftmaxTransform">SoftmaxTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.nn.Softmin.html#torch.nn.Softmin">Softmin (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.softmin.html#torch.nn.functional.softmin">softmin() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.Softplus.html#torch.nn.Softplus">Softplus (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.softplus.html#torch.nn.functional.softplus">softplus() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.SoftplusTransform">SoftplusTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.nn.Softshrink.html#torch.nn.Softshrink">Softshrink (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.softshrink.html#torch.nn.functional.softshrink">softshrink() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.Softsign.html#torch.nn.Softsign">Softsign (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.softsign.html#torch.nn.functional.softsign">softsign() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.linalg.solve.html#torch.linalg.solve">solve() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.solve_ex.html#torch.linalg.solve_ex">solve_ex() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.solve_triangular.html#torch.linalg.solve_triangular">solve_triangular() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.sort.html#torch.sort">sort() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sort.html#torch.Tensor.sort">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.sorted_indices">sorted_indices (torch.nn.utils.rnn.PackedSequence attribute)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.sparse_">sparse_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.sparse_bsc_tensor.html#torch.sparse_bsc_tensor">sparse_bsc_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.sparse_bsr_tensor.html#torch.sparse_bsr_tensor">sparse_bsr_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.sparse_compressed_tensor.html#torch.sparse_compressed_tensor">sparse_compressed_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.sparse_coo_tensor.html#torch.sparse_coo_tensor">sparse_coo_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.sparse_csc_tensor.html#torch.sparse_csc_tensor">sparse_csc_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.sparse_csr_tensor.html#torch.sparse_csr_tensor">sparse_csr_tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.Tensor.sparse_dim.html#torch.Tensor.sparse_dim">sparse_dim() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.sparse_mask.html#torch.Tensor.sparse_mask">sparse_mask() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.sparse_resize_.html#torch.Tensor.sparse_resize_">sparse_resize_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.sparse_resize_and_clear_.html#torch.Tensor.sparse_resize_and_clear_">sparse_resize_and_clear_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam">SparseAdam (class in torch.optim)</a>
</li>
      <li><a href="multiprocessing.html#torch.multiprocessing.spawn">spawn() (in module torch.multiprocessing)</a>
</li>
      <li><a href="multiprocessing.html#torch.multiprocessing.SpawnContext">SpawnContext (class in torch.multiprocessing)</a>
</li>
      <li><a href="generated/torch.sparse.spdiags.html#torch.sparse.spdiags">spdiags() (in module torch.sparse)</a>
</li>
      <li><a href="generated/torch.nn.utils.spectral_norm.html#torch.nn.utils.spectral_norm">spectral_norm() (in module torch.nn.utils)</a>

      <ul>
        <li><a href="generated/torch.nn.utils.parametrizations.spectral_norm.html#torch.nn.utils.parametrizations.spectral_norm">(in module torch.nn.utils.parametrizations)</a>
</li>
      </ul></li>
      <li><a href="special.html#torch.special.spherical_bessel_j0">spherical_bessel_j0() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.split.html#torch.split">split() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.split.html#torch.Tensor.split">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.sqrt.html#torch.sqrt">sqrt() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sqrt.html#torch.Tensor.sqrt">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sqrt_.html#torch.Tensor.sqrt_">sqrt_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.square.html#torch.square">square() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.square.html#torch.Tensor.square">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.square_.html#torch.Tensor.square_">square_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.squeeze.html#torch.squeeze">squeeze() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.squeeze.html#torch.Tensor.squeeze">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.squeeze_.html#torch.Tensor.squeeze_">squeeze_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.sspaddmm.html#torch.sspaddmm">sspaddmm() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sspaddmm.html#torch.Tensor.sspaddmm">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.constraints.stack">stack (in module torch.distributions.constraints)</a>
</li>
      <li><a href="generated/torch.stack.html#torch.stack">stack() (in module torch)</a>
</li>
      <li><a href="generated/torch.func.stack_module_state.html#torch.func.stack_module_state">stack_module_state() (in module torch.func)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.stack_trace">stack_trace (torch.fx.Node property)</a>
</li>
      <li><a href="data.html#torch.utils.data.StackDataset">StackDataset (class in torch.utils.data)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.StackTransform">StackTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry.html#torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry">StandaloneModuleConfigEntry (class in torch.ao.quantization.fx.custom_config)</a>
</li>
      <li><a href="generated/torch.mps.profiler.start.html#torch.mps.profiler.start">start() (in module torch.mps.profiler)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.start_processes">start_processes() (in module torch.distributed.elastic.multiprocessing)</a>
</li>
      <li><a href="pipeline.html#torch.distributed.pipeline.sync.skip.skippable.stash">stash (class in torch.distributed.pipeline.sync.skip.skippable)</a>
</li>
      <li><a href="monitor.html#torch.monitor.Stat">Stat (class in torch.monitor)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.state_dict">state_dict() (torch.cuda.amp.GradScaler method)</a>

      <ul>
        <li><a href="distributed.optim.html#torch.distributed.optim.PostLocalSGDOptimizer.state_dict">(torch.distributed.optim.PostLocalSGDOptimizer method)</a>
</li>
        <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.state_dict">(torch.distributed.optim.ZeroRedundancyOptimizer method)</a>
</li>
        <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.state_dict">(torch.jit.ScriptModule method)</a>
</li>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.state_dict">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.state_dict">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.state_dict">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.state_dict">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.state_dict">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.state_dict">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.state_dict">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.state_dict">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ChainedScheduler.html#torch.optim.lr_scheduler.ChainedScheduler.state_dict">(torch.optim.lr_scheduler.ChainedScheduler method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ConstantLR.html#torch.optim.lr_scheduler.ConstantLR.state_dict">(torch.optim.lr_scheduler.ConstantLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR.state_dict">(torch.optim.lr_scheduler.CosineAnnealingLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.state_dict">(torch.optim.lr_scheduler.CosineAnnealingWarmRestarts method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.ExponentialLR.html#torch.optim.lr_scheduler.ExponentialLR.state_dict">(torch.optim.lr_scheduler.ExponentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR.state_dict">(torch.optim.lr_scheduler.LambdaLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.LinearLR.html#torch.optim.lr_scheduler.LinearLR.state_dict">(torch.optim.lr_scheduler.LinearLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR.state_dict">(torch.optim.lr_scheduler.MultiplicativeLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR.state_dict">(torch.optim.lr_scheduler.MultiStepLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.OneCycleLR.html#torch.optim.lr_scheduler.OneCycleLR.state_dict">(torch.optim.lr_scheduler.OneCycleLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.PolynomialLR.html#torch.optim.lr_scheduler.PolynomialLR.state_dict">(torch.optim.lr_scheduler.PolynomialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.SequentialLR.html#torch.optim.lr_scheduler.SequentialLR.state_dict">(torch.optim.lr_scheduler.SequentialLR method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR.state_dict">(torch.optim.lr_scheduler.StepLR method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.state_dict">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.Optimizer.state_dict.html#torch.optim.Optimizer.state_dict">(torch.optim.Optimizer method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.state_dict">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.state_dict">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.state_dict">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.state_dict">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.state_dict">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.state_dict_type">state_dict_type() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.CallgrindStats.stats">stats() (torch.utils.benchmark.CallgrindStats method)</a>
</li>
      <li><a href="generated/torch.std.html#torch.std">std() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.std.html#torch.Tensor.std">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.std_mean.html#torch.std_mean">std_mean() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.stddev">stddev (torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.stddev">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.stddev">(torch.distributions.exponential.Exponential property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.stddev">(torch.distributions.gumbel.Gumbel property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.stddev">(torch.distributions.laplace.Laplace property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.stddev">(torch.distributions.normal.Normal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.stddev">(torch.distributions.uniform.Uniform property)</a>
</li>
      </ul></li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.step">step() (torch.cuda.amp.GradScaler method)</a>

      <ul>
        <li><a href="distributed.optim.html#torch.distributed.optim.DistributedOptimizer.step">(torch.distributed.optim.DistributedOptimizer method)</a>
</li>
        <li><a href="distributed.optim.html#torch.distributed.optim.PostLocalSGDOptimizer.step">(torch.distributed.optim.PostLocalSGDOptimizer method)</a>
</li>
        <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer.step">(torch.distributed.optim.ZeroRedundancyOptimizer method)</a>
</li>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.step">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.step">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.step">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.step">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.step">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.step">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.step">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.html#torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.step">(torch.optim.lr_scheduler.CosineAnnealingWarmRestarts method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.step">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.Optimizer.step.html#torch.optim.Optimizer.step">(torch.optim.Optimizer method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.step">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.step">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.step">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.step">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.step">(torch.optim.SparseAdam method)</a>
</li>
        <li><a href="profiler.html#torch.profiler.profile.step">(torch.profiler.profile method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR">StepLR (class in torch.optim.lr_scheduler)</a>
</li>
      <li><a href="generated/torch.stft.html#torch.stft">stft() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.stft.html#torch.Tensor.stft">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.transforms.StickBreakingTransform">StickBreakingTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="generated/torch.mps.profiler.stop.html#torch.mps.profiler.stop">stop() (in module torch.mps.profiler)</a>
</li>
      <li><a href="generated/torch.Tensor.storage.html#torch.Tensor.storage">storage() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.storage_offset.html#torch.Tensor.storage_offset">storage_offset() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.storage_type.html#torch.Tensor.storage_type">storage_type() (torch.Tensor method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageReader">StorageReader (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter">StorageWriter (class in torch.distributed.checkpoint)</a>
</li>
      <li><a href="distributed.html#torch.distributed.Store">Store (class in torch.distributed)</a>
</li>
      <li><a href="backends.html#torch.backends.opt_einsum.strategy">strategy (in module torch.backends.opt_einsum)</a>
</li>
      <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream">Stream (class in torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.stream.html#torch.cuda.stream">stream() (in module torch.cuda)</a>
</li>
      <li><a href="generated/torch.cuda.StreamContext.html#torch.cuda.StreamContext">StreamContext (class in torch.cuda)</a>
</li>
      <li><a href="generated/torch.jit.strict_fusion.html#torch.jit.strict_fusion">strict_fusion (class in torch.jit)</a>
</li>
      <li><a href="generated/torch.Tensor.stride.html#torch.Tensor.stride">stride() (torch.Tensor method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.studentT.StudentT">StudentT (class in torch.distributions.studentT)</a>
</li>
      <li><a href="generated/torch.sub.html#torch.sub">sub() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.sub.html#torch.Tensor.sub">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sub_.html#torch.Tensor.sub_">sub_() (torch.Tensor method)</a>
</li>
      <li><a href="elastic/multiprocessing.html#torch.distributed.elastic.multiprocessing.api.SubprocessContext">SubprocessContext (class in torch.distributed.elastic.multiprocessing.api)</a>
</li>
      <li><a href="data.html#torch.utils.data.Subset">Subset (class in torch.utils.data)</a>
</li>
      <li><a href="data.html#torch.utils.data.SubsetRandomSampler">SubsetRandomSampler (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.subtract.html#torch.subtract">subtract() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.subtract.html#torch.Tensor.subtract">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.subtract_.html#torch.Tensor.subtract_">subtract_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.sum.html#torch.sum">sum() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.sparse.sum.html#torch.sparse.sum">(in module torch.sparse)</a>
</li>
        <li><a href="generated/torch.Tensor.sum.html#torch.Tensor.sum">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.sum_to_size.html#torch.Tensor.sum_to_size">sum_to_size() (torch.Tensor method)</a>
</li>
      <li><a href="tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter">SummaryWriter (class in torch.utils.tensorboard.writer)</a>
</li>
      <li><a href="fsdp.html#torch.distributed.fsdp.FullyShardedDataParallel.summon_full_params">summon_full_params() (torch.distributed.fsdp.FullyShardedDataParallel static method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.support">support (torch.distributions.bernoulli.Bernoulli attribute)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.support">(torch.distributions.beta.Beta attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.support">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.support">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.support">(torch.distributions.cauchy.Cauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.support">(torch.distributions.continuous_bernoulli.ContinuousBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.support">(torch.distributions.dirichlet.Dirichlet attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.support">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.support">(torch.distributions.exponential.Exponential attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.support">(torch.distributions.fishersnedecor.FisherSnedecor attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.support">(torch.distributions.gamma.Gamma attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.support">(torch.distributions.geometric.Geometric attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.support">(torch.distributions.gumbel.Gumbel attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.support">(torch.distributions.half_cauchy.HalfCauchy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.support">(torch.distributions.half_normal.HalfNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.support">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.support">(torch.distributions.kumaraswamy.Kumaraswamy attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.support">(torch.distributions.laplace.Laplace attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lkj_cholesky.LKJCholesky.support">(torch.distributions.lkj_cholesky.LKJCholesky attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.support">(torch.distributions.log_normal.LogNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.support">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.support">(torch.distributions.mixture_same_family.MixtureSameFamily property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.support">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.support">(torch.distributions.multivariate_normal.MultivariateNormal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.support">(torch.distributions.negative_binomial.NegativeBinomial attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.support">(torch.distributions.normal.Normal attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.support">(torch.distributions.one_hot_categorical.OneHotCategorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.support">(torch.distributions.pareto.Pareto property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.support">(torch.distributions.poisson.Poisson attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.support">(torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.support">(torch.distributions.relaxed_bernoulli.RelaxedBernoulli attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.support">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.support">(torch.distributions.studentT.StudentT attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution.support">(torch.distributions.transformed_distribution.TransformedDistribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.support">(torch.distributions.uniform.Uniform property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.support">(torch.distributions.von_mises.VonMises attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.support">(torch.distributions.weibull.Weibull attribute)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.support">(torch.distributions.wishart.Wishart attribute)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.svd.html#torch.svd">svd() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.svd.html#torch.linalg.svd">(in module torch.linalg)</a>
</li>
        <li><a href="generated/torch.Tensor.svd.html#torch.Tensor.svd">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.svd_lowrank.html#torch.svd_lowrank">svd_lowrank() (in module torch)</a>
</li>
      <li><a href="generated/torch.linalg.svdvals.html#torch.linalg.svdvals">svdvals() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.ao.quantization.swap_module.html#torch.ao.quantization.swap_module">swap_module (class in torch.ao.quantization)</a>
</li>
      <li><a href="generated/torch.swapaxes.html#torch.swapaxes">swapaxes() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.swapaxes.html#torch.Tensor.swapaxes">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.swapdims.html#torch.swapdims">swapdims() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.swapdims.html#torch.Tensor.swapdims">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.sym_float.html#torch.sym_float">sym_float() (in module torch)</a>
</li>
      <li><a href="generated/torch.sym_int.html#torch.sym_int">sym_int() (in module torch)</a>
</li>
      <li><a href="generated/torch.sym_max.html#torch.sym_max">sym_max() (in module torch)</a>
</li>
      <li><a href="generated/torch.sym_min.html#torch.sym_min">sym_min() (in module torch)</a>
</li>
      <li><a href="generated/torch.sym_not.html#torch.sym_not">sym_not() (in module torch)</a>
</li>
      <li><a href="fx.html#torch.fx.symbolic_trace">symbolic_trace() (in module torch.fx)</a>
</li>
      <li><a href="torch.html#torch.SymBool">SymBool (class in torch)</a>
</li>
      <li><a href="torch.html#torch.SymFloat">SymFloat (class in torch)</a>
</li>
      <li><a href="torch.html#torch.SymInt">SymInt (class in torch)</a>
</li>
      <li><a href="generated/torch.nn.SyncBatchNorm.html#torch.nn.SyncBatchNorm">SyncBatchNorm (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.cuda.synchronize.html#torch.cuda.synchronize">synchronize() (in module torch.cuda)</a>

      <ul>
        <li><a href="generated/torch.mps.synchronize.html#torch.mps.synchronize">(in module torch.mps)</a>
</li>
        <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.synchronize">(torch.cuda.Event method)</a>
</li>
        <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream.synchronize">(torch.cuda.ExternalStream method)</a>
</li>
        <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream.synchronize">(torch.cuda.Stream method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="T">T</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="tensors.html#torch.Tensor.T">T (torch.Tensor attribute)</a>
</li>
      <li><a href="generated/torch.t.html#torch.t">t() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.t.html#torch.Tensor.t">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.t_.html#torch.Tensor.t_">t_() (torch.Tensor method)</a>
</li>
      <li><a href="torch.html#torch.Tag">Tag (class in torch)</a>
</li>
      <li><a href="generated/torch.take.html#torch.take">take() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.take.html#torch.Tensor.take">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.take_along_dim.html#torch.take_along_dim">take_along_dim() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.take_along_dim.html#torch.Tensor.take_along_dim">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.tan.html#torch.tan">tan() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.tan.html#torch.Tensor.tan">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.tan_.html#torch.Tensor.tan_">tan_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.Tanh.html#torch.nn.Tanh">Tanh (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.tanh.html#torch.tanh">tanh() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.nn.functional.tanh.html#torch.nn.functional.tanh">(in module torch.nn.functional)</a>
</li>
        <li><a href="generated/torch.Tensor.tanh.html#torch.Tensor.tanh">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.tanh_.html#torch.Tensor.tanh_">tanh_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.nn.Tanhshrink.html#torch.nn.Tanhshrink">Tanhshrink (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.tanhshrink.html#torch.nn.functional.tanhshrink">tanhshrink() (in module torch.nn.functional)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transforms.TanhTransform">TanhTransform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="distributed.html#torch.distributed.TCPStore">TCPStore (class in torch.distributed)</a>
</li>
      <li><a href="distributions.html#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature">temperature (torch.distributions.relaxed_bernoulli.RelaxedBernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature">(torch.distributions.relaxed_categorical.RelaxedOneHotCategorical property)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.temperature.html#torch.cuda.temperature">temperature() (in module torch.cuda)</a>
</li>
      <li><a href="tensors.html#torch.Tensor">Tensor (class in torch)</a>
</li>
      <li><a href="generated/torch.tensor.html#torch.tensor">tensor() (in module torch)</a>
</li>
      <li><a href="generated/torch.tensor_split.html#torch.tensor_split">tensor_split() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.tensor_split.html#torch.Tensor.tensor_split">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="profiler.html#torch.profiler.tensorboard_trace_handler">tensorboard_trace_handler() (in module torch.profiler)</a>
</li>
      <li><a href="monitor.html#torch.monitor.TensorboardEventHandler">TensorboardEventHandler (class in torch.monitor)</a>
</li>
      <li><a href="data.html#torch.utils.data.TensorDataset">TensorDataset (class in torch.utils.data)</a>
</li>
      <li><a href="generated/torch.tensordot.html#torch.tensordot">tensordot() (in module torch)</a>
</li>
      <li><a href="generated/torch.linalg.tensorinv.html#torch.linalg.tensorinv">tensorinv() (in module torch.linalg)</a>
</li>
      <li><a href="distributed.tensor.parallel.html#torch.distributed.tensor.parallel.multihead_attention_tp.TensorParallelMultiheadAttention">TensorParallelMultiheadAttention (class in torch.distributed.tensor.parallel.multihead_attention_tp)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.TensorPipeRpcBackendOptions">TensorPipeRpcBackendOptions (class in torch.distributed.rpc)</a>
</li>
      <li><a href="generated/torch.linalg.tensorsolve.html#torch.linalg.tensorsolve">tensorsolve() (in module torch.linalg)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.then">then() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.threshold.html#torch.ao.nn.quantized.functional.threshold">threshold (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Threshold.html#torch.nn.Threshold">Threshold (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.threshold.html#torch.nn.functional.threshold">threshold() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.threshold_.html#torch.nn.functional.threshold_">threshold_() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.tile.html#torch.tile">tile() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.tile.html#torch.Tensor.tile">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Timer.timeit">timeit() (torch.utils.benchmark.Timer method)</a>
</li>
      <li><a href="benchmark_utils.html#torch.utils.benchmark.Timer">Timer (class in torch.utils.benchmark)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerClient">TimerClient (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerRequest">TimerRequest (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="elastic/timer.html#torch.distributed.elastic.timer.TimerServer">TimerServer (class in torch.distributed.elastic.timer)</a>
</li>
      <li><a href="monitor.html#torch.monitor.Event.timestamp">timestamp (torch.monitor.Event property)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.to">to() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.to">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.to">(torch.nn.utils.rnn.PackedSequence method)</a>
</li>
        <li><a href="generated/torch.Tensor.to.html#torch.Tensor.to">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Tracer.to_bool">to_bool() (torch.fx.Tracer method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_dense.html#torch.Tensor.to_dense">to_dense() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.backend_config.BackendConfig.html#torch.ao.quantization.backend_config.BackendConfig.to_dict">to_dict() (torch.ao.quantization.backend_config.BackendConfig method)</a>

      <ul>
        <li><a href="generated/torch.ao.quantization.backend_config.BackendPatternConfig.html#torch.ao.quantization.backend_config.BackendPatternConfig.to_dict">(torch.ao.quantization.backend_config.BackendPatternConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.backend_config.DTypeConfig.html#torch.ao.quantization.backend_config.DTypeConfig.to_dict">(torch.ao.quantization.backend_config.DTypeConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.html#torch.ao.quantization.fx.custom_config.ConvertCustomConfig.to_dict">(torch.ao.quantization.fx.custom_config.ConvertCustomConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig.html#torch.ao.quantization.fx.custom_config.FuseCustomConfig.to_dict">(torch.ao.quantization.fx.custom_config.FuseCustomConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.html#torch.ao.quantization.fx.custom_config.PrepareCustomConfig.to_dict">(torch.ao.quantization.fx.custom_config.PrepareCustomConfig method)</a>
</li>
        <li><a href="generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.html#torch.ao.quantization.qconfig_mapping.QConfigMapping.to_dict">(torch.ao.quantization.qconfig_mapping.QConfigMapping method)</a>
</li>
      </ul></li>
      <li><a href="dlpack.html#torch.utils.dlpack.to_dlpack">to_dlpack() (in module torch.utils.dlpack)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.to_empty">to_empty() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.to_empty">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.GraphModule.to_folder">to_folder() (torch.fx.GraphModule method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_mkldnn.html#torch.Tensor.to_mkldnn">to_mkldnn() (torch.Tensor method)</a>
</li>
      <li><a href="nested.html#torch.nested.to_padded_tensor">to_padded_tensor() (in module torch.nested)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse.html#torch.Tensor.to_sparse">to_sparse() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse_bsc.html#torch.Tensor.to_sparse_bsc">to_sparse_bsc() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse_bsr.html#torch.Tensor.to_sparse_bsr">to_sparse_bsr() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse_coo.html#torch.Tensor.to_sparse_coo">to_sparse_coo() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse_csc.html#torch.Tensor.to_sparse_csc">to_sparse_csc() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.to_sparse_csr.html#torch.Tensor.to_sparse_csr">to_sparse_csr() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.tolist.html#torch.Tensor.tolist">tolist() (torch.Tensor method)</a>

      <ul>
        <li><a href="storage.html#torch.TypedStorage.tolist">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.tolist">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.topk.html#torch.topk">topk() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.topk.html#torch.Tensor.topk">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li>
    torch

      <ul>
        <li><a href="torch.html#module-torch">module</a>
</li>
      </ul></li>
      <li>
    torch.__config__

      <ul>
        <li><a href="config_mod.html#module-torch.__config__">module</a>
</li>
      </ul></li>
      <li>
    torch._logging

      <ul>
        <li><a href="logging.html#module-torch._logging">module</a>
</li>
      </ul></li>
      <li>
    torch.amp

      <ul>
        <li><a href="amp.html#module-torch.amp">module</a>
</li>
      </ul></li>
      <li>
    torch.ao

      <ul>
        <li><a href="quantization.html#module-torch.ao">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.qat

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.qat">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.qat.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.qat.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.intrinsic.quantized.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.intrinsic.quantized.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.qat.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.qat.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantizable

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantizable.modules

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantizable.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.functional

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.functional">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.ao.nn.quantized.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.reference

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.quantized.reference.modules

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.quantized.reference.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.sparse

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.sparse">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.sparse.quantized

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.nn.sparse.quantized.dynamic

      <ul>
        <li><a href="quantization.html#module-torch.ao.nn.sparse.quantized.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns._numeric_suite

      <ul>
        <li><a href="torch.ao.ns._numeric_suite.html#module-torch.ao.ns._numeric_suite">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns._numeric_suite_fx

      <ul>
        <li><a href="torch.ao.ns._numeric_suite_fx.html#module-torch.ao.ns._numeric_suite_fx">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.ns.fx

      <ul>
        <li><a href="quantization.html#module-torch.ao.ns.fx">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning.scheduler

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning.scheduler">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.pruning.sparsifier

      <ul>
        <li><a href="quantization.html#module-torch.ao.pruning.sparsifier">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.backend_config

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.backend_config">module</a>
</li>
      </ul></li>
      <li>
    torch.ao.quantization.fx

      <ul>
        <li><a href="quantization.html#module-torch.ao.quantization.fx">module</a>
</li>
      </ul></li>
      <li>
    torch.autograd

      <ul>
        <li><a href="autograd.html#module-torch.autograd">module</a>, <a href="torch.html#module-torch.autograd">[1]</a>
</li>
      </ul></li>
      <li>
    torch.backends

      <ul>
        <li><a href="backends.html#module-torch.backends">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.cpu

      <ul>
        <li><a href="backends.html#module-torch.backends.cpu">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.cuda

      <ul>
        <li><a href="backends.html#module-torch.backends.cuda">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.cudnn

      <ul>
        <li><a href="backends.html#module-torch.backends.cudnn">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.mkl

      <ul>
        <li><a href="backends.html#module-torch.backends.mkl">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.mkldnn

      <ul>
        <li><a href="backends.html#module-torch.backends.mkldnn">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.mps

      <ul>
        <li><a href="backends.html#module-torch.backends.mps">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.openmp

      <ul>
        <li><a href="backends.html#module-torch.backends.openmp">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.opt_einsum

      <ul>
        <li><a href="backends.html#module-torch.backends.opt_einsum">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.quantized

      <ul>
        <li><a href="backends.html#module-torch.backends.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.xeon

      <ul>
        <li><a href="backends.html#module-torch.backends.xeon">module</a>
</li>
      </ul></li>
      <li>
    torch.backends.xnnpack

      <ul>
        <li><a href="backends.html#module-torch.backends.xnnpack">module</a>
</li>
      </ul></li>
      <li>
    torch.compiler

      <ul>
        <li><a href="compiler.html#module-torch.compiler">module</a>
</li>
      </ul></li>
      <li>
    torch.contrib

      <ul>
        <li><a href="torch.html#module-torch.contrib">module</a>
</li>
      </ul></li>
      <li>
    torch.cpu

      <ul>
        <li><a href="amp.html#module-torch.cpu">module</a>
</li>
      </ul></li>
      <li>
    torch.cpu.amp

      <ul>
        <li><a href="amp.html#module-torch.cpu.amp">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda

      <ul>
        <li><a href="cuda.html#module-torch.cuda">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda._sanitizer

      <ul>
        <li><a href="cuda._sanitizer.html#module-torch.cuda._sanitizer">module</a>
</li>
      </ul></li>
      <li>
    torch.cuda.amp

      <ul>
        <li><a href="amp.html#module-torch.cuda.amp">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed

      <ul>
        <li><a href="distributed.html#module-torch.distributed">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.ddp_comm_hooks

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.ddp_comm_hooks">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.algorithms.model_averaging

      <ul>
        <li><a href="distributed.html#module-torch.distributed.algorithms.model_averaging">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.autograd

      <ul>
        <li><a href="rpc.html#module-torch.distributed.autograd">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.checkpoint

      <ul>
        <li><a href="distributed.checkpoint.html#module-torch.distributed.checkpoint">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.agent

      <ul>
        <li><a href="elastic/agent.html#module-torch.distributed.elastic.agent">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.agent.server

      <ul>
        <li><a href="elastic/agent.html#module-torch.distributed.elastic.agent.server">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.events

      <ul>
        <li><a href="elastic/events.html#module-torch.distributed.elastic.events">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.metrics

      <ul>
        <li><a href="elastic/metrics.html#module-torch.distributed.elastic.metrics">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing

      <ul>
        <li><a href="elastic/multiprocessing.html#module-torch.distributed.elastic.multiprocessing">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.multiprocessing.errors

      <ul>
        <li><a href="elastic/errors.html#module-torch.distributed.elastic.multiprocessing.errors">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous

      <ul>
        <li><a href="elastic/rendezvous.html#module-torch.distributed.elastic.rendezvous">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.rendezvous.registry

      <ul>
        <li><a href="elastic/rendezvous.html#module-torch.distributed.elastic.rendezvous.registry">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.timer

      <ul>
        <li><a href="elastic/timer.html#module-torch.distributed.elastic.timer">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.utils

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.elastic.utils.data

      <ul>
        <li><a href="distributed.html#module-torch.distributed.elastic.utils.data">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.fsdp

      <ul>
        <li><a href="fsdp.html#module-torch.distributed.fsdp">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.launch

      <ul>
        <li><a href="distributed.html#module-torch.distributed.launch">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.launcher

      <ul>
        <li><a href="distributed.html#module-torch.distributed.launcher">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn.api

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn.api">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn.jit

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn.jit">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.nn.jit.templates

      <ul>
        <li><a href="distributed.html#module-torch.distributed.nn.jit.templates">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.optim

      <ul>
        <li><a href="distributed.optim.html#module-torch.distributed.optim">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline">module</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li>
    torch.distributed.pipeline.sync

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.pipeline.sync.skip

      <ul>
        <li><a href="distributed.html#module-torch.distributed.pipeline.sync.skip">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.rpc

      <ul>
        <li><a href="rpc.html#module-torch.distributed.rpc">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.run

      <ul>
        <li><a href="elastic/run.html#module-torch.distributed.run">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.tensor

      <ul>
        <li><a href="distributed.html#module-torch.distributed.tensor">module</a>
</li>
      </ul></li>
      <li>
    torch.distributed.tensor.parallel

      <ul>
        <li><a href="distributed.tensor.parallel.html#module-torch.distributed.tensor.parallel">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions

      <ul>
        <li><a href="distributions.html#module-torch.distributions">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.constraint_registry

      <ul>
        <li><a href="distributions.html#module-torch.distributions.constraint_registry">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.constraints

      <ul>
        <li><a href="distributions.html#module-torch.distributions.constraints">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.kl

      <ul>
        <li><a href="distributions.html#module-torch.distributions.kl">module</a>
</li>
      </ul></li>
      <li>
    torch.distributions.transforms

      <ul>
        <li><a href="distributions.html#module-torch.distributions.transforms">module</a>
</li>
      </ul></li>
      <li>
    torch.fft

      <ul>
        <li><a href="fft.html#module-torch.fft">module</a>
</li>
      </ul></li>
      <li><a href="type_info.html#torch.torch.finfo">torch.finfo (class in torch)</a>
</li>
      <li>
    torch.func

      <ul>
        <li><a href="func.api.html#module-torch.func">module</a>
</li>
      </ul></li>
      <li>
    torch.futures

      <ul>
        <li><a href="futures.html#module-torch.futures">module</a>
</li>
      </ul></li>
      <li>
    torch.fx

      <ul>
        <li><a href="fx.html#module-torch.fx">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.migrate_gradual_types

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.migrate_gradual_types">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.experimental.unification.multipledispatch

      <ul>
        <li><a href="fx.html#module-torch.fx.experimental.unification.multipledispatch">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes

      <ul>
        <li><a href="fx.html#module-torch.fx.passes">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.backends

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.backends">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.dialect

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.dialect">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.dialect.common

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.dialect.common">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.infra

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.infra">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.tests

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.tests">module</a>
</li>
      </ul></li>
      <li>
    torch.fx.passes.utils

      <ul>
        <li><a href="fx.html#module-torch.fx.passes.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.hub

      <ul>
        <li><a href="hub.html#module-torch.hub">module</a>
</li>
      </ul></li>
      <li><a href="type_info.html#torch.torch.iinfo">torch.iinfo (class in torch)</a>
</li>
      <li>
    torch.jit

      <ul>
        <li><a href="jit.html#module-torch.jit">module</a>
</li>
      </ul></li>
      <li>
    torch.jit.mobile

      <ul>
        <li><a href="jit.html#module-torch.jit.mobile">module</a>
</li>
      </ul></li>
      <li>
    torch.jit.supported_ops

      <ul>
        <li><a href="jit_builtin_functions.html#module-torch.jit.supported_ops">module</a>
</li>
      </ul></li>
      <li>
    torch.jit.unsupported_tensor_ops

      <ul>
        <li><a href="jit_unsupported.html#module-torch.jit.unsupported_tensor_ops">module</a>
</li>
      </ul></li>
      <li>
    torch.linalg

      <ul>
        <li><a href="linalg.html#module-torch.linalg">module</a>
</li>
      </ul></li>
      <li>
    torch.masked

      <ul>
        <li><a href="masked.html#module-torch.masked">module</a>
</li>
      </ul></li>
      <li>
    torch.masked.maskedtensor

      <ul>
        <li><a href="masked.html#module-torch.masked.maskedtensor">module</a>
</li>
      </ul></li>
      <li>
    torch.monitor

      <ul>
        <li><a href="monitor.html#module-torch.monitor">module</a>
</li>
      </ul></li>
      <li>
    torch.mps

      <ul>
        <li><a href="mps.html#module-torch.mps">module</a>
</li>
      </ul></li>
      <li>
    torch.multiprocessing

      <ul>
        <li><a href="multiprocessing.html#module-torch.multiprocessing">module</a>
</li>
      </ul></li>
      <li>
    torch.nested

      <ul>
        <li><a href="nested.html#module-torch.nested">module</a>
</li>
      </ul></li>
      <li>
    torch.nn

      <ul>
        <li><a href="nn.html#module-torch.nn">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.backends

      <ul>
        <li><a href="nn.html#module-torch.nn.backends">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.qat

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.qat">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.qat.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.qat.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.intrinsic.quantized.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.intrinsic.quantized.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.modules

      <ul>
        <li><a href="nn.html#module-torch.nn.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.parallel

      <ul>
        <li><a href="nn.html#module-torch.nn.parallel">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.qat">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.qat.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.qat.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.qat.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.qat.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantizable

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantizable">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantizable.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantizable.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantized">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.dynamic

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantized.dynamic">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.dynamic.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantized.dynamic.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.quantized.modules

      <ul>
        <li><a href="quantization-support.html#module-torch.nn.quantized.modules">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils

      <ul>
        <li><a href="nn.html#module-torch.nn.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.nn.utils.stateless

      <ul>
        <li><a href="nn.html#module-torch.nn.utils.stateless">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx

      <ul>
        <li><a href="onnx.html#module-torch.onnx">module</a>
</li>
      </ul></li>
      <li>
    torch.onnx._internal.diagnostics

      <ul>
        <li><a href="onnx_diagnostics.html#module-torch.onnx._internal.diagnostics">module</a>
</li>
      </ul></li>
      <li>
    torch.optim

      <ul>
        <li><a href="optim.html#module-torch.optim">module</a>
</li>
      </ul></li>
      <li>
    torch.package

      <ul>
        <li><a href="package.html#module-torch.package">module</a>
</li>
      </ul></li>
      <li>
    torch.package.analyze

      <ul>
        <li><a href="package.html#module-torch.package.analyze">module</a>
</li>
      </ul></li>
      <li>
    torch.profiler

      <ul>
        <li><a href="profiler.html#module-torch.profiler">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization

      <ul>
        <li><a href="quantization-support.html#module-torch.quantization">module</a>
</li>
      </ul></li>
      <li>
    torch.quantization.fx

      <ul>
        <li><a href="quantization-support.html#module-torch.quantization.fx">module</a>
</li>
      </ul></li>
      <li>
    torch.random

      <ul>
        <li><a href="random.html#module-torch.random">module</a>
</li>
      </ul></li>
      <li>
    torch.signal

      <ul>
        <li><a href="signal.html#module-torch.signal">module</a>
</li>
      </ul></li>
      <li>
    torch.signal.windows

      <ul>
        <li><a href="signal.html#module-torch.signal.windows">module</a>
</li>
      </ul></li>
      <li>
    torch.sparse

      <ul>
        <li><a href="sparse.html#module-torch.sparse">module</a>
</li>
      </ul></li>
      <li>
    torch.special

      <ul>
        <li><a href="special.html#module-torch.special">module</a>
</li>
      </ul></li>
      <li>
    torch.testing

      <ul>
        <li><a href="testing.html#module-torch.testing">module</a>
</li>
      </ul></li>
      <li>
    torch.utils

      <ul>
        <li><a href="torch.html#module-torch.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.backcompat

      <ul>
        <li><a href="torch.html#module-torch.utils.backcompat">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark

      <ul>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.examples

      <ul>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.examples">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.op_fuzzers

      <ul>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.op_fuzzers">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils

      <ul>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.benchmark.utils.valgrind_wrapper

      <ul>
        <li><a href="benchmark_utils.html#module-torch.utils.benchmark.utils.valgrind_wrapper">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.bottleneck

      <ul>
        <li><a href="bottleneck.html#module-torch.utils.bottleneck">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data

      <ul>
        <li><a href="data.html#module-torch.utils.data">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes

      <ul>
        <li><a href="data.html#module-torch.utils.data.datapipes">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.dataframe

      <ul>
        <li><a href="data.html#module-torch.utils.data.datapipes.dataframe">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.iter

      <ul>
        <li><a href="data.html#module-torch.utils.data.datapipes.iter">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.map

      <ul>
        <li><a href="data.html#module-torch.utils.data.datapipes.map">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.data.datapipes.utils

      <ul>
        <li><a href="data.html#module-torch.utils.data.datapipes.utils">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.hipify

      <ul>
        <li><a href="torch.html#module-torch.utils.hipify">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.jit

      <ul>
        <li><a href="jit_utils.html#module-torch.utils.jit">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.model_dump

      <ul>
        <li><a href="torch.html#module-torch.utils.model_dump">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.model_zoo

      <ul>
        <li><a href="model_zoo.html#module-torch.utils.model_zoo">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.tensorboard

      <ul>
        <li><a href="tensorboard.html#module-torch.utils.tensorboard">module</a>
</li>
      </ul></li>
      <li>
    torch.utils.viz

      <ul>
        <li><a href="torch.html#module-torch.utils.viz">module</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.JitScalarType.html#torch.onnx.JitScalarType.torch_name">torch_name() (torch.onnx.JitScalarType method)</a>
</li>
      <li><a href="generated/torch.autograd.profiler.profile.total_average.html#torch.autograd.profiler.profile.total_average">total_average() (torch.autograd.profiler.profile method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.total_count">total_count (torch.distributions.multinomial.Multinomial attribute)</a>
</li>
      <li><a href="generated/torch.trace.html#torch.trace">trace() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.jit.trace.html#torch.jit.trace">(in module torch.jit)</a>
</li>
        <li><a href="fx.html#torch.fx.Tracer.trace">(torch.fx.Tracer method)</a>
</li>
        <li><a href="generated/torch.Tensor.trace.html#torch.Tensor.trace">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.jit.trace_module.html#torch.jit.trace_module">trace_module() (in module torch.jit)</a>
</li>
      <li><a href="fx.html#torch.fx.Tracer">Tracer (class in torch.fx)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.train">train() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.train">(torch.nn.Module method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.transforms.Transform">Transform (class in torch.distributions.transforms)</a>
</li>
      <li><a href="fx.html#torch.fx.Transformer.transform">transform() (torch.fx.Transformer method)</a>

      <ul>
        <li><a href="benchmark_utils.html#torch.utils.benchmark.FunctionCounts.transform">(torch.utils.benchmark.FunctionCounts method)</a>
</li>
      </ul></li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultSavePlanner.transform_object">transform_object() (torch.distributed.checkpoint.DefaultSavePlanner method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.DefaultLoadPlanner.transform_tensor">transform_tensor() (torch.distributed.checkpoint.DefaultLoadPlanner method)</a>
</li>
      <li><a href="distributions.html#torch.distributions.transformed_distribution.TransformedDistribution">TransformedDistribution (class in torch.distributions.transformed_distribution)</a>
</li>
      <li><a href="fx.html#torch.fx.Transformer">Transformer (class in torch.fx)</a>

      <ul>
        <li><a href="generated/torch.nn.Transformer.html#torch.nn.Transformer">(class in torch.nn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.TransformerDecoder.html#torch.nn.TransformerDecoder">TransformerDecoder (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.TransformerDecoderLayer.html#torch.nn.TransformerDecoderLayer">TransformerDecoderLayer (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.TransformerEncoder.html#torch.nn.TransformerEncoder">TransformerEncoder (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.TransformerEncoderLayer.html#torch.nn.TransformerEncoderLayer">TransformerEncoderLayer (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.transpose.html#torch.transpose">transpose() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.transpose.html#torch.Tensor.transpose">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.transpose_.html#torch.Tensor.transpose_">transpose_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.trapezoid.html#torch.trapezoid">trapezoid() (in module torch)</a>
</li>
      <li><a href="generated/torch.trapz.html#torch.trapz">trapz() (in module torch)</a>
</li>
      <li><a href="generated/torch.triangular_solve.html#torch.triangular_solve">triangular_solve() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.triangular_solve.html#torch.Tensor.triangular_solve">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.tril.html#torch.tril">tril() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.tril.html#torch.Tensor.tril">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.tril_.html#torch.Tensor.tril_">tril_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.tril_indices.html#torch.tril_indices">tril_indices() (in module torch)</a>
</li>
      <li><a href="generated/torch.nn.functional.triplet_margin_loss.html#torch.nn.functional.triplet_margin_loss">triplet_margin_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.triplet_margin_with_distance_loss.html#torch.nn.functional.triplet_margin_with_distance_loss">triplet_margin_with_distance_loss() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.TripletMarginLoss.html#torch.nn.TripletMarginLoss">TripletMarginLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.TripletMarginWithDistanceLoss.html#torch.nn.TripletMarginWithDistanceLoss">TripletMarginWithDistanceLoss (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.triu.html#torch.triu">triu() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.triu.html#torch.Tensor.triu">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.triu_.html#torch.Tensor.triu_">triu_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.triu_indices.html#torch.triu_indices">triu_indices() (in module torch)</a>
</li>
      <li><a href="generated/torch.true_divide.html#torch.true_divide">true_divide() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.true_divide.html#torch.Tensor.true_divide">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.true_divide_.html#torch.Tensor.true_divide_">true_divide_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.trunc.html#torch.trunc">trunc() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.trunc.html#torch.Tensor.trunc">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.trunc_.html#torch.Tensor.trunc_">trunc_() (torch.Tensor method)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.trunc_normal_">trunc_normal_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.jit.Attribute.html#torch.jit.Attribute.type">type (torch.jit.Attribute attribute)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.type">type() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.type">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.Tensor.type.html#torch.Tensor.type">(torch.Tensor method)</a>
</li>
        <li><a href="storage.html#torch.TypedStorage.type">(torch.TypedStorage method)</a>
</li>
        <li><a href="storage.html#torch.UntypedStorage.type">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.type_as.html#torch.Tensor.type_as">type_as() (torch.Tensor method)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage">TypedStorage (class in torch)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="U">U</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.unbind.html#torch.unbind">unbind() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.unbind.html#torch.Tensor.unbind">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.Unflatten.html#torch.nn.Unflatten">Unflatten (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.unflatten.html#torch.unflatten">unflatten() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.unflatten.html#torch.Tensor.unflatten">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.Unfold.html#torch.nn.Unfold">Unfold (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.unfold.html#torch.nn.functional.unfold">unfold() (in module torch.nn.functional)</a>

      <ul>
        <li><a href="generated/torch.Tensor.unfold.html#torch.Tensor.unfold">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.uniform.Uniform">Uniform (class in torch.distributions.uniform)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.uniform_">uniform_() (in module torch.nn.init)</a>

      <ul>
        <li><a href="generated/torch.Tensor.uniform_.html#torch.Tensor.uniform_">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.nn.parameter.UninitializedBuffer.html#torch.nn.parameter.UninitializedBuffer">UninitializedBuffer (class in torch.nn.parameter)</a>
</li>
      <li><a href="generated/torch.nn.parameter.UninitializedParameter.html#torch.nn.parameter.UninitializedParameter">UninitializedParameter (class in torch.nn.parameter)</a>
</li>
      <li><a href="generated/torch.unique.html#torch.unique">unique() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.unique.html#torch.Tensor.unique">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.unique_consecutive.html#torch.unique_consecutive">unique_consecutive() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.unique_consecutive.html#torch.Tensor.unique_consecutive">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.autograd.forward_ad.unpack_dual.html#torch.autograd.forward_ad.unpack_dual">unpack_dual() (in module torch.autograd.forward_ad)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.unpack_sequence.html#torch.nn.utils.rnn.unpack_sequence">unpack_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.unpad_sequence.html#torch.nn.utils.rnn.unpad_sequence">unpad_sequence() (in module torch.nn.utils.rnn)</a>
</li>
      <li><a href="onnx.html#torch.onnx.unregister_custom_op_symbolic">unregister_custom_op_symbolic() (in module torch.onnx)</a>
</li>
      <li><a href="monitor.html#torch.monitor.unregister_event_handler">unregister_event_handler() (in module torch.monitor)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.unscale_">unscale_() (torch.cuda.amp.GradScaler method)</a>
</li>
      <li><a href="generated/torch.nn.utils.rnn.PackedSequence.html#torch.nn.utils.rnn.PackedSequence.unsorted_indices">unsorted_indices (torch.nn.utils.rnn.PackedSequence attribute)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.unsqueeze.html#torch.unsqueeze">unsqueeze() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.unsqueeze.html#torch.Tensor.unsqueeze">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.unsqueeze_.html#torch.Tensor.unsqueeze_">unsqueeze_() (torch.Tensor method)</a>
</li>
      <li><a href="storage.html#torch.TypedStorage.untyped">untyped() (torch.TypedStorage method)</a>

      <ul>
        <li><a href="storage.html#torch.UntypedStorage.untyped">(torch.UntypedStorage method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.Tensor.untyped_storage.html#torch.Tensor.untyped_storage">untyped_storage() (torch.Tensor method)</a>
</li>
      <li><a href="storage.html#torch.UntypedStorage">UntypedStorage (class in torch)</a>
</li>
      <li><a href="generated/torch.jit.unused.html#torch.jit.unused">unused() (in module torch.jit)</a>
</li>
      <li><a href="amp.html#torch.cuda.amp.GradScaler.update">update() (torch.cuda.amp.GradScaler method)</a>

      <ul>
        <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.update">(torch.nn.ModuleDict method)</a>
</li>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.update">(torch.nn.ParameterDict method)</a>
</li>
      </ul></li>
      <li><a href="fx.html#torch.fx.Node.update_arg">update_arg() (torch.fx.Node method)</a>
</li>
      <li><a href="generated/torch.ao.nn.intrinsic.qat.update_bn_stats.html#torch.ao.nn.intrinsic.qat.update_bn_stats">update_bn_stats (class in torch.ao.nn.intrinsic.qat)</a>
</li>
      <li><a href="fx.html#torch.fx.Node.update_kwarg">update_kwarg() (torch.fx.Node method)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.upsample.html#torch.ao.nn.quantized.functional.upsample">upsample (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.Upsample.html#torch.nn.Upsample">Upsample (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.functional.upsample.html#torch.nn.functional.upsample">upsample() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.upsample_bilinear.html#torch.ao.nn.quantized.functional.upsample_bilinear">upsample_bilinear (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.upsample_bilinear.html#torch.nn.functional.upsample_bilinear">upsample_bilinear() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.ao.nn.quantized.functional.upsample_nearest.html#torch.ao.nn.quantized.functional.upsample_nearest">upsample_nearest (class in torch.ao.nn.quantized.functional)</a>
</li>
      <li><a href="generated/torch.nn.functional.upsample_nearest.html#torch.nn.functional.upsample_nearest">upsample_nearest() (in module torch.nn.functional)</a>
</li>
      <li><a href="generated/torch.nn.UpsamplingBilinear2d.html#torch.nn.UpsamplingBilinear2d">UpsamplingBilinear2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.UpsamplingNearest2d.html#torch.nn.UpsamplingNearest2d">UpsamplingNearest2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms">use_deterministic_algorithms() (in module torch)</a>
</li>
      <li><a href="generated/torch.cuda.utilization.html#torch.cuda.utilization">utilization() (in module torch.cuda)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="V">V</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.jit.Attribute.html#torch.jit.Attribute.value">value (torch.jit.Attribute attribute)</a>
</li>
      <li><a href="futures.html#torch.futures.Future.value">value() (torch.futures.Future method)</a>
</li>
      <li><a href="generated/torch.nn.ModuleDict.html#torch.nn.ModuleDict.values">values() (torch.nn.ModuleDict method)</a>

      <ul>
        <li><a href="generated/torch.nn.ParameterDict.html#torch.nn.ParameterDict.values">(torch.nn.ParameterDict method)</a>
</li>
        <li><a href="generated/torch.Tensor.values.html#torch.Tensor.values">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.vander.html#torch.vander">vander() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.linalg.vander.html#torch.linalg.vander">(in module torch.linalg)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.var.html#torch.var">var() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.var.html#torch.Tensor.var">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.var_mean.html#torch.var_mean">var_mean() (in module torch)</a>
</li>
      <li><a href="distributions.html#torch.distributions.bernoulli.Bernoulli.variance">variance (torch.distributions.bernoulli.Bernoulli property)</a>

      <ul>
        <li><a href="distributions.html#torch.distributions.beta.Beta.variance">(torch.distributions.beta.Beta property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.binomial.Binomial.variance">(torch.distributions.binomial.Binomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.categorical.Categorical.variance">(torch.distributions.categorical.Categorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.cauchy.Cauchy.variance">(torch.distributions.cauchy.Cauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.continuous_bernoulli.ContinuousBernoulli.variance">(torch.distributions.continuous_bernoulli.ContinuousBernoulli property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.dirichlet.Dirichlet.variance">(torch.distributions.dirichlet.Dirichlet property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.distribution.Distribution.variance">(torch.distributions.distribution.Distribution property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.exponential.Exponential.variance">(torch.distributions.exponential.Exponential property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.fishersnedecor.FisherSnedecor.variance">(torch.distributions.fishersnedecor.FisherSnedecor property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gamma.Gamma.variance">(torch.distributions.gamma.Gamma property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.geometric.Geometric.variance">(torch.distributions.geometric.Geometric property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.gumbel.Gumbel.variance">(torch.distributions.gumbel.Gumbel property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_cauchy.HalfCauchy.variance">(torch.distributions.half_cauchy.HalfCauchy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.half_normal.HalfNormal.variance">(torch.distributions.half_normal.HalfNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.independent.Independent.variance">(torch.distributions.independent.Independent property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.kumaraswamy.Kumaraswamy.variance">(torch.distributions.kumaraswamy.Kumaraswamy property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.laplace.Laplace.variance">(torch.distributions.laplace.Laplace property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.log_normal.LogNormal.variance">(torch.distributions.log_normal.LogNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.variance">(torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.mixture_same_family.MixtureSameFamily.variance">(torch.distributions.mixture_same_family.MixtureSameFamily property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multinomial.Multinomial.variance">(torch.distributions.multinomial.Multinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.multivariate_normal.MultivariateNormal.variance">(torch.distributions.multivariate_normal.MultivariateNormal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.negative_binomial.NegativeBinomial.variance">(torch.distributions.negative_binomial.NegativeBinomial property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.normal.Normal.variance">(torch.distributions.normal.Normal property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.one_hot_categorical.OneHotCategorical.variance">(torch.distributions.one_hot_categorical.OneHotCategorical property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.pareto.Pareto.variance">(torch.distributions.pareto.Pareto property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.poisson.Poisson.variance">(torch.distributions.poisson.Poisson property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.studentT.StudentT.variance">(torch.distributions.studentT.StudentT property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.uniform.Uniform.variance">(torch.distributions.uniform.Uniform property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.von_mises.VonMises.variance">(torch.distributions.von_mises.VonMises property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.weibull.Weibull.variance">(torch.distributions.weibull.Weibull property)</a>
</li>
        <li><a href="distributions.html#torch.distributions.wishart.Wishart.variance">(torch.distributions.wishart.Wishart property)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.vdot.html#torch.vdot">vdot() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.vdot.html#torch.Tensor.vdot">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.linalg.vecdot.html#torch.linalg.vecdot">vecdot() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.linalg.vector_norm.html#torch.linalg.vector_norm">vector_norm() (in module torch.linalg)</a>
</li>
      <li><a href="generated/torch.nn.utils.vector_to_parameters.html#torch.nn.utils.vector_to_parameters">vector_to_parameters() (in module torch.nn.utils)</a>
</li>
      <li><a href="backends.html#torch.backends.mkl.verbose">verbose (class in torch.backends.mkl)</a>

      <ul>
        <li><a href="backends.html#torch.backends.mkldnn.verbose">(class in torch.backends.mkldnn)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.onnx.verification.VerificationOptions.html#torch.onnx.verification.VerificationOptions">VerificationOptions (class in torch.onnx.verification)</a>
</li>
      <li><a href="generated/torch.onnx.verification.GraphInfo.html#torch.onnx.verification.GraphInfo.verify_export">verify_export() (torch.onnx.verification.GraphInfo method)</a>
</li>
      <li><a href="cpp_extension.html#torch.utils.cpp_extension.verify_ninja_availability">verify_ninja_availability() (in module torch.utils.cpp_extension)</a>
</li>
      <li><a href="pipeline.html#torch.distributed.pipeline.sync.skip.skippable.verify_skippables">verify_skippables() (in module torch.distributed.pipeline.sync.skip.skippable)</a>
</li>
      <li><a href="backends.html#torch.backends.cudnn.version">version() (in module torch.backends.cudnn)</a>
</li>
      <li><a href="generated/torch.autograd.functional.vhp.html#torch.autograd.functional.vhp">vhp() (in module torch.autograd.functional)</a>
</li>
      <li><a href="generated/torch.Tensor.view.html#torch.Tensor.view">view() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.Tensor.view_as.html#torch.Tensor.view_as">view_as() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.view_as_complex.html#torch.view_as_complex">view_as_complex() (in module torch)</a>
</li>
      <li><a href="generated/torch.view_as_real.html#torch.view_as_real">view_as_real() (in module torch)</a>
</li>
      <li><a href="generated/torch.autograd.functional.vjp.html#torch.autograd.functional.vjp">vjp() (in module torch.autograd.functional)</a>

      <ul>
        <li><a href="generated/torch.func.vjp.html#torch.func.vjp">(in module torch.func)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.vmap.html#torch.vmap">vmap() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.func.vmap.html#torch.func.vmap">(in module torch.func)</a>
</li>
        <li><a href="generated/torch.autograd.Function.vmap.html#torch.autograd.Function.vmap">(torch.autograd.Function static method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.von_mises.VonMises">VonMises (class in torch.distributions.von_mises)</a>
</li>
      <li><a href="generated/torch.vsplit.html#torch.vsplit">vsplit() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.vsplit.html#torch.Tensor.vsplit">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.vstack.html#torch.vstack">vstack() (in module torch)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="W">W</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="distributed.html#torch.distributed.Store.wait">wait() (in module torch.distributed.Store)</a>

      <ul>
        <li><a href="generated/torch.jit.wait.html#torch.jit.wait">(in module torch.jit)</a>
</li>
        <li><a href="generated/torch.cuda.Event.html#torch.cuda.Event.wait">(torch.cuda.Event method)</a>
</li>
        <li><a href="elastic/rendezvous.html#torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.wait">(torch.distributed.elastic.rendezvous.etcd_store.EtcdStore method)</a>
</li>
        <li><a href="futures.html#torch.futures.Future.wait">(torch.futures.Future method)</a>
</li>
      </ul></li>
      <li><a href="futures.html#torch.futures.wait_all">wait_all() (in module torch.futures)</a>
</li>
      <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream.wait_event">wait_event() (torch.cuda.ExternalStream method)</a>

      <ul>
        <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream.wait_event">(torch.cuda.Stream method)</a>
</li>
      </ul></li>
      <li><a href="generated/torch.cuda.ExternalStream.html#torch.cuda.ExternalStream.wait_stream">wait_stream() (torch.cuda.ExternalStream method)</a>

      <ul>
        <li><a href="generated/torch.cuda.Stream.html#torch.cuda.Stream.wait_stream">(torch.cuda.Stream method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.weibull.Weibull">Weibull (class in torch.distributions.weibull)</a>
</li>
      <li><a href="generated/torch.nn.utils.weight_norm.html#torch.nn.utils.weight_norm">weight_norm() (in module torch.nn.utils)</a>
</li>
      <li><a href="data.html#torch.utils.data.WeightedRandomSampler">WeightedRandomSampler (class in torch.utils.data)</a>
</li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.where.html#torch.where">where() (in module torch)</a>

      <ul>
        <li><a href="generated/torch.Tensor.where.html#torch.Tensor.where">(torch.Tensor method)</a>
</li>
      </ul></li>
      <li><a href="distributions.html#torch.distributions.wishart.Wishart">Wishart (class in torch.distributions.wishart)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.ObserverBase.html#torch.ao.quantization.observer.ObserverBase.with_args">with_args() (torch.ao.quantization.observer.ObserverBase class method)</a>
</li>
      <li><a href="generated/torch.ao.quantization.observer.ObserverBase.html#torch.ao.quantization.observer.ObserverBase.with_callable_args">with_callable_args() (torch.ao.quantization.observer.ObserverBase class method)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.Worker">Worker (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.WorkerGroup">WorkerGroup (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="rpc.html#torch.distributed.rpc.WorkerInfo">WorkerInfo (class in torch.distributed.rpc)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.WorkerSpec">WorkerSpec (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="elastic/agent.html#torch.distributed.elastic.agent.server.WorkerState">WorkerState (class in torch.distributed.elastic.agent.server)</a>
</li>
      <li><a href="fx.html#torch.fx.wrap">wrap() (in module torch.fx)</a>
</li>
      <li><a href="torch.overrides.html#torch.overrides.wrap_torch_function">wrap_torch_function() (in module torch.overrides)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.StorageWriter.write_data">write_data() (torch.distributed.checkpoint.StorageWriter method)</a>
</li>
      <li><a href="distributed.checkpoint.html#torch.distributed.checkpoint.WriteItem">WriteItem (class in torch.distributed.checkpoint)</a>
</li>
  </ul></td>
</tr></table>

<h2 id="X">X</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="nn.init.html#torch.nn.init.xavier_normal_">xavier_normal_() (in module torch.nn.init)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.xavier_uniform_">xavier_uniform_() (in module torch.nn.init)</a>
</li>
      <li><a href="special.html#torch.special.xlog1py">xlog1py() (in module torch.special)</a>
</li>
      <li><a href="generated/torch.xlogy.html#torch.xlogy">xlogy() (in module torch)</a>

      <ul>
        <li><a href="special.html#torch.special.xlogy">(in module torch.special)</a>
</li>
        <li><a href="generated/torch.Tensor.xlogy.html#torch.Tensor.xlogy">(torch.Tensor method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.Tensor.xlogy_.html#torch.Tensor.xlogy_">xlogy_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.xpu">xpu() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.xpu">(torch.nn.Module method)</a>
</li>
      </ul></li>
  </ul></td>
</tr></table>

<h2 id="Z">Z</h2>
<table style="width: 100%" class="indextable genindextable"><tr>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.Tensor.zero_.html#torch.Tensor.zero_">zero_() (torch.Tensor method)</a>
</li>
      <li><a href="generated/torch.jit.ScriptModule.html#torch.jit.ScriptModule.zero_grad">zero_grad() (torch.jit.ScriptModule method)</a>

      <ul>
        <li><a href="generated/torch.nn.Module.html#torch.nn.Module.zero_grad">(torch.nn.Module method)</a>
</li>
        <li><a href="generated/torch.optim.Adadelta.html#torch.optim.Adadelta.zero_grad">(torch.optim.Adadelta method)</a>
</li>
        <li><a href="generated/torch.optim.Adagrad.html#torch.optim.Adagrad.zero_grad">(torch.optim.Adagrad method)</a>
</li>
        <li><a href="generated/torch.optim.Adam.html#torch.optim.Adam.zero_grad">(torch.optim.Adam method)</a>
</li>
        <li><a href="generated/torch.optim.Adamax.html#torch.optim.Adamax.zero_grad">(torch.optim.Adamax method)</a>
</li>
        <li><a href="generated/torch.optim.AdamW.html#torch.optim.AdamW.zero_grad">(torch.optim.AdamW method)</a>
</li>
        <li><a href="generated/torch.optim.ASGD.html#torch.optim.ASGD.zero_grad">(torch.optim.ASGD method)</a>
</li>
        <li><a href="generated/torch.optim.LBFGS.html#torch.optim.LBFGS.zero_grad">(torch.optim.LBFGS method)</a>
</li>
        <li><a href="generated/torch.optim.NAdam.html#torch.optim.NAdam.zero_grad">(torch.optim.NAdam method)</a>
</li>
        <li><a href="generated/torch.optim.Optimizer.zero_grad.html#torch.optim.Optimizer.zero_grad">(torch.optim.Optimizer method)</a>
</li>
        <li><a href="generated/torch.optim.RAdam.html#torch.optim.RAdam.zero_grad">(torch.optim.RAdam method)</a>
</li>
        <li><a href="generated/torch.optim.RMSprop.html#torch.optim.RMSprop.zero_grad">(torch.optim.RMSprop method)</a>
</li>
        <li><a href="generated/torch.optim.Rprop.html#torch.optim.Rprop.zero_grad">(torch.optim.Rprop method)</a>
</li>
        <li><a href="generated/torch.optim.SGD.html#torch.optim.SGD.zero_grad">(torch.optim.SGD method)</a>
</li>
        <li><a href="generated/torch.optim.SparseAdam.html#torch.optim.SparseAdam.zero_grad">(torch.optim.SparseAdam method)</a>
</li>
      </ul></li>
  </ul></td>
  <td style="width: 33%; vertical-align: top;"><ul>
      <li><a href="generated/torch.nn.ZeroPad1d.html#torch.nn.ZeroPad1d">ZeroPad1d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ZeroPad2d.html#torch.nn.ZeroPad2d">ZeroPad2d (class in torch.nn)</a>
</li>
      <li><a href="generated/torch.nn.ZeroPad3d.html#torch.nn.ZeroPad3d">ZeroPad3d (class in torch.nn)</a>
</li>
      <li><a href="distributed.optim.html#torch.distributed.optim.ZeroRedundancyOptimizer">ZeroRedundancyOptimizer (class in torch.distributed.optim)</a>
</li>
      <li><a href="generated/torch.zeros.html#torch.zeros">zeros() (in module torch)</a>
</li>
      <li><a href="nn.init.html#torch.nn.init.zeros_">zeros_() (in module torch.nn.init)</a>
</li>
      <li><a href="generated/torch.zeros_like.html#torch.zeros_like">zeros_like() (in module torch)</a>
</li>
      <li><a href="special.html#torch.special.zeta">zeta() (in module torch.special)</a>
</li>
  </ul></td>
</tr></table>



             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/sphinx_highlight.js"></script>
         <script src="_static/clipboard.min.js"></script>
         <script src="_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>