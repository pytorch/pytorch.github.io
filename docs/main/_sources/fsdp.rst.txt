FullyShardedDataParallel
========================

.. automodule:: torch.distributed.fsdp

.. autoclass:: torch.distributed.fsdp.FullyShardedDataParallel
  :members:

.. autoclass:: torch.distributed.fsdp.BackwardPrefetch
  :members:

.. autoclass:: torch.distributed.fsdp.ShardingStrategy
  :members:

.. autoclass:: torch.distributed.fsdp.MixedPrecision
  :members:

.. autoclass:: torch.distributed.fsdp.CPUOffload
  :members:

.. autoclass:: torch.distributed.fsdp.StateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.FullStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.ShardedStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.LocalStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.OptimStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.FullOptimStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.ShardedOptimStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.LocalOptimStateDictConfig
  :members:

.. autoclass:: torch.distributed.fsdp.StateDictSettings
  :members:
