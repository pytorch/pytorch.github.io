

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Probability distributions - torch.distributions &mdash; PyTorch master documentation</title>
  

  
  
  
  

  

  
  
    

  

  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  <link rel="stylesheet" href="_static/css/pytorch_theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Multiprocessing package - torch.multiprocessing" href="multiprocessing.html" />
    <link rel="prev" title="Automatic differentiation package - torch.autograd" href="autograd.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html">
          

          
            
            <img src="_static/pytorch-logo-dark.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.4.0 <br/> <a href="https://pytorch.org/docs/versions.html"> version selector &#x25BC</a>
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          

            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd mechanics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#excluding-subgraphs-from-backward">Excluding subgraphs from backward</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/autograd.html#requires-grad"><code class="docutils literal"><span class="pre">requires_grad</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#how-autograd-encodes-the-history">How autograd encodes the history</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#in-place-operations-with-autograd">In-place operations with autograd</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#in-place-correctness-checks">In-place correctness checks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">Broadcasting semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/broadcasting.html#general-semantics">General semantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/broadcasting.html#in-place-semantics">In-place semantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/broadcasting.html#backwards-compatibility">Backwards compatibility</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/cuda.html#asynchronous-execution">Asynchronous execution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/cuda.html#cuda-streams">CUDA streams</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/cuda.html#memory-management">Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/cuda.html#best-practices">Best practices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/cuda.html#device-agnostic-code">Device-agnostic code</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/cuda.html#use-pinned-memory-buffers">Use pinned memory buffers</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/cuda.html#use-nn-dataparallel-instead-of-multiprocessing">Use nn.DataParallel instead of multiprocessing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">Extending PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/extending.html#extending-torch-autograd">Extending <code class="docutils literal"><span class="pre">torch.autograd</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/extending.html#extending-torch-nn">Extending <code class="docutils literal"><span class="pre">torch.nn</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/extending.html#adding-a-module">Adding a <code class="docutils literal"><span class="pre">Module</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/extending.html#writing-custom-c-extensions">Writing custom C extensions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/faq.html">Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/faq.html#my-model-reports-cuda-runtime-error-2-out-of-memory">My model reports &#8220;cuda runtime error(2): out of memory&#8221;</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/faq.html#my-gpu-memory-isn-t-freed-properly">My GPU memory isn&#8217;t freed properly</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/faq.html#my-data-loader-workers-return-identical-random-numbers">My data loader workers return identical random numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/faq.html#my-recurrent-network-doesn-t-work-with-data-parallelism">My recurrent network doesn&#8217;t work with data parallelism</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">Multiprocessing best practices</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/multiprocessing.html#sharing-cuda-tensors">Sharing CUDA tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/multiprocessing.html#best-practices-and-tips">Best practices and tips</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/multiprocessing.html#avoiding-and-fighting-deadlocks">Avoiding and fighting deadlocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/multiprocessing.html#reuse-buffers-passed-through-a-queue">Reuse buffers passed through a Queue</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/multiprocessing.html#asynchronous-multiprocess-training-e-g-hogwild">Asynchronous multiprocess training (e.g. Hogwild)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="notes/multiprocessing.html#hogwild">Hogwild</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">Serialization semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/serialization.html#best-practices">Best practices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/serialization.html#recommended-approach-for-saving-a-model">Recommended approach for saving a model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/windows.html">Windows FAQ</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/windows.html#building-from-source">Building from source</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#include-optional-components">Include optional components</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#speeding-cuda-build-for-windows">Speeding CUDA build for Windows</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#one-key-install-script">One key install script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/windows.html#extension">Extension</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#cffi-extension">CFFI Extension</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#cpp-extension">Cpp Extension</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/windows.html#installation">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#package-not-found-in-win-32-channel">Package not found in win-32 channel.</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#why-are-there-no-python-2-packages-for-windows">Why are there no Python 2 packages for Windows?</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#import-error">Import error</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/windows.html#usage-multiprocessing">Usage (multiprocessing)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#multiprocessing-error-without-if-clause-protection">Multiprocessing error without if-clause protection</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#multiprocessing-error-broken-pipe">Multiprocessing error &#8220;Broken pipe&#8221;</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#multiprocessing-error-driver-shut-down">Multiprocessing error &#8220;driver shut down&#8221;</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/windows.html#cuda-ipc-operations">CUDA IPC operations</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="torch.html">torch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="torch.html#tensors">Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.html#creation-ops">Creation Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#indexing-slicing-joining-mutating-ops">Indexing, Slicing, Joining, Mutating Ops</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torch.html#random-sampling">Random sampling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.html#in-place-random-sampling">In-place random sampling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torch.html#serialization">Serialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.html#parallelism">Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.html#locally-disabling-gradient-computation">Locally disabling gradient computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="torch.html#math-operations">Math operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torch.html#pointwise-ops">Pointwise Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#reduction-ops">Reduction Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#comparison-ops">Comparison Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#spectral-ops">Spectral Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#other-operations">Other Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="torch.html#blas-and-lapack-operations">BLAS and LAPACK Operations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tensor_attributes.html#torch-dtype">torch.dtype</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_attributes.html#torch-device">torch.device</a></li>
<li class="toctree-l2"><a class="reference internal" href="tensor_attributes.html#torch-layout">torch.layout</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#random-number-generator">Random Number Generator</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#communication-collectives">Communication collectives</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#streams-and-events">Streams and events</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#memory-management">Memory management</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#nvidia-tools-extension-nvtx">NVIDIA Tools Extension (NVTX)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">torch.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nn.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#containers">Containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#module"><span class="hidden-section">Module</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#sequential"><span class="hidden-section">Sequential</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#modulelist"><span class="hidden-section">ModuleList</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#parameterlist"><span class="hidden-section">ParameterList</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#convolution-layers">Convolution layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv1d"><span class="hidden-section">Conv1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv2d"><span class="hidden-section">Conv2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv3d"><span class="hidden-section">Conv3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#convtranspose1d"><span class="hidden-section">ConvTranspose1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#convtranspose2d"><span class="hidden-section">ConvTranspose2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#convtranspose3d"><span class="hidden-section">ConvTranspose3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#pooling-layers">Pooling layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxpool1d"><span class="hidden-section">MaxPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxpool2d"><span class="hidden-section">MaxPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxpool3d"><span class="hidden-section">MaxPool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxunpool1d"><span class="hidden-section">MaxUnpool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxunpool2d"><span class="hidden-section">MaxUnpool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxunpool3d"><span class="hidden-section">MaxUnpool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avgpool1d"><span class="hidden-section">AvgPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avgpool2d"><span class="hidden-section">AvgPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avgpool3d"><span class="hidden-section">AvgPool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#fractionalmaxpool2d"><span class="hidden-section">FractionalMaxPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lppool1d"><span class="hidden-section">LPPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lppool2d"><span class="hidden-section">LPPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptivemaxpool1d"><span class="hidden-section">AdaptiveMaxPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptivemaxpool2d"><span class="hidden-section">AdaptiveMaxPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptivemaxpool3d"><span class="hidden-section">AdaptiveMaxPool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptiveavgpool1d"><span class="hidden-section">AdaptiveAvgPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptiveavgpool2d"><span class="hidden-section">AdaptiveAvgPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptiveavgpool3d"><span class="hidden-section">AdaptiveAvgPool3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#padding-layers">Padding layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#reflectionpad1d"><span class="hidden-section">ReflectionPad1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#reflectionpad2d"><span class="hidden-section">ReflectionPad2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#replicationpad1d"><span class="hidden-section">ReplicationPad1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#replicationpad2d"><span class="hidden-section">ReplicationPad2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#replicationpad3d"><span class="hidden-section">ReplicationPad3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#zeropad2d"><span class="hidden-section">ZeroPad2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#constantpad1d"><span class="hidden-section">ConstantPad1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#constantpad2d"><span class="hidden-section">ConstantPad2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#constantpad3d"><span class="hidden-section">ConstantPad3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#non-linear-activations-weighted-sum-nonlinearity">Non-linear activations (weighted sum, nonlinearity)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#elu"><span class="hidden-section">ELU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hardshrink"><span class="hidden-section">Hardshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hardtanh"><span class="hidden-section">Hardtanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#leakyrelu"><span class="hidden-section">LeakyReLU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#logsigmoid"><span class="hidden-section">LogSigmoid</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#prelu"><span class="hidden-section">PReLU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#relu"><span class="hidden-section">ReLU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#relu6"><span class="hidden-section">ReLU6</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#rrelu"><span class="hidden-section">RReLU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#selu"><span class="hidden-section">SELU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#sigmoid"><span class="hidden-section">Sigmoid</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softplus"><span class="hidden-section">Softplus</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softshrink"><span class="hidden-section">Softshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softsign"><span class="hidden-section">Softsign</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#tanh"><span class="hidden-section">Tanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#tanhshrink"><span class="hidden-section">Tanhshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#threshold"><span class="hidden-section">Threshold</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#non-linear-activations-other">Non-linear activations (other)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softmin"><span class="hidden-section">Softmin</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softmax"><span class="hidden-section">Softmax</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softmax2d"><span class="hidden-section">Softmax2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#logsoftmax"><span class="hidden-section">LogSoftmax</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#normalization-layers">Normalization layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batchnorm1d"><span class="hidden-section">BatchNorm1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batchnorm2d"><span class="hidden-section">BatchNorm2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batchnorm3d"><span class="hidden-section">BatchNorm3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#instancenorm1d"><span class="hidden-section">InstanceNorm1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#instancenorm2d"><span class="hidden-section">InstanceNorm2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#instancenorm3d"><span class="hidden-section">InstanceNorm3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#layernorm"><span class="hidden-section">LayerNorm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#localresponsenorm"><span class="hidden-section">LocalResponseNorm</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#recurrent-layers">Recurrent layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#rnn"><span class="hidden-section">RNN</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lstm"><span class="hidden-section">LSTM</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#gru"><span class="hidden-section">GRU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#rnncell"><span class="hidden-section">RNNCell</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lstmcell"><span class="hidden-section">LSTMCell</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#grucell"><span class="hidden-section">GRUCell</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#linear-layers">Linear layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#linear"><span class="hidden-section">Linear</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#bilinear"><span class="hidden-section">Bilinear</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#dropout-layers">Dropout layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dropout"><span class="hidden-section">Dropout</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dropout2d"><span class="hidden-section">Dropout2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dropout3d"><span class="hidden-section">Dropout3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#alphadropout"><span class="hidden-section">AlphaDropout</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#sparse-layers">Sparse layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#embedding"><span class="hidden-section">Embedding</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#embeddingbag"><span class="hidden-section">EmbeddingBag</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#distance-functions">Distance functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosinesimilarity"><span class="hidden-section">CosineSimilarity</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pairwisedistance"><span class="hidden-section">PairwiseDistance</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#loss-functions">Loss functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#l1loss"><span class="hidden-section">L1Loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#mseloss"><span class="hidden-section">MSELoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#crossentropyloss"><span class="hidden-section">CrossEntropyLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#nllloss"><span class="hidden-section">NLLLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#poissonnllloss"><span class="hidden-section">PoissonNLLLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#kldivloss"><span class="hidden-section">KLDivLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#bceloss"><span class="hidden-section">BCELoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#bcewithlogitsloss"><span class="hidden-section">BCEWithLogitsLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#marginrankingloss"><span class="hidden-section">MarginRankingLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hingeembeddingloss"><span class="hidden-section">HingeEmbeddingLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabelmarginloss"><span class="hidden-section">MultiLabelMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#smoothl1loss"><span class="hidden-section">SmoothL1Loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softmarginloss"><span class="hidden-section">SoftMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabelsoftmarginloss"><span class="hidden-section">MultiLabelSoftMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosineembeddingloss"><span class="hidden-section">CosineEmbeddingLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multimarginloss"><span class="hidden-section">MultiMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#tripletmarginloss"><span class="hidden-section">TripletMarginLoss</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#vision-layers">Vision layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pixelshuffle"><span class="hidden-section">PixelShuffle</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsample"><span class="hidden-section">Upsample</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsamplingnearest2d"><span class="hidden-section">UpsamplingNearest2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsamplingbilinear2d"><span class="hidden-section">UpsamplingBilinear2d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#dataparallel-layers-multi-gpu-distributed">DataParallel layers (multi-GPU, distributed)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dataparallel"><span class="hidden-section">DataParallel</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#distributeddataparallel"><span class="hidden-section">DistributedDataParallel</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#utilities">Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#clip-grad-norm"><span class="hidden-section">clip_grad_norm_</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#clip-grad-value"><span class="hidden-section">clip_grad_value_</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#weight-norm"><span class="hidden-section">weight_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#remove-weight-norm"><span class="hidden-section">remove_weight_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#packedsequence"><span class="hidden-section">PackedSequence</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pack-padded-sequence"><span class="hidden-section">pack_padded_sequence</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pad-packed-sequence"><span class="hidden-section">pad_packed_sequence</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pad-sequence"><span class="hidden-section">pad_sequence</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pack-sequence"><span class="hidden-section">pack_sequence</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nn.html#torch-nn-functional">torch.nn.functional</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nn.html#convolution-functions">Convolution functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id20"><span class="hidden-section">conv1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id21"><span class="hidden-section">conv2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id22"><span class="hidden-section">conv3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv-transpose1d"><span class="hidden-section">conv_transpose1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv-transpose2d"><span class="hidden-section">conv_transpose2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv-transpose3d"><span class="hidden-section">conv_transpose3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#pooling-functions">Pooling functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avg-pool1d"><span class="hidden-section">avg_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avg-pool2d"><span class="hidden-section">avg_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avg-pool3d"><span class="hidden-section">avg_pool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-pool1d"><span class="hidden-section">max_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-pool2d"><span class="hidden-section">max_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-pool3d"><span class="hidden-section">max_pool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-unpool1d"><span class="hidden-section">max_unpool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-unpool2d"><span class="hidden-section">max_unpool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-unpool3d"><span class="hidden-section">max_unpool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lp-pool1d"><span class="hidden-section">lp_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lp-pool2d"><span class="hidden-section">lp_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-max-pool1d"><span class="hidden-section">adaptive_max_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-max-pool2d"><span class="hidden-section">adaptive_max_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-max-pool3d"><span class="hidden-section">adaptive_max_pool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-avg-pool1d"><span class="hidden-section">adaptive_avg_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-avg-pool2d"><span class="hidden-section">adaptive_avg_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-avg-pool3d"><span class="hidden-section">adaptive_avg_pool3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#non-linear-activation-functions">Non-linear activation functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id23"><span class="hidden-section">threshold</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id24"><span class="hidden-section">relu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id25"><span class="hidden-section">hardtanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id26"><span class="hidden-section">relu6</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id27"><span class="hidden-section">elu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id28"><span class="hidden-section">selu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#leaky-relu"><span class="hidden-section">leaky_relu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id29"><span class="hidden-section">prelu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id30"><span class="hidden-section">rrelu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#glu"><span class="hidden-section">glu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id31"><span class="hidden-section">logsigmoid</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id32"><span class="hidden-section">hardshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id33"><span class="hidden-section">tanhshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id34"><span class="hidden-section">softsign</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id35"><span class="hidden-section">softplus</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id36"><span class="hidden-section">softmin</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id37"><span class="hidden-section">softmax</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id38"><span class="hidden-section">softshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#log-softmax"><span class="hidden-section">log_softmax</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id39"><span class="hidden-section">tanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id40"><span class="hidden-section">sigmoid</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#normalization-functions">Normalization functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batch-norm"><span class="hidden-section">batch_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#instance-norm"><span class="hidden-section">instance_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#layer-norm"><span class="hidden-section">layer_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#local-response-norm"><span class="hidden-section">local_response_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#normalize"><span class="hidden-section">normalize</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#linear-functions">Linear functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id41"><span class="hidden-section">linear</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#dropout-functions">Dropout functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id42"><span class="hidden-section">dropout</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#alpha-dropout"><span class="hidden-section">alpha_dropout</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id43"><span class="hidden-section">dropout2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id44"><span class="hidden-section">dropout3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#id45">Distance functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pairwise-distance"><span class="hidden-section">pairwise_distance</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosine-similarity"><span class="hidden-section">cosine_similarity</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#id46">Loss functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#binary-cross-entropy"><span class="hidden-section">binary_cross_entropy</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#poisson-nll-loss"><span class="hidden-section">poisson_nll_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosine-embedding-loss"><span class="hidden-section">cosine_embedding_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cross-entropy"><span class="hidden-section">cross_entropy</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hinge-embedding-loss"><span class="hidden-section">hinge_embedding_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#kl-div"><span class="hidden-section">kl_div</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#l1-loss"><span class="hidden-section">l1_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#mse-loss"><span class="hidden-section">mse_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#margin-ranking-loss"><span class="hidden-section">margin_ranking_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabel-margin-loss"><span class="hidden-section">multilabel_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabel-soft-margin-loss"><span class="hidden-section">multilabel_soft_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multi-margin-loss"><span class="hidden-section">multi_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#nll-loss"><span class="hidden-section">nll_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#binary-cross-entropy-with-logits"><span class="hidden-section">binary_cross_entropy_with_logits</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#smooth-l1-loss"><span class="hidden-section">smooth_l1_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#soft-margin-loss"><span class="hidden-section">soft_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#triplet-margin-loss"><span class="hidden-section">triplet_margin_loss</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#vision-functions">Vision functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pixel-shuffle"><span class="hidden-section">pixel_shuffle</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pad"><span class="hidden-section">pad</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id47"><span class="hidden-section">upsample</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsample-nearest"><span class="hidden-section">upsample_nearest</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsample-bilinear"><span class="hidden-section">upsample_bilinear</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#grid-sample"><span class="hidden-section">grid_sample</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#affine-grid"><span class="hidden-section">affine_grid</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#dataparallel-functions-multi-gpu-distributed">DataParallel functions (multi-GPU, distributed)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#data-parallel"><span class="hidden-section">data_parallel</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nn.html#torch-nn-init">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a><ul>
<li class="toctree-l2"><a class="reference internal" href="optim.html#how-to-use-an-optimizer">How to use an optimizer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="optim.html#constructing-it">Constructing it</a></li>
<li class="toctree-l3"><a class="reference internal" href="optim.html#per-parameter-options">Per-parameter options</a></li>
<li class="toctree-l3"><a class="reference internal" href="optim.html#taking-an-optimization-step">Taking an optimization step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="optim.html#optimizer-step"><code class="docutils literal"><span class="pre">optimizer.step()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="optim.html#optimizer-step-closure"><code class="docutils literal"><span class="pre">optimizer.step(closure)</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="optim.html#algorithms">Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="optim.html#how-to-adjust-learning-rate">How to adjust Learning Rate</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a><ul>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#locally-disabling-gradient-computation">Locally disabling gradient computation</a></li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#in-place-operations-on-tensors">In-place operations on Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="autograd.html#in-place-correctness-checks">In-place correctness checks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#variable-deprecated">Variable (deprecated)</a></li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#tensor-autograd-functions">Tensor autograd functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#function"><span class="hidden-section">Function</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#profiler">Profiler</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">torch.distributions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#score-function">Score function</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pathwise-derivative">Pathwise derivative</a></li>
<li class="toctree-l2"><a class="reference internal" href="#distribution"><span class="hidden-section">Distribution</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#exponentialfamily"><span class="hidden-section">ExponentialFamily</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#bernoulli"><span class="hidden-section">Bernoulli</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#beta"><span class="hidden-section">Beta</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#binomial"><span class="hidden-section">Binomial</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#categorical"><span class="hidden-section">Categorical</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#cauchy"><span class="hidden-section">Cauchy</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#chi2"><span class="hidden-section">Chi2</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#dirichlet"><span class="hidden-section">Dirichlet</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#exponential"><span class="hidden-section">Exponential</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#fishersnedecor"><span class="hidden-section">FisherSnedecor</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#gamma"><span class="hidden-section">Gamma</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#geometric"><span class="hidden-section">Geometric</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#gumbel"><span class="hidden-section">Gumbel</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#independent"><span class="hidden-section">Independent</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#laplace"><span class="hidden-section">Laplace</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#lognormal"><span class="hidden-section">LogNormal</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#multinomial"><span class="hidden-section">Multinomial</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#multivariatenormal"><span class="hidden-section">MultivariateNormal</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#normal"><span class="hidden-section">Normal</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#onehotcategorical"><span class="hidden-section">OneHotCategorical</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#pareto"><span class="hidden-section">Pareto</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#poisson"><span class="hidden-section">Poisson</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#relaxedbernoulli"><span class="hidden-section">RelaxedBernoulli</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#relaxedonehotcategorical"><span class="hidden-section">RelaxedOneHotCategorical</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#studentt"><span class="hidden-section">StudentT</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#transformeddistribution"><span class="hidden-section">TransformedDistribution</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#uniform"><span class="hidden-section">Uniform</span></a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch.distributions.kl"><cite>KL Divergence</cite></a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch.distributions.transforms"><cite>Transforms</cite></a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch.distributions.constraints"><cite>Constraints</cite></a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-torch.distributions.constraint_registry"><cite>Constraint Registry</cite></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="multiprocessing.html">torch.multiprocessing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="multiprocessing.html#strategy-management">Strategy management</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiprocessing.html#sharing-cuda-tensors">Sharing CUDA tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiprocessing.html#sharing-strategies">Sharing strategies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="multiprocessing.html#file-descriptor-file-descriptor">File descriptor - <code class="docutils literal"><span class="pre">file_descriptor</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="multiprocessing.html#file-system-file-system">File system - <code class="docutils literal"><span class="pre">file_system</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a><ul>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#basics">Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#initialization">Initialization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="distributed.html#tcp-initialization">TCP initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed.html#shared-file-system-initialization">Shared file-system initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed.html#environment-variable-initialization">Environment variable initialization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#groups">Groups</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#point-to-point-communication">Point-to-point communication</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#collective-functions">Collective functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#multi-gpu-collective-functions">Multi-GPU collective functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#launch-utility">Launch utility</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="ffi.html">torch.utils.ffi</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">torch.onnx</a><ul>
<li class="toctree-l2"><a class="reference internal" href="onnx.html#example-end-to-end-alexnet-from-pytorch-to-caffe2">Example: End-to-end AlexNet from PyTorch to Caffe2</a></li>
<li class="toctree-l2"><a class="reference internal" href="onnx.html#limitations">Limitations</a></li>
<li class="toctree-l2"><a class="reference internal" href="onnx.html#supported-operators">Supported operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="onnx.html#functions">Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="legacy.html">torch.legacy</a></li>
</ul>
<p class="caption"><span class="caption-text">torchvision Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="torchvision/index.html">torchvision</a><ul>
<li class="toctree-l2"><a class="reference internal" href="torchvision/datasets.html">torchvision.datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#mnist">MNIST</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#fashion-mnist">Fashion-MNIST</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#emnist">EMNIST</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#coco">COCO</a><ul>
<li class="toctree-l4"><a class="reference internal" href="torchvision/datasets.html#captions">Captions</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchvision/datasets.html#detection">Detection</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#lsun">LSUN</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#imagefolder">ImageFolder</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#datasetfolder">DatasetFolder</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#imagenet-12">Imagenet-12</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#cifar">CIFAR</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#stl10">STL10</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#svhn">SVHN</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#phototour">PhotoTour</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/models.html">torchvision.models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#id1">Alexnet</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#id2">VGG</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#id3">ResNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#id4">SqueezeNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#id5">DenseNet</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/models.html#inception-v3">Inception v3</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/transforms.html">torchvision.transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torchvision/transforms.html#transforms-on-pil-image">Transforms on PIL Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/transforms.html#transforms-on-torch-tensor">Transforms on torch.*Tensor</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/transforms.html#conversion-transforms">Conversion Transforms</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/transforms.html#generic-transforms">Generic Transforms</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/utils.html">torchvision.utils</a></li>
</ul>
</li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PyTorch</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Probability distributions - torch.distributions</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/distributions.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-torch.distributions">
<span id="probability-distributions-torch-distributions"></span><h1>Probability distributions - torch.distributions<a class="headerlink" href="#module-torch.distributions" title="Permalink to this headline"></a></h1>
<p>The <code class="docutils literal"><span class="pre">distributions</span></code> package contains parameterizable probability distributions
and sampling functions. This allows the construction of stochastic computation
graphs and stochastic gradient estimators for optimization.</p>
<p>It is not possible to directly backpropagate through random samples. However,
there are two main methods for creating surrogate functions that can be
backpropagated through. These are the score function estimator/likelihood ratio
estimator/REINFORCE and the pathwise derivative estimator. REINFORCE is commonly
seen as the basis for policy gradient methods in reinforcement learning, and the
pathwise derivative estimator is commonly seen in the reparameterization trick
in variational autoencoders. Whilst the score function only requires the value
of samples <span class="math">\(f(x)\)</span>, the pathwise derivative requires the derivative
<span class="math">\(f'(x)\)</span>. The next sections discuss these two in a reinforcement learning
example. For more details see
<a class="reference external" href="https://arxiv.org/abs/1506.05254">Gradient Estimation Using Stochastic Computation Graphs</a> .</p>
<div class="section" id="score-function">
<h2>Score function<a class="headerlink" href="#score-function" title="Permalink to this headline"></a></h2>
<p>When the probability density function is differentiable with respect to its
parameters, we only need <code class="xref py py-meth docutils literal"><span class="pre">sample()</span></code> and
<code class="xref py py-meth docutils literal"><span class="pre">log_prob()</span></code> to implement REINFORCE:</p>
<div class="math">
\[\Delta\theta  = \alpha r \frac{\partial\log p(a|\pi^\theta(s))}{\partial\theta}\]</div>
<p>where <span class="math">\(\theta\)</span> are the parameters, <span class="math">\(\alpha\)</span> is the learning rate,
<span class="math">\(r\)</span> is the reward and <span class="math">\(p(a|\pi^\theta(s))\)</span> is the probability of
taking action <span class="math">\(a\)</span> in state <span class="math">\(s\)</span> given policy <span class="math">\(\pi^\theta\)</span>.</p>
<p>In practice we would sample an action from the output of a network, apply this
action in an environment, and then use <code class="docutils literal"><span class="pre">log_prob</span></code> to construct an equivalent
loss function. Note that we use a negative because optimizers use gradient
descent, whilst the rule above assumes gradient ascent. With a categorical
policy, the code for implementing REINFORCE would be as follows:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">probs</span> <span class="o">=</span> <span class="n">policy_network</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
<span class="c1"># Note that this is equivalent to what used to be called multinomial</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">m</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span> <span class="o">*</span> <span class="n">reward</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="pathwise-derivative">
<h2>Pathwise derivative<a class="headerlink" href="#pathwise-derivative" title="Permalink to this headline"></a></h2>
<p>The other way to implement these stochastic/policy gradients would be to use the
reparameterization trick from the
<code class="xref py py-meth docutils literal"><span class="pre">rsample()</span></code> method, where the
parameterized random variable can be constructed via a parameterized
deterministic function of a parameter-free random variable. The reparameterized
sample therefore becomes differentiable. The code for implementing the pathwise
derivative would be as follows:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="n">policy_network</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="p">)</span>
<span class="c1"># Any distribution with .has_rsample == True could work based on the application</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">rsample</span><span class="p">()</span>
<span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>  <span class="c1"># Assuming that reward is differentiable</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">reward</span>
<span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="distribution">
<h2><span class="hidden-section">Distribution</span><a class="headerlink" href="#distribution" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.distribution.Distribution">
<em class="property">class </em><code class="descclassname">torch.distributions.distribution.</code><code class="descname">Distribution</code><span class="sig-paren">(</span><em>batch_shape=torch.Size([])</em>, <em>event_shape=torch.Size([])</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.6)"><code class="xref py py-class docutils literal"><span class="pre">object</span></code></a></p>
<p>Distribution is the abstract base class for probability distributions.</p>
<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.arg_constraints">
<code class="descname">arg_constraints</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.arg_constraints" title="Permalink to this definition"></a></dt>
<dd><p>Returns a dictionary from argument names to
<a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">Constraint</span></code></a> objects that
should be satisfied by each argument of this distribution. Args that
are not tensors need not appear in this dict.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.batch_shape">
<code class="descname">batch_shape</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.batch_shape" title="Permalink to this definition"></a></dt>
<dd><p>Returns the shape over which parameters are batched.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.cdf" title="Permalink to this definition"></a></dt>
<dd><p>Returns the cumulative density/mass function evaluated at
<cite>value</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>value</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; </td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.entropy" title="Permalink to this definition"></a></dt>
<dd><p>Returns entropy of distribution, batched over batch_shape.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Tensor of shape batch_shape.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.enumerate_support" title="Permalink to this definition"></a></dt>
<dd><p>Returns tensor containing all values supported by a discrete
distribution. The result will enumerate over dimension 0, so the shape
of the result will be <cite>(cardinality,) + batch_shape + event_shape</cite>
(where <cite>event_shape = ()</cite> for univariate distributions).</p>
<p>Note that this enumerates over all batched tensors in lock-step
<cite>[[0, 0], [1, 1], ...]</cite>. To iterate over the full Cartesian product
use <cite>itertools.product(m.enumerate_support())</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Tensor iterating over dimension 0.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.event_shape">
<code class="descname">event_shape</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.event_shape" title="Permalink to this definition"></a></dt>
<dd><p>Returns the shape of a single sample (without batching).</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.icdf" title="Permalink to this definition"></a></dt>
<dd><p>Returns the inverse cumulative density/mass function evaluated at
<cite>value</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>value</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; </td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Returns the log of the probability density/mass function evaluated at
<cite>value</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>value</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; </td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.mean" title="Permalink to this definition"></a></dt>
<dd><p>Returns the mean of the distribution.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.perplexity">
<code class="descname">perplexity</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.perplexity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.perplexity" title="Permalink to this definition"></a></dt>
<dd><p>Returns perplexity of distribution, batched over batch_shape.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">Tensor of shape batch_shape.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.rsample" title="Permalink to this definition"></a></dt>
<dd><p>Generates a sample_shape shaped reparameterized sample or sample_shape
shaped batch of reparameterized samples if the distribution parameters
are batched.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.sample" title="Permalink to this definition"></a></dt>
<dd><p>Generates a sample_shape shaped sample or sample_shape shaped batch of
samples if the distribution parameters are batched.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.distribution.Distribution.sample_n">
<code class="descname">sample_n</code><span class="sig-paren">(</span><em>n</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/distribution.html#Distribution.sample_n"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.distribution.Distribution.sample_n" title="Permalink to this definition"></a></dt>
<dd><p>Generates n samples or n batches of samples if the distribution
parameters are batched.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.stddev" title="Permalink to this definition"></a></dt>
<dd><p>Returns the standard deviation of the distribution.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.support" title="Permalink to this definition"></a></dt>
<dd><p>Returns a <a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">Constraint</span></code></a> object
representing this distribution&#8217;s support.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.distribution.Distribution.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.distribution.Distribution.variance" title="Permalink to this definition"></a></dt>
<dd><p>Returns the variance of the distribution.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="exponentialfamily">
<h2><span class="hidden-section">ExponentialFamily</span><a class="headerlink" href="#exponentialfamily" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.exp_family.ExponentialFamily">
<em class="property">class </em><code class="descclassname">torch.distributions.exp_family.</code><code class="descname">ExponentialFamily</code><span class="sig-paren">(</span><em>batch_shape=torch.Size([])</em>, <em>event_shape=torch.Size([])</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exp_family.html#ExponentialFamily"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exp_family.ExponentialFamily" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>ExponentialFamily is the abstract base class for probability distributions belonging to an
exponential family, whose probability mass/density function has the form is defined below</p>
<div class="math">
\[p_{F}(x; \theta) = \exp(\langle t(x), \theta\rangle) - F(\theta) + k(x))\]</div>
<p>where <span class="math">\(\theta\)</span> denotes the natural parameters, <span class="math">\(t(x)\)</span> denotes the sufficient statistic,
<span class="math">\(F(\theta)\)</span> is the log normalizer function for a given family and <span class="math">\(k(x)\)</span> is the carrier
measure.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This class is an intermediary between the <cite>Distribution</cite> class and distributions which belong
to an exponential family mainly to check the correctness of the <cite>.entropy()</cite> and analytic KL
divergence methods. We use this class to compute the entropy and KL divergence using the AD frame-
work and Bregman divergences (courtesy of: Frank Nielsen and Richard Nock, Entropies and
Cross-entropies of Exponential Families).</p>
</div>
<dl class="method">
<dt id="torch.distributions.exp_family.ExponentialFamily.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exp_family.html#ExponentialFamily.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exp_family.ExponentialFamily.entropy" title="Permalink to this definition"></a></dt>
<dd><p>Method to compute the entropy using Bregman divergence of the log normalizer.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="bernoulli">
<h2><span class="hidden-section">Bernoulli</span><a class="headerlink" href="#bernoulli" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.bernoulli.Bernoulli">
<em class="property">class </em><code class="descclassname">torch.distributions.bernoulli.</code><code class="descname">Bernoulli</code><span class="sig-paren">(</span><em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a Bernoulli distribution parameterized by <cite>probs</cite> or <cite>logits</cite>.</p>
<p>Samples are binary (0 or 1). They take the value <cite>1</cite> with probability <cite>p</cite>
and <cite>0</cite> with probability <cite>1 - p</cite>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Bernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.3</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># 30% chance 1; 70% chance 0</span>
<span class="go"> 0.0</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>probs</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the probabilty of sampling <cite>1</cite></li>
<li><strong>logits</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the log-odds of sampling <cite>1</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Interval object&gt;}</em><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.bernoulli.Bernoulli.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.bernoulli.Bernoulli.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.enumerate_support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.has_enumerate_support">
<code class="descname">has_enumerate_support</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.has_enumerate_support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.bernoulli.Bernoulli.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.logits">
<code class="descname">logits</code><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.logits" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.param_shape">
<code class="descname">param_shape</code><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.param_shape" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.probs">
<code class="descname">probs</code><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.probs" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.bernoulli.Bernoulli.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/bernoulli.html#Bernoulli.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Boolean object&gt;</em><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.bernoulli.Bernoulli.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.bernoulli.Bernoulli.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="beta">
<h2><span class="hidden-section">Beta</span><a class="headerlink" href="#beta" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.beta.Beta">
<em class="property">class </em><code class="descclassname">torch.distributions.beta.</code><code class="descname">Beta</code><span class="sig-paren">(</span><em>concentration1</em>, <em>concentration0</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/beta.html#Beta"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.beta.Beta" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Beta distribution parameterized by <cite>concentration1</cite> and <cite>concentration0</cite>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Beta</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Beta distributed with concentration concentration1 and concentration0</span>
<span class="go"> 0.1046</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>concentration1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; 1st concentration parameter of the distribution
(often referred to as alpha)</li>
<li><strong>concentration0</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; 2nd concentration parameter of the distribution
(often referred to as beta)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.beta.Beta.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'concentration1': &lt;torch.distributions.constraints._GreaterThan object&gt;, 'concentration0': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.beta.Beta.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.concentration0">
<code class="descname">concentration0</code><a class="headerlink" href="#torch.distributions.beta.Beta.concentration0" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.concentration1">
<code class="descname">concentration1</code><a class="headerlink" href="#torch.distributions.beta.Beta.concentration1" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.beta.Beta.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/beta.html#Beta.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.beta.Beta.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.beta.Beta.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.beta.Beta.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/beta.html#Beta.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.beta.Beta.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.beta.Beta.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.beta.Beta.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=()</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/beta.html#Beta.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.beta.Beta.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Interval object&gt;</em><a class="headerlink" href="#torch.distributions.beta.Beta.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.beta.Beta.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.beta.Beta.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="binomial">
<h2><span class="hidden-section">Binomial</span><a class="headerlink" href="#binomial" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.binomial.Binomial">
<em class="property">class </em><code class="descclassname">torch.distributions.binomial.</code><code class="descname">Binomial</code><span class="sig-paren">(</span><em>total_count=1</em>, <em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Binomial distribution parameterized by <cite>total_count</cite> and
either <cite>probs</cite> or <cite>logits</cite> (but not both).</p>
<ul class="simple">
<li>Requires a single shared <cite>total_count</cite> for all
parameters and samples.</li>
</ul>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Binomial</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span> <span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="o">.</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="go"> 0</span>
<span class="go"> 22</span>
<span class="go"> 71</span>
<span class="go"> 100</span>
<span class="go">[torch.FloatTensor of size 4]]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>total_count</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; number of Bernoulli trials</li>
<li><strong>probs</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Event probabilities</li>
<li><strong>logits</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Event log-odds</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Interval object&gt;}</em><a class="headerlink" href="#torch.distributions.binomial.Binomial.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.binomial.Binomial.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial.enumerate_support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.has_enumerate_support">
<code class="descname">has_enumerate_support</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.binomial.Binomial.has_enumerate_support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.binomial.Binomial.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.logits">
<code class="descname">logits</code><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial.logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial.logits" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.binomial.Binomial.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.param_shape">
<code class="descname">param_shape</code><a class="headerlink" href="#torch.distributions.binomial.Binomial.param_shape" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.probs">
<code class="descname">probs</code><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial.probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial.probs" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.binomial.Binomial.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/binomial.html#Binomial.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.binomial.Binomial.sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.binomial.Binomial.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.binomial.Binomial.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.binomial.Binomial.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="categorical">
<h2><span class="hidden-section">Categorical</span><a class="headerlink" href="#categorical" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.categorical.Categorical">
<em class="property">class </em><code class="descclassname">torch.distributions.categorical.</code><code class="descname">Categorical</code><span class="sig-paren">(</span><em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a categorical distribution parameterized by either <a class="reference internal" href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code class="xref py py-attr docutils literal"><span class="pre">probs</span></code></a> or
<a class="reference internal" href="#torch.distributions.categorical.Categorical.logits" title="torch.distributions.categorical.Categorical.logits"><code class="xref py py-attr docutils literal"><span class="pre">logits</span></code></a> (but not both).</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">It is equivalent to the distribution that <a class="reference internal" href="torch.html#torch.multinomial" title="torch.multinomial"><code class="xref py py-func docutils literal"><span class="pre">torch.multinomial()</span></code></a>
samples from.</p>
</div>
<p>Samples are integers from <cite>0 ... K-1</cite> where <cite>K</cite> is probs.size(-1).</p>
<p>If <a class="reference internal" href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code class="xref py py-attr docutils literal"><span class="pre">probs</span></code></a> is 1D with length-<cite>K</cite>, each element is the relative
probability of sampling the class at that index.</p>
<p>If <a class="reference internal" href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code class="xref py py-attr docutils literal"><span class="pre">probs</span></code></a> is 2D, it is treated as a batch of relative probability
vectors.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><a class="reference internal" href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code class="xref py py-attr docutils literal"><span class="pre">probs</span></code></a> will be normalized to be summing to 1.</p>
</div>
<p>See also: <a class="reference internal" href="torch.html#torch.multinomial" title="torch.multinomial"><code class="xref py py-func docutils literal"><span class="pre">torch.multinomial()</span></code></a></p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span> <span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># equal probability of 0, 1, 2, 3</span>
<span class="go"> 3</span>
<span class="go">[torch.LongTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>probs</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; event probabilities</li>
<li><strong>logits</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; event log probabilities</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Simplex object&gt;}</em><a class="headerlink" href="#torch.distributions.categorical.Categorical.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.categorical.Categorical.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.categorical.Categorical.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.enumerate_support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.has_enumerate_support">
<code class="descname">has_enumerate_support</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.categorical.Categorical.has_enumerate_support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.categorical.Categorical.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.logits">
<code class="descname">logits</code><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.logits" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.categorical.Categorical.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.param_shape">
<code class="descname">param_shape</code><a class="headerlink" href="#torch.distributions.categorical.Categorical.param_shape" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.probs">
<code class="descname">probs</code><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.probs" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.categorical.Categorical.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/categorical.html#Categorical.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.categorical.Categorical.sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.categorical.Categorical.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.categorical.Categorical.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.categorical.Categorical.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="cauchy">
<h2><span class="hidden-section">Cauchy</span><a class="headerlink" href="#cauchy" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.cauchy.Cauchy">
<em class="property">class </em><code class="descclassname">torch.distributions.cauchy.</code><code class="descname">Cauchy</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Samples from a Cauchy (Lorentz) distribution. The distribution of the ratio of
independent normally distributed random variables with means <cite>0</cite> follows a
Cauchy distribution.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Cauchy</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># sample from a Cauchy distribution with loc=0 and scale=1</span>
<span class="go"> 2.3214</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; mode or median of the distribution.</li>
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; half width at half maximum.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.cauchy.Cauchy.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'loc': &lt;torch.distributions.constraints._Real object&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.cauchy.Cauchy.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.cdf" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.cauchy.Cauchy.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.cauchy.Cauchy.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.cauchy.Cauchy.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.icdf" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.cauchy.Cauchy.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.cauchy.Cauchy.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.cauchy.Cauchy.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/cauchy.html#Cauchy.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.cauchy.Cauchy.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.cauchy.Cauchy.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.cauchy.Cauchy.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="chi2">
<h2><span class="hidden-section">Chi2</span><a class="headerlink" href="#chi2" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.chi2.Chi2">
<em class="property">class </em><code class="descclassname">torch.distributions.chi2.</code><code class="descname">Chi2</code><span class="sig-paren">(</span><em>df</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/chi2.html#Chi2"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.chi2.Chi2" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.gamma.Gamma" title="torch.distributions.gamma.Gamma"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.gamma.Gamma</span></code></a></p>
<p>Creates a Chi2 distribution parameterized by shape parameter <cite>df</cite>.
This is exactly equivalent to Gamma(alpha=0.5*df, beta=0.5)</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Chi2</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Chi2 distributed with shape df=1</span>
<span class="go"> 0.1046</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>df</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; shape parameter of the distribution</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.chi2.Chi2.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'df': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.chi2.Chi2.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.chi2.Chi2.df">
<code class="descname">df</code><a class="headerlink" href="#torch.distributions.chi2.Chi2.df" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="dirichlet">
<h2><span class="hidden-section">Dirichlet</span><a class="headerlink" href="#dirichlet" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.dirichlet.Dirichlet">
<em class="property">class </em><code class="descclassname">torch.distributions.dirichlet.</code><code class="descname">Dirichlet</code><span class="sig-paren">(</span><em>concentration</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/dirichlet.html#Dirichlet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a Dirichlet distribution parameterized by concentration <cite>concentration</cite>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Dirichlet</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Dirichlet distributed with concentrarion concentration</span>
<span class="go"> 0.1046</span>
<span class="go"> 0.8954</span>
<span class="go">[torch.FloatTensor of size 2]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>concentration</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; concentration parameter of the distribution
(often referred to as alpha)</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.dirichlet.Dirichlet.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'concentration': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.dirichlet.Dirichlet.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/dirichlet.html#Dirichlet.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.dirichlet.Dirichlet.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.dirichlet.Dirichlet.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/dirichlet.html#Dirichlet.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.dirichlet.Dirichlet.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.dirichlet.Dirichlet.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=()</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/dirichlet.html#Dirichlet.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.dirichlet.Dirichlet.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Simplex object&gt;</em><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.dirichlet.Dirichlet.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.dirichlet.Dirichlet.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="exponential">
<h2><span class="hidden-section">Exponential</span><a class="headerlink" href="#exponential" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.exponential.Exponential">
<em class="property">class </em><code class="descclassname">torch.distributions.exponential.</code><code class="descname">Exponential</code><span class="sig-paren">(</span><em>rate</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a Exponential distribution parameterized by <cite>rate</cite>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Exponential</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Exponential distributed with rate=1</span>
<span class="go"> 0.1046</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; rate = 1 / scale of the distribution</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'rate': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.exponential.Exponential.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.exponential.Exponential.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential.cdf" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.exponential.Exponential.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.exponential.Exponential.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.exponential.Exponential.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential.icdf" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.exponential.Exponential.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.exponential.Exponential.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.exponential.Exponential.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/exponential.html#Exponential.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.exponential.Exponential.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.exponential.Exponential.stddev" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._GreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.exponential.Exponential.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.exponential.Exponential.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.exponential.Exponential.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="fishersnedecor">
<h2><span class="hidden-section">FisherSnedecor</span><a class="headerlink" href="#fishersnedecor" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor">
<em class="property">class </em><code class="descclassname">torch.distributions.fishersnedecor.</code><code class="descname">FisherSnedecor</code><span class="sig-paren">(</span><em>df1</em>, <em>df2</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/fishersnedecor.html#FisherSnedecor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Fisher-Snedecor distribution parameterized by <cite>df1</cite> and <cite>df2</cite>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">FisherSnedecor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Fisher-Snedecor-distributed with df1=1 and df2=2</span>
<span class="go"> 0.2453</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>df1</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; degrees of freedom parameter 1</li>
<li><strong>df2</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; degrees of freedom parameter 2</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'df1': &lt;torch.distributions.constraints._GreaterThan object&gt;, 'df2': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/fishersnedecor.html#FisherSnedecor.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/fishersnedecor.html#FisherSnedecor.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._GreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.fishersnedecor.FisherSnedecor.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.fishersnedecor.FisherSnedecor.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="gamma">
<h2><span class="hidden-section">Gamma</span><a class="headerlink" href="#gamma" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.gamma.Gamma">
<em class="property">class </em><code class="descclassname">torch.distributions.gamma.</code><code class="descname">Gamma</code><span class="sig-paren">(</span><em>concentration</em>, <em>rate</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gamma.html#Gamma"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gamma.Gamma" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a Gamma distribution parameterized by shape <cite>concentration</cite> and <cite>rate</cite>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Gamma</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Gamma distributed with concentration=1 and rate=1</span>
<span class="go"> 0.1046</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>concentration</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; shape parameter of the distribution
(often referred to as alpha)</li>
<li><strong>rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; rate = 1 / scale of the distribution
(often referred to as beta)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.gamma.Gamma.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'concentration': &lt;torch.distributions.constraints._GreaterThan object&gt;, 'rate': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.gamma.Gamma.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.gamma.Gamma.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gamma.html#Gamma.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gamma.Gamma.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gamma.Gamma.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.gamma.Gamma.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.gamma.Gamma.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gamma.html#Gamma.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gamma.Gamma.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gamma.Gamma.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.gamma.Gamma.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.gamma.Gamma.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gamma.html#Gamma.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gamma.Gamma.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gamma.Gamma.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._GreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.gamma.Gamma.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gamma.Gamma.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.gamma.Gamma.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="geometric">
<h2><span class="hidden-section">Geometric</span><a class="headerlink" href="#geometric" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.geometric.Geometric">
<em class="property">class </em><code class="descclassname">torch.distributions.geometric.</code><code class="descname">Geometric</code><span class="sig-paren">(</span><em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Geometric distribution parameterized by <cite>probs</cite>, where <cite>probs</cite> is the probability of success of Bernoulli
trials. It represents the probability that in k + 1 Bernoulli trials, the first k trials failed, before
seeing a success.</p>
<p>Samples are non-negative integers [0, inf).</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Geometric</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.3</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># underlying Bernoulli has 30% chance 1; 70% chance 0</span>
<span class="go"> 2</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>probs</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the probabilty of sampling <cite>1</cite>. Must be in range (0, 1]</li>
<li><strong>logits</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the log-odds of sampling <cite>1</cite>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Interval object&gt;}</em><a class="headerlink" href="#torch.distributions.geometric.Geometric.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.geometric.Geometric.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.geometric.Geometric.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.logits">
<code class="descname">logits</code><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric.logits"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric.logits" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.geometric.Geometric.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.probs">
<code class="descname">probs</code><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric.probs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric.probs" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.geometric.Geometric.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/geometric.html#Geometric.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.geometric.Geometric.sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._IntegerGreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.geometric.Geometric.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.geometric.Geometric.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.geometric.Geometric.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="gumbel">
<h2><span class="hidden-section">Gumbel</span><a class="headerlink" href="#gumbel" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.gumbel.Gumbel">
<em class="property">class </em><code class="descclassname">torch.distributions.gumbel.</code><code class="descname">Gumbel</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gumbel.html#Gumbel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gumbel.Gumbel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Samples from a Gumbel Distribution.</p>
<p>Examples:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Gumbel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># sample from Gumbel distribution with loc=1, scale=2</span>
<span class="go"> 1.0124</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Location parameter of the distribution</li>
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Scale parameter of the distribution</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.gumbel.Gumbel.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'loc': &lt;torch.distributions.constraints._Real object&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.gumbel.Gumbel.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/gumbel.html#Gumbel.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gumbel.Gumbel.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gumbel.Gumbel.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.stddev" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gumbel.Gumbel.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.gumbel.Gumbel.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.gumbel.Gumbel.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="independent">
<h2><span class="hidden-section">Independent</span><a class="headerlink" href="#independent" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.independent.Independent">
<em class="property">class </em><code class="descclassname">torch.distributions.independent.</code><code class="descname">Independent</code><span class="sig-paren">(</span><em>base_distribution</em>, <em>reinterpreted_batch_ndims</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Reinterprets some of the batch dims of a distribution as event dims.</p>
<p>This is mainly useful for changing the shape of the result of
<a class="reference internal" href="#torch.distributions.independent.Independent.log_prob" title="torch.distributions.independent.Independent.log_prob"><code class="xref py py-meth docutils literal"><span class="pre">log_prob()</span></code></a>. For example to create a diagonal Normal distribution with
the same shape as a Multivariate Normal distribution (so they are
interchangeable), you can:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mvn</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">scale</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">mvn</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">mvn</span><span class="o">.</span><span class="n">event_shape</span><span class="p">]</span>
<span class="go">[torch.Size(()), torch.Size((3,))]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">normal</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">normal</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">normal</span><span class="o">.</span><span class="n">event_shape</span><span class="p">]</span>
<span class="go">[torch.Size((3,)), torch.Size(())]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">diagn</span> <span class="o">=</span> <span class="n">Independent</span><span class="p">(</span><span class="n">normal</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">diagn</span><span class="o">.</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">diagn</span><span class="o">.</span><span class="n">event_shape</span><span class="p">]</span>
<span class="go">[torch.Size(()), torch.Size((3,))]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>base_distribution</strong> (<a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><em>torch.distributions.distribution.Distribution</em></a>) &#8211; a
base distribution</li>
<li><strong>reinterpreted_batch_ndims</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; the number of batch dims to
reinterpret as event dims</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.independent.Independent.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {}</em><a class="headerlink" href="#torch.distributions.independent.Independent.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.independent.Independent.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.independent.Independent.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent.enumerate_support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.independent.Independent.has_enumerate_support">
<code class="descname">has_enumerate_support</code><a class="headerlink" href="#torch.distributions.independent.Independent.has_enumerate_support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.independent.Independent.has_rsample">
<code class="descname">has_rsample</code><a class="headerlink" href="#torch.distributions.independent.Independent.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.independent.Independent.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.independent.Independent.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.independent.Independent.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.independent.Independent.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.independent.Independent.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/independent.html#Independent.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.independent.Independent.sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.independent.Independent.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.independent.Independent.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.independent.Independent.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.independent.Independent.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="laplace">
<h2><span class="hidden-section">Laplace</span><a class="headerlink" href="#laplace" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.laplace.Laplace">
<em class="property">class </em><code class="descclassname">torch.distributions.laplace.</code><code class="descname">Laplace</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Laplace distribution parameterized by <cite>loc</cite> and &#8216;scale&#8217;.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Laplace</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Laplace distributed with loc=0, scale=1</span>
<span class="go"> 0.1046</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; mean of the distribution</li>
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; scale of the distribution</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'loc': &lt;torch.distributions.constraints._Real object&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.laplace.Laplace.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.laplace.Laplace.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace.cdf" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.laplace.Laplace.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.laplace.Laplace.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.laplace.Laplace.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace.icdf" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.laplace.Laplace.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.laplace.Laplace.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.laplace.Laplace.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/laplace.html#Laplace.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.laplace.Laplace.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.laplace.Laplace.stddev" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.laplace.Laplace.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.laplace.Laplace.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.laplace.Laplace.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="lognormal">
<h2><span class="hidden-section">LogNormal</span><a class="headerlink" href="#lognormal" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.log_normal.LogNormal">
<em class="property">class </em><code class="descclassname">torch.distributions.log_normal.</code><code class="descname">LogNormal</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/log_normal.html#LogNormal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.log_normal.LogNormal" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Creates a log-normal distribution parameterized by
<cite>loc</cite> and <cite>scale</cite> where:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">~</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">~</span> <span class="n">LogNormal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
</pre></div>
</div>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">LogNormal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># log-normal distributed with mean=0 and stddev=1</span>
<span class="go"> 0.1046</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; mean of log of distribution</li>
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; standard deviation of log ofthe distribution</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'loc': &lt;torch.distributions.constraints._Real object&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.log_normal.LogNormal.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/log_normal.html#LogNormal.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.loc">
<code class="descname">loc</code><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.loc" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.scale">
<code class="descname">scale</code><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.scale" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._GreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.log_normal.LogNormal.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.log_normal.LogNormal.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="multinomial">
<h2><span class="hidden-section">Multinomial</span><a class="headerlink" href="#multinomial" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.multinomial.Multinomial">
<em class="property">class </em><code class="descclassname">torch.distributions.multinomial.</code><code class="descname">Multinomial</code><span class="sig-paren">(</span><em>total_count=1</em>, <em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multinomial.html#Multinomial"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multinomial.Multinomial" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Multinomial distribution parameterized by <cite>total_count</cite> and
either <cite>probs</cite> or <cite>logits</cite> (but not both). The innermost dimension of
<cite>probs</cite> indexes over categories. All other dimensions index over batches.</p>
<p>Note that <cite>total_count</cite> need not be specified if only <a class="reference internal" href="#torch.distributions.multinomial.Multinomial.log_prob" title="torch.distributions.multinomial.Multinomial.log_prob"><code class="xref py py-meth docutils literal"><span class="pre">log_prob()</span></code></a> is
called (see example below)</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><a class="reference internal" href="#torch.distributions.multinomial.Multinomial.probs" title="torch.distributions.multinomial.Multinomial.probs"><code class="xref py py-attr docutils literal"><span class="pre">probs</span></code></a> will be normalized to be summing to 1.</p>
</div>
<ul class="simple">
<li><a class="reference internal" href="#torch.distributions.multinomial.Multinomial.sample" title="torch.distributions.multinomial.Multinomial.sample"><code class="xref py py-meth docutils literal"><span class="pre">sample()</span></code></a> requires a single shared <cite>total_count</cite> for all
parameters and samples.</li>
<li><a class="reference internal" href="#torch.distributions.multinomial.Multinomial.log_prob" title="torch.distributions.multinomial.Multinomial.log_prob"><code class="xref py py-meth docutils literal"><span class="pre">log_prob()</span></code></a> allows different <cite>total_count</cite> for each parameter and
sample.</li>
</ul>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Multinomial</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># equal probability of 0, 1, 2, 3</span>
<span class="go"> 21</span>
<span class="go"> 24</span>
<span class="go"> 30</span>
<span class="go"> 25</span>
<span class="go">[torch.FloatTensor of size 4]]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">Multinomial</span><span class="p">(</span><span class="n">probs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">-4.1338</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>total_count</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; number of trials</li>
<li><strong>probs</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; event probabilities</li>
<li><strong>logits</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; event log probabilities</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'logits': &lt;torch.distributions.constraints._Real object&gt;}</em><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.multinomial.Multinomial.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multinomial.html#Multinomial.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.logits">
<code class="descname">logits</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.logits" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.param_shape">
<code class="descname">param_shape</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.param_shape" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.probs">
<code class="descname">probs</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.probs" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.multinomial.Multinomial.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multinomial.html#Multinomial.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multinomial.Multinomial.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.multinomial.Multinomial.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="multivariatenormal">
<h2><span class="hidden-section">MultivariateNormal</span><a class="headerlink" href="#multivariatenormal" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal">
<em class="property">class </em><code class="descclassname">torch.distributions.multivariate_normal.</code><code class="descname">MultivariateNormal</code><span class="sig-paren">(</span><em>loc</em>, <em>covariance_matrix=None</em>, <em>precision_matrix=None</em>, <em>scale_tril=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a multivariate normal (also called Gaussian) distribution
parameterized by a mean vector and a covariance matrix.</p>
<p>The multivariate normal distribution can be parameterized either
in terms of a positive definite covariance matrix <span class="math">\(\mathbf{\Sigma}\)</span>
or a positive definite precition matrix <span class="math">\(\mathbf{\Sigma}^{-1}\)</span>
or a lower-triangular matrix <span class="math">\(\mathbf{L}\)</span> with positive-valued
diagonal entries, such that
<span class="math">\(\mathbf{\Sigma} = \mathbf{L}\mathbf{L}^\top\)</span>. This triangular matrix
can be obtained via e.g. Cholesky decomposition of the covariance.</p>
<p class="rubric">Example</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># normally distributed with mean=`[0,0]` and covariance_matrix=`I`</span>
<span class="go">-0.2102</span>
<span class="go">-0.5429</span>
<span class="go">[torch.FloatTensor of size 2]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; mean of the distribution</li>
<li><strong>covariance_matrix</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; positive-definite covariance matrix</li>
<li><strong>precision_matrix</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; positive-definite precision matrix</li>
<li><strong>scale_tril</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; lower-triangular factor of covariance, with positive-valued diagonal</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Only one of <a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix"><code class="xref py py-attr docutils literal"><span class="pre">covariance_matrix</span></code></a> or <a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix"><code class="xref py py-attr docutils literal"><span class="pre">precision_matrix</span></code></a> or
<a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril" title="torch.distributions.multivariate_normal.MultivariateNormal.scale_tril"><code class="xref py py-attr docutils literal"><span class="pre">scale_tril</span></code></a> can be specified.</p>
<p class="last">Using <a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril" title="torch.distributions.multivariate_normal.MultivariateNormal.scale_tril"><code class="xref py py-attr docutils literal"><span class="pre">scale_tril</span></code></a> will be more efficient: all computations internally
are based on <a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril" title="torch.distributions.multivariate_normal.MultivariateNormal.scale_tril"><code class="xref py py-attr docutils literal"><span class="pre">scale_tril</span></code></a>. If <a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix"><code class="xref py py-attr docutils literal"><span class="pre">covariance_matrix</span></code></a> or
<a class="reference internal" href="#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix"><code class="xref py py-attr docutils literal"><span class="pre">precision_matrix</span></code></a> is passed instead, it is only used to compute
the corresponding lower triangular matrices using a Cholesky decomposition.</p>
</div>
<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'loc': &lt;torch.distributions.constraints._RealVector object&gt;, 'covariance_matrix': &lt;torch.distributions.constraints._PositiveDefinite object&gt;, 'precision_matrix': &lt;torch.distributions.constraints._PositiveDefinite object&gt;, 'scale_tril': &lt;torch.distributions.constraints._LowerCholesky object&gt;}</em><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix">
<code class="descname">covariance_matrix</code><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.covariance_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix">
<code class="descname">precision_matrix</code><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.precision_matrix"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.scale_tril">
<code class="descname">scale_tril</code><a class="reference internal" href="_modules/torch/distributions/multivariate_normal.html#MultivariateNormal.scale_tril"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.multivariate_normal.MultivariateNormal.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.multivariate_normal.MultivariateNormal.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="normal">
<h2><span class="hidden-section">Normal</span><a class="headerlink" href="#normal" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.normal.Normal">
<em class="property">class </em><code class="descclassname">torch.distributions.normal.</code><code class="descname">Normal</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a normal (also called Gaussian) distribution parameterized by
<cite>loc</cite> and <cite>scale</cite>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># normally distributed with loc=0 and scale=1</span>
<span class="go"> 0.1046</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; mean of the distribution (often referred to as mu)</li>
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; standard deviation of the distribution
(often referred to as sigma)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.normal.Normal.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'loc': &lt;torch.distributions.constraints._Real object&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.normal.Normal.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.cdf" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.normal.Normal.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.normal.Normal.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.icdf" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.normal.Normal.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.normal.Normal.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.normal.Normal.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/normal.html#Normal.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.normal.Normal.sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.normal.Normal.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.normal.Normal.stddev" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.normal.Normal.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.normal.Normal.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.normal.Normal.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.normal.Normal.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="onehotcategorical">
<h2><span class="hidden-section">OneHotCategorical</span><a class="headerlink" href="#onehotcategorical" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical">
<em class="property">class </em><code class="descclassname">torch.distributions.one_hot_categorical.</code><code class="descname">OneHotCategorical</code><span class="sig-paren">(</span><em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/one_hot_categorical.html#OneHotCategorical"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a one-hot categorical distribution parameterized by <a class="reference internal" href="#torch.distributions.one_hot_categorical.OneHotCategorical.probs" title="torch.distributions.one_hot_categorical.OneHotCategorical.probs"><code class="xref py py-attr docutils literal"><span class="pre">probs</span></code></a> or
<a class="reference internal" href="#torch.distributions.one_hot_categorical.OneHotCategorical.logits" title="torch.distributions.one_hot_categorical.OneHotCategorical.logits"><code class="xref py py-attr docutils literal"><span class="pre">logits</span></code></a>.</p>
<p>Samples are one-hot coded vectors of size <code class="docutils literal"><span class="pre">probs.size(-1)</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><a class="reference internal" href="#torch.distributions.one_hot_categorical.OneHotCategorical.probs" title="torch.distributions.one_hot_categorical.OneHotCategorical.probs"><code class="xref py py-attr docutils literal"><span class="pre">probs</span></code></a> will be normalized to be summing to 1.</p>
</div>
<p>See also: <code class="xref py py-func docutils literal"><span class="pre">torch.distributions.Categorical()</span></code> for specifications of
<a class="reference internal" href="#torch.distributions.one_hot_categorical.OneHotCategorical.probs" title="torch.distributions.one_hot_categorical.OneHotCategorical.probs"><code class="xref py py-attr docutils literal"><span class="pre">probs</span></code></a> and <a class="reference internal" href="#torch.distributions.one_hot_categorical.OneHotCategorical.logits" title="torch.distributions.one_hot_categorical.OneHotCategorical.logits"><code class="xref py py-attr docutils literal"><span class="pre">logits</span></code></a>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">OneHotCategorical</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.25</span> <span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># equal probability of 0, 1, 2, 3</span>
<span class="go"> 0</span>
<span class="go"> 0</span>
<span class="go"> 1</span>
<span class="go"> 0</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>probs</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; event probabilities</li>
<li><strong>logits</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; event log probabilities</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Simplex object&gt;}</em><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/one_hot_categorical.html#OneHotCategorical.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support">
<code class="descname">enumerate_support</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/one_hot_categorical.html#OneHotCategorical.enumerate_support"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.has_enumerate_support">
<code class="descname">has_enumerate_support</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.has_enumerate_support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/one_hot_categorical.html#OneHotCategorical.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.logits">
<code class="descname">logits</code><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.logits" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.param_shape">
<code class="descname">param_shape</code><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.param_shape" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.probs">
<code class="descname">probs</code><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.probs" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/one_hot_categorical.html#OneHotCategorical.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Simplex object&gt;</em><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.one_hot_categorical.OneHotCategorical.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.one_hot_categorical.OneHotCategorical.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="pareto">
<h2><span class="hidden-section">Pareto</span><a class="headerlink" href="#pareto" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.pareto.Pareto">
<em class="property">class </em><code class="descclassname">torch.distributions.pareto.</code><code class="descname">Pareto</code><span class="sig-paren">(</span><em>scale</em>, <em>alpha</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/pareto.html#Pareto"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.pareto.Pareto" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Samples from a Pareto Type 1 distribution.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Pareto</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># sample from a Pareto distribution with scale=1 and alpha=1</span>
<span class="go"> 1.5623</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>scale</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Scale parameter of the distribution</li>
<li><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Shape parameter of the distribution</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.pareto.Pareto.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'alpha': &lt;torch.distributions.constraints._GreaterThan object&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.pareto.Pareto.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.pareto.Pareto.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/pareto.html#Pareto.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.pareto.Pareto.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.pareto.Pareto.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.pareto.Pareto.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.pareto.Pareto.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.pareto.Pareto.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.pareto.Pareto.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.pareto.Pareto.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="poisson">
<h2><span class="hidden-section">Poisson</span><a class="headerlink" href="#poisson" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.poisson.Poisson">
<em class="property">class </em><code class="descclassname">torch.distributions.poisson.</code><code class="descname">Poisson</code><span class="sig-paren">(</span><em>rate</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/poisson.html#Poisson"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.poisson.Poisson" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.exp_family.ExponentialFamily</span></code></a></p>
<p>Creates a Poisson distribution parameterized by <cite>rate</cite>, the rate parameter.</p>
<p>Samples are nonnegative integers, with a pmf given by
$rate^k e^{-rate}/k!$</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Poisson</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="go"> 3</span>
<span class="go">[torch.LongTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>rate</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the rate parameter</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.poisson.Poisson.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'rate': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.poisson.Poisson.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.poisson.Poisson.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/poisson.html#Poisson.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.poisson.Poisson.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.poisson.Poisson.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.poisson.Poisson.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.poisson.Poisson.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/poisson.html#Poisson.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.poisson.Poisson.sample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.poisson.Poisson.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._IntegerGreaterThan object&gt;</em><a class="headerlink" href="#torch.distributions.poisson.Poisson.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.poisson.Poisson.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.poisson.Poisson.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="relaxedbernoulli">
<h2><span class="hidden-section">RelaxedBernoulli</span><a class="headerlink" href="#relaxedbernoulli" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli">
<em class="property">class </em><code class="descclassname">torch.distributions.relaxed_bernoulli.</code><code class="descname">RelaxedBernoulli</code><span class="sig-paren">(</span><em>temperature</em>, <em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/relaxed_bernoulli.html#RelaxedBernoulli"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Creates a RelaxedBernoulli distribution, parametrized by <cite>temperature</cite>, and either
<cite>probs</cite> or <cite>logits</cite>. This is a relaxed version of the <cite>Bernoulli</cite> distribution, so
the values are in (0, 1), and has reparametrizable samples.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">RelaxedBernoulli</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.2</span><span class="p">]),</span>
<span class="go">                         torch.tensor([0.1, 0.2, 0.3, 0.99]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="go"> 0.2951</span>
<span class="go"> 0.3442</span>
<span class="go"> 0.8918</span>
<span class="go"> 0.9021</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>temperature</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; </li>
<li><strong>probs</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the probabilty of sampling <cite>1</cite></li>
<li><strong>logits</strong> (<em>Number</em><em>, </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the log-odds of sampling <cite>1</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Interval object&gt;}</em><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits">
<code class="descname">logits</code><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs">
<code class="descname">probs</code><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Interval object&gt;</em><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature">
<code class="descname">temperature</code><a class="headerlink" href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="relaxedonehotcategorical">
<h2><span class="hidden-section">RelaxedOneHotCategorical</span><a class="headerlink" href="#relaxedonehotcategorical" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical">
<em class="property">class </em><code class="descclassname">torch.distributions.relaxed_categorical.</code><code class="descname">RelaxedOneHotCategorical</code><span class="sig-paren">(</span><em>temperature</em>, <em>probs=None</em>, <em>logits=None</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/relaxed_categorical.html#RelaxedOneHotCategorical"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.transformed_distribution.TransformedDistribution</span></code></a></p>
<p>Creates a RelaxedOneHotCategorical distribution parametrized by <cite>temperature</cite> and either <cite>probs</cite> or <cite>logits</cite>.
This is a relaxed version of the <cite>OneHotCategorical</cite> distribution, so its
values are on simplex, and has reparametrizable samples.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">RelaxedOneHotCategorical</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.2</span><span class="p">]),</span>
<span class="go">                                 torch.tensor([0.1, 0.2, 0.3, 0.4]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># equal probability of 1, 1, 2, 3</span>
<span class="go"> 0.1294</span>
<span class="go"> 0.2324</span>
<span class="go"> 0.3859</span>
<span class="go"> 0.2523</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>temperature</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; relaxation temperature</li>
<li><strong>probs</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; event probabilities</li>
<li><strong>logits</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the log probability of each event.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'probs': &lt;torch.distributions.constraints._Simplex object&gt;}</em><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits">
<code class="descname">logits</code><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs">
<code class="descname">probs</code><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Simplex object&gt;</em><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature">
<code class="descname">temperature</code><a class="headerlink" href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="studentt">
<h2><span class="hidden-section">StudentT</span><a class="headerlink" href="#studentt" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.studentT.StudentT">
<em class="property">class </em><code class="descclassname">torch.distributions.studentT.</code><code class="descname">StudentT</code><span class="sig-paren">(</span><em>df</em>, <em>loc=0.0</em>, <em>scale=1.0</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/studentT.html#StudentT"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.studentT.StudentT" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Creates a Student&#8217;s t-distribution parameterized by <cite>df</cite>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">StudentT</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">2.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># Student&#39;s t-distributed with degrees of freedom=2</span>
<span class="go"> 0.1046</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>df</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; degrees of freedom</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.studentT.StudentT.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'df': &lt;torch.distributions.constraints._GreaterThan object&gt;, 'loc': &lt;torch.distributions.constraints._Real object&gt;, 'scale': &lt;torch.distributions.constraints._GreaterThan object&gt;}</em><a class="headerlink" href="#torch.distributions.studentT.StudentT.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.studentT.StudentT.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/studentT.html#StudentT.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.studentT.StudentT.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.studentT.StudentT.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.studentT.StudentT.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.studentT.StudentT.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/studentT.html#StudentT.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.studentT.StudentT.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.studentT.StudentT.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.studentT.StudentT.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.studentT.StudentT.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/studentT.html#StudentT.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.studentT.StudentT.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.studentT.StudentT.support">
<code class="descname">support</code><em class="property"> = &lt;torch.distributions.constraints._Real object&gt;</em><a class="headerlink" href="#torch.distributions.studentT.StudentT.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.studentT.StudentT.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.studentT.StudentT.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="transformeddistribution">
<h2><span class="hidden-section">TransformedDistribution</span><a class="headerlink" href="#transformeddistribution" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution">
<em class="property">class </em><code class="descclassname">torch.distributions.transformed_distribution.</code><code class="descname">TransformedDistribution</code><span class="sig-paren">(</span><em>base_distribution</em>, <em>transforms</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Extension of the Distribution class, which applies a sequence of Transforms
to a base distribution.  Let f be the composition of transforms applied:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">~</span> <span class="n">BaseDistribution</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">~</span> <span class="n">TransformedDistribution</span><span class="p">(</span><span class="n">BaseDistribution</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
<span class="n">log</span> <span class="n">p</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">=</span> <span class="n">log</span> <span class="n">p</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">log</span> <span class="o">|</span><span class="n">det</span> <span class="p">(</span><span class="n">dX</span><span class="o">/</span><span class="n">dY</span><span class="p">)</span><span class="o">|</span>
</pre></div>
</div>
<p>Note that the <code class="docutils literal"><span class="pre">.event_shape</span></code> of a <a class="reference internal" href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code class="xref py py-class docutils literal"><span class="pre">TransformedDistribution</span></code></a> is the
maximum shape of its base distribution and its transforms, since transforms
can introduce correlations among events.</p>
<dl class="attribute">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {}</em><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.cdf" title="Permalink to this definition"></a></dt>
<dd><p>Computes the cumulative distribution function by inverting the
transform(s) and computing the score of the base distribution.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.has_rsample">
<code class="descname">has_rsample</code><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.icdf" title="Permalink to this definition"></a></dt>
<dd><p>Computes the inverse cumulative distribution function using
transform(s) and computing the score of the base distribution.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.log_prob" title="Permalink to this definition"></a></dt>
<dd><p>Scores the sample by inverting the transform(s) and computing the score
using the score of the base distribution and the log abs det jacobian.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.rsample" title="Permalink to this definition"></a></dt>
<dd><p>Generates a sample_shape shaped reparameterized sample or sample_shape
shaped batch of reparameterized samples if the distribution parameters
are batched. Samples first from base distribution and applies
<cite>transform()</cite> for every transform in the list.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.sample">
<code class="descname">sample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transformed_distribution.html#TransformedDistribution.sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.sample" title="Permalink to this definition"></a></dt>
<dd><p>Generates a sample_shape shaped sample or sample_shape shaped batch of
samples if the distribution parameters are batched. Samples first from
base distribution and applies <cite>transform()</cite> for every transform in the
list.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.transformed_distribution.TransformedDistribution.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.transformed_distribution.TransformedDistribution.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="uniform">
<h2><span class="hidden-section">Uniform</span><a class="headerlink" href="#uniform" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.uniform.Uniform">
<em class="property">class </em><code class="descclassname">torch.distributions.uniform.</code><code class="descname">Uniform</code><span class="sig-paren">(</span><em>low</em>, <em>high</em>, <em>validate_args=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code class="xref py py-class docutils literal"><span class="pre">torch.distributions.distribution.Distribution</span></code></a></p>
<p>Generates uniformly distributed random samples from the half-open interval
<cite>[low, high)</cite>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Uniform</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">5.0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>  <span class="c1"># uniformly distributed in the range [0.0, 5.0)</span>
<span class="go"> 2.3418</span>
<span class="go">[torch.FloatTensor of size 1]</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>low</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; lower range (inclusive).</li>
<li><strong>high</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; upper range (exclusive).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.arg_constraints">
<code class="descname">arg_constraints</code><em class="property"> = {'low': &lt;torch.distributions.constraints._Dependent object&gt;, 'high': &lt;torch.distributions.constraints._Dependent object&gt;}</em><a class="headerlink" href="#torch.distributions.uniform.Uniform.arg_constraints" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.uniform.Uniform.cdf">
<code class="descname">cdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform.cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform.cdf" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.uniform.Uniform.entropy">
<code class="descname">entropy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform.entropy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform.entropy" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.has_rsample">
<code class="descname">has_rsample</code><em class="property"> = True</em><a class="headerlink" href="#torch.distributions.uniform.Uniform.has_rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.uniform.Uniform.icdf">
<code class="descname">icdf</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform.icdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform.icdf" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.uniform.Uniform.log_prob">
<code class="descname">log_prob</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform.log_prob" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.mean">
<code class="descname">mean</code><a class="headerlink" href="#torch.distributions.uniform.Uniform.mean" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="torch.distributions.uniform.Uniform.rsample">
<code class="descname">rsample</code><span class="sig-paren">(</span><em>sample_shape=torch.Size([])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/uniform.html#Uniform.rsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.uniform.Uniform.rsample" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.stddev">
<code class="descname">stddev</code><a class="headerlink" href="#torch.distributions.uniform.Uniform.stddev" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.support">
<code class="descname">support</code><a class="headerlink" href="#torch.distributions.uniform.Uniform.support" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="torch.distributions.uniform.Uniform.variance">
<code class="descname">variance</code><a class="headerlink" href="#torch.distributions.uniform.Uniform.variance" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-torch.distributions.kl">
<span id="kl-divergence"></span><h2><cite>KL Divergence</cite><a class="headerlink" href="#module-torch.distributions.kl" title="Permalink to this headline"></a></h2>
<dl class="function">
<dt id="torch.distributions.kl.kl_divergence">
<code class="descclassname">torch.distributions.kl.</code><code class="descname">kl_divergence</code><span class="sig-paren">(</span><em>p</em>, <em>q</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/kl.html#kl_divergence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.kl.kl_divergence" title="Permalink to this definition"></a></dt>
<dd><p>Compute Kullback-Leibler divergence <span class="math">\(KL(p \| q)\)</span> between two distributions.</p>
<div class="math">
\[KL(p \| q) = \int p(x) \log\frac {p(x)} {q(x)} \,dx\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>p</strong> (<a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><em>Distribution</em></a>) &#8211; A <code class="xref py py-class docutils literal"><span class="pre">Distribution</span></code> object.</li>
<li><strong>q</strong> (<a class="reference internal" href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><em>Distribution</em></a>) &#8211; A <code class="xref py py-class docutils literal"><span class="pre">Distribution</span></code> object.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A batch of KL divergences of shape <cite>batch_shape</cite>.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first"><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a></p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Raises:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/exceptions.html#NotImplementedError" title="(in Python v3.6)"><code class="xref py py-exc docutils literal"><span class="pre">NotImplementedError</span></code></a> &#8211; If the distribution types have not been registered via
<a class="reference internal" href="#torch.distributions.kl.register_kl" title="torch.distributions.kl.register_kl"><code class="xref py py-meth docutils literal"><span class="pre">register_kl()</span></code></a>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.distributions.kl.register_kl">
<code class="descclassname">torch.distributions.kl.</code><code class="descname">register_kl</code><span class="sig-paren">(</span><em>type_p</em>, <em>type_q</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/kl.html#register_kl"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.kl.register_kl" title="Permalink to this definition"></a></dt>
<dd><p>Decorator to register a pairwise function with <a class="reference internal" href="#torch.distributions.kl.kl_divergence" title="torch.distributions.kl.kl_divergence"><code class="xref py py-meth docutils literal"><span class="pre">kl_divergence()</span></code></a>.
Usage:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="nd">@register_kl</span><span class="p">(</span><span class="n">Normal</span><span class="p">,</span> <span class="n">Normal</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">kl_normal_normal</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span>
    <span class="c1"># insert implementation here</span>
</pre></div>
</div>
<p>Lookup returns the most specific (type,type) match ordered by subclass. If
the match is ambiguous, a <cite>RuntimeWarning</cite> is raised. For example to
resolve the ambiguous situation:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="nd">@register_kl</span><span class="p">(</span><span class="n">BaseP</span><span class="p">,</span> <span class="n">DerivedQ</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">kl_version1</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span> <span class="o">...</span>
<span class="nd">@register_kl</span><span class="p">(</span><span class="n">DerivedP</span><span class="p">,</span> <span class="n">BaseQ</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">kl_version2</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">):</span> <span class="o">...</span>
</pre></div>
</div>
<p>you should register a third most-specific implementation, e.g.:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">register_kl</span><span class="p">(</span><span class="n">DerivedP</span><span class="p">,</span> <span class="n">DerivedQ</span><span class="p">)(</span><span class="n">kl_version1</span><span class="p">)</span>  <span class="c1"># Break the tie.</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>type_p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.6)"><em>type</em></a>) &#8211; A subclass of <code class="xref py py-class docutils literal"><span class="pre">Distribution</span></code>.</li>
<li><strong>type_q</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.6)"><em>type</em></a>) &#8211; A subclass of <code class="xref py py-class docutils literal"><span class="pre">Distribution</span></code>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-torch.distributions.transforms">
<span id="transforms"></span><h2><cite>Transforms</cite><a class="headerlink" href="#module-torch.distributions.transforms" title="Permalink to this headline"></a></h2>
<dl class="class">
<dt id="torch.distributions.transforms.Transform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">Transform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#Transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.Transform" title="Permalink to this definition"></a></dt>
<dd><p>Abstract class for invertable transformations with computable log
det jacobians. They are primarily used in
<code class="xref py py-class docutils literal"><span class="pre">torch.distributions.TransformedDistribution</span></code>.</p>
<p>Caching is useful for tranforms whose inverses are either expensive or
numerically unstable. Note that care must be taken with memoized values
since the autograd graph may be reversed. For example while the following
works with or without caching:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">t</span><span class="o">.</span><span class="n">log_abs_det_jacobian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># x will receive gradients.</span>
</pre></div>
</div>
<p>However the following will error when caching due to dependency reversal:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">grad</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="p">[</span><span class="n">y</span><span class="p">])</span>  <span class="c1"># error because z is x</span>
</pre></div>
</div>
<p>Derived classes should implement one or both of <code class="xref py py-meth docutils literal"><span class="pre">_call()</span></code> or
<code class="xref py py-meth docutils literal"><span class="pre">_inverse()</span></code>. Derived classes that set <cite>bijective=True</cite> should also
implement <a class="reference internal" href="#torch.distributions.transforms.Transform.log_abs_det_jacobian" title="torch.distributions.transforms.Transform.log_abs_det_jacobian"><code class="xref py py-meth docutils literal"><span class="pre">log_abs_det_jacobian()</span></code></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>cache_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Size of cache. If zero, no caching is done. If one,
the latest single value is cached. Only 0 and 1 are supported.</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>domain</strong> (<a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">Constraint</span></code></a>) &#8211; The constraint representing valid inputs to this transform.</li>
<li><strong>codomain</strong> (<a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">Constraint</span></code></a>) &#8211; The constraint representing valid outputs to this transform
which are inputs to the inverse transform.</li>
<li><strong>bijective</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.6)"><em>bool</em></a>) &#8211; Whether this transform is bijective. A transform
<code class="docutils literal"><span class="pre">t</span></code> is bijective iff <code class="docutils literal"><span class="pre">t.inv(t(x))</span> <span class="pre">==</span> <span class="pre">x</span></code> and
<code class="docutils literal"><span class="pre">t(t.inv(y))</span> <span class="pre">==</span> <span class="pre">y</span></code> for every <code class="docutils literal"><span class="pre">x</span></code> in the domain and <code class="docutils literal"><span class="pre">y</span></code> in
the codomain. Transforms that are not bijective should at least
maintain the weaker pseudoinverse properties
<code class="docutils literal"><span class="pre">t(t.inv(t(x))</span> <span class="pre">==</span> <span class="pre">t(x)</span></code> and <code class="docutils literal"><span class="pre">t.inv(t(t.inv(y)))</span> <span class="pre">==</span> <span class="pre">t.inv(y)</span></code>.</li>
<li><strong>sign</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; For bijective univariate transforms, this
should be +1 or -1 depending on whether transform is monotone
increasing or decreasing.</li>
<li><strong>event_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Number of dimensions that are correlated together in
the transform <code class="docutils literal"><span class="pre">event_shape</span></code>. This should be 0 for pointwise
transforms, 1 for transforms that act jointly on vectors, 2 for
transforms that act jointly on matrices, etc.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.distributions.transforms.Transform.inv">
<code class="descname">inv</code><a class="headerlink" href="#torch.distributions.transforms.Transform.inv" title="Permalink to this definition"></a></dt>
<dd><p>Returns the inverse <a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal"><span class="pre">Transform</span></code></a> of this transform.
This should satisfy <code class="docutils literal"><span class="pre">t.inv.inv</span> <span class="pre">is</span> <span class="pre">t</span></code>.</p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.transforms.Transform.sign">
<code class="descname">sign</code><a class="headerlink" href="#torch.distributions.transforms.Transform.sign" title="Permalink to this definition"></a></dt>
<dd><p>Returns the sign of the determinant of the Jacobian, if applicable.
In general this only makes sense for bijective transforms.</p>
</dd></dl>

<dl class="method">
<dt id="torch.distributions.transforms.Transform.log_abs_det_jacobian">
<code class="descname">log_abs_det_jacobian</code><span class="sig-paren">(</span><em>x</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#Transform.log_abs_det_jacobian"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.Transform.log_abs_det_jacobian" title="Permalink to this definition"></a></dt>
<dd><p>Computes the log det jacobian <cite>log |dy/dx|</cite> given input and output.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.ComposeTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">ComposeTransform</code><span class="sig-paren">(</span><em>parts</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#ComposeTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.ComposeTransform" title="Permalink to this definition"></a></dt>
<dd><p>Composes multiple transforms in a chain.
The transforms being composed are responsible for caching.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>parts</strong> (list of <a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal"><span class="pre">Transform</span></code></a>) &#8211; A list of transforms to compose.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.ExpTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">ExpTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#ExpTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.ExpTransform" title="Permalink to this definition"></a></dt>
<dd><p>Transform via the mapping <span class="math">\(y = \exp(x)\)</span>.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.PowerTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">PowerTransform</code><span class="sig-paren">(</span><em>exponent</em>, <em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#PowerTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.PowerTransform" title="Permalink to this definition"></a></dt>
<dd><p>Transform via the mapping <span class="math">\(y = x^{\text{exponent}}\)</span>.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.SigmoidTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">SigmoidTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#SigmoidTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.SigmoidTransform" title="Permalink to this definition"></a></dt>
<dd><p>Transform via the mapping <span class="math">\(y = \frac{1}{1 + \exp(-x)}\)</span> and <span class="math">\(x = \text{logit}(y)\)</span>.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.AbsTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">AbsTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#AbsTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.AbsTransform" title="Permalink to this definition"></a></dt>
<dd><p>Transform via the mapping <span class="math">\(y = |x|\)</span>.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.AffineTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">AffineTransform</code><span class="sig-paren">(</span><em>loc</em>, <em>scale</em>, <em>event_dim=0</em>, <em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#AffineTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.AffineTransform" title="Permalink to this definition"></a></dt>
<dd><p>Transform via the pointwise affine mapping <span class="math">\(y = \text{loc} + \text{scale} \times x\)</span>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>loc</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; Location parameter.</li>
<li><strong>scale</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.6)"><em>float</em></a>) &#8211; Scale parameter.</li>
<li><strong>event_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.6)"><em>int</em></a>) &#8211; Optional size of <cite>event_shape</cite>. This should be zero
for univariate random variables, 1 for distributions over vectors,
2 for distributions over matrices, etc.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.SoftmaxTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">SoftmaxTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#SoftmaxTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.SoftmaxTransform" title="Permalink to this definition"></a></dt>
<dd><p>Transform from unconstrained space to the simplex via <span class="math">\(y = \exp(x)\)</span> then
normalizing.</p>
<p>This is not bijective and cannot be used for HMC. However this acts mostly
coordinate-wise (except for the final normalization), and thus is
appropriate for coordinate-wise optimization algorithms.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.StickBreakingTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">StickBreakingTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#StickBreakingTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.StickBreakingTransform" title="Permalink to this definition"></a></dt>
<dd><p>Transform from unconstrained space to the simplex of one additional
dimension via a stick-breaking process.</p>
<p>This transform arises as an iterated sigmoid transform in a stick-breaking
construction of the <cite>Dirichlet</cite> distribution: the first logit is
transformed via sigmoid to the first probability and the probability of
everything else, and then the process recurses.</p>
<p>This is bijective and appropriate for use in HMC; however it mixes
coordinates together and is less appropriate for optimization.</p>
</dd></dl>

<dl class="class">
<dt id="torch.distributions.transforms.LowerCholeskyTransform">
<em class="property">class </em><code class="descclassname">torch.distributions.transforms.</code><code class="descname">LowerCholeskyTransform</code><span class="sig-paren">(</span><em>cache_size=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/transforms.html#LowerCholeskyTransform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.transforms.LowerCholeskyTransform" title="Permalink to this definition"></a></dt>
<dd><p>Transform from unconstrained matrices to lower-triangular matrices with
nonnegative diagonal entries.</p>
<p>This is useful for parameterizing positive definite matrices in terms of
their Cholesky factorization.</p>
</dd></dl>

</div>
<div class="section" id="module-torch.distributions.constraints">
<span id="constraints"></span><h2><cite>Constraints</cite><a class="headerlink" href="#module-torch.distributions.constraints" title="Permalink to this headline"></a></h2>
<p>The following constraints are implemented:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">constraints.boolean</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.dependent</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.greater_than(lower_bound)</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.integer_interval(lower_bound,</span> <span class="pre">upper_bound)</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.interval(lower_bound,</span> <span class="pre">upper_bound)</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.lower_cholesky</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.lower_triangular</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.nonnegative_integer</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.positive</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.positive_definite</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.positive_integer</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.real</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.real_vector</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.simplex</span></code></li>
<li><code class="docutils literal"><span class="pre">constraints.unit_interval</span></code></li>
</ul>
<dl class="class">
<dt id="torch.distributions.constraints.Constraint">
<em class="property">class </em><code class="descclassname">torch.distributions.constraints.</code><code class="descname">Constraint</code><a class="reference internal" href="_modules/torch/distributions/constraints.html#Constraint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.constraints.Constraint" title="Permalink to this definition"></a></dt>
<dd><p>Abstract base class for constraints.</p>
<p>A constraint object represents a region over which a variable is valid,
e.g. within which a variable can be optimized.</p>
<dl class="method">
<dt id="torch.distributions.constraints.Constraint.check">
<code class="descname">check</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/constraints.html#Constraint.check"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.constraints.Constraint.check" title="Permalink to this definition"></a></dt>
<dd><p>Returns a byte tensor of <cite>sample_shape + batch_shape</cite> indicating
whether each event in value satisfies this constraint.</p>
</dd></dl>

</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.constraints.dependent_property">
<code class="descclassname">torch.distributions.constraints.</code><code class="descname">dependent_property</code><a class="headerlink" href="#torch.distributions.constraints.dependent_property" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal"><span class="pre">_DependentProperty</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.constraints.integer_interval">
<code class="descclassname">torch.distributions.constraints.</code><code class="descname">integer_interval</code><a class="headerlink" href="#torch.distributions.constraints.integer_interval" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal"><span class="pre">_IntegerInterval</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.constraints.greater_than">
<code class="descclassname">torch.distributions.constraints.</code><code class="descname">greater_than</code><a class="headerlink" href="#torch.distributions.constraints.greater_than" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal"><span class="pre">_GreaterThan</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.constraints.less_than">
<code class="descclassname">torch.distributions.constraints.</code><code class="descname">less_than</code><a class="headerlink" href="#torch.distributions.constraints.less_than" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal"><span class="pre">_LessThan</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="torch.distributions.constraints.interval">
<code class="descclassname">torch.distributions.constraints.</code><code class="descname">interval</code><a class="headerlink" href="#torch.distributions.constraints.interval" title="Permalink to this definition"></a></dt>
<dd><p>alias of <code class="xref py py-class docutils literal"><span class="pre">_Interval</span></code></p>
</dd></dl>

</div>
<div class="section" id="module-torch.distributions.constraint_registry">
<span id="constraint-registry"></span><h2><cite>Constraint Registry</cite><a class="headerlink" href="#module-torch.distributions.constraint_registry" title="Permalink to this headline"></a></h2>
<p>PyTorch provides two global <a class="reference internal" href="#torch.distributions.constraint_registry.ConstraintRegistry" title="torch.distributions.constraint_registry.ConstraintRegistry"><code class="xref py py-class docutils literal"><span class="pre">ConstraintRegistry</span></code></a> objects that link
<a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">Constraint</span></code></a> objects to
<a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal"><span class="pre">Transform</span></code></a> objects. These objects both
input constraints and return transforms, but they have different guarantees on
bijectivity.</p>
<ol class="arabic simple">
<li><code class="docutils literal"><span class="pre">biject_to(constraint)</span></code> looks up a bijective
<a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal"><span class="pre">Transform</span></code></a> from <code class="docutils literal"><span class="pre">constraints.real</span></code>
to the given <code class="docutils literal"><span class="pre">constraint</span></code>. The returned transform is guaranteed to have
<code class="docutils literal"><span class="pre">.bijective</span> <span class="pre">=</span> <span class="pre">True</span></code> and should implement <code class="docutils literal"><span class="pre">.log_abs_det_jacobian()</span></code>.</li>
<li><code class="docutils literal"><span class="pre">transform_to(constraint)</span></code> looks up a not-necessarily bijective
<a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal"><span class="pre">Transform</span></code></a> from <code class="docutils literal"><span class="pre">constraints.real</span></code>
to the given <code class="docutils literal"><span class="pre">constraint</span></code>. The returned transform is not guaranteed to
implement <code class="docutils literal"><span class="pre">.log_abs_det_jacobian()</span></code>.</li>
</ol>
<p>The <code class="docutils literal"><span class="pre">transform_to()</span></code> registry is useful for performing unconstrained
optimization on constrained parameters of probability distributions, which are
indicated by each distribution&#8217;s <code class="docutils literal"><span class="pre">.arg_constraints</span></code> dict. These transforms often
overparameterize a space in order to avoid rotation; they are thus more
suitable for coordinate-wise optimization algorithms like Adam:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">loc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">unconstrained</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">scale</span> <span class="o">=</span> <span class="n">transform_to</span><span class="p">(</span><span class="n">Normal</span><span class="o">.</span><span class="n">arg_constraints</span><span class="p">[</span><span class="s1">&#39;scale&#39;</span><span class="p">])(</span><span class="n">unconstrained</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
<p>The <code class="docutils literal"><span class="pre">biject_to()</span></code> registry is useful for Hamiltonian Monte Carlo, where
samples from a probability distribution with constrained <code class="docutils literal"><span class="pre">.support</span></code> are
propagated in an unconstrained space, and algorithms are typically rotation
invariant.:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">dist</span> <span class="o">=</span> <span class="n">Exponential</span><span class="p">(</span><span class="n">rate</span><span class="p">)</span>
<span class="n">unconstrained</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">biject_to</span><span class="p">(</span><span class="n">dist</span><span class="o">.</span><span class="n">support</span><span class="p">)(</span><span class="n">unconstrained</span><span class="p">)</span>
<span class="n">potential_energy</span> <span class="o">=</span> <span class="o">-</span><span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">An example where <code class="docutils literal"><span class="pre">transform_to</span></code> and <code class="docutils literal"><span class="pre">biject_to</span></code> differ is
<code class="docutils literal"><span class="pre">constraints.simplex</span></code>: <code class="docutils literal"><span class="pre">transform_to(constraints.simplex)</span></code> returns a
<a class="reference internal" href="#torch.distributions.transforms.SoftmaxTransform" title="torch.distributions.transforms.SoftmaxTransform"><code class="xref py py-class docutils literal"><span class="pre">SoftmaxTransform</span></code></a> that simply
exponentiates and normalizes its inputs; this is a cheap and mostly
coordinate-wise operation appropriate for algorithms like SVI. In
contrast, <code class="docutils literal"><span class="pre">biject_to(constraints.simplex)</span></code> returns a
<a class="reference internal" href="#torch.distributions.transforms.StickBreakingTransform" title="torch.distributions.transforms.StickBreakingTransform"><code class="xref py py-class docutils literal"><span class="pre">StickBreakingTransform</span></code></a> that
bijects its input down to a one-fewer-dimensional space; this a more
expensive less numerically stable transform but is needed for algorithms
like HMC.</p>
</div>
<p>The <code class="docutils literal"><span class="pre">biject_to</span></code> and <code class="docutils literal"><span class="pre">transform_to</span></code> objects can be extended by user-defined
constraints and transforms using their <code class="docutils literal"><span class="pre">.register()</span></code> method either as a
function on singleton constraints:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">transform_to</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">my_constraint</span><span class="p">,</span> <span class="n">my_transform</span><span class="p">)</span>
</pre></div>
</div>
<p>or as a decorator on parameterized constraints:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="nd">@transform_to</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">MyConstraintClass</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">my_factory</span><span class="p">(</span><span class="n">constraint</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">constraint</span><span class="p">,</span> <span class="n">MyConstraintClass</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">MyTransform</span><span class="p">(</span><span class="n">constraint</span><span class="o">.</span><span class="n">param1</span><span class="p">,</span> <span class="n">constraint</span><span class="o">.</span><span class="n">param2</span><span class="p">)</span>
</pre></div>
</div>
<p>You can create your own registry by creating a new <a class="reference internal" href="#torch.distributions.constraint_registry.ConstraintRegistry" title="torch.distributions.constraint_registry.ConstraintRegistry"><code class="xref py py-class docutils literal"><span class="pre">ConstraintRegistry</span></code></a>
object.</p>
<dl class="class">
<dt id="torch.distributions.constraint_registry.ConstraintRegistry">
<em class="property">class </em><code class="descclassname">torch.distributions.constraint_registry.</code><code class="descname">ConstraintRegistry</code><a class="reference internal" href="_modules/torch/distributions/constraint_registry.html#ConstraintRegistry"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.constraint_registry.ConstraintRegistry" title="Permalink to this definition"></a></dt>
<dd><p>Registry to link constraints to transforms.</p>
<dl class="method">
<dt id="torch.distributions.constraint_registry.ConstraintRegistry.register">
<code class="descname">register</code><span class="sig-paren">(</span><em>constraint</em>, <em>factory=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/distributions/constraint_registry.html#ConstraintRegistry.register"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.distributions.constraint_registry.ConstraintRegistry.register" title="Permalink to this definition"></a></dt>
<dd><p>Registers a <a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">Constraint</span></code></a>
subclass in this registry. Usage:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="nd">@my_registry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">MyConstraintClass</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">construct_transform</span><span class="p">(</span><span class="n">constraint</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">constraint</span><span class="p">,</span> <span class="n">MyConstraint</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">MyTransform</span><span class="p">(</span><span class="n">constraint</span><span class="o">.</span><span class="n">arg_constraints</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>constraint</strong> (subclass of <a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">Constraint</span></code></a>) &#8211; A subclass of <a class="reference internal" href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code class="xref py py-class docutils literal"><span class="pre">Constraint</span></code></a>, or
a singleton object of the desired class.</li>
<li><strong>factory</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#callable" title="(in Python v3.6)"><em>callable</em></a>) &#8211; A callable that inputs a constraint object and returns
a  <a class="reference internal" href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code class="xref py py-class docutils literal"><span class="pre">Transform</span></code></a> object.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="multiprocessing.html" class="btn btn-neutral float-right" title="Multiprocessing package - torch.multiprocessing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="autograd.html" class="btn btn-neutral" title="Automatic differentiation package - torch.autograd" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Torch Contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'master',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  <script type="text/javascript">
      jQuery(function () {
          
          SphinxRtdTheme.Navigation.enableSticky();
          
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-1', 'auto');
  ga('send', 'pageview');

</script>


</body>
</html>