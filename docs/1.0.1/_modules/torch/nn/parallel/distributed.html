


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.nn.parallel.distributed &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/nn/parallel/distributed.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  <a href='http://pytorch.org/docs/versions.html'>1.0.1 &#x25BC</a>
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html#torch-nn-functional">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html#torch-nn-init">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../multiprocessing.html">torch.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ffi.html">torch.utils.ffi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed_deprecated.html">torch.distributed.deprecated</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../legacy.html">torch.legacy</a></li>
</ul>
<p class="caption"><span class="caption-text">torchvision Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torchvision/index.html">torchvision</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
          <li><a href="../../../torch.html">torch</a> &gt;</li>
        
      <li>torch.nn.parallel.distributed</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.nn.parallel.distributed</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">copy</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">torch.cuda.comm</span> <span class="k">import</span> <span class="n">broadcast_coalesced</span>
<span class="kn">from</span> <span class="nn">torch.cuda</span> <span class="k">import</span> <span class="n">nccl</span>
<span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>

<span class="k">if</span> <span class="n">dist</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="kn">from</span> <span class="nn">torch.distributed.distributed_c10d</span> <span class="k">import</span> <span class="n">_get_default_group</span>

<span class="kn">from</span> <span class="nn">..modules</span> <span class="k">import</span> <span class="n">Module</span>
<span class="kn">from</span> <span class="nn">.replicate</span> <span class="k">import</span> <span class="n">replicate</span>
<span class="kn">from</span> <span class="nn">.scatter_gather</span> <span class="k">import</span> <span class="n">scatter_kwargs</span><span class="p">,</span> <span class="n">gather</span>
<span class="kn">from</span> <span class="nn">.parallel_apply</span> <span class="k">import</span> <span class="n">parallel_apply</span>
<span class="kn">from</span> <span class="nn">torch.cuda._utils</span> <span class="k">import</span> <span class="n">_get_device_index</span>


<div class="viewcode-block" id="DistributedDataParallel"><a class="viewcode-back" href="../../../../nn.html#torch.nn.parallel.DistributedDataParallel">[docs]</a><span class="k">class</span> <span class="nc">DistributedDataParallel</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Implements distributed data parallelism that is based on</span>
<span class="sd">    torch.distributed package at the module level.</span>

<span class="sd">    This container parallelizes the application of the given module by</span>
<span class="sd">    splitting the input across the specified devices by chunking in the batch</span>
<span class="sd">    dimension. The module is replicated on each machine and each device, and</span>
<span class="sd">    each such replica handles a portion of the input. During the backwards</span>
<span class="sd">    pass, gradients from each node are averaged.</span>

<span class="sd">    The batch size should be larger than the number of GPUs used locally. It</span>
<span class="sd">    should also be an integer multiple of the number of GPUs so that each chunk</span>
<span class="sd">    is the same size (so that each GPU processes the same number of samples).</span>

<span class="sd">    See also: :ref:`distributed-basics` and :ref:`cuda-nn-dataparallel-instead`.</span>
<span class="sd">    The same constraints on input as in :class:`torch.nn.DataParallel` apply.</span>

<span class="sd">    Creation of this class requires that ``torch.distributed`` to be already</span>
<span class="sd">    initialized, by calling :func:`torch.distributed.init_process_group`</span>

<span class="sd">    ``DistributedDataParallel`` can be used in the following two ways:</span>

<span class="sd">    (1) Single-Process Multi-GPU</span>

<span class="sd">    In this case, a single process will be</span>
<span class="sd">    spawned on each host/node and each process will operate on all the GPUs</span>
<span class="sd">    of the node where it&#39;s running. To use ``DistributedDataParallel`` in</span>
<span class="sd">    this way, you can simply construct the model as the following:</span>

<span class="sd">        &gt;&gt;&gt; torch.distributed.init_process_group(backend=&quot;nccl&quot;)</span>
<span class="sd">        &gt;&gt;&gt; model = DistributedDataParallel(model) # device_ids will include all GPU devices be default</span>

<span class="sd">    (2) Multi-Process Single-GPU</span>

<span class="sd">    This is the highly recommended way to use ``DistributedDataParallel``, with</span>
<span class="sd">    multiple processes, each of which operates on a single GPU. This is</span>
<span class="sd">    currently the fastest approach to do data parallel training using PyTorch</span>
<span class="sd">    and applies to both single-node(multi-GPU) and multi-node data</span>
<span class="sd">    parallel training. It is proven to be significantly faster than</span>
<span class="sd">    :class:`torch.nn.DataParallel` for single-node multi-GPU data</span>
<span class="sd">    parallel training.</span>

<span class="sd">    Here is how to use it: on each host with N GPUs, you should spawn up N</span>
<span class="sd">    processes, while ensuring that each process invidually works on a single GPU</span>
<span class="sd">    from 0 to N-1. Therefore, it is your job to ensure that your training script</span>
<span class="sd">    operates on a single given GPU by calling:</span>

<span class="sd">        &gt;&gt;&gt; torch.cuda.set_device(i)</span>

<span class="sd">    where i is from 0 to N-1. In each process, you should refer the following</span>
<span class="sd">    to construct this module:</span>

<span class="sd">        &gt;&gt;&gt; torch.distributed.init_process_group(backend=&#39;nccl&#39;, world_size=4, init_method=&#39;...&#39;)</span>
<span class="sd">        &gt;&gt;&gt; model = DistributedDataParallel(model, device_ids=[i], output_device=i)</span>

<span class="sd">    In order to spawn up multiple processes per node, you can use either</span>
<span class="sd">    ``torch.distributed.launch`` or ``torch.multiprocessing.spawn``</span>

<span class="sd">    .. note:: ``nccl`` backend is currently the fastest and</span>
<span class="sd">        highly recommended backend to be used with Multi-Process Single-GPU</span>
<span class="sd">        distributed training and this applies to both single-node and multi-node</span>
<span class="sd">        distributed training</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This module works only with the ``gloo`` and ``nccl`` backends.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        Constructor, forward method, and differentiation of the output (or a</span>
<span class="sd">        function of the output of this module) is a distributed synchronization</span>
<span class="sd">        point. Take that into account in case different processes might be</span>
<span class="sd">        executing different code.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This module assumes all parameters are registered in the model by the</span>
<span class="sd">        time it is created. No parameters should be added nor removed later.</span>
<span class="sd">        Same applies to buffers.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This module assumes all parameters are registered in the model of each</span>
<span class="sd">        distributed processes are in the same order. The module itself will</span>
<span class="sd">        conduct gradient all-reduction following the reverse order of the</span>
<span class="sd">        registered parameters of the model. In other wise, it is users&#39;</span>
<span class="sd">        responsibility to ensure that each distributed process has the exact</span>
<span class="sd">        same model and thus the exact parameter registeration order.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This module assumes all buffers and gradients are dense.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This module doesn&#39;t work with :func:`torch.autograd.grad` (i.e. it will</span>
<span class="sd">        only work if gradients are to be accumulated in ``.grad`` attributes of</span>
<span class="sd">        parameters).</span>

<span class="sd">    .. warning::</span>

<span class="sd">        If you plan on using this module with a ``nccl`` backend or a ``gloo``</span>
<span class="sd">        backend (that uses Infiniband), together with a DataLoader that uses</span>
<span class="sd">        multiple workers, please change the multiprocessing start method to</span>
<span class="sd">        ``forkserver`` (Python 3 only) or ``spawn``. Unfortunately</span>
<span class="sd">        Gloo (that uses Infiniband) and NCCL2 are not fork safe, and you will</span>
<span class="sd">        likely experience deadlocks if you don&#39;t change this setting.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        Forward and backward hooks defined on :attr:`module` and its submodules</span>
<span class="sd">        won&#39;t be invoked anymore, unless the hooks are initialized in the</span>
<span class="sd">        :meth:`forward` method.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        You should never try to change your model&#39;s parameters after wrapping</span>
<span class="sd">        up your model with DistributedDataParallel. In other words, when</span>
<span class="sd">        wrapping up your model with DistributedDataParallel, the constructor of</span>
<span class="sd">        DistributedDataParallel will register the additional gradient</span>
<span class="sd">        reduction functions on all the parameters of the model itself at the</span>
<span class="sd">        time of construction. If you change the model&#39;s parameters after</span>
<span class="sd">        the DistributedDataParallel construction, this is not supported and</span>
<span class="sd">        unexpected behaviors can happen, since some parameters&#39; gradient</span>
<span class="sd">        reduction functions might not get called.</span>

<span class="sd">    .. note::</span>
<span class="sd">        Parameters are never broadcast between processes. The module performs</span>
<span class="sd">        an all-reduce step on gradients and assumes that they will be modified</span>
<span class="sd">        by the optimizer in all processes in the same way. Buffers</span>
<span class="sd">        (e.g. BatchNorm stats) are broadcast from the module in process of rank</span>
<span class="sd">        0, to all other replicas in the system in every iteration.</span>

<span class="sd">    Args:</span>
<span class="sd">        module (Module): module to be parallelized</span>
<span class="sd">        device_ids (list of int or torch.device): CUDA devices (default: all devices)</span>
<span class="sd">        output_device (int or torch.device): device location of output (default: device_ids[0])</span>
<span class="sd">        broadcast_buffers (bool): flag that enables syncing (broadcasting) buffers of</span>
<span class="sd">                           the module at beginning of the forward function.</span>
<span class="sd">                           (default: True)</span>
<span class="sd">        process_group: the process group to be used for distributed data</span>
<span class="sd">                       all-reduction. If None, the default process group, which</span>
<span class="sd">                       is created by ```torch.distributed.init_process_group```,</span>
<span class="sd">                       will be used. (default: None)</span>
<span class="sd">        bucket_cap_mb: DistributedDataParallel will bucket parameters into</span>
<span class="sd">                       multiple buckets so that gradient reduction of each</span>
<span class="sd">                       bucket can potentially overlap with backward computation.</span>
<span class="sd">                       bucket_cap_mb controls the bucket size in MegaBytes (MB)</span>
<span class="sd">                       (default: 25)</span>
<span class="sd">        check_reduction: when setting to True, it enables DistributedDataParallel</span>
<span class="sd">                         to automatically check if the previous iteration&#39;s</span>
<span class="sd">                         backward reductions were successfully issued at the</span>
<span class="sd">                         beginning of every iteration&#39;s forward function.</span>
<span class="sd">                         You normally don&#39;t need this option enabled unless you</span>
<span class="sd">                         are observing weird behaviors such as different ranks</span>
<span class="sd">                         are getting different gradients, which should not</span>
<span class="sd">                         happen if DistributedDataParallel is corrected used.</span>
<span class="sd">                         (default: False)</span>

<span class="sd">    Attributes:</span>
<span class="sd">        module (Module): the module to be parallelized</span>

<span class="sd">    Example::</span>
<span class="sd">        &gt;&gt;&gt; torch.distributed.init_process_group(backend=&#39;nccl&#39;, world_size=4, init_method=&#39;...&#39;)</span>
<span class="sd">        &gt;&gt;&gt; net = torch.nn.DistributedDataParallel(model, pg)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">output_device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">broadcast_buffers</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">process_group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bucket_cap_mb</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
                 <span class="n">check_reduction</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">DistributedDataParallel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Use all devices by default</span>
        <span class="k">if</span> <span class="n">device_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">device_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()))</span>

        <span class="k">if</span> <span class="n">output_device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output_device</span> <span class="o">=</span> <span class="n">device_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">process_group</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">process_group</span> <span class="o">=</span> <span class="n">_get_default_group</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">process_group</span> <span class="o">=</span> <span class="n">process_group</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">module</span> <span class="o">=</span> <span class="n">module</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">_get_device_index</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="kc">True</span><span class="p">),</span> <span class="n">device_ids</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_device</span> <span class="o">=</span> <span class="n">_get_device_index</span><span class="p">(</span><span class="n">output_device</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_buffers</span> <span class="o">=</span> <span class="n">broadcast_buffers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_reduction</span> <span class="o">=</span> <span class="n">check_reduction</span>

        <span class="n">MB</span> <span class="o">=</span> <span class="mi">1024</span> <span class="o">*</span> <span class="mi">1024</span>

        <span class="c1"># used for intra-node param sync and inter-node sync as well</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_bucket_size</span> <span class="o">=</span> <span class="mi">250</span> <span class="o">*</span> <span class="n">MB</span>

        <span class="c1"># reduction bucket size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bucket_bytes_cap</span> <span class="o">=</span> <span class="n">bucket_cap_mb</span> <span class="o">*</span> <span class="n">MB</span>

        <span class="c1"># Sync params and buffers</span>
        <span class="n">module_states</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">module_states</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dist_broadcast_coalesced</span><span class="p">(</span><span class="n">module_states</span><span class="p">,</span>
                                           <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_bucket_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_ddp_init_helper</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_ddp_init_helper</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialization helper function that does the following:</span>

<span class="sd">        (1) replicating the module from device[0] to the other devices</span>
<span class="sd">        (2) bucketing the parameters for reductions</span>
<span class="sd">        (3) resetting the bucketing states</span>
<span class="sd">        (4) registering the grad hooks</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># TODO: we don&#39;t need to replicate params in here. they&#39;re always going to</span>
            <span class="c1"># be broadcasted using larger blocks in broadcast_coalesced, so it might be</span>
            <span class="c1"># better to not pollute the caches with these small blocks</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_module_copies</span> <span class="o">=</span> <span class="n">replicate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">,</span> <span class="n">detach</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_module_copies</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span>

            <span class="k">for</span> <span class="n">module_copy</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_copies</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
                <span class="k">for</span> <span class="n">param</span><span class="p">,</span> <span class="n">copy_param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">module_copy</span><span class="o">.</span><span class="n">parameters</span><span class="p">()):</span>
                    <span class="n">copy_param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_module_copies</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">modules_params_data</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">modules_buffers_data</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">))]</span>

        <span class="k">for</span> <span class="n">dev_idx</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_module_copies</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">modules_params_data</span><span class="p">[</span><span class="n">dev_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">modules_buffers_data</span><span class="p">[</span><span class="n">dev_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">b</span><span class="o">.</span><span class="n">data</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">buffers</span><span class="p">()]</span>

        <span class="c1"># This is a triply-nested list where the &quot;dimensions&quot; are: devices, buckets, bucket_elems</span>
        <span class="n">param_buckets</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Split the parameters into buckets and by types as well</span>
        <span class="c1"># We only need to bucket and reduce parameters that require grad and</span>
        <span class="c1"># this is also true for backward since only the backward hooks for</span>
        <span class="c1"># parameters that require grad will be registered with gradient</span>
        <span class="c1"># reduction functions</span>
        <span class="n">params_to_bucket</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_copies</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">dev_idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_module_copies</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                    <span class="n">params_to_bucket</span><span class="p">[</span><span class="n">dev_idx</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

        <span class="n">param_buckets</span> <span class="o">=</span> <span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">_dist_bucket_tensors</span><span class="p">(</span><span class="n">dev_params_to_bucket</span><span class="p">,</span>
                                                   <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_bytes_cap</span><span class="p">),</span>
                                                   <span class="n">fine_grained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                         <span class="k">for</span> <span class="n">dev_params_to_bucket</span> <span class="ow">in</span> <span class="n">params_to_bucket</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bucket_map</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># We transpose param_buckets, so the loop is over buckets.</span>
        <span class="c1"># param_buckets_tuple is a doubly-nested list with &quot;dims&quot;: devices, bucket_elems</span>
        <span class="k">for</span> <span class="n">bucket_idx</span><span class="p">,</span> <span class="n">param_buckets_tuple</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">param_buckets</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="c1"># Now, we transpose again, so we iterate over bucket_elems, but getting tuples</span>
            <span class="c1"># of params from each device.</span>
            <span class="k">for</span> <span class="n">param_tuple</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">param_buckets_tuple</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">param_tuple</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                    <span class="k">continue</span>
                <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">param_tuple</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">bucket_map</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">bucket_idx</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">buckets</span> <span class="o">=</span> <span class="p">[[[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">])]</span>
                        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">))]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">))]</span>
        <span class="c1"># The number of params ready in each bucket</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buckets_ready_size</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">))]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">))]</span>

        <span class="c1"># coalesced bucket for only device 0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buckets_coalesced</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">))]</span>
        <span class="c1"># We will always reduce the bucket following the reverse order</span>
        <span class="c1"># that is, alway reduces following the order of: n - 1, n - 2, ..., 0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">next_bucket</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="c1"># When all buckets are reduced, this will be set to True. This flag is</span>
        <span class="c1"># useful for sanity checks to ensure that each iteration&#39;s backward has</span>
        <span class="c1"># always reduced all buckets</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_buckets_reduced</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_previous_reduction</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ready_buckets_not_reduced</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduction_works</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">devs_ready</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_register_grad_hooks</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_default_group</span><span class="p">()</span>
        <span class="n">attrs</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;process_group&#39;</span><span class="p">],</span> \
            <span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;default_streams&#39;</span><span class="p">],</span> \
            <span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;_grad_accs&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">attrs</span>

    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="c1"># If serializable, then the process group should be the default one</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">process_group</span> <span class="o">=</span> <span class="n">_get_default_group</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_previous_reduction</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistributedDataParallel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__setstate__</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ddp_init_helper</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_check_default_group</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">pickle_not_supported</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_group</span> <span class="o">!=</span> <span class="n">_get_default_group</span><span class="p">():</span>
                <span class="n">pickle_not_supported</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
            <span class="n">pickle_not_supported</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">if</span> <span class="n">pickle_not_supported</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;DDP Pickling/Unpickling are only supported &quot;</span>
                               <span class="s2">&quot;when using DDP with the default process &quot;</span>
                               <span class="s2">&quot;group. That is, when you have called &quot;</span>
                               <span class="s2">&quot;init_process_group and have not passed &quot;</span>
                               <span class="s2">&quot;process_group argument to DDP constructor&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_check_previous_reduction</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="c1"># self.check_previous_reduction will be False in the first iteration</span>
        <span class="c1"># and is then toggled to True for all future iterations.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">check_previous_reduction</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">check_previous_reduction</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">all_buckets_reduced</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Not all gradients have been reduced from &quot;</span>
                                   <span class="s2">&quot;the backward of the previous iteration. &quot;</span>
                                   <span class="s2">&quot;This is unexpected and fatal error. Please &quot;</span>
                                   <span class="s2">&quot;check and ensure that the model&#39;s &quot;</span>
                                   <span class="s2">&quot;parameters are not changed after you wrap &quot;</span>
                                   <span class="s2">&quot;up the model with DistributedDataParallel.&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">all_buckets_reduced</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">check_reduction</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_previous_reduction</span><span class="p">()</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_sync_params</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">module</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parallel_apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_module_copies</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)],</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">scatter</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">device_ids</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">scatter_kwargs</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="n">device_ids</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parallel_apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">replicas</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">parallel_apply</span><span class="p">(</span><span class="n">replicas</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">replicas</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">gather</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">output_device</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gather</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">output_device</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_previous_reduction</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistributedDataParallel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_module_copies</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>
            <span class="n">module</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_dist_broadcast_coalesced</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">):</span>
        <span class="n">dist</span><span class="o">.</span><span class="n">_dist_broadcast_coalesced</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">process_group</span><span class="p">,</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">buffer_size</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_sync_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># intra-node parameter sync</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">broadcast_coalesced</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modules_params_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">,</span>
                                         <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_bucket_size</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">module_params_data</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules_params_data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
                <span class="k">for</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">param_data</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">module_params_data</span><span class="p">):</span>
                    <span class="n">param_data</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

        <span class="c1"># module buffer sync</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_buffers</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modules_buffers_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># cross-node buffer sync</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_dist_broadcast_coalesced</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modules_buffers_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_bucket_size</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># intra-node buffer sync</span>
                    <span class="n">result</span> <span class="o">=</span> <span class="n">broadcast_coalesced</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">modules_buffers_data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                                 <span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">,</span>
                                                 <span class="bp">self</span><span class="o">.</span><span class="n">broadcast_bucket_size</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">tensors</span><span class="p">,</span> <span class="n">module_buffers_data</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules_buffers_data</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
                        <span class="k">for</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">buffer_data</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">module_buffers_data</span><span class="p">):</span>
                            <span class="n">buffer_data</span><span class="o">.</span><span class="n">set_</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_register_grad_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_grad_accs</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># need to keep them in scope</span>

        <span class="c1"># default stream tracking to launch nccl reduce kernels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">default_streams</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dev_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">dev_id</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">default_streams</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_stream</span><span class="p">())</span>

        <span class="k">for</span> <span class="n">device_idx</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_module_copies</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                    <span class="n">p_tmp</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
                    <span class="n">grad_acc</span> <span class="o">=</span> <span class="n">p_tmp</span><span class="o">.</span><span class="n">grad_fn</span><span class="o">.</span><span class="n">next_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">grad_acc</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_make_param_hook</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">device_idx</span><span class="p">))</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_grad_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">grad_acc</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_param_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="p">,</span> <span class="n">device_idx</span><span class="p">):</span>
        <span class="n">bucket_idx</span><span class="p">,</span> <span class="n">bucket_offset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bucket_map</span><span class="p">[</span><span class="n">param</span><span class="p">]</span>

        <span class="k">def</span> <span class="nf">distributed_data_parallel_hook</span><span class="p">(</span><span class="o">*</span><span class="n">unused</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;DistributedDataParallel only works &quot;</span>
                                   <span class="s2">&quot;with gradients that don&#39;t require grad&quot;</span><span class="p">)</span>
            <span class="n">bucket</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">buckets</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">][</span><span class="n">device_idx</span><span class="p">]</span>
            <span class="n">bucket</span><span class="p">[</span><span class="n">bucket_offset</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">buckets_ready_size</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">][</span><span class="n">device_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="c1"># We can flush these and save memory for replicas</span>
            <span class="k">if</span> <span class="n">device_idx</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">param</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">set_</span><span class="p">()</span>

            <span class="c1"># Current device&#39;s bucket is full</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">buckets_ready_size</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">][</span><span class="n">device_idx</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">devs_ready</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">devs_ready</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">]</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">):</span>
                    <span class="k">return</span>

                <span class="c1"># Now all devices&#39;s buckets with index: bucket_idx are ready</span>
                <span class="k">if</span> <span class="n">bucket_idx</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_bucket</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_queue_reduction</span><span class="p">(</span><span class="n">bucket_idx</span><span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">next_bucket</span> <span class="o">-=</span> <span class="mi">1</span>
                    <span class="c1"># Now reduce anything that is ready but not yet reduced</span>
                    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ready_buckets_not_reduced</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">sorted_todo</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ready_buckets_not_reduced</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">sorted_todo</span><span class="p">:</span>
                            <span class="c1"># Nothing can be reduced now</span>
                            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_bucket</span><span class="p">:</span>
                                <span class="k">break</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">_queue_reduction</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">ready_buckets_not_reduced</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_bucket</span><span class="p">:</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">next_bucket</span> <span class="o">-=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">ready_buckets_not_reduced</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">bucket_idx</span><span class="p">)</span>

                <span class="c1"># When all devices&#39; buckets</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">next_bucket</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># A final sync for all the reduction works</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_sync_reduction_works</span><span class="p">()</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">all_buckets_reduced</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="n">distributed_data_parallel_hook</span>

    <span class="k">def</span> <span class="nf">_queue_reduction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bucket_idx</span><span class="p">):</span>
        <span class="c1"># _queue_reduction will use a seperate CUDA stream to coalesce</span>
        <span class="c1"># the small tensors to achieve more parallelisms, before passing the</span>
        <span class="c1"># coalesced tensor into the c10d CUDA stream for reduction</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">_queue_reduction</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">process_group</span><span class="p">,</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">buckets</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">],</span>
                                       <span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduction_works</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buckets_coalesced</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">_sync_reduction_works</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Now only work on the first GPU of self.device_ids</span>
        <span class="c1"># _sync_reduction will use a seperate CUDA stream to uncoalesce</span>
        <span class="c1"># the coalesced tensors to achieve more parallelisms</span>
        <span class="k">for</span> <span class="n">bucket_idx</span><span class="p">,</span> <span class="n">grads_batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">buckets</span><span class="p">):</span>
            <span class="n">dist</span><span class="o">.</span><span class="n">_sync_reduction</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction_works</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">],</span>
                                 <span class="n">grads_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                 <span class="bp">self</span><span class="o">.</span><span class="n">buckets_coalesced</span><span class="p">[</span><span class="n">bucket_idx</span><span class="p">])</span>

        <span class="c1"># Reset the module states</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">next_bucket</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ready_buckets_not_reduced</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduction_works</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">devs_ready</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">))]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">buckets</span> <span class="o">=</span> <span class="p">[[[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">[</span><span class="n">i</span><span class="p">])]</span>
                        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">))]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buckets_coalesced</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">buckets_ready_size</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_ids</span><span class="p">))]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bucket_sizes</span><span class="p">))]</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Torch Contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript">
           var DOCUMENTATION_OPTIONS = {
               URL_ROOT:'../../../../',
               VERSION:'master',
               LANGUAGE:'None',
               COLLAPSE_INDEX:false,
               FILE_SUFFIX:'.html',
               HAS_SOURCE:  true,
               SOURCELINK_SUFFIX: '.txt'
           };
       </script>
         <script type="text/javascript" src="../../../../_static/jquery.js"></script>
         <script type="text/javascript" src="../../../../_static/underscore.js"></script>
         <script type="text/javascript" src="../../../../_static/doctools.js"></script>
         <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js"></script>
         <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js"></script>
         <script type="text/javascript" src="../../../../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://pytorch.org/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>