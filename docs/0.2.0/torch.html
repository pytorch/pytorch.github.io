

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch &mdash; PyTorch master documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
  
    <link rel="stylesheet" href="_static/css/pytorch_theme.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="genindex.html"/>
        <link rel="search" title="Search" href="search.html"/>
    <link rel="top" title="PyTorch master documentation" href="index.html"/>
        <link rel="next" title="torch.Tensor" href="tensors.html"/>
        <link rel="prev" title="Serialization semantics" href="notes/serialization.html"/> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html">
          

          
            
            <img src="_static/pytorch-logo-dark.svg" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                <a href="https://pytorch.org/docs/versions.html"> 0.2.0_1 &#x25BC</a>
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd mechanics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#excluding-subgraphs-from-backward">Excluding subgraphs from backward</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/autograd.html#requires-grad"><code class="docutils literal"><span class="pre">requires_grad</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/autograd.html#volatile"><code class="docutils literal"><span class="pre">volatile</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#how-autograd-encodes-the-history">How autograd encodes the history</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#in-place-operations-on-variables">In-place operations on Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/autograd.html#in-place-correctness-checks">In-place correctness checks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">Broadcasting semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/broadcasting.html#general-semantics">General semantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/broadcasting.html#in-place-semantics">In-place semantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/broadcasting.html#backwards-compatibility">Backwards compatibility</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/cuda.html#best-practices">Best practices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/cuda.html#use-pinned-memory-buffers">Use pinned memory buffers</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/cuda.html#use-nn-dataparallel-instead-of-multiprocessing">Use nn.DataParallel instead of multiprocessing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">Extending PyTorch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/extending.html#extending-torch-autograd">Extending <code class="docutils literal"><span class="pre">torch.autograd</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/extending.html#extending-torch-nn">Extending <code class="docutils literal"><span class="pre">torch.nn</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/extending.html#adding-a-module">Adding a <code class="docutils literal"><span class="pre">Module</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="notes/extending.html#writing-custom-c-extensions">Writing custom C extensions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">Multiprocessing best practices</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/multiprocessing.html#sharing-cuda-tensors">Sharing CUDA tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="notes/multiprocessing.html#best-practices-and-tips">Best practices and tips</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/multiprocessing.html#avoiding-and-fighting-deadlocks">Avoiding and fighting deadlocks</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/multiprocessing.html#reuse-buffers-passed-through-a-queue">Reuse buffers passed through a Queue</a></li>
<li class="toctree-l3"><a class="reference internal" href="notes/multiprocessing.html#asynchronous-multiprocess-training-e-g-hogwild">Asynchronous multiprocess training (e.g. Hogwild)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="notes/multiprocessing.html#hogwild">Hogwild</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">Serialization semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="notes/serialization.html#best-practices">Best practices</a><ul>
<li class="toctree-l3"><a class="reference internal" href="notes/serialization.html#recommended-approach-for-saving-a-model">Recommended approach for saving a model</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">torch</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#tensors">Tensors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#creation-ops">Creation Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="#indexing-slicing-joining-mutating-ops">Indexing, Slicing, Joining, Mutating Ops</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#random-sampling">Random sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#serialization">Serialization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parallelism">Parallelism</a></li>
<li class="toctree-l2"><a class="reference internal" href="#math-operations">Math operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#pointwise-ops">Pointwise Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reduction-ops">Reduction Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="#comparison-ops">Comparison Ops</a></li>
<li class="toctree-l3"><a class="reference internal" href="#other-operations">Other Operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#blas-and-lapack-operations">BLAS and LAPACK Operations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">torch.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nn.html#parameters">Parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#containers">Containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#module"><span class="hidden-section">Module</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#sequential"><span class="hidden-section">Sequential</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#modulelist"><span class="hidden-section">ModuleList</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#parameterlist"><span class="hidden-section">ParameterList</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#convolution-layers">Convolution Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv1d"><span class="hidden-section">Conv1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv2d"><span class="hidden-section">Conv2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv3d"><span class="hidden-section">Conv3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#convtranspose1d"><span class="hidden-section">ConvTranspose1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#convtranspose2d"><span class="hidden-section">ConvTranspose2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#convtranspose3d"><span class="hidden-section">ConvTranspose3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#pooling-layers">Pooling Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxpool1d"><span class="hidden-section">MaxPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxpool2d"><span class="hidden-section">MaxPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxpool3d"><span class="hidden-section">MaxPool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxunpool1d"><span class="hidden-section">MaxUnpool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxunpool2d"><span class="hidden-section">MaxUnpool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#maxunpool3d"><span class="hidden-section">MaxUnpool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avgpool1d"><span class="hidden-section">AvgPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avgpool2d"><span class="hidden-section">AvgPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avgpool3d"><span class="hidden-section">AvgPool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#fractionalmaxpool2d"><span class="hidden-section">FractionalMaxPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lppool2d"><span class="hidden-section">LPPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptivemaxpool1d"><span class="hidden-section">AdaptiveMaxPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptivemaxpool2d"><span class="hidden-section">AdaptiveMaxPool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptiveavgpool1d"><span class="hidden-section">AdaptiveAvgPool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptiveavgpool2d"><span class="hidden-section">AdaptiveAvgPool2d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#padding-layers">Padding Layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#reflectionpad2d"><span class="hidden-section">ReflectionPad2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#replicationpad2d"><span class="hidden-section">ReplicationPad2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#replicationpad3d"><span class="hidden-section">ReplicationPad3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#zeropad2d"><span class="hidden-section">ZeroPad2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#constantpad2d"><span class="hidden-section">ConstantPad2d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#non-linear-activations">Non-linear Activations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#relu"><span class="hidden-section">ReLU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#relu6"><span class="hidden-section">ReLU6</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#elu"><span class="hidden-section">ELU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#selu"><span class="hidden-section">SELU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#prelu"><span class="hidden-section">PReLU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#leakyrelu"><span class="hidden-section">LeakyReLU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#threshold"><span class="hidden-section">Threshold</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hardtanh"><span class="hidden-section">Hardtanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#sigmoid"><span class="hidden-section">Sigmoid</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#tanh"><span class="hidden-section">Tanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#logsigmoid"><span class="hidden-section">LogSigmoid</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softplus"><span class="hidden-section">Softplus</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softshrink"><span class="hidden-section">Softshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softsign"><span class="hidden-section">Softsign</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#tanhshrink"><span class="hidden-section">Tanhshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softmin"><span class="hidden-section">Softmin</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softmax"><span class="hidden-section">Softmax</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#logsoftmax"><span class="hidden-section">LogSoftmax</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#normalization-layers">Normalization layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batchnorm1d"><span class="hidden-section">BatchNorm1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batchnorm2d"><span class="hidden-section">BatchNorm2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batchnorm3d"><span class="hidden-section">BatchNorm3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#instancenorm1d"><span class="hidden-section">InstanceNorm1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#instancenorm2d"><span class="hidden-section">InstanceNorm2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#instancenorm3d"><span class="hidden-section">InstanceNorm3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#recurrent-layers">Recurrent layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#rnn"><span class="hidden-section">RNN</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lstm"><span class="hidden-section">LSTM</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#gru"><span class="hidden-section">GRU</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#rnncell"><span class="hidden-section">RNNCell</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lstmcell"><span class="hidden-section">LSTMCell</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#grucell"><span class="hidden-section">GRUCell</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#linear-layers">Linear layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#linear"><span class="hidden-section">Linear</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#dropout-layers">Dropout layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dropout"><span class="hidden-section">Dropout</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dropout2d"><span class="hidden-section">Dropout2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dropout3d"><span class="hidden-section">Dropout3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#alphadropout"><span class="hidden-section">AlphaDropout</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#sparse-layers">Sparse layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#embedding"><span class="hidden-section">Embedding</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#embeddingbag"><span class="hidden-section">EmbeddingBag</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#distance-functions">Distance functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosinesimilarity"><span class="hidden-section">CosineSimilarity</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pairwisedistance"><span class="hidden-section">PairwiseDistance</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#loss-functions">Loss functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#l1loss"><span class="hidden-section">L1Loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#mseloss"><span class="hidden-section">MSELoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#crossentropyloss"><span class="hidden-section">CrossEntropyLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#nllloss"><span class="hidden-section">NLLLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#poissonnllloss"><span class="hidden-section">PoissonNLLLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#nllloss2d"><span class="hidden-section">NLLLoss2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#kldivloss"><span class="hidden-section">KLDivLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#bceloss"><span class="hidden-section">BCELoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#bcewithlogitsloss"><span class="hidden-section">BCEWithLogitsLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#marginrankingloss"><span class="hidden-section">MarginRankingLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hingeembeddingloss"><span class="hidden-section">HingeEmbeddingLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabelmarginloss"><span class="hidden-section">MultiLabelMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#smoothl1loss"><span class="hidden-section">SmoothL1Loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#softmarginloss"><span class="hidden-section">SoftMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabelsoftmarginloss"><span class="hidden-section">MultiLabelSoftMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosineembeddingloss"><span class="hidden-section">CosineEmbeddingLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multimarginloss"><span class="hidden-section">MultiMarginLoss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#tripletmarginloss"><span class="hidden-section">TripletMarginLoss</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#vision-layers">Vision layers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pixelshuffle"><span class="hidden-section">PixelShuffle</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsample"><span class="hidden-section">Upsample</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsamplingnearest2d"><span class="hidden-section">UpsamplingNearest2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsamplingbilinear2d"><span class="hidden-section">UpsamplingBilinear2d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#dataparallel-layers-multi-gpu-distributed">DataParallel layers (multi-GPU, distributed)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#dataparallel"><span class="hidden-section">DataParallel</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#distributeddataparallel"><span class="hidden-section">DistributedDataParallel</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#utilities">Utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#clip-grad-norm"><span class="hidden-section">clip_grad_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#weight-norm"><span class="hidden-section">weight_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#remove-weight-norm"><span class="hidden-section">remove_weight_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#packedsequence"><span class="hidden-section">PackedSequence</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pack-padded-sequence"><span class="hidden-section">pack_padded_sequence</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pad-packed-sequence"><span class="hidden-section">pad_packed_sequence</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nn.html#torch-nn-functional">torch.nn.functional</a><ul>
<li class="toctree-l2"><a class="reference internal" href="nn.html#convolution-functions">Convolution functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id16"><span class="hidden-section">conv1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id17"><span class="hidden-section">conv2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id18"><span class="hidden-section">conv3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv-transpose1d"><span class="hidden-section">conv_transpose1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv-transpose2d"><span class="hidden-section">conv_transpose2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#conv-transpose3d"><span class="hidden-section">conv_transpose3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#pooling-functions">Pooling functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avg-pool1d"><span class="hidden-section">avg_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avg-pool2d"><span class="hidden-section">avg_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#avg-pool3d"><span class="hidden-section">avg_pool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-pool1d"><span class="hidden-section">max_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-pool2d"><span class="hidden-section">max_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-pool3d"><span class="hidden-section">max_pool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-unpool1d"><span class="hidden-section">max_unpool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-unpool2d"><span class="hidden-section">max_unpool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#max-unpool3d"><span class="hidden-section">max_unpool3d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#lp-pool2d"><span class="hidden-section">lp_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-max-pool1d"><span class="hidden-section">adaptive_max_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-max-pool2d"><span class="hidden-section">adaptive_max_pool2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-avg-pool1d"><span class="hidden-section">adaptive_avg_pool1d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#adaptive-avg-pool2d"><span class="hidden-section">adaptive_avg_pool2d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#non-linear-activation-functions">Non-linear activation functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id19"><span class="hidden-section">threshold</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id20"><span class="hidden-section">relu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id21"><span class="hidden-section">hardtanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id22"><span class="hidden-section">relu6</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id23"><span class="hidden-section">elu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id24"><span class="hidden-section">selu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#leaky-relu"><span class="hidden-section">leaky_relu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id25"><span class="hidden-section">prelu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#rrelu"><span class="hidden-section">rrelu</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id26"><span class="hidden-section">logsigmoid</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hardshrink"><span class="hidden-section">hardshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id27"><span class="hidden-section">tanhshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id28"><span class="hidden-section">softsign</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id29"><span class="hidden-section">softplus</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id30"><span class="hidden-section">softmin</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id31"><span class="hidden-section">softmax</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id32"><span class="hidden-section">softshrink</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#log-softmax"><span class="hidden-section">log_softmax</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id33"><span class="hidden-section">tanh</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id34"><span class="hidden-section">sigmoid</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#normalization-functions">Normalization functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#batch-norm"><span class="hidden-section">batch_norm</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#normalize"><span class="hidden-section">normalize</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#linear-functions">Linear functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id35"><span class="hidden-section">linear</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#dropout-functions">Dropout functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id36"><span class="hidden-section">dropout</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#alpha-dropout"><span class="hidden-section">alpha_dropout</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id37"><span class="hidden-section">dropout2d</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id38"><span class="hidden-section">dropout3d</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#id39">Distance functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pairwise-distance"><span class="hidden-section">pairwise_distance</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosine-similarity"><span class="hidden-section">cosine_similarity</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#id40">Loss functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#binary-cross-entropy"><span class="hidden-section">binary_cross_entropy</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#poisson-nll-loss"><span class="hidden-section">poisson_nll_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cosine-embedding-loss"><span class="hidden-section">cosine_embedding_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#cross-entropy"><span class="hidden-section">cross_entropy</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#hinge-embedding-loss"><span class="hidden-section">hinge_embedding_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#kl-div"><span class="hidden-section">kl_div</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#l1-loss"><span class="hidden-section">l1_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#mse-loss"><span class="hidden-section">mse_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#margin-ranking-loss"><span class="hidden-section">margin_ranking_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabel-margin-loss"><span class="hidden-section">multilabel_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multilabel-soft-margin-loss"><span class="hidden-section">multilabel_soft_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#multi-margin-loss"><span class="hidden-section">multi_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#nll-loss"><span class="hidden-section">nll_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#binary-cross-entropy-with-logits"><span class="hidden-section">binary_cross_entropy_with_logits</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#smooth-l1-loss"><span class="hidden-section">smooth_l1_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#soft-margin-loss"><span class="hidden-section">soft_margin_loss</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#triplet-margin-loss"><span class="hidden-section">triplet_margin_loss</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="nn.html#vision-functions">Vision functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pixel-shuffle"><span class="hidden-section">pixel_shuffle</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#pad"><span class="hidden-section">pad</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#id42"><span class="hidden-section">upsample</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsample-nearest"><span class="hidden-section">upsample_nearest</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#upsample-bilinear"><span class="hidden-section">upsample_bilinear</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#grid-sample"><span class="hidden-section">grid_sample</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="nn.html#affine-grid"><span class="hidden-section">affine_grid</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nn.html#torch-nn-init">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a><ul>
<li class="toctree-l2"><a class="reference internal" href="optim.html#how-to-use-an-optimizer">How to use an optimizer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="optim.html#constructing-it">Constructing it</a></li>
<li class="toctree-l3"><a class="reference internal" href="optim.html#per-parameter-options">Per-parameter options</a></li>
<li class="toctree-l3"><a class="reference internal" href="optim.html#taking-an-optimization-step">Taking an optimization step</a><ul>
<li class="toctree-l4"><a class="reference internal" href="optim.html#optimizer-step"><code class="docutils literal"><span class="pre">optimizer.step()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="optim.html#optimizer-step-closure"><code class="docutils literal"><span class="pre">optimizer.step(closure)</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="optim.html#algorithms">Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="optim.html#how-to-adjust-learning-rate">How to adjust Learning Rate</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a><ul>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#variable">Variable</a><ul>
<li class="toctree-l3"><a class="reference internal" href="autograd.html#api-compatibility">API compatibility</a></li>
<li class="toctree-l3"><a class="reference internal" href="autograd.html#in-place-operations-on-variables">In-place operations on Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="autograd.html#in-place-correctness-checks">In-place correctness checks</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#function"><span class="hidden-section">Function</span></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="multiprocessing.html">torch.multiprocessing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="multiprocessing.html#strategy-management">Strategy management</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiprocessing.html#sharing-cuda-tensors">Sharing CUDA tensors</a></li>
<li class="toctree-l2"><a class="reference internal" href="multiprocessing.html#sharing-strategies">Sharing strategies</a><ul>
<li class="toctree-l3"><a class="reference internal" href="multiprocessing.html#file-descriptor-file-descriptor">File descriptor - <code class="docutils literal"><span class="pre">file_descriptor</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="multiprocessing.html#file-system-file-system">File system - <code class="docutils literal"><span class="pre">file_system</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a><ul>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#initialization">Initialization</a><ul>
<li class="toctree-l3"><a class="reference internal" href="distributed.html#tcp-initialization">TCP initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed.html#shared-file-system-initialization">Shared file-system initialization</a></li>
<li class="toctree-l3"><a class="reference internal" href="distributed.html#environment-variable-initialization">Environment variable initialization</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#groups">Groups</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#point-to-point-communication">Point-to-point communication</a></li>
<li class="toctree-l2"><a class="reference internal" href="distributed.html#collective-functions">Collective functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="legacy.html">torch.legacy</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#communication-collectives">Communication collectives</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#streams-and-events">Streams and events</a></li>
<li class="toctree-l2"><a class="reference internal" href="cuda.html#nvidia-tools-extension-nvtx">NVIDIA Tools Extension (NVTX)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="ffi.html">torch.utils.ffi</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
</ul>
<p class="caption"><span class="caption-text">torchvision Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="torchvision/torchvision.html">torchvision</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchvision/datasets.html">torchvision.datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="torchvision/datasets.html#mnist">MNIST</a></li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/datasets.html#coco">COCO</a><ul>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#captions">Captions</a></li>
<li class="toctree-l3"><a class="reference internal" href="torchvision/datasets.html#detection">Detection</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/datasets.html#lsun">LSUN</a></li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/datasets.html#imagefolder">ImageFolder</a></li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/datasets.html#imagenet-12">Imagenet-12</a></li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/datasets.html#cifar">CIFAR</a></li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/datasets.html#stl10">STL10</a></li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/datasets.html#svhn">SVHN</a></li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/datasets.html#phototour">PhotoTour</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="torchvision/models.html">torchvision.models</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchvision/transforms.html">torchvision.transforms</a><ul>
<li class="toctree-l2"><a class="reference internal" href="torchvision/transforms.html#transforms-on-pil-image">Transforms on PIL.Image</a></li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/transforms.html#transforms-on-torch-tensor">Transforms on torch.*Tensor</a></li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/transforms.html#conversion-transforms">Conversion Transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="torchvision/transforms.html#generic-transforms">Generic Transforms</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="torchvision/utils.html">torchvision.utils</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PyTorch</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>torch</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/torch.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-torch">
<span id="torch"></span><h1>torch<a class="headerlink" href="#module-torch" title="Permalink to this headline">¶</a></h1>
<p>The torch package contains data structures for multi-dimensional
tensors and mathematical operations over these are defined.
Additionally, it provides many utilities for efficient serializing of
Tensors and arbitrary types, and other useful utilities.</p>
<p>It has a CUDA counterpart, that enables you to run your tensor computations
on an NVIDIA GPU with compute capability &gt;= 3.0.</p>
<div class="section" id="tensors">
<h2>Tensors<a class="headerlink" href="#tensors" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="torch.is_tensor">
<code class="descclassname">torch.</code><code class="descname">is_tensor</code><span class="sig-paren">(</span><em>obj</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch.html#is_tensor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.is_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True if <cite>obj</cite> is a pytorch tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>obj</strong> (<em>Object</em>) &#8211; Object to test</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.is_storage">
<code class="descclassname">torch.</code><code class="descname">is_storage</code><span class="sig-paren">(</span><em>obj</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch.html#is_storage"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.is_storage" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True if <cite>obj</cite> is a pytorch storage object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>obj</strong> (<em>Object</em>) &#8211; Object to test</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.set_default_tensor_type">
<code class="descclassname">torch.</code><code class="descname">set_default_tensor_type</code><span class="sig-paren">(</span><em>t</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch.html#set_default_tensor_type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.set_default_tensor_type" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="torch.numel">
<code class="descclassname">torch.</code><code class="descname">numel</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#torch.numel" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the total number of elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">120</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">numel</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">16</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.set_printoptions">
<code class="descclassname">torch.</code><code class="descname">set_printoptions</code><span class="sig-paren">(</span><em>precision=None</em>, <em>threshold=None</em>, <em>edgeitems=None</em>, <em>linewidth=None</em>, <em>profile=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/_tensor_str.html#set_printoptions"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.set_printoptions" title="Permalink to this definition">¶</a></dt>
<dd><p>Set options for printing. Items shamelessly taken from Numpy</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>precision</strong> &#8211; Number of digits of precision for floating point output
(default 8).</li>
<li><strong>threshold</strong> &#8211; Total number of array elements which trigger summarization
rather than full repr (default 1000).</li>
<li><strong>edgeitems</strong> &#8211; Number of array items in summary at beginning and end of
each dimension (default 3).</li>
<li><strong>linewidth</strong> &#8211; The number of characters per line for the purpose of
inserting line breaks (default 80). Thresholded matricies will
ignore this parameter.</li>
<li><strong>profile</strong> &#8211; Sane defaults for pretty printing. Can override with any of
the above options. (default, short, full)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<div class="section" id="creation-ops">
<h3>Creation Ops<a class="headerlink" href="#creation-ops" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.eye">
<code class="descclassname">torch.</code><code class="descname">eye</code><span class="sig-paren">(</span><em>n</em>, <em>m=None</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.eye" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Number of rows</li>
<li><strong>m</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a><em>, </em><em>optional</em>) &#8211; Number of columns. If None, defaults to <cite>n</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">a 2-D tensor with ones on the diagonal and zeros elsewhere</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a></p>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="go"> 1  0  0</span>
<span class="go"> 0  1  0</span>
<span class="go"> 0  0  1</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.from_numpy">
<code class="descclassname">torch.</code><code class="descname">from_numpy</code><span class="sig-paren">(</span><em>ndarray</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.from_numpy" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><code class="xref py py-class docutils literal"><span class="pre">Tensor</span></code></a> from a <a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.13)"><code class="xref py py-class docutils literal"><span class="pre">numpy.ndarray</span></code></a>.</p>
<p>The returned tensor and <cite>ndarray</cite> share the same memory. Modifications to the
tensor will be reflected in the <cite>ndarray</cite> and vice versa. The returned tensor
is not resizable.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span>
<span class="go">torch.LongTensor([1, 2, 3])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">array([-1,  2,  3])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.linspace">
<code class="descclassname">torch.</code><code class="descname">linspace</code><span class="sig-paren">(</span><em>start</em>, <em>end</em>, <em>steps=100</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.linspace" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a one-dimensional Tensor of <code class="xref py py-attr docutils literal"><span class="pre">steps</span></code>
equally spaced points between <code class="xref py py-attr docutils literal"><span class="pre">start</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">end</span></code></p>
<p>The output tensor is 1D of size <code class="xref py py-attr docutils literal"><span class="pre">steps</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>start</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The starting value for the set of points</li>
<li><strong>end</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The ending value for the set of points</li>
<li><strong>steps</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Number of points to sample between <code class="xref py py-attr docutils literal"><span class="pre">start</span></code>
and <code class="xref py py-attr docutils literal"><span class="pre">end</span></code></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go">  3.0000</span>
<span class="go">  4.7500</span>
<span class="go">  6.5000</span>
<span class="go">  8.2500</span>
<span class="go"> 10.0000</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go">-10</span>
<span class="go"> -5</span>
<span class="go">  0</span>
<span class="go">  5</span>
<span class="go"> 10</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go">-10</span>
<span class="go"> -5</span>
<span class="go">  0</span>
<span class="go">  5</span>
<span class="go"> 10</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.logspace">
<code class="descclassname">torch.</code><code class="descname">logspace</code><span class="sig-paren">(</span><em>start</em>, <em>end</em>, <em>steps=100</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.logspace" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a one-dimensional Tensor of <code class="xref py py-attr docutils literal"><span class="pre">steps</span></code> points
logarithmically spaced between <span class="math">\(10^{start}\)</span> and <span class="math">\(10^{end}\)</span></p>
<p>The output is a 1D tensor of size <code class="xref py py-attr docutils literal"><span class="pre">steps</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>start</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The starting value for the set of points</li>
<li><strong>end</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The ending value for the set of points</li>
<li><strong>steps</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Number of points to sample between
<code class="xref py py-attr docutils literal"><span class="pre">start</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">end</span></code></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">start</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go"> 1.0000e-10</span>
<span class="go"> 1.0000e-05</span>
<span class="go"> 1.0000e+00</span>
<span class="go"> 1.0000e+05</span>
<span class="go"> 1.0000e+10</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="go">  1.2589</span>
<span class="go">  2.1135</span>
<span class="go">  3.5481</span>
<span class="go">  5.9566</span>
<span class="go"> 10.0000</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.ones">
<code class="descclassname">torch.</code><code class="descname">ones</code><span class="sig-paren">(</span><em>*sizes</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.ones" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor filled with the scalar value <cite>1</cite>, with the shape defined
by the varargs <code class="xref py py-attr docutils literal"><span class="pre">sizes</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sizes</strong> (<em>int...</em>) &#8211; a set of ints defining the shape of the output Tensor.</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="go"> 1  1  1</span>
<span class="go"> 1  1  1</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.rand">
<code class="descclassname">torch.</code><code class="descname">rand</code><span class="sig-paren">(</span><em>*sizes</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.rand" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor filled with random numbers from a uniform distribution
on the interval <span class="math">\([0, 1)\)</span></p>
<p>The shape of the Tensor is defined by the varargs <code class="xref py py-attr docutils literal"><span class="pre">sizes</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sizes</strong> (<em>int...</em>) &#8211; a set of ints defining the shape of the output Tensor.</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="go"> 0.9193</span>
<span class="go"> 0.3347</span>
<span class="go"> 0.3232</span>
<span class="go"> 0.7715</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="go"> 0.5010  0.5140  0.0719</span>
<span class="go"> 0.1435  0.5636  0.0538</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.randn">
<code class="descclassname">torch.</code><code class="descname">randn</code><span class="sig-paren">(</span><em>*sizes</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.randn" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor filled with random numbers from a normal distribution
with zero mean and variance of one.</p>
<p>The shape of the Tensor is defined by the varargs <code class="xref py py-attr docutils literal"><span class="pre">sizes</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sizes</strong> (<em>int...</em>) &#8211; a set of ints defining the shape of the output Tensor.</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="go">-0.1145</span>
<span class="go"> 0.0094</span>
<span class="go">-1.1717</span>
<span class="go"> 0.9846</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="go"> 1.4339  0.3351 -1.0999</span>
<span class="go"> 1.5458 -0.9643 -0.3558</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.randperm">
<code class="descclassname">torch.</code><code class="descname">randperm</code><span class="sig-paren">(</span><em>n</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; LongTensor<a class="headerlink" href="#torch.randperm" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a random permutation of integers from <code class="docutils literal"><span class="pre">0</span></code> to <code class="docutils literal"><span class="pre">n</span> <span class="pre">-</span> <span class="pre">1</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>n</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the upper bound (exclusive)</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>

<span class="go"> 2</span>
<span class="go"> 1</span>
<span class="go"> 3</span>
<span class="go"> 0</span>
<span class="go">[torch.LongTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.arange">
<code class="descclassname">torch.</code><code class="descname">arange</code><span class="sig-paren">(</span><em>start</em>, <em>end</em>, <em>step=1</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.arange" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a 1D Tensor of size <span class="math">\(floor((end - start) / step)\)</span> with values
from the interval <code class="docutils literal"><span class="pre">[start,</span> <span class="pre">end)</span></code> taken with step <code class="xref py py-attr docutils literal"><span class="pre">step</span></code> starting
from <cite>start</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>start</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The starting value for the set of points</li>
<li><strong>end</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The ending value for the set of points</li>
<li><strong>step</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The gap between each pair of adjacent points</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go">[torch.FloatTensor of size 3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 1.0000</span>
<span class="go"> 1.5000</span>
<span class="go"> 2.0000</span>
<span class="go">[torch.FloatTensor of size 3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.range">
<code class="descclassname">torch.</code><code class="descname">range</code><span class="sig-paren">(</span><em>start</em>, <em>end</em>, <em>step=1</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.range" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a 1D Tensor of size <span class="math">\(floor((end - start) / step) + 1\)</span> with values
from <code class="xref py py-attr docutils literal"><span class="pre">start</span></code> to <code class="xref py py-attr docutils literal"><span class="pre">end</span></code> with step <code class="xref py py-attr docutils literal"><span class="pre">step</span></code>. Step is the gap
between two values in the tensor. <span class="math">\(x_{i+1} = x_i + step\)</span></p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This function is deprecated in favor of <a class="reference internal" href="#torch.arange" title="torch.arange"><code class="xref py py-func docutils literal"><span class="pre">torch.arange()</span></code></a>.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>start</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The starting value for the set of points</li>
<li><strong>end</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The ending value for the set of points</li>
<li><strong>step</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The gap between each pair of adjacent points</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 1.0000</span>
<span class="go"> 1.5000</span>
<span class="go"> 2.0000</span>
<span class="go"> 2.5000</span>
<span class="go"> 3.0000</span>
<span class="go"> 3.5000</span>
<span class="go"> 4.0000</span>
<span class="go">[torch.FloatTensor of size 7]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.zeros">
<code class="descclassname">torch.</code><code class="descname">zeros</code><span class="sig-paren">(</span><em>*sizes</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.zeros" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor filled with the scalar value <cite>0</cite>, with the shape defined
by the varargs <code class="xref py py-attr docutils literal"><span class="pre">sizes</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sizes</strong> (<em>int...</em>) &#8211; a set of ints defining the shape of the output Tensor.</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="go"> 0  0  0</span>
<span class="go"> 0  0  0</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

<span class="go"> 0</span>
<span class="go"> 0</span>
<span class="go"> 0</span>
<span class="go"> 0</span>
<span class="go"> 0</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="indexing-slicing-joining-mutating-ops">
<h3>Indexing, Slicing, Joining, Mutating Ops<a class="headerlink" href="#indexing-slicing-joining-mutating-ops" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.cat">
<code class="descclassname">torch.</code><code class="descname">cat</code><span class="sig-paren">(</span><em>seq</em>, <em>dim=0</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.cat" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenates the given sequence of <code class="xref py py-attr docutils literal"><span class="pre">seq</span></code> Tensors in the given dimension.</p>
<p><a class="reference internal" href="#torch.cat" title="torch.cat"><code class="xref py py-func docutils literal"><span class="pre">torch.cat()</span></code></a> can be seen as an inverse operation for <a class="reference internal" href="#torch.split" title="torch.split"><code class="xref py py-func docutils literal"><span class="pre">torch.split()</span></code></a>
and <a class="reference internal" href="#torch.chunk" title="torch.chunk"><code class="xref py py-func docutils literal"><span class="pre">torch.chunk()</span></code></a></p>
<p><a class="reference internal" href="#torch.cat" title="torch.cat"><code class="xref py py-func docutils literal"><span class="pre">cat()</span></code></a> can be best understood via examples.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>seq</strong> (<em>sequence of Tensors</em>) &#8211; Can be any python sequence of <cite>Tensor</cite>
of the same type.</li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a><em>, </em><em>optional</em>) &#8211; The dimension over which the tensors are concatenated</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output argument</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>

<span class="go"> 0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735</span>
<span class="go"> 0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735</span>
<span class="go"> 0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735</span>
<span class="go">[torch.FloatTensor of size 6x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918  0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735  1.5981 -0.5265 -0.8735</span>
<span class="go">[torch.FloatTensor of size 2x9]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.chunk">
<code class="descclassname">torch.</code><code class="descname">chunk</code><span class="sig-paren">(</span><em>tensor</em>, <em>chunks</em>, <em>dim=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/functional.html#chunk"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.chunk" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits a tensor into a number of chunks along a given dimension.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tensor</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; tensor to split.</li>
<li><strong>chunks</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; number of chunks to return.</li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; dimension along which to split the tensor.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.gather">
<code class="descclassname">torch.</code><code class="descname">gather</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>index</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.gather" title="Permalink to this definition">¶</a></dt>
<dd><p>Gathers values along an axis specified by <cite>dim</cite>.</p>
<p>For a 3-D tensor the output is specified by:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 0</span>
<span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]][</span><span class="n">k</span><span class="p">]</span>  <span class="c1"># if dim == 1</span>
<span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">input</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">index</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">]]</span>  <span class="c1"># if dim == 2</span>
</pre></div>
</div>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is an n-dimensional tensor with size
<span class="math">\((x_0, x_1..., x_{i-1}, x_i, x_{i+1}, ..., x_{n-1})\)</span>
and <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> = i, then <code class="xref py py-attr docutils literal"><span class="pre">index</span></code> must be an n-dimensional tensor with
size <span class="math">\((x_0, x_1, ..., x_{i-1}, y, x_{i+1}, ..., x_{n-1})\)</span> where y &gt;= 1 and
<code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will have the same size as <code class="xref py py-attr docutils literal"><span class="pre">index</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; The source tensor</li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; The axis along which to index</li>
<li><strong>index</strong> (<em>LongTensor</em>) &#8211; The indices of elements to gather</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Destination tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]]))</span>
<span class="go"> 1  1</span>
<span class="go"> 4  3</span>
<span class="go">[torch.FloatTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.index_select">
<code class="descclassname">torch.</code><code class="descname">index_select</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>index</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.index_select" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> which indexes the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> <cite>Tensor</cite> along dimension
<code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> using the entries in <code class="xref py py-attr docutils literal"><span class="pre">index</span></code> which is a <cite>LongTensor</cite>.</p>
<p>The returned <cite>Tensor</cite> has the same number of dimensions as
the original <cite>Tensor</cite>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The returned <cite>Tensor</cite> does <strong>not</strong> use the same storage as
the original <cite>Tensor</cite></p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Input data</li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension in which we index</li>
<li><strong>index</strong> (<em>LongTensor</em>) &#8211; the 1D tensor containing the indices to index</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output argument</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1.2045  2.4084  0.4001  1.1372</span>
<span class="go"> 0.5596  1.5677  0.6219 -0.7954</span>
<span class="go"> 1.3635 -1.2313 -0.5414 -1.8478</span>
<span class="go">[torch.FloatTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>

<span class="go"> 1.2045  2.4084  0.4001  1.1372</span>
<span class="go"> 1.3635 -1.2313 -0.5414 -1.8478</span>
<span class="go">[torch.FloatTensor of size 2x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>

<span class="go"> 1.2045  0.4001</span>
<span class="go"> 0.5596  0.6219</span>
<span class="go"> 1.3635 -0.5414</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.masked_select">
<code class="descclassname">torch.</code><code class="descname">masked_select</code><span class="sig-paren">(</span><em>input</em>, <em>mask</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.masked_select" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new 1D <cite>Tensor</cite> which indexes the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> <cite>Tensor</cite> according to
the binary mask <code class="xref py py-attr docutils literal"><span class="pre">mask</span></code> which is a <cite>ByteTensor</cite>.</p>
<p>The shapes of the <code class="xref py py-attr docutils literal"><span class="pre">mask</span></code> tensor and the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> tensor don&#8217;t need
to match, but they must be <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The returned <cite>Tensor</cite> does <strong>not</strong> use the same storage
as the original <cite>Tensor</cite></p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Input data</li>
<li><strong>mask</strong> (<em>ByteTensor</em>) &#8211; the tensor containing the binary mask to index with</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output argument</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1.2045  2.4084  0.4001  1.1372</span>
<span class="go"> 0.5596  1.5677  0.6219 -0.7954</span>
<span class="go"> 1.3635 -1.2313 -0.5414 -1.8478</span>
<span class="go">[torch.FloatTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mask</span>

<span class="go"> 1  1  0  1</span>
<span class="go"> 1  1  1  0</span>
<span class="go"> 1  0  0  0</span>
<span class="go">[torch.ByteTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

<span class="go"> 1.2045</span>
<span class="go"> 2.4084</span>
<span class="go"> 1.1372</span>
<span class="go"> 0.5596</span>
<span class="go"> 1.5677</span>
<span class="go"> 0.6219</span>
<span class="go"> 1.3635</span>
<span class="go">[torch.FloatTensor of size 7]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.nonzero">
<code class="descclassname">torch.</code><code class="descname">nonzero</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; LongTensor<a class="headerlink" href="#torch.nonzero" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a tensor containing the indices of all non-zero elements of
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.  Each row in the result contains the indices of a non-zero
element in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> has <cite>n</cite> dimensions, then the resulting indices Tensor
<code class="xref py py-attr docutils literal"><span class="pre">out</span></code> is of size <cite>z x n</cite>, where <cite>z</cite> is the total number of non-zero
elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<em>LongTensor</em><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite> containing indices</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>

<span class="go"> 0</span>
<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 4</span>
<span class="go">[torch.LongTensor of size 4x1]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
<span class="gp">... </span>                            <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
<span class="gp">... </span>                            <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
<span class="gp">... </span>                            <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span><span class="o">-</span><span class="mf">0.4</span><span class="p">]]))</span>

<span class="go"> 0  0</span>
<span class="go"> 1  1</span>
<span class="go"> 2  2</span>
<span class="go"> 3  3</span>
<span class="go">[torch.LongTensor of size 4x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.split">
<code class="descclassname">torch.</code><code class="descname">split</code><span class="sig-paren">(</span><em>tensor</em>, <em>split_size</em>, <em>dim=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/functional.html#split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits the tensor into equally sized chunks (if possible).</p>
<p>Last chunk will be smaller if the tensor size along a given dimension
is not divisible by <code class="docutils literal"><span class="pre">split_size</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tensor</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; tensor to split.</li>
<li><strong>split_size</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; size of a single chunk.</li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; dimension along which to split the tensor.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.squeeze">
<code class="descclassname">torch.</code><code class="descname">squeeze</code><span class="sig-paren">(</span><em>input</em>, <em>dim=None</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.squeeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a <cite>Tensor</cite> with all the dimensions of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> of size <cite>1</cite> removed.</p>
<p>If <cite>input</cite> is of shape: <span class="math">\((A x 1 x B x C x 1 x D)\)</span> then the <cite>out</cite> Tensor
will be of shape: <span class="math">\((A x B x C x D)\)</span></p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is given, a squeeze operation is done only in the given
dimension. If <cite>input</cite> is of shape: <span class="math">\((A x 1 x B)\)</span>, <cite>squeeze(input, 0)</cite>
leaves the Tensor unchanged, but <cite>squeeze(input, 1)</cite> will squeeze the tensor
to the shape <span class="math">\((A x B)\)</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">As an exception to the above, a 1-dimensional tensor of size 1 will
not have its dimensions changed.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The returned Tensor shares the storage with the input Tensor,
so changing the contents of one will change the contents of the other.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a><em>, </em><em>optional</em>) &#8211; if given, the input will be squeezed only in
this dimension</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">(2L, 1L, 2L, 1L, 2L)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">(2L, 2L, 2L)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">(2L, 1L, 2L, 1L, 2L)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">(2L, 2L, 1L, 2L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.stack">
<code class="descclassname">torch.</code><code class="descname">stack</code><span class="sig-paren">(</span><em>sequence</em>, <em>dim=0</em>, <em>out=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/functional.html#stack"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.stack" title="Permalink to this definition">¶</a></dt>
<dd><p>Concatenates sequence of tensors along a new dimension.</p>
<p>All tensors need to be of the same size.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>sequence</strong> (<em>Sequence</em>) &#8211; sequence of tensors to concatenate.</li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; dimension to insert. Has to be between 0 and the number
of dimensions of concatenated tensors (inclusive).</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.t">
<code class="descclassname">torch.</code><code class="descname">t</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.t" title="Permalink to this definition">¶</a></dt>
<dd><p>Expects <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> to be a matrix (2D Tensor) and transposes
dimensions 0 and 1.</p>
<p>Can be seen as a short-hand function for <cite>transpose(input, 0, 1)</cite></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 0.4834  0.6907  1.3417</span>
<span class="go">-0.1300  0.5295  0.2321</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="go"> 0.4834 -0.1300</span>
<span class="go"> 0.6907  0.5295</span>
<span class="go"> 1.3417  0.2321</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.transpose">
<code class="descclassname">torch.</code><code class="descname">transpose</code><span class="sig-paren">(</span><em>input</em>, <em>dim0</em>, <em>dim1</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.transpose" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a <cite>Tensor</cite> that is a transposed version of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.
The given dimensions <code class="xref py py-attr docutils literal"><span class="pre">dim0</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">dim1</span></code> are swapped.</p>
<p>The resulting <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> Tensor shares it&#8217;s underlying storage with the
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor, so changing the content of one would change the content
of the other.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim0</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; The first dimension to be transposed</li>
<li><strong>dim1</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; The second dimension to be transposed</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 0.5983 -0.0341  2.4918</span>
<span class="go"> 1.5981 -0.5265 -0.8735</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.5983  1.5981</span>
<span class="go">-0.0341 -0.5265</span>
<span class="go"> 2.4918 -0.8735</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.unbind">
<code class="descclassname">torch.</code><code class="descname">unbind</code><span class="sig-paren">(</span><em>tensor</em>, <em>dim=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/functional.html#unbind"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.unbind" title="Permalink to this definition">¶</a></dt>
<dd><p>Removes a tensor dimension.</p>
<p>Returns a tuple of all slices along a given dimension, already without it.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tensor</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; tensor to unbind.</li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; dimension to remove.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.unsqueeze">
<code class="descclassname">torch.</code><code class="descname">unsqueeze</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.unsqueeze" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new tensor with a dimension of size one inserted at the
specified position.</p>
<p>The returned tensor shares the same underlying data with this tensor.</p>
<p>A negative dim value can be used and will correspond to
<span class="math">\(dim + input.dim() + 1\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; The index at which to insert the singleton dimension</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="go"> 1  2  3  4</span>
<span class="go">[torch.FloatTensor of size 1x4]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 4x1]</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="random-sampling">
<h2>Random sampling<a class="headerlink" href="#random-sampling" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="torch.manual_seed">
<code class="descclassname">torch.</code><code class="descname">manual_seed</code><span class="sig-paren">(</span><em>seed</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch.html#manual_seed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.manual_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the seed for generating random numbers. And returns a
<cite>torch._C.Generator</cite> object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>seed</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/2/library/functions.html#long" title="(in Python v2.7)"><em>long</em></a>) &#8211; The desired seed.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.initial_seed">
<code class="descclassname">torch.</code><code class="descname">initial_seed</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch.html#initial_seed"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.initial_seed" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the initial seed for generating random numbers as a
python <cite>long</cite>.</p>
</dd></dl>

<dl class="function">
<dt id="torch.get_rng_state">
<code class="descclassname">torch.</code><code class="descname">get_rng_state</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch.html#get_rng_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.get_rng_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the random number generator state as a ByteTensor.</p>
</dd></dl>

<dl class="function">
<dt id="torch.set_rng_state">
<code class="descclassname">torch.</code><code class="descname">set_rng_state</code><span class="sig-paren">(</span><em>new_state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch.html#set_rng_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.set_rng_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the random number generator state.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>new_state</strong> (<em>torch.ByteTensor</em>) &#8211; The desired state</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="data">
<dt id="torch.default_generator">
<code class="descclassname">torch.</code><code class="descname">default_generator</code><em class="property"> = &lt;torch._C.Generator object&gt;</em><a class="headerlink" href="#torch.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="torch.bernoulli">
<code class="descclassname">torch.</code><code class="descname">bernoulli</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.bernoulli" title="Permalink to this definition">¶</a></dt>
<dd><p>Draws binary random numbers (0 or 1) from a bernoulli distribution.</p>
<p>The <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor should be a tensor containing probabilities
to be used for drawing the binary random number.
Hence, all values in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> have to be in the range:
<span class="math">\(0 &lt;= input_i &lt;= 1\)</span></p>
<p>The <cite>i-th</cite> element of the output tensor will draw a value <cite>1</cite> according
to the <cite>i-th</cite> probability value given in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p>The returned <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> Tensor only has values 0 or 1 and is of the same
shape as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Probability values for the bernoulli distribution</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># generate a uniform random matrix with range [0, 1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.7544  0.8140  0.9842</span>
<span class="go"> 0.5282  0.0595  0.6445</span>
<span class="go"> 0.1925  0.9553  0.9732</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1  1  1</span>
<span class="go"> 0  0  1</span>
<span class="go"> 0  1  1</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># probability of drawing &quot;1&quot; is 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1  1  1</span>
<span class="go"> 1  1  1</span>
<span class="go"> 1  1  1</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="c1"># probability of drawing &quot;1&quot; is 0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">bernoulli</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 0  0  0</span>
<span class="go"> 0  0  0</span>
<span class="go"> 0  0  0</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.multinomial">
<code class="descclassname">torch.</code><code class="descname">multinomial</code><span class="sig-paren">(</span><em>input</em>, <em>num_samples</em>, <em>replacement=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; LongTensor<a class="headerlink" href="#torch.multinomial" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor where each row
contains <code class="xref py py-attr docutils literal"><span class="pre">num_samples</span></code> indices sampled from the multinomial probability
distribution located in the corresponding row of Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The rows of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> do not need to sum to one (in which case we use
the values as weights), but must be non-negative and have a non-zero sum.</p>
</div>
<p>Indices are ordered from left to right according to when each was sampled
(first samples are placed in first column).</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a vector, <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> is a vector of size <cite>num_samples</cite>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a matrix with <cite>m</cite> rows, <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> is an matrix of shape
<cite>m × n</cite>.</p>
<p>If replacement is <cite>True</cite>, samples are drawn with replacement.</p>
<p>If not, they are drawn without replacement, which means that when a
sample index is drawn for a row, it cannot be drawn again for that row.</p>
<p>This implies the constraint that <code class="xref py py-attr docutils literal"><span class="pre">num_samples</span></code> must be lower than
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> length (or number of columns of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> if it is a matrix).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Tensor containing probabilities</li>
<li><strong>num_samples</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; number of samples to draw</li>
<li><strong>replacement</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a><em>, </em><em>optional</em>) &#8211; Whether to draw with replacement or not</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span> <span class="c1"># create a Tensor of weights</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 0</span>
<span class="go"> 0</span>
<span class="go">[torch.LongTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go">[torch.LongTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.normal">
<code class="descclassname">torch.</code><code class="descname">normal</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.normal" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">normal</code><span class="sig-paren">(</span><em>means</em>, <em>std</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Returns a Tensor of random numbers drawn from separate normal distributions
who&#8217;s mean and standard deviation are given.</p>
<p>The <code class="xref py py-attr docutils literal"><span class="pre">means</span></code> is a Tensor with the mean of
each output element&#8217;s normal distribution</p>
<p>The <a class="reference internal" href="#torch.std" title="torch.std"><code class="xref py py-attr docutils literal"><span class="pre">std</span></code></a> is a Tensor with the standard deviation of
each output element&#8217;s normal distribution</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">means</span></code> and <a class="reference internal" href="#torch.std" title="torch.std"><code class="xref py py-attr docutils literal"><span class="pre">std</span></code></a> don&#8217;t need to match.
The total number of elements in each Tensor need to be the same.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When the shapes do not match, the shape of <code class="xref py py-attr docutils literal"><span class="pre">means</span></code>
is used as the shape for the returned output Tensor</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>means</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the Tensor of per-element means</li>
<li><strong>std</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the Tensor of per-element standard deviations</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the optional result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">means</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">std</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">))</span>

 <span class="mf">1.5104</span>
 <span class="mf">1.6955</span>
 <span class="mf">2.4895</span>
 <span class="mf">4.9185</span>
 <span class="mf">4.9895</span>
 <span class="mf">6.9155</span>
 <span class="mf">7.3683</span>
 <span class="mf">8.1836</span>
 <span class="mf">8.7164</span>
 <span class="mf">9.8916</span>
<span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">normal</code><span class="sig-paren">(</span><em>mean=0.0</em>, <em>std</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Similar to the function above, but the means are shared among all drawn
elements.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>means</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a><em>, </em><em>optional</em>) &#8211; the mean for all distributions</li>
<li><strong>std</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the Tensor of per-element standard deviations</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the optional result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="go">  0.5723</span>
<span class="go">  0.0871</span>
<span class="go"> -0.3783</span>
<span class="go"> -2.5689</span>
<span class="go"> 10.7893</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">normal</code><span class="sig-paren">(</span><em>means</em>, <em>std=1.0</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Similar to the function above, but the standard-deviations are shared among
all drawn elements.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>means</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the Tensor of per-element means</li>
<li><strong>std</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a><em>, </em><em>optional</em>) &#8211; the standard deviation for all distributions</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the optional result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">means</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="go"> 1.1681</span>
<span class="go"> 2.8884</span>
<span class="go"> 3.7718</span>
<span class="go"> 2.5616</span>
<span class="go"> 4.2500</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="serialization">
<h2>Serialization<a class="headerlink" href="#serialization" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="torch.save">
<code class="descclassname">torch.</code><code class="descname">save</code><span class="sig-paren">(</span><em>obj</em>, <em>f</em>, <em>pickle_module=&lt;module 'pickle' from '/private/home/soumith/anaconda3/lib/python3.6/pickle.py'&gt;</em>, <em>pickle_protocol=2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/serialization.html#save"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.save" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves an object to a disk file.</p>
<p>See also: <a class="reference internal" href="notes/serialization.html#recommend-saving-models"><span class="std std-ref">Recommended approach for saving a model</span></a></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>obj</strong> &#8211; saved object</li>
<li><strong>f</strong> &#8211; a file-like object (has to implement fileno that returns a file descriptor)
or a string containing a file name</li>
<li><strong>pickle_module</strong> &#8211; module used for pickling metadata and objects</li>
<li><strong>pickle_protocol</strong> &#8211; can be specified to override the default protocol</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.load">
<code class="descclassname">torch.</code><code class="descname">load</code><span class="sig-paren">(</span><em>f</em>, <em>map_location=None</em>, <em>pickle_module=&lt;module 'pickle' from '/private/home/soumith/anaconda3/lib/python3.6/pickle.py'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/serialization.html#load"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads an object saved with <a class="reference internal" href="#torch.save" title="torch.save"><code class="xref py py-func docutils literal"><span class="pre">torch.save()</span></code></a> from a file.</p>
<p>torch.load can dynamically remap storages to be loaded on a different device
using the map_location argument. If it&#8217;s a callable, it will be called with
two arguments: storage and location tag. It&#8217;s expected to either return a
storage that&#8217;s been moved to a different location, or None (and the location
will be resolved using the default method). If this argument is a dict it&#8217;s
expected to be a mapping from location tags used in a file, to location
tags of the current system.</p>
<p>By default the location tags are &#8216;cpu&#8217; for host tensors and &#8216;cuda:device_id&#8217;
(e.g. &#8216;cuda:2&#8217;) for cuda tensors. User extensions can register their own
tagging and deserialization methods using register_package.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>f</strong> &#8211; a file-like object (has to implement fileno that returns a file
descriptor, and must implement seek), or a string containing a file
name</li>
<li><strong>map_location</strong> &#8211; a function or a dict specifying how to remap storage
locations</li>
<li><strong>pickle_module</strong> &#8211; module used for unpickling metadata and objects (has to
match the pickle_module used to serialize file)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Example</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tensors.pt&#39;</span><span class="p">)</span>
<span class="go"># Load all tensors onto the CPU</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tensors.pt&#39;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="k">lambda</span> <span class="n">storage</span><span class="p">,</span> <span class="n">loc</span><span class="p">:</span> <span class="n">storage</span><span class="p">)</span>
<span class="go"># Map tensors from GPU 1 to GPU 0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tensors.pt&#39;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;cuda:1&#39;</span><span class="p">:</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">})</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="parallelism">
<h2>Parallelism<a class="headerlink" href="#parallelism" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="torch.get_num_threads">
<code class="descclassname">torch.</code><code class="descname">get_num_threads</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="headerlink" href="#torch.get_num_threads" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the number of OpenMP threads used for parallelizing CPU operations</p>
</dd></dl>

<dl class="function">
<dt id="torch.set_num_threads">
<code class="descclassname">torch.</code><code class="descname">set_num_threads</code><span class="sig-paren">(</span><em>int</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.set_num_threads" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the number of OpenMP threads used for parallelizing CPU operations</p>
</dd></dl>

</div>
<div class="section" id="math-operations">
<h2>Math operations<a class="headerlink" href="#math-operations" title="Permalink to this headline">¶</a></h2>
<div class="section" id="pointwise-ops">
<h3>Pointwise Ops<a class="headerlink" href="#pointwise-ops" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.abs">
<code class="descclassname">torch.</code><code class="descname">abs</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.abs" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the element-wise absolute value of the given <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> a tensor.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]))</span>
<span class="go">FloatTensor([1, 2, 3])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.acos">
<code class="descclassname">torch.</code><code class="descname">acos</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.acos" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the arccosine  of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">acos</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go"> 2.2608</span>
<span class="go"> 1.2956</span>
<span class="go"> 1.1075</span>
<span class="go">    nan</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.add">
<code class="descclassname">torch.</code><code class="descname">add</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.add" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">add</code><span class="sig-paren">(</span><em>input</em>, <em>value</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Adds the scalar <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> to each element of the input <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>
and returns a new resulting tensor.</p>
<p><span class="math">\(out = tensor + value\)</span></p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type FloatTensor or DoubleTensor, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> must be
a real number, otherwise it should be an integer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>value</strong> (<em>Number</em>) &#8211; the number to be added to each element of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4050</span>
<span class="go">-1.2227</span>
<span class="go"> 1.8688</span>
<span class="go">-0.4185</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="go"> 20.4050</span>
<span class="go"> 18.7773</span>
<span class="go"> 21.8688</span>
<span class="go"> 19.5815</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">add</code><span class="sig-paren">(</span><em>input</em>, <em>value=1</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> is multiplied by the scalar
<code class="xref py py-attr docutils literal"><span class="pre">value</span></code> and added to each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.
The resulting Tensor is returned.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> must be
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<p><span class="math">\(out = input + (other * value)\)</span></p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> is of type FloatTensor or DoubleTensor, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> must be
a real number, otherwise it should be an integer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the first input <cite>Tensor</cite></li>
<li><strong>value</strong> (<em>Number</em>) &#8211; the scalar multiplier for <code class="xref py py-attr docutils literal"><span class="pre">other</span></code></li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the second input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.9310</span>
<span class="go"> 2.0330</span>
<span class="go"> 0.0852</span>
<span class="go">-0.2941</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go"> 1.0663  0.2544</span>
<span class="go">-0.1513  0.0749</span>
<span class="go">[torch.FloatTensor of size 2x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go"> 9.7322</span>
<span class="go"> 4.5770</span>
<span class="go">-1.4279</span>
<span class="go"> 0.4552</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.addcdiv">
<code class="descclassname">torch.</code><code class="descname">addcdiv</code><span class="sig-paren">(</span><em>tensor</em>, <em>value=1</em>, <em>tensor1</em>, <em>tensor2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.addcdiv" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the element-wise division of <code class="xref py py-attr docutils literal"><span class="pre">tensor1</span></code> by <code class="xref py py-attr docutils literal"><span class="pre">tensor2</span></code>,
multiply the result by the scalar <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> and add it to <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code>.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code>, <code class="xref py py-attr docutils literal"><span class="pre">tensor1</span></code>, and <code class="xref py py-attr docutils literal"><span class="pre">tensor2</span></code> must be
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> must be
a real number, otherwise an integer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tensor</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the tensor to be added</li>
<li><strong>value</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; multiplier for <cite>tensor1 ./ tensor2</cite></li>
<li><strong>tensor1</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Numerator tensor</li>
<li><strong>tensor2</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Denominator tensor</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addcdiv</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">)</span>

<span class="go"> 0.0122 -0.0188 -0.2354</span>
<span class="go"> 0.7396 -1.5721  1.2878</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.addcmul">
<code class="descclassname">torch.</code><code class="descname">addcmul</code><span class="sig-paren">(</span><em>tensor</em>, <em>value=1</em>, <em>tensor1</em>, <em>tensor2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.addcmul" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the element-wise multiplication of <code class="xref py py-attr docutils literal"><span class="pre">tensor1</span></code>
by <code class="xref py py-attr docutils literal"><span class="pre">tensor2</span></code>, multiply the result by the scalar <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
and add it to <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code>.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code>, <code class="xref py py-attr docutils literal"><span class="pre">tensor1</span></code>, and <code class="xref py py-attr docutils literal"><span class="pre">tensor2</span></code> must be
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code> must be
a real number, otherwise an integer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tensor</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the tensor to be added</li>
<li><strong>value</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; multiplier for <cite>tensor1 .* tensor2</cite></li>
<li><strong>tensor1</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; tensor to be multiplied</li>
<li><strong>tensor2</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; tensor to be multiplied</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addcmul</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">)</span>

<span class="go"> 0.0122 -0.0188 -0.2354</span>
<span class="go"> 0.7396 -1.5721  1.2878</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.asin">
<code class="descclassname">torch.</code><code class="descname">asin</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.asin" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the arcsine  of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">asin</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.6900</span>
<span class="go"> 0.2752</span>
<span class="go"> 0.4633</span>
<span class="go">    nan</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.atan">
<code class="descclassname">torch.</code><code class="descname">atan</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.atan" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the arctangent  of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">atan</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.5669</span>
<span class="go"> 0.2653</span>
<span class="go"> 0.4203</span>
<span class="go"> 0.9196</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.atan2">
<code class="descclassname">torch.</code><code class="descname">atan2</code><span class="sig-paren">(</span><em>input1</em>, <em>input2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.atan2" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the arctangent of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input1</span></code>
and <code class="xref py py-attr docutils literal"><span class="pre">input2</span></code>.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">input2</span></code> must be
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input1</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the first input <cite>Tensor</cite></li>
<li><strong>input2</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the second input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">atan2</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<span class="go">-2.4167</span>
<span class="go"> 2.9755</span>
<span class="go"> 0.9363</span>
<span class="go"> 1.6613</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.ceil">
<code class="descclassname">torch.</code><code class="descname">ceil</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.ceil" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the ceil of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>,
the smallest integer greater than or equal to each element.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 2</span>
<span class="go"> 1</span>
<span class="go">-0</span>
<span class="go">-0</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.clamp">
<code class="descclassname">torch.</code><code class="descname">clamp</code><span class="sig-paren">(</span><em>input</em>, <em>min</em>, <em>max</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.clamp" title="Permalink to this definition">¶</a></dt>
<dd><p>Clamp all elements in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> into the range <cite>[min, max]</cite> and return
a resulting Tensor.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>      <span class="o">|</span> <span class="nb">min</span><span class="p">,</span> <span class="k">if</span> <span class="n">x_i</span> <span class="o">&lt;</span> <span class="nb">min</span>
<span class="n">y_i</span> <span class="o">=</span> <span class="o">|</span> <span class="n">x_i</span><span class="p">,</span> <span class="k">if</span> <span class="nb">min</span> <span class="o">&lt;=</span> <span class="n">x_i</span> <span class="o">&lt;=</span> <span class="nb">max</span>
      <span class="o">|</span> <span class="nb">max</span><span class="p">,</span> <span class="k">if</span> <span class="n">x_i</span> <span class="o">&gt;</span> <span class="nb">max</span>
</pre></div>
</div>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <a class="reference internal" href="#torch.min" title="torch.min"><code class="xref py py-attr docutils literal"><span class="pre">min</span></code></a>
and <a class="reference internal" href="#torch.max" title="torch.max"><code class="xref py py-attr docutils literal"><span class="pre">max</span></code></a> must be real numbers, otherwise they should be integers</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>min</strong> (<em>Number</em>) &#8211; lower-bound of the range to be clamped to</li>
<li><strong>max</strong> (<em>Number</em>) &#8211; upper-bound of the range to be clamped to</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 0.5000</span>
<span class="go"> 0.3912</span>
<span class="go">-0.5000</span>
<span class="go">-0.5000</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">clamp</code><span class="sig-paren">(</span><em>input</em>, <em>*</em>, <em>min</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Clamps all elements in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> to be larger or equal <a class="reference internal" href="#torch.min" title="torch.min"><code class="xref py py-attr docutils literal"><span class="pre">min</span></code></a>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
should be a real number, otherwise it should be an integer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>value</strong> (<em>Number</em>) &#8211; minimal value of each element in the output</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.5000</span>
<span class="go"> 0.5000</span>
<span class="go"> 0.5000</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">clamp</code><span class="sig-paren">(</span><em>input</em>, <em>*</em>, <em>max</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Clamps all elements in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> to be smaller or equal <a class="reference internal" href="#torch.max" title="torch.max"><code class="xref py py-attr docutils literal"><span class="pre">max</span></code></a>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
should be a real number, otherwise it should be an integer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>value</strong> (<em>Number</em>) &#8211; maximal value of each element in the output</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 0.5000</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.cos">
<code class="descclassname">torch.</code><code class="descname">cos</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.cos" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the cosine  of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go"> 0.8041</span>
<span class="go"> 0.9633</span>
<span class="go"> 0.9018</span>
<span class="go"> 0.2557</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.cosh">
<code class="descclassname">torch.</code><code class="descname">cosh</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.cosh" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the hyperbolic cosine  of the elements of
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cosh</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go"> 1.2095</span>
<span class="go"> 1.0372</span>
<span class="go"> 1.1015</span>
<span class="go"> 1.9917</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.div">
<code class="descclassname">torch.</code><code class="descname">div</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.div" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">div</code><span class="sig-paren">(</span><em>input</em>, <em>value</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Divides each element of the input <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> with the scalar <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
and returns a new resulting tensor.</p>
<p><span class="math">\(out = tensor / value\)</span></p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
should be a real number, otherwise it should be an integer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>value</strong> (<em>Number</em>) &#8211; the number to be divided to each element of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.6147</span>
<span class="go">-1.1237</span>
<span class="go">-0.1604</span>
<span class="go">-0.6853</span>
<span class="go"> 0.1063</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="go">-1.2294</span>
<span class="go">-2.2474</span>
<span class="go">-0.3208</span>
<span class="go">-1.3706</span>
<span class="go"> 0.2126</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">div</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is divided by each element
of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">other</span></code>. The resulting Tensor is returned. The shapes of
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> must be
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<p><span class="math">\(out_i = input_i / other_i\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the numerator <cite>Tensor</cite></li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the denominator <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.1810  0.4017  0.2863 -0.1013</span>
<span class="go"> 0.6183  2.0696  0.9012 -1.5933</span>
<span class="go"> 0.5679  0.4743 -0.0117 -0.1266</span>
<span class="go">-0.1213  0.9629  0.2682  1.5968</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go"> 0.8774  0.7650</span>
<span class="go"> 0.8866  1.4805</span>
<span class="go">-0.6490  1.1172</span>
<span class="go"> 1.4259 -0.8146</span>
<span class="go"> 1.4633 -0.1228</span>
<span class="go"> 0.4643 -0.6029</span>
<span class="go"> 0.3492  1.5270</span>
<span class="go"> 1.6103 -0.6291</span>
<span class="go">[torch.FloatTensor of size 8x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">div</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="go">-0.2062  0.5251  0.3229 -0.0684</span>
<span class="go">-0.9528  1.8525  0.6320  1.9559</span>
<span class="go"> 0.3881 -3.8625 -0.0253  0.2099</span>
<span class="go">-0.3473  0.6306  0.1666 -2.5381</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.exp">
<code class="descclassname">torch.</code><code class="descname">exp</code><span class="sig-paren">(</span><em>tensor</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.exp" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the exponential of each element.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">2</span><span class="p">)]))</span>
<span class="go">torch.FloatTensor([1, 2])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.floor">
<code class="descclassname">torch.</code><code class="descname">floor</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.floor" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the floor of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>,
the largest integer less than or equal to each element.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 0</span>
<span class="go">-1</span>
<span class="go">-1</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.fmod">
<code class="descclassname">torch.</code><code class="descname">fmod</code><span class="sig-paren">(</span><em>input</em>, <em>divisor</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.fmod" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the element-wise remainder of division.</p>
<p>The dividend and divisor may contain both for integer and floating point
numbers. The remainder has the same sign as the dividend <cite>tensor</cite>.</p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">divisor</span></code> is a Tensor, the shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">divisor</span></code> must be <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; The dividend</li>
<li><strong>divisor</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The divisor. This may be either a number or a
tensor of the same shape as the dividend.</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">fmod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">torch.FloatTensor([-1, -0, -1, 1, 0, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">fmod</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span> <span class="mf">1.5</span><span class="p">)</span>
<span class="go">torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="#torch.remainder" title="torch.remainder"><code class="xref py py-func docutils literal"><span class="pre">torch.remainder()</span></code></a>, which computes the element-wise remainder of
division equivalently to Python&#8217;s <cite>%</cite> operator</p>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.frac">
<code class="descclassname">torch.</code><code class="descname">frac</code><span class="sig-paren">(</span><em>tensor</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.frac" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the fractional portion of each element in <cite>tensor</cite>.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">frac</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.2</span><span class="p">])</span>
<span class="go">torch.FloatTensor([0, 0.5, -0.2])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.lerp">
<code class="descclassname">torch.</code><code class="descname">lerp</code><span class="sig-paren">(</span><em>start</em>, <em>end</em>, <em>weight</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.lerp" title="Permalink to this definition">¶</a></dt>
<dd><p>Does a linear interpolation of two tensors <code class="xref py py-attr docutils literal"><span class="pre">start</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">end</span></code> based
on a scalar <code class="xref py py-attr docutils literal"><span class="pre">weight</span></code>: and returns the resulting <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> Tensor.</p>
<p><span class="math">\(out_i = start_i + weight * (end_i - start_i)\)</span></p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">start</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">end</span></code> must be
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>start</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the <cite>Tensor</cite> with the starting points</li>
<li><strong>end</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the <cite>Tensor</cite> with the ending points</li>
<li><strong>weight</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; the weight for the interpolation formula</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">start</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">end</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">start</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">end</span>

<span class="go"> 10</span>
<span class="go"> 10</span>
<span class="go"> 10</span>
<span class="go"> 10</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">lerp</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="go"> 5.5000</span>
<span class="go"> 6.0000</span>
<span class="go"> 6.5000</span>
<span class="go"> 7.0000</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.log">
<code class="descclassname">torch.</code><code class="descname">log</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.log" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the natural logarithm of the elements
of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4183</span>
<span class="go"> 0.3722</span>
<span class="go">-0.3091</span>
<span class="go"> 0.4149</span>
<span class="go"> 0.5857</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go">    nan</span>
<span class="go">-0.9883</span>
<span class="go">    nan</span>
<span class="go">-0.8797</span>
<span class="go">-0.5349</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.log1p">
<code class="descclassname">torch.</code><code class="descname">log1p</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.log1p" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the natural logarithm of (1 + <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>).</p>
<p><span class="math">\(y_i = log(x_i + 1)\)</span></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function is more accurate than <a class="reference internal" href="#torch.log" title="torch.log"><code class="xref py py-func docutils literal"><span class="pre">torch.log()</span></code></a> for small
values of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code></p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4183</span>
<span class="go"> 0.3722</span>
<span class="go">-0.3091</span>
<span class="go"> 0.4149</span>
<span class="go"> 0.5857</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go">-0.5418</span>
<span class="go"> 0.3164</span>
<span class="go">-0.3697</span>
<span class="go"> 0.3471</span>
<span class="go"> 0.4611</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.mul">
<code class="descclassname">torch.</code><code class="descname">mul</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.mul" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">mul</code><span class="sig-paren">(</span><em>input</em>, <em>value</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Multiplies each element of the input <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> with the scalar
<code class="xref py py-attr docutils literal"><span class="pre">value</span></code> and returns a new resulting tensor.</p>
<p><span class="math">\(out = tensor * value\)</span></p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, <code class="xref py py-attr docutils literal"><span class="pre">value</span></code>
should be a real number, otherwise it should be an integer</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>value</strong> (<em>Number</em>) &#8211; the number to be multiplied to each element of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.9374</span>
<span class="go">-0.5254</span>
<span class="go">-0.6069</span>
<span class="go">[torch.FloatTensor of size 3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="go">-93.7411</span>
<span class="go">-52.5374</span>
<span class="go">-60.6908</span>
<span class="go">[torch.FloatTensor of size 3]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">mul</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is multiplied by each element of the
Tensor <code class="xref py py-attr docutils literal"><span class="pre">other</span></code>. The resulting Tensor is returned.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> must be
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<p><span class="math">\(out_i = input_i * other_i\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the first multiplicand <cite>Tensor</cite></li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the second multiplicand <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.7280  0.0598 -1.4327 -0.5825</span>
<span class="go">-0.1427 -0.0690  0.0821 -0.3270</span>
<span class="go">-0.9241  0.5110  0.4070 -1.1188</span>
<span class="go">-0.8308  0.7426 -0.6240 -1.1582</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go"> 0.0430 -1.0775  0.6015  1.1647 -0.6549  0.0308 -0.1670  1.0742</span>
<span class="go">-1.2593  0.0292 -0.0849  0.4530  1.2404 -0.4659 -0.1840  0.5974</span>
<span class="go">[torch.FloatTensor of size 2x8]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mul</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="go">-0.0313 -0.0645 -0.8618 -0.6784</span>
<span class="go"> 0.0934 -0.0021 -0.0137 -0.3513</span>
<span class="go"> 1.1638  0.0149 -0.0346 -0.5068</span>
<span class="go">-1.0304 -0.3460  0.1148 -0.6919</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.neg">
<code class="descclassname">torch.</code><code class="descname">neg</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.neg" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the negative of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p><span class="math">\(out = -1 * input\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4430</span>
<span class="go"> 1.1690</span>
<span class="go">-0.8836</span>
<span class="go">-0.4565</span>
<span class="go"> 0.2968</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 0.4430</span>
<span class="go">-1.1690</span>
<span class="go"> 0.8836</span>
<span class="go"> 0.4565</span>
<span class="go">-0.2968</span>
<span class="go">[torch.FloatTensor of size 5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.pow">
<code class="descclassname">torch.</code><code class="descname">pow</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.pow" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">pow</code><span class="sig-paren">(</span><em>input</em>, <em>exponent</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Takes the power of each element in <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> with <code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> and
returns a Tensor with the result.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> can be either a single <code class="docutils literal"><span class="pre">float</span></code> number or a <code class="docutils literal"><span class="pre">Tensor</span></code>
with the same number of elements as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> is a scalar value, the operation applied is:</p>
<p><span class="math">\(out_i = x_i ^ {exponent}\)</span></p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> is a Tensor, the operation applied is:</p>
<p><span class="math">\(out_i = x_i ^ {exponent_i}\)</span></p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> is a Tensor, the shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>
and <code class="xref py py-attr docutils literal"><span class="pre">exponent</span></code> must be <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>exponent</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a><em> or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the exponent value</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.5274</span>
<span class="go">-0.8232</span>
<span class="go">-2.1128</span>
<span class="go"> 1.7558</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="go"> 0.2781</span>
<span class="go"> 0.6776</span>
<span class="go"> 4.4640</span>
<span class="go"> 3.0829</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">exp</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">exp</span><span class="p">)</span>

<span class="go">   1</span>
<span class="go">   4</span>
<span class="go">  27</span>
<span class="go"> 256</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">pow</code><span class="sig-paren">(</span><em>base</em>, <em>input</em>, <em>out=None</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p><code class="xref py py-attr docutils literal"><span class="pre">base</span></code> is a scalar <code class="docutils literal"><span class="pre">float</span></code> value, and <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a Tensor.
The returned Tensor <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> is of the same shape as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code></p>
<p>The operation applied is:</p>
<p><span class="math">\(out_i = base ^ {input_i}\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>base</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; the scalar base value for the power operation</li>
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the exponent <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">base</span> <span class="o">=</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">base</span><span class="p">,</span> <span class="n">exp</span><span class="p">)</span>

<span class="go">  2</span>
<span class="go">  4</span>
<span class="go">  8</span>
<span class="go"> 16</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.reciprocal">
<code class="descclassname">torch.</code><code class="descname">reciprocal</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.reciprocal" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the reciprocal of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>,
i.e. <span class="math">\(1.0 / x\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">reciprocal</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 0.7210</span>
<span class="go"> 2.5565</span>
<span class="go">-1.1583</span>
<span class="go">-1.8289</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.remainder">
<code class="descclassname">torch.</code><code class="descname">remainder</code><span class="sig-paren">(</span><em>input</em>, <em>divisor</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.remainder" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the element-wise remainder of division.</p>
<p>The divisor and dividend may contain both for integer and floating point
numbers. The remainder has the same sign as the divisor.</p>
<p>When <code class="xref py py-attr docutils literal"><span class="pre">divisor</span></code> is a Tensor, the shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">divisor</span></code> must be <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; The dividend</li>
<li><strong>divisor</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The divisor. This may be either a number or a
tensor of the same shape as the dividend.</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">remainder</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">torch.FloatTensor([1, 0, 1, 1, 0, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">remainder</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]),</span> <span class="mf">1.5</span><span class="p">)</span>
<span class="go">torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5])</span>
</pre></div>
</div>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference internal" href="#torch.fmod" title="torch.fmod"><code class="xref py py-func docutils literal"><span class="pre">torch.fmod()</span></code></a>, which computes the element-wise remainder of
division equivalently to the C library function <code class="docutils literal"><span class="pre">fmod()</span></code></p>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.round">
<code class="descclassname">torch.</code><code class="descname">round</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.round" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with each of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> rounded
to the closest integer.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.2290</span>
<span class="go"> 1.3409</span>
<span class="go">-0.5662</span>
<span class="go">-0.0899</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go">-1</span>
<span class="go">-0</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.rsqrt">
<code class="descclassname">torch.</code><code class="descname">rsqrt</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.rsqrt" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the reciprocal of the square-root of each of
the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.2290</span>
<span class="go"> 1.3409</span>
<span class="go">-0.5662</span>
<span class="go">-0.0899</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 0.9020</span>
<span class="go"> 0.8636</span>
<span class="go">    nan</span>
<span class="go">    nan</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.sigmoid">
<code class="descclassname">torch.</code><code class="descname">sigmoid</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.sigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the sigmoid of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4972</span>
<span class="go"> 1.3512</span>
<span class="go"> 0.1056</span>
<span class="go">-0.2650</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 0.3782</span>
<span class="go"> 0.7943</span>
<span class="go"> 0.5264</span>
<span class="go"> 0.4341</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.sign">
<code class="descclassname">torch.</code><code class="descname">sign</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.sign" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the sign of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go">-1</span>
<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go"> 1</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.sin">
<code class="descclassname">torch.</code><code class="descname">sin</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.sin" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the sine of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.5944</span>
<span class="go"> 0.2684</span>
<span class="go"> 0.4322</span>
<span class="go"> 0.9667</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.sinh">
<code class="descclassname">torch.</code><code class="descname">sinh</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.sinh" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the hyperbolic sine of the elements of
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sinh</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.6804</span>
<span class="go"> 0.2751</span>
<span class="go"> 0.4619</span>
<span class="go"> 1.7225</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.sqrt">
<code class="descclassname">torch.</code><code class="descname">sqrt</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.sqrt" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the square-root of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.2290</span>
<span class="go"> 1.3409</span>
<span class="go">-0.5662</span>
<span class="go">-0.0899</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1.1086</span>
<span class="go"> 1.1580</span>
<span class="go">    nan</span>
<span class="go">    nan</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.tan">
<code class="descclassname">torch.</code><code class="descname">tan</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.tan" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the tangent of the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tan</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.7392</span>
<span class="go"> 0.2786</span>
<span class="go"> 0.4792</span>
<span class="go"> 3.7801</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.tanh">
<code class="descclassname">torch.</code><code class="descname">tanh</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.tanh" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the hyperbolic tangent of the elements
of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>
<span class="go">-0.6366</span>
<span class="go"> 0.2718</span>
<span class="go"> 0.4469</span>
<span class="go"> 1.3122</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.5625</span>
<span class="go"> 0.2653</span>
<span class="go"> 0.4193</span>
<span class="go"> 0.8648</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.trunc">
<code class="descclassname">torch.</code><code class="descname">trunc</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.trunc" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <cite>Tensor</cite> with the truncated integer values of
the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4972</span>
<span class="go"> 1.3512</span>
<span class="go"> 0.1056</span>
<span class="go">-0.2650</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">trunc</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go">-0</span>
<span class="go"> 1</span>
<span class="go"> 0</span>
<span class="go">-0</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="reduction-ops">
<h3>Reduction Ops<a class="headerlink" href="#reduction-ops" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.cumprod">
<code class="descclassname">torch.</code><code class="descname">cumprod</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.cumprod" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the cumulative product of elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> in the dimension
<code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>For example, if <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a vector of size N, the result will also be
a vector of size N, with elements:
<span class="math">\(y_i = x_1 * x_2 * x_3 * ... * x_i\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to do the operation over</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.1148</span>
<span class="go"> 1.8423</span>
<span class="go"> 1.4143</span>
<span class="go">-0.4403</span>
<span class="go"> 1.2859</span>
<span class="go">-1.2514</span>
<span class="go">-0.4748</span>
<span class="go"> 1.1735</span>
<span class="go">-1.6332</span>
<span class="go">-0.4272</span>
<span class="go">[torch.FloatTensor of size 10]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="go"> 1.1148</span>
<span class="go"> 2.0537</span>
<span class="go"> 2.9045</span>
<span class="go">-1.2788</span>
<span class="go">-1.6444</span>
<span class="go"> 2.0578</span>
<span class="go">-0.9770</span>
<span class="go">-1.1466</span>
<span class="go"> 1.8726</span>
<span class="go">-0.8000</span>
<span class="go">[torch.FloatTensor of size 10]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">[</span><span class="mi">5</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cumprod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="go"> 1.1148</span>
<span class="go"> 2.0537</span>
<span class="go"> 2.9045</span>
<span class="go">-1.2788</span>
<span class="go">-1.6444</span>
<span class="go">-0.0000</span>
<span class="go"> 0.0000</span>
<span class="go"> 0.0000</span>
<span class="go">-0.0000</span>
<span class="go"> 0.0000</span>
<span class="go">[torch.FloatTensor of size 10]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.cumsum">
<code class="descclassname">torch.</code><code class="descname">cumsum</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.cumsum" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the cumulative sum of elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> in the dimension
<code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>For example, if <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a vector of size N, the result will also be
a vector of size N, with elements:
<span class="math">\(y_i = x_1 + x_2 + x_3 + ... + x_i\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to do the operation over</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.6039</span>
<span class="go">-0.2214</span>
<span class="go">-0.3705</span>
<span class="go">-0.0169</span>
<span class="go"> 1.3415</span>
<span class="go">-0.1230</span>
<span class="go"> 0.9719</span>
<span class="go"> 0.6081</span>
<span class="go">-0.1286</span>
<span class="go"> 1.0947</span>
<span class="go">[torch.FloatTensor of size 10]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="go">-0.6039</span>
<span class="go">-0.8253</span>
<span class="go">-1.1958</span>
<span class="go">-1.2127</span>
<span class="go"> 0.1288</span>
<span class="go"> 0.0058</span>
<span class="go"> 0.9777</span>
<span class="go"> 1.5858</span>
<span class="go"> 1.4572</span>
<span class="go"> 2.5519</span>
<span class="go">[torch.FloatTensor of size 10]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.dist">
<code class="descclassname">torch.</code><code class="descname">dist</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>p=2</em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#torch.dist" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the p-norm of (<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> - <code class="xref py py-attr docutils literal"><span class="pre">other</span></code>)</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> must be
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the Right-hand-side input <cite>Tensor</cite></li>
<li><strong>p</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a><em>, </em><em>optional</em>) &#8211; The norm to be computed.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 0.2505</span>
<span class="go">-0.4571</span>
<span class="go">-0.3733</span>
<span class="go"> 0.7807</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span>

<span class="go"> 0.7782</span>
<span class="go">-0.5185</span>
<span class="go"> 1.4106</span>
<span class="go">-2.4063</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">)</span>
<span class="go">3.302832063224223</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">3.3677282206393286</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="go">inf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">5.560028076171875</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.mean">
<code class="descclassname">torch.</code><code class="descname">mean</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.mean" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">mean</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the mean value of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.2946 -0.9143  2.1809</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">0.32398951053619385</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">mean</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the mean value of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is true, the output Tensor is of the same size
as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where it is of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <a class="reference internal" href="#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code></a>), resulting in the
output Tensor having 1 fewer dimension.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to reduce</li>
<li><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a><em>, </em><em>optional</em>) &#8211; whether the output tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>
retained or not</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-1.2738 -0.3058  0.1230 -1.9615</span>
<span class="go"> 0.8771 -0.5430 -0.9233  0.9879</span>
<span class="go"> 1.4107  0.0317 -0.6823  0.2255</span>
<span class="go">-1.3854  0.4953 -0.2160  0.2435</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go">-0.8545</span>
<span class="go"> 0.0997</span>
<span class="go"> 0.2464</span>
<span class="go">-0.2157</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

<span class="go">-0.8545</span>
<span class="go"> 0.0997</span>
<span class="go"> 0.2464</span>
<span class="go">-0.2157</span>
<span class="go">[torch.FloatTensor of size 4x1]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.median">
<code class="descclassname">torch.</code><code class="descname">median</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.median" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">median</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the median value of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4729 -0.2266 -0.2085</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.2085</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">median</code><span class="sig-paren">(</span><em>input</em>, <em>dim=-1</em>, <em>keepdim=False</em>, <em>values=None</em>, <em>indices=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Returns the median value of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>. Also returns the index location of the median value
as a <cite>LongTensor</cite>.</p>
<p>By default, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is the last dimension of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is true, the output Tensors are of the same size
as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where they are of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <a class="reference internal" href="#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code></a>), resulting in
the outputs Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to reduce</li>
<li><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a>) &#8211; whether the output Tensors have <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not</li>
<li><strong>values</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result Tensor</li>
<li><strong>indices</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result index Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> -0.6891 -0.6662</span>
<span class="go"> 0.2697  0.7412</span>
<span class="go"> 0.5254 -0.7402</span>
<span class="go"> 0.5528 -0.2399</span>
<span class="go">[torch.FloatTensor of size 4x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4056 -0.3372  1.0973 -2.4884  0.4334</span>
<span class="go"> 2.1336  0.3841  0.1404 -0.1821 -0.7646</span>
<span class="go">-0.2403  1.3975 -2.0068  0.1298  0.0212</span>
<span class="go">-1.5371 -0.7257 -0.4871 -0.2359 -1.1724</span>
<span class="go">[torch.FloatTensor of size 4x5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">(</span>
<span class="go"> 0.4056</span>
<span class="go"> 0.1404</span>
<span class="go"> 0.0212</span>
<span class="go">-0.7257</span>
<span class="go">[torch.FloatTensor of size 4]</span>
<span class="go">,</span>
<span class="go"> 0</span>
<span class="go"> 2</span>
<span class="go"> 4</span>
<span class="go"> 1</span>
<span class="go">[torch.LongTensor of size 4]</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.mode">
<code class="descclassname">torch.</code><code class="descname">mode</code><span class="sig-paren">(</span><em>input</em>, <em>dim=-1</em>, <em>keepdim=False</em>, <em>values=None</em>, <em>indices=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.mode" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the mode value of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>. Also returns the index location of the mode value
as a <cite>LongTensor</cite>.</p>
<p>By default, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is the last dimension of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is true, the output Tensors are of the same size as
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where they are of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <a class="reference internal" href="#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code></a>), resulting
in the output Tensors having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function is not defined for <code class="docutils literal"><span class="pre">torch.cuda.Tensor</span></code> yet.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to reduce</li>
<li><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a>) &#8211; whether the output tensors have <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not</li>
<li><strong>values</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result Tensor</li>
<li><strong>indices</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result index Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> -0.6891 -0.6662</span>
<span class="go"> 0.2697  0.7412</span>
<span class="go"> 0.5254 -0.7402</span>
<span class="go"> 0.5528 -0.2399</span>
<span class="go">[torch.FloatTensor of size 4x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4056 -0.3372  1.0973 -2.4884  0.4334</span>
<span class="go"> 2.1336  0.3841  0.1404 -0.1821 -0.7646</span>
<span class="go">-0.2403  1.3975 -2.0068  0.1298  0.0212</span>
<span class="go">-1.5371 -0.7257 -0.4871 -0.2359 -1.1724</span>
<span class="go">[torch.FloatTensor of size 4x5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="go">(</span>
<span class="go">-2.4884</span>
<span class="go">-0.7646</span>
<span class="go">-2.0068</span>
<span class="go">-1.5371</span>
<span class="go">[torch.FloatTensor of size 4]</span>
<span class="go">,</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go"> 2</span>
<span class="go"> 0</span>
<span class="go">[torch.LongTensor of size 4]</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.norm">
<code class="descclassname">torch.</code><code class="descname">norm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.norm" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">norm</code><span class="sig-paren">(</span><em>input</em>, <em>p=2</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the p-norm of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>p</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a><em>, </em><em>optional</em>) &#8211; the exponent value in the norm formulation</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4376 -0.5328  0.9547</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">1.0338925067372466</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">norm</code><span class="sig-paren">(</span><em>input</em>, <em>p</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the p-norm of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is true, the output Tensor is of the same size as
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where it is of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <a class="reference internal" href="#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code></a>), resulting
in the output Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>p</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; the exponent value in the norm formulation</li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to reduce</li>
<li><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a>) &#8211; whether the output Tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.6891 -0.6662</span>
<span class="go"> 0.2697  0.7412</span>
<span class="go"> 0.5254 -0.7402</span>
<span class="go"> 0.5528 -0.2399</span>
<span class="go">[torch.FloatTensor of size 4x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.9585</span>
<span class="go"> 0.7888</span>
<span class="go"> 0.9077</span>
<span class="go"> 0.6026</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

<span class="go"> 2</span>
<span class="go"> 2</span>
<span class="go"> 2</span>
<span class="go"> 2</span>
<span class="go">[torch.FloatTensor of size 4x1]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.prod">
<code class="descclassname">torch.</code><code class="descname">prod</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.prod" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">prod</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the product of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.6170  0.3546  0.0253</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">0.005537458061418483</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">prod</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the product of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is true, the output Tensor is of the same size as
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where it is of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <a class="reference internal" href="#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code></a>), resulting
in the output Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to reduce</li>
<li><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a>) &#8211; whether the output Tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.1598 -0.6884</span>
<span class="go">-0.1831 -0.4412</span>
<span class="go">-0.9925 -0.6244</span>
<span class="go">-0.2416 -0.8080</span>
<span class="go">[torch.FloatTensor of size 4x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go">-0.1100</span>
<span class="go"> 0.0808</span>
<span class="go"> 0.6197</span>
<span class="go"> 0.1952</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.std">
<code class="descclassname">torch.</code><code class="descname">std</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.std" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">std</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the standard-deviation of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-1.3063  1.4182 -0.3061</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">1.3782334731508061</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">std</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the standard-deviation of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the
given dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is true, the output Tensor is of the same size as
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where it is of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <a class="reference internal" href="#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code></a>), resulting
in the output Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to reduce</li>
<li><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a>) &#8211; whether the output Tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.1889 -2.4856  0.0043  1.8169</span>
<span class="go">-0.7701 -0.4682 -2.2410  0.4098</span>
<span class="go"> 0.1919 -1.1856 -1.0361  0.9085</span>
<span class="go"> 0.0173  1.0662  0.2143 -0.5576</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="go"> 1.7756</span>
<span class="go"> 1.1025</span>
<span class="go"> 1.0045</span>
<span class="go"> 0.6725</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.sum">
<code class="descclassname">torch.</code><code class="descname">sum</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.sum" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">sum</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the sum of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.6170  0.3546  0.0253</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">0.9969287421554327</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">sum</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the sum of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is true, the output Tensor is of the same size
as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where it is of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <a class="reference internal" href="#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code></a>), resulting in
the output Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to reduce</li>
<li><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a>) &#8211; whether the output Tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.4640  0.0609  0.1122  0.4784</span>
<span class="go">-1.3063  1.6443  0.4714 -0.7396</span>
<span class="go">-1.3561 -0.1959  1.0609 -1.9855</span>
<span class="go"> 2.6833  0.5746 -0.5709 -0.4430</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.1874</span>
<span class="go"> 0.0698</span>
<span class="go">-2.4767</span>
<span class="go"> 2.2440</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.var">
<code class="descclassname">torch.</code><code class="descname">var</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.var" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">var</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the variance of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-1.3063  1.4182 -0.3061</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">1.899527506513334</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">var</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Returns the variance of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is true, the output Tensors are of the same size
as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where they are of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <a class="reference internal" href="#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code></a>), resulting in
the outputs Tensor having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to reduce</li>
<li><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a>) &#8211; whether the output Tensor has <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the result Tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-1.2738 -0.3058  0.1230 -1.9615</span>
<span class="go"> 0.8771 -0.5430 -0.9233  0.9879</span>
<span class="go"> 1.4107  0.0317 -0.6823  0.2255</span>
<span class="go">-1.3854  0.4953 -0.2160  0.2435</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.8859</span>
<span class="go"> 0.9509</span>
<span class="go"> 0.7548</span>
<span class="go"> 0.6949</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="comparison-ops">
<h3>Comparison Ops<a class="headerlink" href="#comparison-ops" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.eq">
<code class="descclassname">torch.</code><code class="descname">eq</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.eq" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes element-wise equality</p>
<p>The second argument can be a number or a tensor whose shape is
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a> with the first argument.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Tensor to compare</li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; Tensor or value to compare</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor. Must be a <cite>ByteTensor</cite> or the same
type as <cite>tensor</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><dl class="docutils">
<dt>a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where the</dt>
<dd><p class="first last">tensors are equal and a 0 at every other location</p>
</dd>
</dl>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a></p>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go">1  0</span>
<span class="go">0  1</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.equal">
<code class="descclassname">torch.</code><code class="descname">equal</code><span class="sig-paren">(</span><em>tensor1</em>, <em>tensor2</em><span class="sig-paren">)</span> &#x2192; bool<a class="headerlink" href="#torch.equal" title="Permalink to this definition">¶</a></dt>
<dd><p>True if two tensors have the same size and elements, False otherwise.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]))</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.ge">
<code class="descclassname">torch.</code><code class="descname">ge</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.ge" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes <cite>tensor &gt;= other</cite> element-wise.</p>
<p>The second argument can be a number or a tensor whose shape is
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a> with the first argument.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Tensor to compare</li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; Tensor or value to compare</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor. Must be a <cite>ByteTensor</cite> or the same
type as <cite>tensor</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><dl class="docutils">
<dt>a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where</dt>
<dd><p class="first last">comparison is true.</p>
</dd>
</dl>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a></p>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ge</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go"> 1  1</span>
<span class="go"> 0  1</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.gt">
<code class="descclassname">torch.</code><code class="descname">gt</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.gt" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes <cite>tensor &gt; other</cite> element-wise.</p>
<p>The second argument can be a number or a tensor whose shape is
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a> with the first argument.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Tensor to compare</li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; Tensor or value to compare</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor. Must be a <cite>ByteTensor</cite> or the same
type as <cite>tensor</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><dl class="docutils">
<dt>a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where</dt>
<dd><p class="first last">comparison is true.</p>
</dd>
</dl>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a></p>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">gt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go"> 0  1</span>
<span class="go"> 0  0</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.kthvalue">
<code class="descclassname">torch.</code><code class="descname">kthvalue</code><span class="sig-paren">(</span><em>input</em>, <em>k</em>, <em>dim=None</em>, <em>keepdim=False</em>, <em>out=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.kthvalue" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the <code class="xref py py-attr docutils literal"><span class="pre">k</span></code> th smallest element of the given <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor
along a given dimension.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is not given, the last dimension of the <cite>input</cite> is chosen.</p>
<p>A tuple of <cite>(values, indices)</cite> is returned, where the <cite>indices</cite> is the indices
of the kth-smallest element in the original <cite>input</cite> Tensor in dimention <cite>dim</cite>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is true, both the <code class="xref py py-attr docutils literal"><span class="pre">values</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">indices</span></code> Tensors
are the same size as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>, except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where
they are of size 1. Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed
(see <a class="reference internal" href="#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code></a>), resulting in both the <code class="xref py py-attr docutils literal"><span class="pre">values</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">indices</span></code> Tensors having 1 fewer dimension than the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>k</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; k for the k-th smallest element</li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a><em>, </em><em>optional</em>) &#8211; The dimension to find the kth value along</li>
<li><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a>) &#8211; whether the output Tensors have <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not</li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; The output tuple of (Tensor, LongTensor)
can be optionally given to be used as output buffers</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go"> 5</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">kthvalue</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="go">(</span>
<span class="go"> 4</span>
<span class="go">[torch.FloatTensor of size 1]</span>
<span class="go">,</span>
<span class="go"> 3</span>
<span class="go">[torch.LongTensor of size 1]</span>
<span class="go">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span><span class="o">.</span><span class="n">resize_</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go">1  2  3</span>
<span class="go">4  5  6</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">kthvalue</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="kc">True</span><span class="p">)</span>
<span class="go">(</span>
<span class="go">4  5  6</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>
<span class="go">       ,</span>
<span class="go">1  1  1</span>
<span class="go">[torch.LongTensor of size 1x3]</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.le">
<code class="descclassname">torch.</code><code class="descname">le</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.le" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes <cite>tensor &lt;= other</cite> element-wise.</p>
<p>The second argument can be a number or a tensor whose shape is
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a> with the first argument.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Tensor to compare</li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; Tensor or value to compare</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor. Must be a <cite>ByteTensor</cite> or the same
type as <cite>tensor</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><dl class="docutils">
<dt>a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where</dt>
<dd><p class="first last">comparison is true.</p>
</dd>
</dl>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a></p>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">le</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go"> 1  0</span>
<span class="go"> 1  1</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.lt">
<code class="descclassname">torch.</code><code class="descname">lt</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.lt" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes <cite>tensor &lt; other</cite> element-wise.</p>
<p>The second argument can be a number or a tensor whose shape is
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a> with the first argument.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Tensor to compare</li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; Tensor or value to compare</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor. Must be a <cite>ByteTensor</cite> or
the same type as <cite>tensor</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><dl class="docutils">
<dt>a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where</dt>
<dd><p class="first last">comparison is true.</p>
</dd>
</dl>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a></p>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">lt</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go"> 0  0</span>
<span class="go"> 1  0</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.max">
<code class="descclassname">torch.</code><code class="descname">max</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.max" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">max</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the maximum value of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4729 -0.2266 -0.2085</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">0.4729</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">max</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Returns the maximum value of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>. The second return value is the index location of each
maximum value found (argmax).</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is true, the output Tensors are of the same size
as <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where they are of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <a class="reference internal" href="#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code></a>), resulting
in the output Tensors having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to reduce</li>
<li><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a>) &#8211; whether the output Tensors have <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not</li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; the result tuple of two output Tensors (max, max_indices)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;</span> <span class="n">a</span>

<span class="mf">0.0692</span>  <span class="mf">0.3142</span>  <span class="mf">1.2513</span> <span class="o">-</span><span class="mf">0.5428</span>
<span class="mf">0.9288</span>  <span class="mf">0.8552</span> <span class="o">-</span><span class="mf">0.2073</span>  <span class="mf">0.6409</span>
<span class="mf">1.0695</span> <span class="o">-</span><span class="mf">0.0101</span> <span class="o">-</span><span class="mf">2.4507</span> <span class="o">-</span><span class="mf">1.2230</span>
<span class="mf">0.7426</span> <span class="o">-</span><span class="mf">0.7666</span>  <span class="mf">0.4862</span> <span class="o">-</span><span class="mf">0.6628</span>
<span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x4</span><span class="p">]</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">(</span>
 <span class="mf">1.2513</span>
 <span class="mf">0.9288</span>
 <span class="mf">1.0695</span>
 <span class="mf">0.7426</span>
<span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="p">]</span>
<span class="p">,</span>
 <span class="mi">2</span>
 <span class="mi">0</span>
 <span class="mi">0</span>
 <span class="mi">0</span>
<span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">max</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is compared with the corresponding
element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> and an element-wise <cite>max</cite> is taken.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> don&#8217;t need to match,
but they must be <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When the shapes do not match, the shape of the returned output tensor
follows the <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcasting rules</span></a>.</p>
</div>
<p><span class="math">\(out_i = max(tensor_i, other_i)\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the second input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go"> 1.0067</span>
<span class="go">-0.8010</span>
<span class="go"> 0.6258</span>
<span class="go"> 0.3627</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go"> 0.6258</span>
<span class="go"> 0.3627</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.min">
<code class="descclassname">torch.</code><code class="descname">min</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.min" title="Permalink to this definition">¶</a></dt>
<dd><dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">min</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float</dt>
<dd></dd></dl>

<p>Returns the minimum value of all elements in the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 0.4729 -0.2266 -0.2085</span>
<span class="go">[torch.FloatTensor of size 1x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="go">-0.22663167119026184</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">min</code><span class="sig-paren">(</span><em>input</em>, <em>dim</em>, <em>keepdim=False</em>, <em>out=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span></dt>
<dd></dd></dl>

<p>Returns the minimum value of each row of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor in the given
dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code>. The second return value is the index location of each
minimum value found (argmin).</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">keepdim</span></code> is true, the output Tensors are of the same size as
<code class="xref py py-attr docutils literal"><span class="pre">input</span></code> except in the dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> where they are of size 1.
Otherwise, <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is squeezed (see <a class="reference internal" href="#torch.squeeze" title="torch.squeeze"><code class="xref py py-func docutils literal"><span class="pre">torch.squeeze()</span></code></a>), resulting in
the output Tensors having 1 fewer dimension than <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the dimension to reduce</li>
<li><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a>) &#8211; whether the output tensors have <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> retained or not</li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; the result tuple of two output Tensors (min, min_indices)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;</span> <span class="n">a</span>

<span class="mf">0.0692</span>  <span class="mf">0.3142</span>  <span class="mf">1.2513</span> <span class="o">-</span><span class="mf">0.5428</span>
<span class="mf">0.9288</span>  <span class="mf">0.8552</span> <span class="o">-</span><span class="mf">0.2073</span>  <span class="mf">0.6409</span>
<span class="mf">1.0695</span> <span class="o">-</span><span class="mf">0.0101</span> <span class="o">-</span><span class="mf">2.4507</span> <span class="o">-</span><span class="mf">1.2230</span>
<span class="mf">0.7426</span> <span class="o">-</span><span class="mf">0.7666</span>  <span class="mf">0.4862</span> <span class="o">-</span><span class="mf">0.6628</span>
<span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="n">x4</span><span class="p">]</span>

<span class="o">&gt;&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="mf">0.5428</span>
<span class="mf">0.2073</span>
<span class="mf">2.4507</span>
<span class="mf">0.7666</span>
<span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="p">]</span>

<span class="mi">3</span>
<span class="mi">2</span>
<span class="mi">2</span>
<span class="mi">1</span>
<span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span> <span class="n">of</span> <span class="n">size</span> <span class="mi">4</span><span class="p">]</span>
</pre></div>
</div>
<dl class="function">
<dt>
<code class="descclassname">torch.</code><code class="descname">min</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor</dt>
<dd></dd></dl>

<p>Each element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is compared with the corresponding
element of the Tensor <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> and an element-wise <cite>min</cite> is taken.
The resulting Tensor is returned.</p>
<p>The shapes of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> don&#8217;t need to match,
but they must be <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When the shapes do not match, the shape of the returned output tensor
follows the <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcasting rules</span></a>.</p>
</div>
<p><span class="math">\(out_i = min(tensor_i, other_i)\)</span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the second input <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3869</span>
<span class="go"> 0.3912</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go"> 1.0067</span>
<span class="go">-0.8010</span>
<span class="go"> 0.6258</span>
<span class="go"> 0.3627</span>
<span class="go">[torch.FloatTensor of size 4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="go"> 1.0067</span>
<span class="go">-0.8010</span>
<span class="go">-0.8634</span>
<span class="go">-0.5468</span>
<span class="go">[torch.FloatTensor of size 4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.ne">
<code class="descclassname">torch.</code><code class="descname">ne</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.ne" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes <cite>tensor != other</cite> element-wise.</p>
<p>The second argument can be a number or a tensor whose shape is
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a> with the first argument.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Tensor to compare</li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em> or </em><a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; Tensor or value to compare</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor. Must be a <cite>ByteTensor</cite> or the same
type as <cite>tensor</cite>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><dl class="docutils">
<dt>a <code class="docutils literal"><span class="pre">torch.ByteTensor</span></code> containing a 1 at each location where</dt>
<dd><p class="first last">comparison is true.</p>
</dd>
</dl>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a></p>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]))</span>
<span class="go"> 0  1</span>
<span class="go"> 1  0</span>
<span class="go">[torch.ByteTensor of size 2x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.sort">
<code class="descclassname">torch.</code><code class="descname">sort</code><span class="sig-paren">(</span><em>input</em>, <em>dim=None</em>, <em>descending=False</em>, <em>out=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.sort" title="Permalink to this definition">¶</a></dt>
<dd><p>Sorts the elements of the <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor along a given dimension
in ascending order by value.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is not given, the last dimension of the <cite>input</cite> is chosen.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">descending</span></code> is <cite>True</cite> then the elements are sorted in descending
order by value.</p>
<p>A tuple of (sorted_tensor, sorted_indices) is returned, where the
sorted_indices are the indices of the elements in the original <cite>input</cite> Tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a><em>, </em><em>optional</em>) &#8211; The dimension to sort along</li>
<li><strong>descending</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a><em>, </em><em>optional</em>) &#8211; Controls the sorting order
(ascending or descending)</li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; The output tuple of (Tensor, LongTensor)
can be optionally given to be used as output buffers</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span>

<span class="go">-1.6747  0.0610  0.1190  1.4137</span>
<span class="go">-1.4782  0.7159  1.0341  1.3678</span>
<span class="go">-0.3324 -0.0782  0.3518  0.4763</span>
<span class="go">[torch.FloatTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span>

<span class="go"> 0  1  3  2</span>
<span class="go"> 2  1  0  3</span>
<span class="go"> 3  1  0  2</span>
<span class="go">[torch.LongTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span>

<span class="go">-1.6747 -0.0782 -1.4782 -0.3324</span>
<span class="go"> 0.3518  0.0610  0.4763  0.1190</span>
<span class="go"> 1.0341  0.7159  1.4137  1.3678</span>
<span class="go">[torch.FloatTensor of size 3x4]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">indices</span>

<span class="go"> 0  2  1  2</span>
<span class="go"> 2  0  2  0</span>
<span class="go"> 1  1  0  1</span>
<span class="go">[torch.LongTensor of size 3x4]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.topk">
<code class="descclassname">torch.</code><code class="descname">topk</code><span class="sig-paren">(</span><em>input</em>, <em>k</em>, <em>dim=None</em>, <em>largest=True</em>, <em>sorted=True</em>, <em>out=None) -&gt; (Tensor</em>, <em>LongTensor</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.topk" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the <code class="xref py py-attr docutils literal"><span class="pre">k</span></code> largest elements of the given <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> Tensor along
a given dimension.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is not given, the last dimension of the <cite>input</cite> is chosen.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">largest</span></code> is <cite>False</cite> then the <cite>k</cite> smallest elements are returned.</p>
<p>A tuple of <cite>(values, indices)</cite> is returned, where the <cite>indices</cite> are the indices
of the elements in the original <cite>input</cite> Tensor.</p>
<p>The boolean option <code class="xref py py-attr docutils literal"><span class="pre">sorted</span></code> if <cite>True</cite>, will make sure that the returned
<cite>k</cite> elements are themselves sorted</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>k</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; the k in &#8220;top-k&#8221;</li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a><em>, </em><em>optional</em>) &#8211; The dimension to sort along</li>
<li><strong>largest</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a><em>, </em><em>optional</em>) &#8211; Controls whether to return largest or
smallest elements</li>
<li><strong>sorted</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a><em>, </em><em>optional</em>) &#8211; Controls whether to return the elements
in sorted order</li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; The output tuple of (Tensor, LongTensor)
can be optionally given to be used as output buffers</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go"> 4</span>
<span class="go"> 5</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="go">(</span>
<span class="go"> 5</span>
<span class="go"> 4</span>
<span class="go"> 3</span>
<span class="go">[torch.FloatTensor of size 3]</span>
<span class="go">,</span>
<span class="go"> 4</span>
<span class="go"> 3</span>
<span class="go"> 2</span>
<span class="go">[torch.LongTensor of size 3]</span>
<span class="go">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">largest</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">(</span>
<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go"> 3</span>
<span class="go">[torch.FloatTensor of size 3]</span>
<span class="go">,</span>
<span class="go"> 0</span>
<span class="go"> 1</span>
<span class="go"> 2</span>
<span class="go">[torch.LongTensor of size 3]</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="other-operations">
<h3>Other Operations<a class="headerlink" href="#other-operations" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.cross">
<code class="descclassname">torch.</code><code class="descname">cross</code><span class="sig-paren">(</span><em>input</em>, <em>other</em>, <em>dim=-1</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.cross" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the cross product of vectors in dimension <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>
and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code>.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">other</span></code> must have the same size, and the size of their
<code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> dimension should be 3.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is not given, it defaults to the first dimension found with the
size 3.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>other</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the second input <cite>Tensor</cite></li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a><em>, </em><em>optional</em>) &#8211; the dimension to take the cross-product in.</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-0.6652 -1.0116 -0.6857</span>
<span class="go"> 0.2286  0.4446 -0.5272</span>
<span class="go"> 0.0476  0.2321  1.9991</span>
<span class="go"> 0.6199  1.1924 -0.9397</span>
<span class="go">[torch.FloatTensor of size 4x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go">-0.1042 -1.1156  0.1947</span>
<span class="go"> 0.9947  0.1149  0.4701</span>
<span class="go">-1.0108  0.8319 -0.0750</span>
<span class="go"> 0.9045 -1.3754  1.0976</span>
<span class="go">[torch.FloatTensor of size 4x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cross</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="go">-0.9619  0.2009  0.6367</span>
<span class="go"> 0.2696 -0.6318 -0.4160</span>
<span class="go">-1.6805 -2.0171  0.2741</span>
<span class="go"> 0.0163 -1.5304 -1.9311</span>
<span class="go">[torch.FloatTensor of size 4x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cross</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>

<span class="go">-0.9619  0.2009  0.6367</span>
<span class="go"> 0.2696 -0.6318 -0.4160</span>
<span class="go">-1.6805 -2.0171  0.2741</span>
<span class="go"> 0.0163 -1.5304 -1.9311</span>
<span class="go">[torch.FloatTensor of size 4x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.diag">
<code class="descclassname">torch.</code><code class="descname">diag</code><span class="sig-paren">(</span><em>input</em>, <em>diagonal=0</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.diag" title="Permalink to this definition">¶</a></dt>
<dd><ul class="simple">
<li>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a vector (1D Tensor), then returns a 2D square Tensor
with the elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> as the diagonal.</li>
<li>If <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> is a matrix (2D Tensor), then returns a 1D Tensor with
the diagonal elements of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</li>
</ul>
<p>The argument <code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> controls which diagonal to consider.</p>
<ul class="simple">
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> = 0, is the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> &gt; 0, is above the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">diagonal</span></code> &lt; 0, is below the main diagonal.</li>
</ul>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>diagonal</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a><em>, </em><em>optional</em>) &#8211; the diagonal to consider</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<p>Get the square matrix where the input vector is the diagonal:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.0480</span>
<span class="go">-2.3405</span>
<span class="go">-1.1138</span>
<span class="go">[torch.FloatTensor of size 3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1.0480  0.0000  0.0000</span>
<span class="go"> 0.0000 -2.3405  0.0000</span>
<span class="go"> 0.0000  0.0000 -1.1138</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.0000  1.0480  0.0000  0.0000</span>
<span class="go"> 0.0000  0.0000 -2.3405  0.0000</span>
<span class="go"> 0.0000  0.0000  0.0000 -1.1138</span>
<span class="go"> 0.0000  0.0000  0.0000  0.0000</span>
<span class="go">[torch.FloatTensor of size 4x4]</span>
</pre></div>
</div>
<p>Get the k-th diagonal of a given matrix:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">-1.5328 -1.3210 -1.5204</span>
<span class="go"> 0.8596  0.0471 -0.2239</span>
<span class="go">-0.6617  0.0146 -1.0817</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="go">-1.5328</span>
<span class="go"> 0.0471</span>
<span class="go">-1.0817</span>
<span class="go">[torch.FloatTensor of size 3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="go">-1.3210</span>
<span class="go">-0.2239</span>
<span class="go">[torch.FloatTensor of size 2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.histc">
<code class="descclassname">torch.</code><code class="descname">histc</code><span class="sig-paren">(</span><em>input</em>, <em>bins=100</em>, <em>min=0</em>, <em>max=0</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.histc" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the histogram of a tensor.</p>
<p>The elements are sorted into equal width bins between <cite>min</cite> and <cite>max</cite>. If <cite>min</cite>
and <cite>max</cite> are both zero, the minimum and maximum values of the data are used.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Input data</li>
<li><strong>bins</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Number of histogram bins</li>
<li><strong>min</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Lower end of the range (inclusive)</li>
<li><strong>max</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; Upper end of the range (inclusive)</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output argument</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the histogram</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a></p>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">histc</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="go">FloatTensor([0, 2, 1, 0])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.renorm">
<code class="descclassname">torch.</code><code class="descname">renorm</code><span class="sig-paren">(</span><em>input</em>, <em>p</em>, <em>dim</em>, <em>maxnorm</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.renorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a Tensor where each sub-tensor of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code> along dimension
<code class="xref py py-attr docutils literal"><span class="pre">dim</span></code> is normalized such that the <cite>p</cite>-norm of the sub-tensor is lower
than the value <code class="xref py py-attr docutils literal"><span class="pre">maxnorm</span></code></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If the norm of a row is lower than <cite>maxnorm</cite>, the row is unchanged</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; The input Tensor</li>
<li><strong>p</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The power for the norm computation</li>
<li><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a>) &#8211; The dimension to slice over to get the sub-tensors</li>
<li><strong>maxnorm</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#float" title="(in Python v2.7)"><em>float</em></a>) &#8211; The maximum norm to keep each sub-tensor under</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1  1  1</span>
<span class="go"> 2  2  2</span>
<span class="go"> 3  3  3</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">renorm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="go"> 1.0000  1.0000  1.0000</span>
<span class="go"> 1.6667  1.6667  1.6667</span>
<span class="go"> 1.6667  1.6667  1.6667</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.trace">
<code class="descclassname">torch.</code><code class="descname">trace</code><span class="sig-paren">(</span><em>input</em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#torch.trace" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the sum of the elements of the diagonal of the input 2D matrix.</p>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 1  2  3</span>
<span class="go"> 4  5  6</span>
<span class="go"> 7  8  9</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="go">15.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.tril">
<code class="descclassname">torch.</code><code class="descname">tril</code><span class="sig-paren">(</span><em>input</em>, <em>k=0</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.tril" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the lower triangular part of the matrix (2D Tensor) <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>,
the other elements of the result Tensor <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> are set to 0.</p>
<p>The lower triangular part of the matrix is defined as the elements on and
below the diagonal.</p>
<p>The argument <code class="xref py py-attr docutils literal"><span class="pre">k</span></code> controls which diagonal to consider.</p>
<ul class="simple">
<li><code class="xref py py-attr docutils literal"><span class="pre">k</span></code> = 0, is the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">k</span></code> &gt; 0, is above the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">k</span></code> &lt; 0, is below the main diagonal.</li>
</ul>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>k</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a><em>, </em><em>optional</em>) &#8211; the diagonal to consider</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3225  1.7304  1.4573</span>
<span class="go">-0.3052 -0.3111 -0.1809</span>
<span class="go"> 1.2469  0.0064 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1.3225  0.0000  0.0000</span>
<span class="go">-0.3052 -0.3111  0.0000</span>
<span class="go"> 1.2469  0.0064 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="go"> 1.3225  1.7304  0.0000</span>
<span class="go">-0.3052 -0.3111 -0.1809</span>
<span class="go"> 1.2469  0.0064 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">tril</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">k</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.0000  0.0000  0.0000</span>
<span class="go">-0.3052  0.0000  0.0000</span>
<span class="go"> 1.2469  0.0064  0.0000</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.triu">
<code class="descclassname">torch.</code><code class="descname">triu</code><span class="sig-paren">(</span><em>input</em>, <em>k=0</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.triu" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the upper triangular part of the matrix (2D Tensor) <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>,
the other elements of the result Tensor <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> are set to 0.</p>
<p>The upper triangular part of the matrix is defined as the elements on and
above the diagonal.</p>
<p>The argument <code class="xref py py-attr docutils literal"><span class="pre">k</span></code> controls which diagonal to consider.</p>
<ul class="simple">
<li><code class="xref py py-attr docutils literal"><span class="pre">k</span></code> = 0, is the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">k</span></code> &gt; 0, is above the main diagonal.</li>
<li><code class="xref py py-attr docutils literal"><span class="pre">k</span></code> &lt; 0, is below the main diagonal.</li>
</ul>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input <cite>Tensor</cite></li>
<li><strong>k</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#int" title="(in Python v2.7)"><em>int</em></a><em>, </em><em>optional</em>) &#8211; the diagonal to consider</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; The result <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 1.3225  1.7304  1.4573</span>
<span class="go">-0.3052 -0.3111 -0.1809</span>
<span class="go"> 1.2469  0.0064 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>

<span class="go"> 1.3225  1.7304  1.4573</span>
<span class="go"> 0.0000 -0.3111 -0.1809</span>
<span class="go"> 0.0000  0.0000 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="go"> 0.0000  1.7304  1.4573</span>
<span class="go"> 0.0000  0.0000 -0.1809</span>
<span class="go"> 0.0000  0.0000  0.0000</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">k</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="go"> 1.3225  1.7304  1.4573</span>
<span class="go">-0.3052 -0.3111 -0.1809</span>
<span class="go"> 0.0000  0.0064 -1.6250</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="blas-and-lapack-operations">
<h3>BLAS and LAPACK Operations<a class="headerlink" href="#blas-and-lapack-operations" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.addbmm">
<code class="descclassname">torch.</code><code class="descname">addbmm</code><span class="sig-paren">(</span><em>beta=1</em>, <em>mat</em>, <em>alpha=1</em>, <em>batch1</em>, <em>batch2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.addbmm" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a batch matrix-matrix product of matrices stored
in <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code>,
with a reduced add step (all matrix multiplications get accumulated
along the first dimension).
<code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> is added to the final result.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> must be 3D Tensors each containing the
same number of matrices.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> is a <cite>b x n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> is a <cite>b x m x p</cite>
Tensor, :<code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> must be <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>
with a <cite>n x p</cite> Tensor and attr:<cite>out</cite> will be a <cite>n x p</cite> Tensor.</p>
<p>In other words,
<span class="math">\(res = (beta * M) + (alpha * sum(batch1_i &#64; batch2_i, i = 0, b))\)</span></p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <cite>beta</cite> and <cite>alpha</cite>
must be real numbers, otherwise they should be integers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>beta</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; multiplier for <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code></li>
<li><strong>mat</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; matrix to be added</li>
<li><strong>alpha</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; multiplier for <cite>batch1 &#64; batch2</cite></li>
<li><strong>batch1</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; First batch of matrices to be multiplied</li>
<li><strong>batch2</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Second batch of matrices to be multiplied</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addbmm</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">)</span>

<span class="go"> -3.1162  11.0071   7.3102   0.1824  -7.6892</span>
<span class="go">  1.8265   6.0739   0.4589  -0.5641  -5.4283</span>
<span class="go"> -9.3387  -0.1794  -1.2318  -6.8841  -4.7239</span>
<span class="go">[torch.FloatTensor of size 3x5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.addmm">
<code class="descclassname">torch.</code><code class="descname">addmm</code><span class="sig-paren">(</span><em>beta=1</em>, <em>mat</em>, <em>alpha=1</em>, <em>mat1</em>, <em>mat2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.addmm" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a matrix multiplication of the matrices <code class="xref py py-attr docutils literal"><span class="pre">mat1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">mat2</span></code>.
The matrix <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> is added to the final result.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">mat1</span></code> is a <cite>n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">mat2</span></code> is a <cite>m x p</cite> Tensor,
then <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> must be <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a> with
a <cite>n x p</cite> Tensor and <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be a <cite>n x p</cite> Tensor.</p>
<p><cite>alpha</cite> and <cite>beta</cite> are scaling factors on <cite>mat1 &#64; mat2</cite> and <cite>mat</cite> respectively.</p>
<p>In other words,
<span class="math">\(out = (beta * M) + (alpha * mat1 &#64; mat2)\)</span></p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <code class="xref py py-attr docutils literal"><span class="pre">beta</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">alpha</span></code> must be real numbers, otherwise they should be integers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>beta</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; multiplier for <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code></li>
<li><strong>mat</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; matrix to be added</li>
<li><strong>alpha</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; multiplier for <cite>mat1 &#64; mat2</cite></li>
<li><strong>mat1</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; First matrix to be multiplied</li>
<li><strong>mat2</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Second matrix to be multiplied</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mat1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mat2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addmm</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">)</span>

<span class="go">-0.4095 -1.9703  1.3561</span>
<span class="go"> 5.7674 -4.9760  2.7378</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.addmv">
<code class="descclassname">torch.</code><code class="descname">addmv</code><span class="sig-paren">(</span><em>beta=1</em>, <em>tensor</em>, <em>alpha=1</em>, <em>mat</em>, <em>vec</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.addmv" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a matrix-vector product of the matrix <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> and
the vector <code class="xref py py-attr docutils literal"><span class="pre">vec</span></code>.
The vector <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code> is added to the final result.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> is a <cite>n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">vec</span></code> is a 1D Tensor of size <cite>m</cite>,
then <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code> must be <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>
with a 1D tensor of size <cite>n</cite> and <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be 1D tensor of size <cite>n</cite>.</p>
<p><cite>alpha</cite> and <cite>beta</cite> are scaling factors on <cite>mat * vec</cite> and <cite>tensor</cite> respectively.</p>
<p>In other words:</p>
<p><span class="math">\(out = (beta * tensor) + (alpha * (mat &#64; vec2))\)</span></p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <code class="xref py py-attr docutils literal"><span class="pre">beta</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">alpha</span></code> must be real numbers, otherwise they should be integers</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>beta</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; multiplier for <code class="xref py py-attr docutils literal"><span class="pre">tensor</span></code></li>
<li><strong>tensor</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; vector to be added</li>
<li><strong>alpha</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; multiplier for <cite>mat &#64; vec</cite></li>
<li><strong>mat</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; matrix to be multiplied</li>
<li><strong>vec</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; vector to be multiplied</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addmv</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">)</span>

<span class="go">-2.0939</span>
<span class="go">-2.2950</span>
<span class="go">[torch.FloatTensor of size 2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.addr">
<code class="descclassname">torch.</code><code class="descname">addr</code><span class="sig-paren">(</span><em>beta=1</em>, <em>mat</em>, <em>alpha=1</em>, <em>vec1</em>, <em>vec2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.addr" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the outer-product of vectors <code class="xref py py-attr docutils literal"><span class="pre">vec1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">vec2</span></code>
and adds it to the matrix <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code>.</p>
<p>Optional values <code class="xref py py-attr docutils literal"><span class="pre">beta</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">alpha</span></code> are scalars that multiply
<code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> and <span class="math">\((vec1 \otimes vec2)\)</span> respectively</p>
<p>In other words,
<span class="math">\(out = (beta * mat) + (alpha * vec1 \otimes vec2)\)</span></p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">vec1</span></code> is a vector of size <cite>n</cite> and <code class="xref py py-attr docutils literal"><span class="pre">vec2</span></code> is a vector
of size <cite>m</cite>, then <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> must be
<a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a> with a matrix of size <cite>n x m</cite>
and <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be a matrix of size <cite>n x m</cite>.</p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <code class="xref py py-attr docutils literal"><span class="pre">beta</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">alpha</span></code> must be real numbers, otherwise they should be integers</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>beta</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; Multiplier for <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code></li>
<li><strong>mat</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Matrix to be added</li>
<li><strong>alpha</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; Multiplier for outer product of
for <code class="xref py py-attr docutils literal"><span class="pre">vec1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">vec2</span></code></li>
<li><strong>vec1</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; First vector of the outer product</li>
<li><strong>vec2</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Second vector of the outer product</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">vec1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vec2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">addr</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">vec1</span><span class="p">,</span> <span class="n">vec2</span><span class="p">)</span>
<span class="go"> 1  2</span>
<span class="go"> 2  4</span>
<span class="go"> 3  6</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.baddbmm">
<code class="descclassname">torch.</code><code class="descname">baddbmm</code><span class="sig-paren">(</span><em>beta=1</em>, <em>mat</em>, <em>alpha=1</em>, <em>batch1</em>, <em>batch2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.baddbmm" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a batch matrix-matrix product of matrices in <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code>
and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code>.
<code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> is added to the final result.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> must be 3D Tensors each containing the same
number of matrices.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> is a <cite>b x n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> is a <cite>b x m x p</cite>
Tensor, then <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> must be <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcastable</span></a>
with a <cite>b x n x p</cite> Tensor and <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be a <cite>b x n x p</cite> Tensor.</p>
<p>In other words,
<span class="math">\(res_i = (beta * M_i) + (alpha * batch1_i \times batch2_i)\)</span></p>
<p>For inputs of type <cite>FloatTensor</cite> or <cite>DoubleTensor</cite>, args <code class="xref py py-attr docutils literal"><span class="pre">beta</span></code> and
<code class="xref py py-attr docutils literal"><span class="pre">alpha</span></code> must be real numbers, otherwise they should be integers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>beta</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; multiplier for <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code></li>
<li><strong>mat</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; tensor to be added</li>
<li><strong>alpha</strong> (<em>Number</em><em>, </em><em>optional</em>) &#8211; multiplier for <cite>batch1 &#64; batch2</cite></li>
<li><strong>batch1</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; First batch of matrices to be multiplied</li>
<li><strong>batch2</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Second batch of matrices to be multiplied</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">baddbmm</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([10, 3, 5])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.bmm">
<code class="descclassname">torch.</code><code class="descname">bmm</code><span class="sig-paren">(</span><em>batch1</em>, <em>batch2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.bmm" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a batch matrix-matrix product of matrices stored in <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code>
and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code>.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> must be 3D Tensors each containing
the same number of matrices.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">batch1</span></code> is a <cite>b x n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">batch2</span></code> is a <cite>b x m x p</cite>
Tensor, <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be a <cite>b x n x p</cite> Tensor.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function does not <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcast</span></a>.
For broadcasting matrix products, see <a class="reference internal" href="#torch.matmul" title="torch.matmul"><code class="xref py py-func docutils literal"><span class="pre">torch.matmul()</span></code></a>.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>batch1</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; First batch of matrices to be multiplied</li>
<li><strong>batch2</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Second batch of matrices to be multiplied</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">batch1</span><span class="p">,</span> <span class="n">batch2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([10, 3, 5])</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.btrifact">
<code class="descclassname">torch.</code><code class="descname">btrifact</code><span class="sig-paren">(</span><em>A</em>, <em>info=None</em>, <em>pivot=True</em><span class="sig-paren">)</span> &#x2192; Tensor, IntTensor<a class="headerlink" href="#torch.btrifact" title="Permalink to this definition">¶</a></dt>
<dd><p>Batch LU factorization.</p>
<p>Returns a tuple containing the LU factorization and pivots.
The optional argument <cite>info</cite> provides information if the
factorization succeeded for each minibatch example.
The info values are from dgetrf and a non-zero value indicates an error
occurred. The specific values are from cublas if cuda is being used, otherwise
LAPACK. Pivoting is done if pivot is set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>A</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; tensor to factor.</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_LU</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">btrifact</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.btrisolve">
<code class="descclassname">torch.</code><code class="descname">btrisolve</code><span class="sig-paren">(</span><em>b</em>, <em>LU_data</em>, <em>LU_pivots</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.btrisolve" title="Permalink to this definition">¶</a></dt>
<dd><p>Batch LU solve.</p>
<p>Returns the LU solve of the linear system Ax = b.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>b</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; RHS tensor.</li>
<li><strong>LU_data</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Pivoted LU factorization of A from btrifact.</li>
<li><strong>LU_pivots</strong> (<em>IntTensor</em>) &#8211; Pivots of the LU factorization.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A_LU</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">btrifact</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">btrisolve</span><span class="p">(</span><span class="o">*</span><span class="n">A_LU</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span>
<span class="go">6.664001874625056e-08</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.dot">
<code class="descclassname">torch.</code><code class="descname">dot</code><span class="sig-paren">(</span><em>tensor1</em>, <em>tensor2</em><span class="sig-paren">)</span> &#x2192; float<a class="headerlink" href="#torch.dot" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the dot product (inner product) of two tensors.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function does not <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcast</span></a>.</p>
</div>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span>
<span class="go">7.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.eig">
<code class="descclassname">torch.</code><code class="descname">eig</code><span class="sig-paren">(</span><em>a</em>, <em>eigenvectors=False</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.eig" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the eigenvalues and eigenvectors of a real square matrix.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>a</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; A square matrix for which the eigenvalues and eigenvectors will
be computed</li>
<li><strong>eigenvectors</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a>) &#8211; <cite>True</cite> to compute both eigenvalues and eigenvectors.
Otherwise, only eigenvalues will be computed.</li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; Output tensors</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p>tuple containing</p>
<blockquote>
<div><ul class="simple">
<li><strong>e</strong> (<em>Tensor</em>): the right eigenvalues of <code class="docutils literal"><span class="pre">a</span></code></li>
<li><dl class="first docutils">
<dt><strong>v</strong> (<em>Tensor</em>): the eigenvectors of <code class="docutils literal"><span class="pre">a</span></code> if <code class="docutils literal"><span class="pre">eigenvectors</span></code></dt>
<dd>is <code class="docutils literal"><span class="pre">True</span></code>; otherwise an empty tensor</dd>
</dl>
</li>
</ul>
</div></blockquote>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>, <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.gels">
<code class="descclassname">torch.</code><code class="descname">gels</code><span class="sig-paren">(</span><em>B</em>, <em>A</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.gels" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the solution to the least squares and least norm problems for a full
rank <span class="math">\(m\)</span> by <span class="math">\(n\)</span> matrix <span class="math">\(A\)</span>.</p>
<p>If <span class="math">\(m &gt;= n\)</span>, <a class="reference internal" href="#torch.gels" title="torch.gels"><code class="xref py py-func docutils literal"><span class="pre">gels()</span></code></a> solves the least-squares problem:</p>
<div class="math">
\[\begin{array}{ll}
\mbox{minimize} &amp; \|AX-B\|_F.
\end{array}\]</div>
<p>If <span class="math">\(m &lt; n\)</span>, <a class="reference internal" href="#torch.gels" title="torch.gels"><code class="xref py py-func docutils literal"><span class="pre">gels()</span></code></a> solves the least-norm problem:</p>
<div class="math">
\[\begin{array}{ll}
\mbox{minimize} &amp; \|X\|_F &amp; \mbox{subject to} &amp; AX = B.
\end{array}\]</div>
<p>The first <span class="math">\(n\)</span> rows of the returned matrix <span class="math">\(X\)</span> contains the
solution. The remaining rows contain residual information: the euclidean norm
of each column starting at row <span class="math">\(n\)</span> is the residual for the corresponding
column.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>B</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; The matrix <span class="math">\(B\)</span></li>
<li><strong>A</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; The <span class="math">\(m\)</span> by <span class="math">\(n\)</span> matrix <span class="math">\(A\)</span></li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; Optional destination tensor</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p>tuple containing:</p>
<blockquote>
<div><ul class="simple">
<li><strong>X</strong> (<em>Tensor</em>): the least squares solution</li>
<li><strong>qr</strong> (<em>Tensor</em>): the details of the QR factorization</li>
</ul>
</div></blockquote>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>, <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>)</p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The returned matrices will always be tranposed, irrespective of the strides
of the input matrices. That is, they will have stride <cite>(1, m)</cite> instead of
<cite>(m, 1)</cite>.</p>
</div>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">],</span>
<span class="go">                      [ 12, 14],</span>
<span class="go">                      [ 14, 12],</span>
<span class="go">                      [ 16, 16],</span>
<span class="go">                      [ 18, 16]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gels</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>
<span class="go">2.0000  1.0000</span>
<span class="go">1.0000  1.0000</span>
<span class="go">1.0000  2.0000</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.geqrf">
<code class="descclassname">torch.</code><code class="descname">geqrf</code><span class="sig-paren">(</span><em>input</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.geqrf" title="Permalink to this definition">¶</a></dt>
<dd><p>This is a low-level function for calling LAPACK directly.</p>
<p>You&#8217;ll generally want to use <a class="reference internal" href="#torch.qr" title="torch.qr"><code class="xref py py-func docutils literal"><span class="pre">torch.qr()</span></code></a> instead.</p>
<p>Computes a QR decomposition of <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>, but without constructing
<cite>Q</cite> and <cite>R</cite> as explicit separate matrices.</p>
<p>Rather, this directly calls the underlying LAPACK function <cite>?geqrf</cite>
which produces a sequence of &#8216;elementary reflectors&#8217;.</p>
<p>See <a class="reference external" href="https://software.intel.com/en-us/node/521004">LAPACK documentation</a> for further details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input matrix</li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; The result tuple of (Tensor, Tensor)</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.ger">
<code class="descclassname">torch.</code><code class="descname">ger</code><span class="sig-paren">(</span><em>vec1</em>, <em>vec2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.ger" title="Permalink to this definition">¶</a></dt>
<dd><p>Outer product of <code class="xref py py-attr docutils literal"><span class="pre">vec1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">vec2</span></code>.
If <code class="xref py py-attr docutils literal"><span class="pre">vec1</span></code> is a vector of size <cite>n</cite> and <code class="xref py py-attr docutils literal"><span class="pre">vec2</span></code> is a vector of
size <cite>m</cite>, then <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> must be a matrix of size <cite>n x m</cite>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function does not <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcast</span></a>.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>vec1</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; 1D input vector</li>
<li><strong>vec2</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; 1D input vector</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; optional output matrix</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">v1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">v2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">ger</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)</span>

<span class="go">  1   2   3</span>
<span class="go">  2   4   6</span>
<span class="go">  3   6   9</span>
<span class="go">  4   8  12</span>
<span class="go">[torch.FloatTensor of size 4x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.gesv">
<code class="descclassname">torch.</code><code class="descname">gesv</code><span class="sig-paren">(</span><em>B</em>, <em>A</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.gesv" title="Permalink to this definition">¶</a></dt>
<dd><p><cite>X, LU = torch.gesv(B, A)</cite> returns the solution to the system of linear
equations represented by <span class="math">\(AX = B\)</span></p>
<p><cite>LU</cite> contains <cite>L</cite> and <cite>U</cite> factors for LU factorization of <cite>A</cite>.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">A</span></code> has to be a square and non-singular matrix (2D Tensor).</p>
<p>If <cite>A</cite> is an <cite>m x m</cite> matrix and <cite>B</cite> is <cite>m x k</cite>,
the result <cite>LU</cite> is <cite>m x m</cite> and <cite>X</cite> is <cite>m x k</cite> .</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Irrespective of the original strides, the returned matrices
<cite>X</cite> and <cite>LU</cite> will be transposed, i.e. with strides <cite>(1, m)</cite>
instead of <cite>(m, 1)</cite>.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>B</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; input matrix of <cite>m x k</cite> dimensions</li>
<li><strong>A</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; input square matrix of <cite>m x m</cite> dimensions</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; optional output matrix</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">6.80</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.11</span><span class="p">,</span>  <span class="mf">5.66</span><span class="p">,</span>  <span class="mf">5.97</span><span class="p">,</span>  <span class="mf">8.23</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">6.05</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.30</span><span class="p">,</span>  <span class="mf">5.36</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.44</span><span class="p">,</span>  <span class="mf">1.08</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">0.45</span><span class="p">,</span>  <span class="mf">2.58</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.70</span><span class="p">,</span>  <span class="mf">0.27</span><span class="p">,</span>  <span class="mf">9.04</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">8.32</span><span class="p">,</span>  <span class="mf">2.71</span><span class="p">,</span>  <span class="mf">4.35</span><span class="p">,</span>  <span class="o">-</span><span class="mf">7.17</span><span class="p">,</span>  <span class="mf">2.14</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">9.67</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.14</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.26</span><span class="p">,</span>  <span class="mf">6.08</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.87</span><span class="p">]])</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">4.02</span><span class="p">,</span>  <span class="mf">6.19</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.22</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.57</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.03</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">1.56</span><span class="p">,</span>  <span class="mf">4.00</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.67</span><span class="p">,</span>  <span class="mf">1.75</span><span class="p">,</span>  <span class="mf">2.86</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">9.81</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.09</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.57</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.61</span><span class="p">,</span>  <span class="mf">8.99</span><span class="p">]])</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">LU</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gesv</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span>
<span class="go">9.250057093890353e-06</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.inverse">
<code class="descclassname">torch.</code><code class="descname">inverse</code><span class="sig-paren">(</span><em>input</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.inverse" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the inverse of the square matrix <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Irrespective of the original strides, the returned matrix will be
transposed, i.e. with strides <cite>(1, m)</cite> instead of <cite>(m, 1)</cite></p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input 2D square <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; the optional output <cite>Tensor</cite></li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span>

<span class="go"> 0.7800  0.2267  0.7855  0.9479  0.5914  0.7119  0.4437  0.9131  0.1289  0.1982</span>
<span class="go"> 0.0045  0.0425  0.2229  0.4626  0.6210  0.0207  0.6338  0.7067  0.6381  0.8196</span>
<span class="go"> 0.8350  0.7810  0.8526  0.9364  0.7504  0.2737  0.0694  0.5899  0.8516  0.3883</span>
<span class="go"> 0.6280  0.6016  0.5357  0.2936  0.7827  0.2772  0.0744  0.2627  0.6326  0.9153</span>
<span class="go"> 0.7897  0.0226  0.3102  0.0198  0.9415  0.9896  0.3528  0.9397  0.2074  0.6980</span>
<span class="go"> 0.5235  0.6119  0.6522  0.3399  0.3205  0.5555  0.8454  0.3792  0.4927  0.6086</span>
<span class="go"> 0.1048  0.0328  0.5734  0.6318  0.9802  0.4458  0.0979  0.3320  0.3701  0.0909</span>
<span class="go"> 0.2616  0.3485  0.4370  0.5620  0.5291  0.8295  0.7693  0.1807  0.0650  0.8497</span>
<span class="go"> 0.1655  0.2192  0.6913  0.0093  0.0178  0.3064  0.6715  0.5101  0.2561  0.3396</span>
<span class="go"> 0.4370  0.4695  0.8333  0.1180  0.4266  0.4161  0.0699  0.4263  0.8865  0.2578</span>
<span class="go">[torch.FloatTensor of size 10x10]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span>

<span class="go"> 1.0000  0.0000  0.0000 -0.0000  0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000</span>
<span class="go"> 0.0000  1.0000 -0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000 -0.0000 -0.0000</span>
<span class="go"> 0.0000  0.0000  1.0000 -0.0000 -0.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000</span>
<span class="go"> 0.0000  0.0000  0.0000  1.0000  0.0000  0.0000  0.0000 -0.0000 -0.0000  0.0000</span>
<span class="go"> 0.0000  0.0000 -0.0000 -0.0000  1.0000  0.0000  0.0000 -0.0000 -0.0000 -0.0000</span>
<span class="go"> 0.0000  0.0000  0.0000 -0.0000  0.0000  1.0000 -0.0000 -0.0000 -0.0000 -0.0000</span>
<span class="go"> 0.0000  0.0000  0.0000 -0.0000  0.0000  0.0000  1.0000  0.0000 -0.0000  0.0000</span>
<span class="go"> 0.0000  0.0000 -0.0000 -0.0000  0.0000  0.0000 -0.0000  1.0000 -0.0000  0.0000</span>
<span class="go">-0.0000  0.0000 -0.0000 -0.0000  0.0000  0.0000 -0.0000 -0.0000  1.0000 -0.0000</span>
<span class="go">-0.0000  0.0000 -0.0000 -0.0000 -0.0000  0.0000 -0.0000 -0.0000  0.0000  1.0000</span>
<span class="go">[torch.FloatTensor of size 10x10]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">z</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">10</span><span class="p">)))</span> <span class="c1"># Max nonzero</span>
<span class="go">5.096662789583206e-07</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.matmul">
<code class="descclassname">torch.</code><code class="descname">matmul</code><span class="sig-paren">(</span><em>tensor1</em>, <em>tensor2</em>, <em>out=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/functional.html#matmul"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.matmul" title="Permalink to this definition">¶</a></dt>
<dd><p>Matrix product of two tensors.</p>
<p>The behavior depends on the dimensionality of the tensors as follows:</p>
<ul class="simple">
<li>If both tensors are 1-dimensional, the dot product (scalar) is returned.</li>
<li>If both arguments are 2-dimensional, the matrix-matrix product is returned.</li>
<li>If the first argument is 1-dimensional and the second argument is 2-dimensional,
a 1 is prepended to its dimension for the purpose of the matrix multiply.
After the matrix multiply, the prepended dimension is removed.</li>
<li>If the first argument is 2-dimensional and the second argument is 1-dimensional,
the matrix-vector product is returned.</li>
<li>If both arguments are at least 1-dimensional and at least one argument is
N-dimensional (where N &gt; 2), then a batched matrix multiply is returned.  If the first
argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the
batched matrix multiply and removed after.  If the second argument is 1-dimensional, a
1 is appended to its dimension for the purpose of the batched matrix multiple and removed after.
The non-matrix (i.e. batch) dimensions are <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcasted</span></a> (and thus
must be broadcastable).  For example, if <code class="xref py py-attr docutils literal"><span class="pre">tensor1</span></code> is a <cite>j x 1 x n x m</cite> Tensor
and <code class="xref py py-attr docutils literal"><span class="pre">tensor2</span></code> is a <cite>k x m x p</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be an <cite>j x k x n x p</cite> Tensor.</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The 1-dimensional dot product version of this function does not support an <code class="xref py py-attr docutils literal"><span class="pre">out</span></code> parameter.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tensor1</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; First tensor to be multiplied</li>
<li><strong>tensor2</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Second tensor to be multiplied</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="torch.mm">
<code class="descclassname">torch.</code><code class="descname">mm</code><span class="sig-paren">(</span><em>mat1</em>, <em>mat2</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.mm" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a matrix multiplication of the matrices <code class="xref py py-attr docutils literal"><span class="pre">mat1</span></code> and <code class="xref py py-attr docutils literal"><span class="pre">mat2</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">mat1</span></code> is a <cite>n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">mat2</span></code> is a <cite>m x p</cite> Tensor,
<code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be a <cite>n x p</cite> Tensor.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function does not <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcast</span></a>.
For broadcasting matrix products, see <a class="reference internal" href="#torch.matmul" title="torch.matmul"><code class="xref py py-func docutils literal"><span class="pre">torch.matmul()</span></code></a>.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>mat1</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; First matrix to be multiplied</li>
<li><strong>mat2</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; Second matrix to be multiplied</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mat1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mat2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">)</span>
<span class="go"> 0.0519 -0.3304  1.2232</span>
<span class="go"> 4.3910 -5.1498  2.7571</span>
<span class="go">[torch.FloatTensor of size 2x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.mv">
<code class="descclassname">torch.</code><code class="descname">mv</code><span class="sig-paren">(</span><em>mat</em>, <em>vec</em>, <em>out=None</em><span class="sig-paren">)</span> &#x2192; Tensor<a class="headerlink" href="#torch.mv" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs a matrix-vector product of the matrix <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> and the vector
<code class="xref py py-attr docutils literal"><span class="pre">vec</span></code>.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">mat</span></code> is a <cite>n x m</cite> Tensor, <code class="xref py py-attr docutils literal"><span class="pre">vec</span></code> is a 1D Tensor of size <cite>m</cite>,
<code class="xref py py-attr docutils literal"><span class="pre">out</span></code> will be 1D of size <cite>n</cite>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This function does not <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">broadcast</span></a>.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>mat</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; matrix to be multiplied</li>
<li><strong>vec</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; vector to be multiplied</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; Output tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vec</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">vec</span><span class="p">)</span>
<span class="go">-2.0939</span>
<span class="go">-2.2950</span>
<span class="go">[torch.FloatTensor of size 2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.orgqr">
<code class="descclassname">torch.</code><code class="descname">orgqr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.orgqr" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="torch.ormqr">
<code class="descclassname">torch.</code><code class="descname">ormqr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.ormqr" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="torch.potrf">
<code class="descclassname">torch.</code><code class="descname">potrf</code><span class="sig-paren">(</span><em>a</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.potrf" title="Permalink to this definition">¶</a></dt>
<dd><p>potrf(a, upper, out=None)</p>
<p>Computes the Cholesky decomposition of a positive semidefinite
matrix <code class="xref py py-attr docutils literal"><span class="pre">a</span></code>: returns matrix <cite>u</cite>
If <cite>upper</cite> is True or not provided, <cite>u</cite> is upper triangular
such that <span class="math">\(a = u^T u\)</span>.
If <cite>upper</cite> is False, <cite>u</cite> is lower triangular
such that <span class="math">\(a = u u^T\)</span>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>a</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input 2D <cite>Tensor</cite>, a symmetric positive semidefinite matrix</li>
<li><strong>upper</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a><em>, </em><em>optional</em>) &#8211; Return upper (default) or lower triangular matrix</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; A Tensor for u</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">t</span><span class="p">())</span> <span class="c1"># make symmetric positive definite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">potrf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 2.3563  3.2318 -0.9406</span>
<span class="go"> 3.2318  4.9557 -2.1618</span>
<span class="go">-0.9406 -2.1618  2.2443</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span>

<span class="go"> 1.5350  2.1054 -0.6127</span>
<span class="go"> 0.0000  0.7233 -1.2053</span>
<span class="go"> 0.0000  0.0000  0.6451</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span><span class="n">u</span><span class="p">)</span>

<span class="go"> 2.3563  3.2318 -0.9406</span>
<span class="go"> 3.2318  4.9557 -2.1618</span>
<span class="go">-0.9406 -2.1618  2.2443</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.potri">
<code class="descclassname">torch.</code><code class="descname">potri</code><span class="sig-paren">(</span><em>u</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.potri" title="Permalink to this definition">¶</a></dt>
<dd><p>potri(u, upper, out=None)</p>
<p>Computes the inverse of a positive semidefinite matrix given its
Cholesky factor <code class="xref py py-attr docutils literal"><span class="pre">u</span></code>: returns matrix <cite>inv</cite>
If <cite>upper</cite> is True or not provided, <cite>u</cite> is upper triangular
such that <span class="math">\(inv = (u^T u)^{-1}\)</span>.
If <cite>upper</cite> is False, <cite>u</cite> is lower triangular
such that <span class="math">\(inv = (u u^T)^{-1}\)</span>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>u</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input 2D <cite>Tensor</cite>, a upper or lower triangular
Cholesky factor</li>
<li><strong>upper</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a><em>, </em><em>optional</em>) &#8211; Flag if upper (default) or lower triangular matrix</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; A Tensor for inv</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">t</span><span class="p">())</span> <span class="c1"># make symmetric positive definite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">potrf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 2.3563  3.2318 -0.9406</span>
<span class="go"> 3.2318  4.9557 -2.1618</span>
<span class="go">-0.9406 -2.1618  2.2443</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">potri</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>

<span class="go"> 12.5724 -10.1765  -4.5333</span>
<span class="go">-10.1765   8.5852   4.0047</span>
<span class="go"> -4.5333   4.0047   2.4031</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">inverse</span><span class="p">()</span>

<span class="go"> 12.5723 -10.1765  -4.5333</span>
<span class="go">-10.1765   8.5852   4.0047</span>
<span class="go"> -4.5333   4.0047   2.4031</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.potrs">
<code class="descclassname">torch.</code><code class="descname">potrs</code><span class="sig-paren">(</span><em>b</em>, <em>u</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.potrs" title="Permalink to this definition">¶</a></dt>
<dd><p>potrs(b, u, upper, out=None)</p>
<p>Solves a linear system of equations with a positive semidefinite
matrix to be inverted given its given a Cholesky factor
matrix <code class="xref py py-attr docutils literal"><span class="pre">u</span></code>: returns matrix <cite>c</cite>
If <cite>upper</cite> is True or not provided, <cite>u</cite> is and upper triangular
such that <span class="math">\(c = (u^T u)^{-1} b\)</span>.
If <cite>upper</cite> is False, <cite>u</cite> is and lower triangular
such that <span class="math">\(c = (u u^T)^{-1} b\)</span>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><cite>b</cite> is always a 2D <cite>Tensor</cite>, use <cite>b.unsqueeze(1)</cite> to convert a vector.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>b</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the right hand side 2D <cite>Tensor</cite></li>
<li><strong>u</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input 2D <cite>Tensor</cite>, a upper or lower triangular
Cholesky factor</li>
<li><strong>upper</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a><em>, </em><em>optional</em>) &#8211; Return upper (default) or lower triangular matrix</li>
<li><strong>out</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) &#8211; A Tensor for c</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">t</span><span class="p">())</span> <span class="c1"># make symmetric positive definite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">potrf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 2.3563  3.2318 -0.9406</span>
<span class="go"> 3.2318  4.9557 -2.1618</span>
<span class="go">-0.9406 -2.1618  2.2443</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span>

<span class="go">-0.3119 -1.8224</span>
<span class="go">-0.2798  0.1789</span>
<span class="go">-0.3735  1.7451</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">potrs</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="n">u</span><span class="p">)</span>

<span class="go"> 0.6187 -32.6438</span>
<span class="go">-0.7234  27.0703</span>
<span class="go">-0.6039  13.1717</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">inverse</span><span class="p">(),</span><span class="n">b</span><span class="p">)</span>

<span class="go"> 0.6187 -32.6436</span>
<span class="go">-0.7234  27.0702</span>
<span class="go">-0.6039  13.1717</span>
<span class="go">[torch.FloatTensor of size 3x2]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.pstrf">
<code class="descclassname">torch.</code><code class="descname">pstrf</code><span class="sig-paren">(</span><em>a</em>, <em>out=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.pstrf" title="Permalink to this definition">¶</a></dt>
<dd><p>pstrf(a, upper, out=None)</p>
<p>Computes the pivoted Cholesky decomposition of a positive semidefinite
matrix <code class="xref py py-attr docutils literal"><span class="pre">a</span></code>: returns matrices <cite>u</cite> and <cite>piv</cite>.
If <cite>upper</cite> is True or not provided, <cite>u</cite> is and upper triangular
such that <span class="math">\(a = p^T u^T u p\)</span>, with <cite>p</cite> the permutation given by <cite>piv</cite>.
If <cite>upper</cite> is False, <cite>u</cite> is and lower triangular
such that <span class="math">\(a = p^T u u^T p\)</span>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>a</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input 2D <cite>Tensor</cite></li>
<li><strong>upper</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a><em>, </em><em>optional</em>) &#8211; Return upper (default) or lower triangular matrix</li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; A tuple of u and piv Tensors</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="n">t</span><span class="p">())</span> <span class="c1"># make symmetric positive definite</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go"> 5.4417 -2.5280  1.3643</span>
<span class="go">-2.5280  2.9689 -2.1368</span>
<span class="go"> 1.3643 -2.1368  4.6116</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span><span class="p">,</span><span class="n">piv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pstrf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span>

<span class="go"> 2.3328  0.5848 -1.0837</span>
<span class="go"> 0.0000  2.0663 -0.7274</span>
<span class="go"> 0.0000  0.0000  1.1249</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">piv</span>

<span class="go"> 0</span>
<span class="go"> 2</span>
<span class="go"> 1</span>
<span class="go">[torch.IntTensor of size 3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">piv</span><span class="o">.</span><span class="n">long</span><span class="p">())</span><span class="o">.</span><span class="n">index_select</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">piv</span><span class="o">.</span><span class="n">long</span><span class="p">())</span><span class="o">.</span><span class="n">t</span><span class="p">()</span> <span class="c1"># make pivot permutation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">u</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span><span class="n">u</span><span class="p">)),</span><span class="n">p</span><span class="p">)</span> <span class="c1"># reconstruct</span>

<span class="go"> 5.4417  1.3643 -2.5280</span>
<span class="go"> 1.3643  4.6116 -2.1368</span>
<span class="go">-2.5280 -2.1368  2.9689</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.qr">
<code class="descclassname">torch.</code><code class="descname">qr</code><span class="sig-paren">(</span><em>input</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.qr" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the QR decomposition of a matrix <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>: returns matrices
<cite>q</cite> and <cite>r</cite> such that <span class="math">\(x = q * r\)</span>, with <cite>q</cite> being an orthogonal matrix
and <cite>r</cite> being an upper triangular matrix.</p>
<p>This returns the thin (reduced) QR factorization.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">precision may be lost if the magnitudes of the elements of <cite>input</cite>
are large</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">while it should always give you a valid decomposition, it may not
give you the same one across platforms - it will depend on your
LAPACK implementation.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Irrespective of the original strides, the returned matrix <cite>q</cite> will be
transposed, i.e. with strides <cite>(1, m)</cite> instead of <cite>(m, 1)</cite>.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input 2D <cite>Tensor</cite></li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; A tuple of Q and R Tensors</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">12</span><span class="p">,</span> <span class="o">-</span><span class="mi">51</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span> <span class="o">-</span><span class="mi">68</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="o">-</span><span class="mi">41</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">q</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">q</span>

<span class="go">-0.8571  0.3943  0.3314</span>
<span class="go">-0.4286 -0.9029 -0.0343</span>
<span class="go"> 0.2857 -0.1714  0.9429</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span>

<span class="go"> -14.0000  -21.0000   14.0000</span>
<span class="go">   0.0000 -175.0000   70.0000</span>
<span class="go">   0.0000    0.0000  -35.0000</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>

<span class="go">  12  -51    4</span>
<span class="go">   6  167  -68</span>
<span class="go">  -4   24  -41</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span> <span class="n">q</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>

<span class="go"> 1 -0  0</span>
<span class="go">-0  1  0</span>
<span class="go"> 0  0  1</span>
<span class="go">[torch.FloatTensor of size 3x3]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.svd">
<code class="descclassname">torch.</code><code class="descname">svd</code><span class="sig-paren">(</span><em>input</em>, <em>some=True</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.svd" title="Permalink to this definition">¶</a></dt>
<dd><p><cite>U, S, V = torch.svd(A)</cite> returns the singular value decomposition of a
real matrix <cite>A</cite> of size <cite>(n x m)</cite> such that <span class="math">\(A = USV'*\)</span>.</p>
<p><cite>U</cite> is of shape <cite>n x n</cite></p>
<p><cite>S</cite> is of shape <cite>n x m</cite></p>
<p><cite>V</cite> is of shape <cite>m x m</cite>.</p>
<p><code class="xref py py-attr docutils literal"><span class="pre">some</span></code> represents the number of singular values to be computed.
If <cite>some=True</cite>, it computes some and <cite>some=False</cite> computes all.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Irrespective of the original strides, the returned matrix <cite>U</cite>
will be transposed, i.e. with strides <cite>(1, n)</cite> instead of <cite>(n, 1)</cite>.</p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input 2D Tensor</li>
<li><strong>some</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#bool" title="(in Python v2.7)"><em>bool</em></a><em>, </em><em>optional</em>) &#8211; controls the number of singular values to be computed</li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; the result tuple</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Example:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mf">8.79</span><span class="p">,</span>  <span class="mf">6.11</span><span class="p">,</span> <span class="o">-</span><span class="mf">9.15</span><span class="p">,</span>  <span class="mf">9.57</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.49</span><span class="p">,</span>  <span class="mf">9.84</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">9.93</span><span class="p">,</span>  <span class="mf">6.91</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.93</span><span class="p">,</span>  <span class="mf">1.64</span><span class="p">,</span>  <span class="mf">4.02</span><span class="p">,</span>  <span class="mf">0.15</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">9.83</span><span class="p">,</span>  <span class="mf">5.04</span><span class="p">,</span>  <span class="mf">4.86</span><span class="p">,</span>  <span class="mf">8.83</span><span class="p">,</span>  <span class="mf">9.80</span><span class="p">,</span> <span class="o">-</span><span class="mf">8.99</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">5.45</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.27</span><span class="p">,</span>  <span class="mf">4.85</span><span class="p">,</span>  <span class="mf">0.74</span><span class="p">,</span> <span class="mf">10.00</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.02</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="mf">3.16</span><span class="p">,</span>  <span class="mf">7.98</span><span class="p">,</span>  <span class="mf">3.01</span><span class="p">,</span>  <span class="mf">5.80</span><span class="p">,</span>  <span class="mf">4.27</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.31</span><span class="p">]])</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span>

<span class="go">  8.7900   9.9300   9.8300   5.4500   3.1600</span>
<span class="go">  6.1100   6.9100   5.0400  -0.2700   7.9800</span>
<span class="go"> -9.1500  -7.9300   4.8600   4.8500   3.0100</span>
<span class="go">  9.5700   1.6400   8.8300   0.7400   5.8000</span>
<span class="go"> -3.4900   4.0200   9.8000  10.0000   4.2700</span>
<span class="go">  9.8400   0.1500  -8.9900  -6.0200  -5.3100</span>
<span class="go">[torch.FloatTensor of size 6x5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">u</span>

<span class="go">-0.5911  0.2632  0.3554  0.3143  0.2299</span>
<span class="go">-0.3976  0.2438 -0.2224 -0.7535 -0.3636</span>
<span class="go">-0.0335 -0.6003 -0.4508  0.2334 -0.3055</span>
<span class="go">-0.4297  0.2362 -0.6859  0.3319  0.1649</span>
<span class="go">-0.4697 -0.3509  0.3874  0.1587 -0.5183</span>
<span class="go"> 0.2934  0.5763 -0.0209  0.3791 -0.6526</span>
<span class="go">[torch.FloatTensor of size 6x5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span>

<span class="go"> 27.4687</span>
<span class="go"> 22.6432</span>
<span class="go">  8.5584</span>
<span class="go">  5.9857</span>
<span class="go">  2.0149</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span>

<span class="go">-0.2514  0.8148 -0.2606  0.3967 -0.2180</span>
<span class="go">-0.3968  0.3587  0.7008 -0.4507  0.1402</span>
<span class="go">-0.6922 -0.2489 -0.2208  0.2513  0.5891</span>
<span class="go">-0.3662 -0.3686  0.3859  0.4342 -0.6265</span>
<span class="go">-0.4076 -0.0980 -0.4932 -0.6227 -0.4396</span>
<span class="go">[torch.FloatTensor of size 5x5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">dist</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">)),</span> <span class="n">v</span><span class="o">.</span><span class="n">t</span><span class="p">()))</span>
<span class="go">8.934150226306685e-06</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.symeig">
<code class="descclassname">torch.</code><code class="descname">symeig</code><span class="sig-paren">(</span><em>input</em>, <em>eigenvectors=False</em>, <em>upper=True</em>, <em>out=None) -&gt; (Tensor</em>, <em>Tensor</em><span class="sig-paren">)</span><a class="headerlink" href="#torch.symeig" title="Permalink to this definition">¶</a></dt>
<dd><p><cite>e, V = torch.symeig(input)</cite> returns eigenvalues and eigenvectors
of a symmetric real matrix <code class="xref py py-attr docutils literal"><span class="pre">input</span></code>.</p>
<p><cite>input</cite> and <cite>V</cite> are <cite>m x m</cite> matrices and <cite>e</cite> is a <cite>m</cite> dimensional vector.</p>
<p>This function calculates all eigenvalues (and vectors) of <cite>input</cite>
such that <cite>input = V diag(e) V&#8217;</cite></p>
<p>The boolean argument <code class="xref py py-attr docutils literal"><span class="pre">eigenvectors</span></code> defines computation of
eigenvectors or eigenvalues only.</p>
<p>If it is <cite>False</cite>, only eigenvalues are computed. If it is <cite>True</cite>,
both eigenvalues and eigenvectors are computed.</p>
<p>Since the input matrix <cite>input</cite> is supposed to be symmetric,
only the upper triangular portion is used by default.</p>
<p>If <code class="xref py py-attr docutils literal"><span class="pre">upper</span></code> is <cite>False</cite>, then lower triangular portion is used.</p>
<p>Note: Irrespective of the original strides, the returned matrix <cite>V</cite> will
be transposed, i.e. with strides <cite>(1, m)</cite> instead of <cite>(m, 1)</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#8211; the input symmetric matrix</li>
<li><strong>eigenvectors</strong> (<em>boolean</em><em>, </em><em>optional</em>) &#8211; controls whether eigenvectors have
to be computed</li>
<li><strong>upper</strong> (<em>boolean</em><em>, </em><em>optional</em>) &#8211; controls whether to consider upper-triangular or
lower-triangular region</li>
<li><strong>out</strong> (<a class="reference external" href="https://docs.python.org/2/library/functions.html#tuple" title="(in Python v2.7)"><em>tuple</em></a><em>, </em><em>optional</em>) &#8211; The result tuple of (Tensor, Tensor)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Examples:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span> <span class="mf">1.96</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">6.49</span><span class="p">,</span>  <span class="mf">3.80</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">0.47</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.39</span><span class="p">,</span>  <span class="mf">4.17</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">7.20</span><span class="p">,</span>  <span class="mf">1.50</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.51</span><span class="p">,</span>  <span class="mf">5.70</span><span class="p">,</span>  <span class="mf">0.00</span><span class="p">],</span>
<span class="gp">... </span>                  <span class="p">[</span><span class="o">-</span><span class="mf">0.65</span><span class="p">,</span> <span class="o">-</span><span class="mf">6.34</span><span class="p">,</span>  <span class="mf">2.67</span><span class="p">,</span>  <span class="mf">1.80</span><span class="p">,</span> <span class="o">-</span><span class="mf">7.10</span><span class="p">]])</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">symeig</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">eigenvectors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span>

<span class="go">-11.0656</span>
<span class="go"> -6.2287</span>
<span class="go">  0.8640</span>
<span class="go">  8.8655</span>
<span class="go"> 16.0948</span>
<span class="go">[torch.FloatTensor of size 5]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">v</span>

<span class="go">-0.2981 -0.6075  0.4026 -0.3745  0.4896</span>
<span class="go">-0.5078 -0.2880 -0.4066 -0.3572 -0.6053</span>
<span class="go">-0.0816 -0.3843 -0.6600  0.5008  0.3991</span>
<span class="go">-0.0036 -0.4467  0.4553  0.6204 -0.4564</span>
<span class="go">-0.8041  0.4480  0.1725  0.3108  0.1622</span>
<span class="go">[torch.FloatTensor of size 5x5]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="torch.trtrs">
<code class="descclassname">torch.</code><code class="descname">trtrs</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#torch.trtrs" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tensors.html" class="btn btn-neutral float-right" title="torch.Tensor" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="notes/serialization.html" class="btn btn-neutral" title="Serialization semantics" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Torch Contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'master',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>
