


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.library &mdash; PyTorch 2.2 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/library.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/sphinx-dropdown.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/panels-bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch">
                  <span class="dropdown-title">ExecuTorch</span>
                </a>
              </div>
            </div>  
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active docs-active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torcharrow">
                  <span class="dropdown-title">torcharrow</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/data">
                  <span class="dropdown-title">TorchData</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchrec">
                  <span class="dropdown-title">TorchRec</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/torchx/">
                  <span class="dropdown-title">TorchX</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn about the PyTorch foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>2.2 &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../community/build_ci_governance.html">PyTorch Governance | Build + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/design.html">PyTorch Design Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/governance.html">PyTorch Governance | Mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../community/persons_of_interest.html">PyTorch Governance | Maintainers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notes/amp_examples.html">CUDA Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/extending.func.html">Extending torch.func with autograd.Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpu.html">torch.cpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torch_cuda_memory.html">Understanding CUDA Memory Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torch_cuda_memory.html#generating-a-snapshot">Generating a Snapshot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torch_cuda_memory.html#using-the-visualizer">Using the visualizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torch_cuda_memory.html#snapshot-api-reference">Snapshot API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../export.html">torch.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torch.compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../utils.html">torch.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deterministic.html">torch.utils.deterministic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../logging.html">torch._logging</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../index.html">Module code</a> &gt;</li>
        
          <li><a href="../torch.html">torch</a> &gt;</li>
        
      <li>torch.library</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.library</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">._ops</span> <span class="kn">import</span> <span class="n">OpOverload</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">List</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">weakref</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;Library&#39;</span><span class="p">,</span>
    <span class="s1">&#39;impl&#39;</span><span class="p">,</span>
    <span class="s1">&#39;define&#39;</span><span class="p">,</span>
    <span class="s1">&#39;fallthrough_kernel&#39;</span><span class="p">,</span>
    <span class="s1">&#39;impl_abstract&#39;</span><span class="p">,</span>
    <span class="s1">&#39;get_ctx&#39;</span><span class="p">,</span>
<span class="p">]</span>

<span class="c1"># Set containing the combination of (namespace, operator, DispatchKey) for which a new kernel has been registered</span>
<span class="c1"># The keys in the set are of the form `namespace + &quot;/&quot; + op_name + &quot;/&quot; + dispatch_key`.</span>
<span class="c1"># This set is maintained to ensure that two libraries don&#39;t try to override the exact same functionality to avoid</span>
<span class="c1"># libraries calling into kernels not intended to be called.</span>
<span class="n">_impls</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="n">_defs</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

<span class="c1"># prim is reserved by TorchScript interpreter</span>
<span class="n">_reserved_namespaces</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;prim&#39;</span><span class="p">]</span>

<div class="viewcode-block" id="fallthrough_kernel"><a class="viewcode-back" href="../../library.html#torch.library.fallthrough_kernel">[docs]</a><span class="k">def</span> <span class="nf">fallthrough_kernel</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A dummy function to pass to ``Library.impl`` in order to register a fallthrough.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;fallthrough_kernel() should never be called.&quot;</span><span class="p">)</span></div>

<div class="viewcode-block" id="Library"><a class="viewcode-back" href="../../library.html#torch.library.Library">[docs]</a><span class="k">class</span> <span class="nc">Library</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A class to create libraries that can be used to register new operators or</span>
<span class="sd">    override operators in existing libraries from Python.</span>
<span class="sd">    A user can optionally pass in a dispatch keyname if they only want to register</span>
<span class="sd">    kernels corresponding to only one specific dispatch key.</span>

<span class="sd">    To create a library to override operators in an existing library (with name ns), set the kind to &quot;IMPL&quot;.</span>
<span class="sd">    To create a new library (with name ns) to register new operators, set the kind to &quot;DEF&quot;.</span>
<span class="sd">    To create a fragment of a possibly existing library to register operators (and bypass</span>
<span class="sd">    the limitation that there is only one library for a given namespace), set the kind to</span>
<span class="sd">    &quot;FRAGMENT&quot;.</span>

<span class="sd">    Args:</span>
<span class="sd">        ns: library name</span>
<span class="sd">        kind: &quot;DEF&quot;, &quot;IMPL&quot; (default: &quot;IMPL&quot;), &quot;FRAGMENT&quot;</span>
<span class="sd">        dispatch_key: PyTorch dispatch key (default: &quot;&quot;)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ns</span><span class="p">,</span> <span class="n">kind</span><span class="p">,</span> <span class="n">dispatch_key</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">kind</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;IMPL&#39;</span><span class="p">,</span> <span class="s1">&#39;DEF&#39;</span><span class="p">,</span> <span class="s1">&#39;FRAGMENT&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unsupported kind: &quot;</span><span class="p">,</span> <span class="n">kind</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ns</span> <span class="ow">in</span> <span class="n">_reserved_namespaces</span> <span class="ow">and</span> <span class="p">(</span><span class="n">kind</span> <span class="o">==</span> <span class="s2">&quot;DEF&quot;</span> <span class="ow">or</span> <span class="n">kind</span> <span class="o">==</span> <span class="s1">&#39;FRAGMENT&#39;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">ns</span><span class="p">,</span> <span class="s2">&quot; is a reserved namespace. Please try creating a library with another name.&quot;</span><span class="p">)</span>

        <span class="n">frame</span> <span class="o">=</span> <span class="n">traceback</span><span class="o">.</span><span class="n">extract_stack</span><span class="p">(</span><span class="n">limit</span><span class="o">=</span><span class="mi">3</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">filename</span><span class="p">,</span> <span class="n">lineno</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">frame</span><span class="o">.</span><span class="n">lineno</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_dispatch_library</span><span class="p">(</span><span class="n">kind</span><span class="p">,</span> <span class="n">ns</span><span class="p">,</span> <span class="n">dispatch_key</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">lineno</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">=</span> <span class="n">ns</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_op_defs</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_op_impls</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_registration_handles</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="s2">&quot;torch._library.utils.RegistrationHandle&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kind</span> <span class="o">=</span> <span class="n">kind</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dispatch_key</span> <span class="o">=</span> <span class="n">dispatch_key</span>
        <span class="c1"># Use a finalizer to setup the &quot;destructor&quot; instead of __del__.</span>
        <span class="c1"># Python __del__ can lead to weird things (globals and locals may already</span>
        <span class="c1"># be gone when __del__ actually gets called!). finalizers help the</span>
        <span class="c1"># situation because it lets us capture references and keeps them alive</span>
        <span class="n">weakref</span><span class="o">.</span><span class="n">finalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">_del_library</span><span class="p">,</span> <span class="n">_impls</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_op_impls</span><span class="p">,</span> <span class="n">_defs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_op_defs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_registration_handles</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;Library(kind=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">kind</span><span class="si">}</span><span class="s2">, ns=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ns</span><span class="si">}</span><span class="s2">, dispatch_key=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dispatch_key</span><span class="si">}</span><span class="s2">)&gt;&quot;</span>

<div class="viewcode-block" id="Library.define"><a class="viewcode-back" href="../../library.html#torch.library.Library.define">[docs]</a>    <span class="k">def</span> <span class="nf">define</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">schema</span><span class="p">,</span> <span class="n">alias_analysis</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">()):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;Defines a new operator and its semantics in the ns namespace.</span>

<span class="sd">        Args:</span>
<span class="sd">            schema: function schema to define a new operator.</span>
<span class="sd">            alias_analysis (optional): Indicates if the aliasing properties of the operator arguments can be</span>
<span class="sd">                                       inferred from the schema (default behavior) or not (&quot;CONSERVATIVE&quot;).</span>
<span class="sd">            tags (Tag | Sequence[Tag]): one or more torch.Tag to apply to this</span>
<span class="sd">                                       operator. Tagging an operator changes the operator&#39;s behavior</span>
<span class="sd">                                       under various PyTorch subsystems; please read the docs for the</span>
<span class="sd">                                       torch.Tag carefully before applying it.</span>

<span class="sd">        Returns:</span>
<span class="sd">            name of the operator as inferred from the schema.</span>

<span class="sd">        Example::</span>
<span class="sd">            &gt;&gt;&gt; # xdoctest: +REQUIRES(env:TORCH_DOCTEST_LIBRARY)</span>
<span class="sd">            &gt;&gt;&gt; my_lib = Library(&quot;foo&quot;, &quot;DEF&quot;)</span>
<span class="sd">            &gt;&gt;&gt; my_lib.define(&quot;sum(Tensor self) -&gt; Tensor&quot;)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="c1"># This is added because we also want to disallow PURE_FUNCTION alias analysis which is a valid</span>
        <span class="c1"># AliasAnalysis type in C++</span>
        <span class="k">if</span> <span class="n">alias_analysis</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;FROM_SCHEMA&quot;</span><span class="p">,</span> <span class="s2">&quot;CONSERVATIVE&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid alias_analysis type </span><span class="si">{</span><span class="n">alias_analysis</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tags</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tag</span><span class="p">):</span>
            <span class="n">tags</span> <span class="o">=</span> <span class="p">(</span><span class="n">tags</span><span class="p">,)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">alias_analysis</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">tags</span><span class="p">))</span>
        <span class="n">qualname</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">+</span> <span class="s2">&quot;::&quot;</span> <span class="o">+</span> <span class="n">schema</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;(&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_op_defs</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">qualname</span><span class="p">)</span>
        <span class="n">_defs</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">qualname</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span></div>

<div class="viewcode-block" id="Library.impl"><a class="viewcode-back" href="../../library.html#torch.library.Library.impl">[docs]</a>    <span class="k">def</span> <span class="nf">impl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">op_name</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">dispatch_key</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&#39;&#39;&#39;Registers the function implementation for an operator defined in the library.</span>

<span class="sd">        Args:</span>
<span class="sd">            op_name: operator name (along with the overload) or OpOverload object.</span>
<span class="sd">            fn: function that&#39;s the operator implementation for the input dispatch key or :func:`~fallthrough_kernel`</span>
<span class="sd">                to register a fallthrough.</span>
<span class="sd">            dispatch_key: dispatch key that the input function should be registered for. By default, it uses</span>
<span class="sd">                          the dispatch key that the library was created with.</span>

<span class="sd">        Example::</span>
<span class="sd">            &gt;&gt;&gt; my_lib = Library(&quot;aten&quot;, &quot;IMPL&quot;)</span>
<span class="sd">            &gt;&gt;&gt; def div_cpu(self, other):</span>
<span class="sd">            &gt;&gt;&gt;     return self * (1 / other)</span>
<span class="sd">            &gt;&gt;&gt; my_lib.impl(&quot;div.Tensor&quot;, div_cpu, &quot;CPU&quot;)</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">callable</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Input function is required to be a callable but found type </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dispatch_key</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="n">dispatch_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dispatch_key</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op_name</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">op_name</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">op_name</span><span class="p">,</span> <span class="n">OpOverload</span><span class="p">):</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">op_name</span><span class="o">.</span><span class="n">_schema</span><span class="o">.</span><span class="n">name</span>
            <span class="n">overload_name</span> <span class="o">=</span> <span class="n">op_name</span><span class="o">.</span><span class="n">_schema</span><span class="o">.</span><span class="n">overload_name</span>
            <span class="k">if</span> <span class="n">overload_name</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">:</span>
                <span class="n">name</span> <span class="o">=</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span> <span class="o">+</span> <span class="n">overload_name</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;impl should be passed either a name or an OpOverload object as the first argument&quot;</span><span class="p">)</span>

        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ns</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;::&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">dispatch_key</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">_impls</span><span class="p">:</span>
            <span class="c1"># TODO: in future, add more info about where the existing function is registered (this info is</span>
            <span class="c1"># today already returned by the C++ warning when impl is called but we error out before that)</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;This is not allowed since there&#39;s already a kernel registered from python overriding </span><span class="si">{}</span><span class="s2">&quot;</span>
                               <span class="s2">&quot;&#39;s behavior for </span><span class="si">{}</span><span class="s2"> dispatch key and </span><span class="si">{}</span><span class="s2"> namespace.&quot;</span><span class="o">.</span>
                               <span class="nb">format</span><span class="p">(</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;::&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">dispatch_key</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ns</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">dispatch_key</span> <span class="o">==</span> <span class="s2">&quot;Meta&quot;</span><span class="p">:</span>
            <span class="n">dispatcher_op_name</span> <span class="o">=</span> <span class="n">name</span>
            <span class="k">if</span> <span class="s1">&#39;::&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">dispatcher_op_name</span><span class="p">:</span>
                <span class="n">dispatcher_op_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ns</span><span class="si">}</span><span class="s1">::</span><span class="si">{</span><span class="n">dispatcher_op_name</span><span class="si">}</span><span class="s1">&#39;</span>

            <span class="c1"># Internally, we shouldn&#39;t be registering meta kernels for any operators that</span>
            <span class="c1"># have CompositeImplicitAutograd kernels.</span>
            <span class="c1"># Instead, we should be letting those decompositions run, and writing meta kernels</span>
            <span class="c1"># only for the base operators.</span>
            <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_dispatch_has_kernel_for_dispatch_key</span><span class="p">(</span><span class="n">dispatcher_op_name</span><span class="p">,</span> <span class="s2">&quot;CompositeImplicitAutograd&quot;</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;We should not register a meta kernel directly to the operator &#39;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&#39;,&quot;</span>
                    <span class="s2">&quot; because it has a CompositeImplicitAutograd kernel in core.&quot;</span>
                    <span class="s2">&quot; Instead we should let the operator decompose, and ensure that we have meta kernels&quot;</span>
                    <span class="s2">&quot; for the base ops that it decomposes into.&quot;</span><span class="p">)</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="o">.</span><span class="n">impl</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">dispatch_key</span> <span class="k">if</span> <span class="n">dispatch_key</span> <span class="o">!=</span> <span class="s2">&quot;&quot;</span> <span class="k">else</span> <span class="s2">&quot;CompositeImplicitAutograd&quot;</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>

        <span class="n">_impls</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_op_impls</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">key</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">_destroy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">handle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_registration_handles</span><span class="p">:</span>
            <span class="n">handle</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_registration_handles</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span></div>


<span class="k">def</span> <span class="nf">_del_library</span><span class="p">(</span><span class="n">captured_impls</span><span class="p">,</span> <span class="n">op_impls</span><span class="p">,</span> <span class="n">captured_defs</span><span class="p">,</span> <span class="n">op_defs</span><span class="p">,</span> <span class="n">registration_handles</span><span class="p">):</span>
    <span class="n">captured_impls</span> <span class="o">-=</span> <span class="n">op_impls</span>
    <span class="n">captured_defs</span> <span class="o">-=</span> <span class="n">op_defs</span>
    <span class="k">for</span> <span class="n">handle</span> <span class="ow">in</span> <span class="n">registration_handles</span><span class="p">:</span>
        <span class="n">handle</span><span class="o">.</span><span class="n">destroy</span><span class="p">()</span>


<span class="n">_keep_alive</span> <span class="o">=</span> <span class="p">[]</span>


<span class="n">NAMELESS_SCHEMA</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;\(.*\) -&gt; .*&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="define"><a class="viewcode-back" href="../../library.html#torch.library.define">[docs]</a><span class="nd">@functools</span><span class="o">.</span><span class="n">singledispatch</span>
<span class="k">def</span> <span class="nf">define</span><span class="p">(</span><span class="n">qualname</span><span class="p">,</span> <span class="n">schema</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">lib</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">()):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Defines a new operator.</span>

<span class="sd">    In PyTorch, defining an op (short for &quot;operator&quot;) is a two step-process:</span>
<span class="sd">    - we need to define the op (by providing an operator name and schema)</span>
<span class="sd">    - we need to implement behavior for how the operator interacts with</span>
<span class="sd">    various PyTorch subsystems, like CPU/CUDA Tensors, Autograd, etc.</span>

<span class="sd">    This entrypoint defines the custom operator (the first step)</span>
<span class="sd">    you must then perform the second step by calling various</span>
<span class="sd">    ``impl_*`` APIs, like :func:`torch.library.impl` or</span>
<span class="sd">    :func:`torch.library.impl_abstract`.</span>

<span class="sd">    Args:</span>
<span class="sd">        qualname (str): The qualified name for the operator. Should be</span>
<span class="sd">            a string that looks like &quot;namespace::name&quot;, e.g. &quot;aten::sin&quot;.</span>
<span class="sd">            Operators in PyTorch need a namespace to</span>
<span class="sd">            avoid name collisions; a given operator may only be created once.</span>
<span class="sd">            If you are writing a Python library, we recommend the namespace to</span>
<span class="sd">            be the name of your top-level module.</span>
<span class="sd">        schema (str): The schema of the operator. E.g. &quot;(Tensor x) -&gt; Tensor&quot;</span>
<span class="sd">            for an op that accepts one Tensor and returns one Tensor. It does</span>
<span class="sd">            not contain the operator name (that is passed in ``qualname``).</span>
<span class="sd">        lib (Optional[Library]): If provided, the lifetime of this operator</span>
<span class="sd">            will be tied to the lifetime of the Library object.</span>
<span class="sd">        tags (Tag | Sequence[Tag]): one or more torch.Tag to apply to this</span>
<span class="sd">            operator. Tagging an operator changes the operator&#39;s behavior</span>
<span class="sd">            under various PyTorch subsystems; please read the docs for the</span>
<span class="sd">            torch.Tag carefully before applying it.</span>

<span class="sd">    Example::</span>
<span class="sd">        &gt;&gt;&gt; # xdoctest: +REQUIRES(env:TORCH_DOCTEST_LIBRARY)</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Define the operator</span>
<span class="sd">        &gt;&gt;&gt; torch.library.define(&quot;mylib::sin&quot;, &quot;(Tensor x) -&gt; Tensor&quot;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Add implementations for the operator</span>
<span class="sd">        &gt;&gt;&gt; @torch.library.impl(&quot;mylibrary::sin&quot;, &quot;cpu&quot;)</span>
<span class="sd">        &gt;&gt;&gt; def f(x):</span>
<span class="sd">        &gt;&gt;&gt;     return torch.from_numpy(np.sin(x.numpy()))</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Call the new operator from torch.ops.</span>
<span class="sd">        &gt;&gt;&gt; x = torch.randn(3)</span>
<span class="sd">        &gt;&gt;&gt; y = torch.ops.mylib.sin(x)</span>
<span class="sd">        &gt;&gt;&gt; assert torch.allclose(y, x)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">qualname</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;define(qualname, schema): expected qualname &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;to be instance of str, got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">qualname</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">namespace</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_library</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">parse_namespace</span><span class="p">(</span><span class="n">qualname</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">lib</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">lib</span> <span class="o">=</span> <span class="n">Library</span><span class="p">(</span><span class="n">namespace</span><span class="p">,</span> <span class="s2">&quot;FRAGMENT&quot;</span><span class="p">)</span>
        <span class="n">_keep_alive</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lib</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">NAMELESS_SCHEMA</span><span class="o">.</span><span class="n">fullmatch</span><span class="p">(</span><span class="n">schema</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;define(qualname, schema, ...): expected schema &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;to look like e.g. </span><span class="se">\&quot;</span><span class="s2">(Tensor x) -&gt; Tensor</span><span class="se">\&quot;</span><span class="s2"> but &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;got </span><span class="se">\&quot;</span><span class="si">{</span><span class="n">schema</span><span class="si">}</span><span class="se">\&quot;</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">lib</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="n">schema</span><span class="p">,</span> <span class="n">alias_analysis</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="n">tags</span><span class="p">)</span></div>


<span class="nd">@define</span><span class="o">.</span><span class="n">register</span>
<span class="k">def</span> <span class="nf">_</span><span class="p">(</span><span class="n">lib</span><span class="p">:</span> <span class="n">Library</span><span class="p">,</span> <span class="n">schema</span><span class="p">,</span> <span class="n">alias_analysis</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The old torch.library.define.</span>
<span class="sd">    We&#39;re keeping this around for BC reasons</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">wrap</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">lib</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="n">schema</span><span class="p">,</span> <span class="n">alias_analysis</span><span class="p">)</span>
        <span class="n">lib</span><span class="o">.</span><span class="n">impl</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f</span>
    <span class="k">return</span> <span class="n">wrap</span>


<div class="viewcode-block" id="impl"><a class="viewcode-back" href="../../library.html#torch.library.impl">[docs]</a><span class="nd">@functools</span><span class="o">.</span><span class="n">singledispatch</span>
<span class="k">def</span> <span class="nf">impl</span><span class="p">(</span><span class="n">qualname</span><span class="p">,</span> <span class="n">types</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">lib</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Register an implementation for a device type for this operator.</span>

<span class="sd">    You may pass &quot;default&quot; for ``types`` to register this implementation as the</span>
<span class="sd">    default implementation for ALL device types.</span>
<span class="sd">    Please only use this if the implementation truly supports all device types;</span>
<span class="sd">    for example, this is true if it is a composition of built-in PyTorch operators.</span>

<span class="sd">    Some valid types are: &quot;cpu&quot;, &quot;cuda&quot;, &quot;xla&quot;, &quot;mps&quot;, &quot;ipu&quot;, &quot;xpu&quot;.</span>

<span class="sd">    Args:</span>
<span class="sd">        qualname (str): Should be a string that looks like &quot;namespace::operator_name&quot;.</span>
<span class="sd">        types (str | Sequence[str]): The device types to register an impl to.</span>
<span class="sd">        lib (Optional[Library]): If provided, the lifetime of this registration</span>
<span class="sd">            will be tied to the lifetime of the Library object.</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Define the operator</span>
<span class="sd">        &gt;&gt;&gt; torch.library.define(&quot;mylibrary::sin&quot;, &quot;(Tensor x) -&gt; Tensor&quot;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Add implementations for the cpu device</span>
<span class="sd">        &gt;&gt;&gt; @torch.library.impl(&quot;mylibrary::sin&quot;, &quot;cpu&quot;)</span>
<span class="sd">        &gt;&gt;&gt; def f(x):</span>
<span class="sd">        &gt;&gt;&gt;     return torch.from_numpy(np.sin(x.numpy()))</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; x = torch.randn(3)</span>
<span class="sd">        &gt;&gt;&gt; y = torch.ops.mylibrary.sin(x)</span>
<span class="sd">        &gt;&gt;&gt; assert torch.allclose(y, x.sin())</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">types</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">types</span> <span class="o">=</span> <span class="p">(</span><span class="n">types</span><span class="p">,)</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="nb">set</span><span class="p">({})</span>
    <span class="k">for</span> <span class="n">typ</span> <span class="ow">in</span> <span class="n">types</span><span class="p">:</span>
        <span class="n">is_dispatch_key</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_parse_dispatch_key</span><span class="p">(</span><span class="n">typ</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">is_dispatch_key</span><span class="p">:</span>
            <span class="c1"># We also support passing a DispatchKey to impl. Please prefer using</span>
            <span class="c1"># the higher-level torch.library APIs and only pass DispatchKey to</span>
            <span class="c1"># torch.library.impl with caution (or even better, don&#39;t use this</span>
            <span class="c1"># option and file an issue on GitHub for what you need).</span>
            <span class="c1"># We don&#39;t advertise this to users because</span>
            <span class="c1"># it is very easy to shoot yourself in the foot.</span>
            <span class="n">keys</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">typ</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">keys</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">_device_type_to_key</span><span class="p">(</span><span class="n">typ</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">register</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
        <span class="n">namespace</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_library</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">parse_namespace</span><span class="p">(</span><span class="n">qualname</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">lib</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">use_lib</span> <span class="o">=</span> <span class="n">Library</span><span class="p">(</span><span class="n">namespace</span><span class="p">,</span> <span class="s2">&quot;FRAGMENT&quot;</span><span class="p">)</span>
            <span class="n">_keep_alive</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">use_lib</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">use_lib</span> <span class="o">=</span> <span class="n">lib</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
            <span class="n">use_lib</span><span class="o">.</span><span class="n">impl</span><span class="p">(</span><span class="n">qualname</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">func</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">register</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">register</span><span class="p">(</span><span class="n">func</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_device_type_to_key</span><span class="p">(</span><span class="n">device_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">device_type</span> <span class="o">==</span> <span class="s2">&quot;default&quot;</span><span class="p">:</span>
        <span class="c1"># This is technically not correct, because although all device_type</span>
        <span class="c1"># DispatchKeys are included in CompositeExplicitAutograd,</span>
        <span class="c1"># not everything in CompositeExplicitAutograd is associated with a</span>
        <span class="c1"># device_type. I don&#39;t really care that much about the difference.</span>
        <span class="k">return</span> <span class="s2">&quot;CompositeExplicitAutograd&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_dispatch_key_for_device</span><span class="p">(</span><span class="n">device_type</span><span class="p">)</span>


<span class="nd">@impl</span><span class="o">.</span><span class="n">register</span>
<span class="k">def</span> <span class="nf">_</span><span class="p">(</span><span class="n">lib</span><span class="p">:</span> <span class="n">Library</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">dispatch_key</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Legacy torch.library.impl API. Kept around for BC&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">wrap</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
        <span class="n">lib</span><span class="o">.</span><span class="n">impl</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">dispatch_key</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f</span>
    <span class="k">return</span> <span class="n">wrap</span>



<div class="viewcode-block" id="impl_abstract"><a class="viewcode-back" href="../../library.html#torch.library.impl_abstract">[docs]</a><span class="k">def</span> <span class="nf">impl_abstract</span><span class="p">(</span><span class="n">qualname</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">lib</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">_stacklevel</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;Register an abstract implementation for this operator.</span>

<span class="sd">    An &quot;abstract implementation&quot; specifies the behavior of this operator on</span>
<span class="sd">    Tensors that carry no data. Given some input Tensors with certain properties</span>
<span class="sd">    (sizes/strides/storage_offset/device), it specifies what the properties of</span>
<span class="sd">    the output Tensors are.</span>

<span class="sd">    The abstract implementation has the same signature as the operator.</span>
<span class="sd">    It is run for both FakeTensors and meta tensors. To write an abstract</span>
<span class="sd">    implementation, assume that all Tensor inputs to the operator are</span>
<span class="sd">    regular CPU/CUDA/Meta tensors, but they do not have storage, and</span>
<span class="sd">    you are trying to return regular CPU/CUDA/Meta tensor(s) as output.</span>
<span class="sd">    The abstract implementation must consist of only PyTorch operations</span>
<span class="sd">    (and may not directly access the storage or data of any input or</span>
<span class="sd">    intermediate Tensors).</span>

<span class="sd">    This API may be used as a decorator (see examples).</span>

<span class="sd">    For a detailed guide on custom ops, please see</span>
<span class="sd">    https://docs.google.com/document/d/1W--T6wz8IY8fOI0Vm8BF44PdBgs283QvpelJZWieQWQ/edit</span>

<span class="sd">    Examples:</span>
<span class="sd">        &gt;&gt;&gt; import torch</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from torch import Tensor</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 1: an operator without data-dependent output shape</span>
<span class="sd">        &gt;&gt;&gt; torch.library.define(</span>
<span class="sd">        &gt;&gt;&gt;     &quot;mylib::custom_linear&quot;,</span>
<span class="sd">        &gt;&gt;&gt;     &quot;(Tensor x, Tensor weight, Tensor bias) -&gt; Tensor&quot;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; @torch.library.impl_abstract(&quot;mylib::custom_linear&quot;)</span>
<span class="sd">        &gt;&gt;&gt; def custom_linear_abstract(x, weight):</span>
<span class="sd">        &gt;&gt;&gt;     assert x.dim() == 2</span>
<span class="sd">        &gt;&gt;&gt;     assert weight.dim() == 2</span>
<span class="sd">        &gt;&gt;&gt;     assert bias.dim() == 1</span>
<span class="sd">        &gt;&gt;&gt;     assert x.shape[1] == weight.shape[1]</span>
<span class="sd">        &gt;&gt;&gt;     assert weight.shape[0] == bias.shape[0]</span>
<span class="sd">        &gt;&gt;&gt;     assert x.device == weight.device</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt;     return (x @ weight.t()) + bias</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Example 2: an operator with data-dependent output shape</span>
<span class="sd">        &gt;&gt;&gt; torch.library.define(&quot;mylib::custom_nonzero&quot;, &quot;(Tensor x) -&gt; Tensor&quot;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; @torch.library.impl_abstract(&quot;mylib::custom_nonzero&quot;)</span>
<span class="sd">        &gt;&gt;&gt; def custom_nonzero_abstract(x):</span>
<span class="sd">        &gt;&gt;&gt;     # Number of nonzero-elements is data-dependent.</span>
<span class="sd">        &gt;&gt;&gt;     # Since we cannot peek at the data in an abstract impl,</span>
<span class="sd">        &gt;&gt;&gt;     # we use the ctx object to construct a new symint that</span>
<span class="sd">        &gt;&gt;&gt;     # represents the data-dependent size.</span>
<span class="sd">        &gt;&gt;&gt;     ctx = torch.library.get_ctx()</span>
<span class="sd">        &gt;&gt;&gt;     nnz = ctx.new_dynamic_size()</span>
<span class="sd">        &gt;&gt;&gt;     shape = [nnz, x.dim()]</span>
<span class="sd">        &gt;&gt;&gt;     result = x.new_empty(shape, dtype=torch.int64)</span>
<span class="sd">        &gt;&gt;&gt;     return result</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; @torch.library.impl(&quot;mylib::custom_nonzero&quot;, &quot;cpu&quot;)</span>
<span class="sd">        &gt;&gt;&gt; def custom_nonzero_cpu(x):</span>
<span class="sd">        &gt;&gt;&gt;     x_np = x.numpy()</span>
<span class="sd">        &gt;&gt;&gt;     res = np.stack(np.nonzero(x_np), axis=1)</span>
<span class="sd">        &gt;&gt;&gt;     return torch.tensor(res, device=x.device)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_library</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">get_source</span><span class="p">(</span><span class="n">_stacklevel</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">frame</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">_getframe</span><span class="p">(</span><span class="n">_stacklevel</span><span class="p">)</span>
    <span class="n">caller_module</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getmodule</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
    <span class="c1"># Can be none if you call impl_abstract from somewhere there isn&#39;t a module</span>
    <span class="c1"># (e.g. __main__)</span>
    <span class="n">caller_module_name</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">caller_module</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">caller_module</span><span class="o">.</span><span class="vm">__name__</span>

    <span class="c1"># TODO(rzou): We&#39;re gonna need to stage this change with torchvision,</span>
    <span class="c1"># since torchvision is github first.</span>
    <span class="k">if</span> <span class="n">caller_module_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">caller_module_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;torchvision.&quot;</span><span class="p">):</span>
        <span class="n">caller_module_name</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">inner</span><span class="p">(</span><span class="n">func</span><span class="p">):</span>
        <span class="n">entry</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_library</span><span class="o">.</span><span class="n">simple_registry</span><span class="o">.</span><span class="n">singleton</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">qualname</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">caller_module_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">func_to_register</span> <span class="o">=</span> <span class="n">_check_pystubs_once</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">qualname</span><span class="p">,</span> <span class="n">caller_module_name</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">func_to_register</span> <span class="o">=</span> <span class="n">func</span>

        <span class="n">handle</span> <span class="o">=</span> <span class="n">entry</span><span class="o">.</span><span class="n">abstract_impl</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">func_to_register</span><span class="p">,</span> <span class="n">source</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">lib</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">lib</span><span class="o">.</span><span class="n">_registration_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">func</span>

    <span class="k">if</span> <span class="n">func</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">inner</span>
    <span class="k">return</span> <span class="n">inner</span><span class="p">(</span><span class="n">func</span><span class="p">)</span></div>


<span class="c1"># If the op was defined in C++, then we want to make sure there was an</span>
<span class="c1"># m.impl_abstract_pystub(module, ...) call and that the module is the</span>
<span class="c1"># same as the module that called torch.library.impl_abstract.</span>
<span class="k">def</span> <span class="nf">_check_pystubs_once</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">qualname</span><span class="p">,</span> <span class="n">actual_module_name</span><span class="p">):</span>
    <span class="n">checked</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">inner</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">nonlocal</span> <span class="n">checked</span>
        <span class="k">if</span> <span class="n">checked</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">op</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_library</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">lookup_op</span><span class="p">(</span><span class="n">qualname</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">op</span><span class="o">.</span><span class="n">_defined_in_python</span><span class="p">:</span>
            <span class="n">checked</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="n">maybe_pystub</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">_C</span><span class="o">.</span><span class="n">_dispatch_pystub</span><span class="p">(</span>
            <span class="n">op</span><span class="o">.</span><span class="n">_schema</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
            <span class="n">op</span><span class="o">.</span><span class="n">_schema</span><span class="o">.</span><span class="n">overload_name</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">maybe_pystub</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Operator &#39;</span><span class="si">{</span><span class="n">qualname</span><span class="si">}</span><span class="s2">&#39; was defined in C++ and has a Python &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;abstract impl. In this situation, it is required to have a &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;C++ `m.impl_abstract_pystub` call, but we could not find one.&quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Please add a call to `m.impl_abstract_pystub(</span><span class="se">\&quot;</span><span class="si">{</span><span class="n">actual_module_name</span><span class="si">}</span><span class="se">\&quot;</span><span class="s2">);` &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;to the C++ TORCH_LIBRARY block the operator was &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;defined in.&quot;</span><span class="p">)</span>
        <span class="n">pystub_module</span> <span class="o">=</span> <span class="n">maybe_pystub</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">actual_module_name</span> <span class="o">!=</span> <span class="n">pystub_module</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Operator &#39;</span><span class="si">{</span><span class="n">qualname</span><span class="si">}</span><span class="s2">&#39; specified that its python abstract impl &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;is in the Python module &#39;</span><span class="si">{</span><span class="n">pystub_module</span><span class="si">}</span><span class="s2">&#39; but it was actually found &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;in &#39;</span><span class="si">{</span><span class="n">actual_module_name</span><span class="si">}</span><span class="s2">&#39;. Please either move the abstract impl &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;or correct the m.impl_abstract_pystub call.&quot;</span><span class="p">)</span>
        <span class="n">checked</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inner</span>


<span class="c1"># NOTE [ctx inside the fake implementation]</span>
<span class="c1"># If a user has an operator with data-dependent output shape, then when writing</span>
<span class="c1"># a fake implementation they must query the current ctx and use methods on the</span>
<span class="c1"># ctx to construct a new unbacked symint.</span>
<span class="c1">#</span>
<span class="c1"># This is done via us setting the global_ctx_getter function every time a fake</span>
<span class="c1"># implementation is invoked.</span>
<div class="viewcode-block" id="get_ctx"><a class="viewcode-back" href="../../library.html#torch.library.get_ctx">[docs]</a><span class="k">def</span> <span class="nf">get_ctx</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="s2">&quot;torch._library.abstract_impl.AbstractImplCtx&quot;</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;get_ctx() returns the current AbstractImplCtx object.</span>

<span class="sd">    Calling ``get_ctx()`` is only valid inside of an abstract impl</span>
<span class="sd">    (see :func:`torch.library.impl_abstract` for more usage details.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">_library</span><span class="o">.</span><span class="n">abstract_impl</span><span class="o">.</span><span class="n">global_ctx_getter</span><span class="p">()</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
         <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
         <script src="../../_static/jquery.js"></script>
         <script src="../../_static/underscore.js"></script>
         <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../_static/doctools.js"></script>
         <script src="../../_static/sphinx_highlight.js"></script>
         <script src="../../_static/clipboard.min.js"></script>
         <script src="../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>Â© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>
            
          <li>
            <a href="">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/torcharrow">torcharrow</a>
            </li>

            <li>
              <a href="https://pytorch.org/data">TorchData</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchrec">TorchRec</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/torchx/">TorchX</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>
            
           <ul class="resources-mobile-menu-items">

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>

            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>