


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.nn.utils.spectral_norm &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/nn/utils/spectral_norm.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 

  
  <script src="../../../../_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  <a href="http://pytorch.org/docs/versions.html"> 1.0.0 &#x25BC</a>
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          

            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html#torch-nn-functional">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html#torch-nn-init">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../multiprocessing.html">torch.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ffi.html">torch.utils.ffi</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed_deprecated.html">torch.distributed.deprecated</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../legacy.html">torch.legacy</a></li>
</ul>
<p class="caption"><span class="caption-text">torchvision Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torchvision/index.html">torchvision</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
          <li><a href="../../../torch.html">torch</a> &gt;</li>
        
      <li>torch.nn.utils.spectral_norm</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.nn.utils.spectral_norm</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Spectral Normalization from https://arxiv.org/abs/1802.05957</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn.functional</span> <span class="k">import</span> <span class="n">normalize</span>
<span class="kn">from</span> <span class="nn">torch.nn.parameter</span> <span class="k">import</span> <span class="n">Parameter</span>


<span class="k">class</span> <span class="nc">SpectralNorm</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="c1"># Invariant before and after each forward call:</span>
    <span class="c1">#   u = normalize(W @ v)</span>
    <span class="c1"># NB: At initialization, this invariant is not enforced</span>

    <span class="n">_version</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c1"># At version 1:</span>
    <span class="c1">#   made  `W` not a buffer,</span>
    <span class="c1">#   added `v` as a buffer, and</span>
    <span class="c1">#   made eval mode use `W = u @ W_orig @ v` rather than the stored `W`.</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="n">n_power_iterations</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">dim</span>
        <span class="k">if</span> <span class="n">n_power_iterations</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Expected n_power_iterations to be positive, but &#39;</span>
                             <span class="s1">&#39;got n_power_iterations=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_power_iterations</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_power_iterations</span> <span class="o">=</span> <span class="n">n_power_iterations</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>

    <span class="k">def</span> <span class="nf">reshape_weight_to_matrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="n">weight_mat</span> <span class="o">=</span> <span class="n">weight</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># permute dim to front</span>
            <span class="n">weight_mat</span> <span class="o">=</span> <span class="n">weight_mat</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">,</span>
                                            <span class="o">*</span><span class="p">[</span><span class="n">d</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">weight_mat</span><span class="o">.</span><span class="n">dim</span><span class="p">())</span> <span class="k">if</span> <span class="n">d</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">])</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">weight_mat</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">weight_mat</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">do_power_iteration</span><span class="p">):</span>
        <span class="c1"># NB: If `do_power_iteration` is set, the `u` and `v` vectors are</span>
        <span class="c1">#     updated in power iteration **in-place**. This is very important</span>
        <span class="c1">#     because in `DataParallel` forward, the vectors (being buffers) are</span>
        <span class="c1">#     broadcast from the parallelized module to each module replica,</span>
        <span class="c1">#     which is a new module object created on the fly. And each replica</span>
        <span class="c1">#     runs its own spectral norm power iteration. So simply assigning</span>
        <span class="c1">#     the updated vectors to the module this function runs on will cause</span>
        <span class="c1">#     the update to be lost forever. And the next time the parallelized</span>
        <span class="c1">#     module is replicated, the same randomly initialized vectors are</span>
        <span class="c1">#     broadcast and used!</span>
        <span class="c1">#</span>
        <span class="c1">#     Therefore, to make the change propagate back, we rely on two</span>
        <span class="c1">#     important bahaviors (also enforced via tests):</span>
        <span class="c1">#       1. `DataParallel` doesn&#39;t clone storage if the broadcast tensor</span>
        <span class="c1">#          is alreay on correct device; and it makes sure that the</span>
        <span class="c1">#          parallelized module is already on `device[0]`.</span>
        <span class="c1">#       2. If the out tensor in `out=` kwarg has correct shape, it will</span>
        <span class="c1">#          just fill in the values.</span>
        <span class="c1">#     Therefore, since the same power iteration is performed on all</span>
        <span class="c1">#     devices, simply updating the tensors in-place will make sure that</span>
        <span class="c1">#     the module replica on `device[0]` will update the _u vector on the</span>
        <span class="c1">#     parallized module (by shared storage).</span>
        <span class="c1">#</span>
        <span class="c1">#    However, after we update `u` and `v` in-place, we need to **clone**</span>
        <span class="c1">#    them before using them to normalize the weight. This is to support</span>
        <span class="c1">#    backproping through two forward passes, e.g., the common pattern in</span>
        <span class="c1">#    GAN training: loss = D(real) - D(fake). Otherwise, engine will</span>
        <span class="c1">#    complain that variables needed to do backward for the first forward</span>
        <span class="c1">#    (i.e., the `u` and `v` vectors) are changed in the second forward.</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_orig&#39;</span><span class="p">)</span>
        <span class="n">u</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_u&#39;</span><span class="p">)</span>
        <span class="n">v</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_v&#39;</span><span class="p">)</span>
        <span class="n">weight_mat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape_weight_to_matrix</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">do_power_iteration</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_power_iterations</span><span class="p">):</span>
                    <span class="c1"># Spectral norm of weight equals to `u^T W v`, where `u` and `v`</span>
                    <span class="c1"># are the first left and right singular vectors.</span>
                    <span class="c1"># This power iteration produces approximations of `u` and `v`.</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">weight_mat</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span> <span class="n">u</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">v</span><span class="p">)</span>
                    <span class="n">u</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">weight_mat</span><span class="p">,</span> <span class="n">v</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">u</span><span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_power_iterations</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="c1"># See above on why we need to clone</span>
                    <span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
                    <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

        <span class="n">sigma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">weight_mat</span><span class="p">,</span> <span class="n">v</span><span class="p">))</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span> <span class="o">/</span> <span class="n">sigma</span>
        <span class="k">return</span> <span class="n">weight</span>

    <span class="k">def</span> <span class="nf">remove</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_weight</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">do_power_iteration</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_u&#39;</span><span class="p">)</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_v&#39;</span><span class="p">)</span>
        <span class="nb">delattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_orig&#39;</span><span class="p">)</span>
        <span class="n">module</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">detach</span><span class="p">()))</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_weight</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">do_power_iteration</span><span class="o">=</span><span class="n">module</span><span class="o">.</span><span class="n">training</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_solve_v_and_rescale</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight_mat</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">target_sigma</span><span class="p">):</span>
        <span class="c1"># Tries to returns a vector `v` s.t. `u = normalize(W @ v)`</span>
        <span class="c1"># (the invariant at top of this class) and `u @ W @ v = sigma`.</span>
        <span class="c1"># This uses pinverse in case W^T W is not invertible.</span>
        <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">chain_matmul</span><span class="p">(</span><span class="n">weight_mat</span><span class="o">.</span><span class="n">t</span><span class="p">()</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">weight_mat</span><span class="p">)</span><span class="o">.</span><span class="n">pinverse</span><span class="p">(),</span> <span class="n">weight_mat</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span> <span class="n">u</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">v</span><span class="o">.</span><span class="n">mul_</span><span class="p">(</span><span class="n">target_sigma</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">mv</span><span class="p">(</span><span class="n">weight_mat</span><span class="p">,</span> <span class="n">v</span><span class="p">)))</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">n_power_iterations</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">hook</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hook</span><span class="p">,</span> <span class="n">SpectralNorm</span><span class="p">)</span> <span class="ow">and</span> <span class="n">hook</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">name</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot register two spectral_norm hooks on &quot;</span>
                                   <span class="s2">&quot;the same parameter </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>

        <span class="n">fn</span> <span class="o">=</span> <span class="n">SpectralNorm</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">n_power_iterations</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">weight_mat</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">reshape_weight_to_matrix</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>

            <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">weight_mat</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
            <span class="c1"># randomly initialize `u` and `v`</span>
            <span class="n">u</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">new_empty</span><span class="p">(</span><span class="n">h</span><span class="p">)</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">fn</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>
            <span class="n">v</span> <span class="o">=</span> <span class="n">normalize</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">new_empty</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="n">fn</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>

        <span class="nb">delattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">fn</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="n">module</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="n">fn</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_orig&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
        <span class="c1"># We still need to assign weight back as fn.name because all sorts of</span>
        <span class="c1"># things may assume that it exists, e.g., when initializing weights.</span>
        <span class="c1"># However, we can&#39;t directly assign as it could be an nn.Parameter and</span>
        <span class="c1"># gets added as a parameter. Instead, we register weight.data as a plain</span>
        <span class="c1"># attribute.</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">fn</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
        <span class="n">module</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">fn</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_u&quot;</span><span class="p">,</span> <span class="n">u</span><span class="p">)</span>
        <span class="n">module</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">fn</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_v&quot;</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>

        <span class="n">module</span><span class="o">.</span><span class="n">register_forward_pre_hook</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>

        <span class="n">module</span><span class="o">.</span><span class="n">_register_state_dict_hook</span><span class="p">(</span><span class="n">SpectralNormStateDictHook</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span>
        <span class="n">module</span><span class="o">.</span><span class="n">_register_load_state_dict_pre_hook</span><span class="p">(</span><span class="n">SpectralNormLoadStateDictPreHook</span><span class="p">(</span><span class="n">fn</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">fn</span>


<span class="c1"># This is a top level class because Py2 pickle doesn&#39;t like inner class nor an</span>
<span class="c1"># instancemethod.</span>
<span class="k">class</span> <span class="nc">SpectralNormLoadStateDictPreHook</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="c1"># See docstring of SpectralNorm._version on the changes to spectral_norm.</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fn</span> <span class="o">=</span> <span class="n">fn</span>

    <span class="c1"># For state_dict with version None, (assuming that it has gone through at</span>
    <span class="c1"># least one training forward), we have</span>
    <span class="c1">#</span>
    <span class="c1">#    u = normalize(W_orig @ v)</span>
    <span class="c1">#    W = W_orig / sigma, where sigma = u @ W_orig @ v</span>
    <span class="c1">#</span>
    <span class="c1"># To compute `v`, we solve `W_orig @ x = u`, and let</span>
    <span class="c1">#    v = x / (u @ W_orig @ x) * (W / W_orig).</span>
    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">local_metadata</span><span class="p">,</span> <span class="n">strict</span><span class="p">,</span>
                 <span class="n">missing_keys</span><span class="p">,</span> <span class="n">unexpected_keys</span><span class="p">,</span> <span class="n">error_msgs</span><span class="p">):</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fn</span>
        <span class="n">version</span> <span class="o">=</span> <span class="n">local_metadata</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;spectral_norm&#39;</span><span class="p">,</span> <span class="p">{})</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">fn</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.version&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">version</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">version</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">weight_orig</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">fn</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_orig&#39;</span><span class="p">]</span>
                <span class="n">weight</span> <span class="o">=</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">fn</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                <span class="n">sigma</span> <span class="o">=</span> <span class="p">(</span><span class="n">weight_orig</span> <span class="o">/</span> <span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                <span class="n">weight_mat</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">reshape_weight_to_matrix</span><span class="p">(</span><span class="n">weight_orig</span><span class="p">)</span>
                <span class="n">u</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">fn</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_u&#39;</span><span class="p">]</span>
                <span class="n">v</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">_solve_v_and_rescale</span><span class="p">(</span><span class="n">weight_mat</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">sigma</span><span class="p">)</span>
                <span class="n">state_dict</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">fn</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>


<span class="c1"># This is a top level class because Py2 pickle doesn&#39;t like inner class nor an</span>
<span class="c1"># instancemethod.</span>
<span class="k">class</span> <span class="nc">SpectralNormStateDictHook</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="c1"># See docstring of SpectralNorm._version on the changes to spectral_norm.</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fn</span> <span class="o">=</span> <span class="n">fn</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">prefix</span><span class="p">,</span> <span class="n">local_metadata</span><span class="p">):</span>
        <span class="k">if</span> <span class="s1">&#39;spectral_norm&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">local_metadata</span><span class="p">:</span>
            <span class="n">local_metadata</span><span class="p">[</span><span class="s1">&#39;spectral_norm&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fn</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.version&#39;</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">local_metadata</span><span class="p">[</span><span class="s1">&#39;spectral_norm&#39;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Unexpected key in metadata[&#39;spectral_norm&#39;]: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">))</span>
        <span class="n">local_metadata</span><span class="p">[</span><span class="s1">&#39;spectral_norm&#39;</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fn</span><span class="o">.</span><span class="n">_version</span>


<div class="viewcode-block" id="spectral_norm"><a class="viewcode-back" href="../../../../nn.html#torch.nn.utils.spectral_norm">[docs]</a><span class="k">def</span> <span class="nf">spectral_norm</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="n">n_power_iterations</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Applies spectral normalization to a parameter in the given module.</span>

<span class="sd">    .. math::</span>
<span class="sd">         \mathbf{W} = \dfrac{\mathbf{W}}{\sigma(\mathbf{W})} \\</span>
<span class="sd">         \sigma(\mathbf{W}) = \max_{\mathbf{h}: \mathbf{h} \ne 0} \dfrac{\|\mathbf{W} \mathbf{h}\|_2}{\|\mathbf{h}\|_2}</span>

<span class="sd">    Spectral normalization stabilizes the training of discriminators (critics)</span>
<span class="sd">    in Generaive Adversarial Networks (GANs) by rescaling the weight tensor</span>
<span class="sd">    with spectral norm :math:`\sigma` of the weight matrix calculated using</span>
<span class="sd">    power iteration method. If the dimension of the weight tensor is greater</span>
<span class="sd">    than 2, it is reshaped to 2D in power iteration method to get spectral</span>
<span class="sd">    norm. This is implemented via a hook that calculates spectral norm and</span>
<span class="sd">    rescales weight before every :meth:`~Module.forward` call.</span>

<span class="sd">    See `Spectral Normalization for Generative Adversarial Networks`_ .</span>

<span class="sd">    .. _`Spectral Normalization for Generative Adversarial Networks`: https://arxiv.org/abs/1802.05957</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): containing module</span>
<span class="sd">        name (str, optional): name of weight parameter</span>
<span class="sd">        n_power_iterations (int, optional): number of power iterations to</span>
<span class="sd">            calculate spectal norm</span>
<span class="sd">        eps (float, optional): epsilon for numerical stability in</span>
<span class="sd">            calculating norms</span>
<span class="sd">        dim (int, optional): dimension corresponding to number of outputs,</span>
<span class="sd">            the default is 0, except for modules that are instances of</span>
<span class="sd">            ConvTranspose1/2/3d, when it is 1</span>

<span class="sd">    Returns:</span>
<span class="sd">        The original module with the spectal norm hook</span>

<span class="sd">    Example::</span>

<span class="sd">        &gt;&gt;&gt; m = spectral_norm(nn.Linear(20, 40))</span>
<span class="sd">        Linear (20 -&gt; 40)</span>
<span class="sd">        &gt;&gt;&gt; m.weight_u.size()</span>
<span class="sd">        torch.Size([20])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose1d</span><span class="p">,</span>
                               <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">,</span>
                               <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">)):</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">SpectralNorm</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">n_power_iterations</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">module</span></div>


<div class="viewcode-block" id="remove_spectral_norm"><a class="viewcode-back" href="../../../../nn.html#torch.nn.utils.remove_spectral_norm">[docs]</a><span class="k">def</span> <span class="nf">remove_spectral_norm</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Removes the spectral normalization reparameterization from a module.</span>

<span class="sd">    Args:</span>
<span class="sd">        module (nn.Module): containing module</span>
<span class="sd">        name (str, optional): name of weight parameter</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; m = spectral_norm(nn.Linear(40, 10))</span>
<span class="sd">        &gt;&gt;&gt; remove_spectral_norm(m)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">hook</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hook</span><span class="p">,</span> <span class="n">SpectralNorm</span><span class="p">)</span> <span class="ow">and</span> <span class="n">hook</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">hook</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
            <span class="k">del</span> <span class="n">module</span><span class="o">.</span><span class="n">_forward_pre_hooks</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">module</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;spectral_norm of &#39;</span><span class="si">{}</span><span class="s2">&#39; not found in </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">name</span><span class="p">,</span> <span class="n">module</span><span class="p">))</span></div>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Torch Contributors.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script type="text/javascript" src="../../../../_static/jquery.js"></script>
         <script type="text/javascript" src="../../../../_static/underscore.js"></script>
         <script type="text/javascript" src="../../../../_static/doctools.js"></script>
         <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.9.0/dist/katex.min.js"></script>
         <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.9.0/dist/contrib/auto-render.min.js"></script>
         <script type="text/javascript" src="../../../../_static/katex_autorenderer.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-1', 'auto');
  ga('send', 'pageview');

</script>
<img height="1" width="1" style="border-style:none;" alt="" src="http://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://pytorch.org/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>