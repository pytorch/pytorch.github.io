


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch &mdash; PyTorch 1.6.0 documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/torch.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/jit.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="torch.is_tensor" href="generated/torch.is_tensor.html" />
    <link rel="prev" title="C++" href="cpp_index.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <div class="ecosystem-dropdown">
              <a id="dropdownMenuButton" data-toggle="ecosystem-dropdown">
                Ecosystem
              </a>
              <div class="ecosystem-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/hub"">
                  <span class=dropdown-title>Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class=dropdown-title>Tools & Libraries</span>
                  <p>Explore the ecosystem of tools and libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <div class="resources-dropdown">
              <a id="resourcesDropdownButton" data-toggle="resources-dropdown">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/resources"">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class=dropdown-title>About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  <a href='http://pytorch.org/docs/versions.html'>1.6.0 &#x25BC</a>
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          


            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/amp_examples.html">Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="amp.html">torch.cuda.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="__config__.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text">torchtext</a></li>
<li class="toctree-l1"><a class="reference internal" href="torchvision/index.html">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>torch</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/torch.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="torch">
<h1>torch<a class="headerlink" href="#torch" title="Permalink to this headline">¶</a></h1>
<p>The torch package contains data structures for multi-dimensional
tensors and mathematical operations over these are defined.
Additionally, it provides many utilities for efficient serializing of
Tensors and arbitrary types, and other useful utilities.</p>
<p>It has a CUDA counterpart, that enables you to run your tensor computations
on an NVIDIA GPU with compute capability &gt;= 3.0</p>
<div class="section" id="tensors">
<h2>Tensors<a class="headerlink" href="#tensors" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.is_tensor.html#torch.is_tensor" title="torch.is_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_tensor</span></code></a></p></td>
<td><p>Returns True if <cite>obj</cite> is a PyTorch tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.is_storage.html#torch.is_storage" title="torch.is_storage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_storage</span></code></a></p></td>
<td><p>Returns True if <cite>obj</cite> is a PyTorch storage object.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.is_complex.html#torch.is_complex" title="torch.is_complex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_complex</span></code></a></p></td>
<td><p>Returns True if the data type of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> is a complex data type i.e., one of <code class="docutils literal notranslate"><span class="pre">torch.complex64</span></code>, and <code class="docutils literal notranslate"><span class="pre">torch.complex128</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.is_floating_point.html#torch.is_floating_point" title="torch.is_floating_point"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_floating_point</span></code></a></p></td>
<td><p>Returns True if the data type of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> is a floating point data type i.e., one of <code class="docutils literal notranslate"><span class="pre">torch.float64</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.float32</span></code> and <code class="docutils literal notranslate"><span class="pre">torch.float16</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.is_nonzero.html#torch.is_nonzero" title="torch.is_nonzero"><code class="xref py py-obj docutils literal notranslate"><span class="pre">is_nonzero</span></code></a></p></td>
<td><p>Returns True if the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> is a single element tensor which is not equal to zero after type conversions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.set_default_dtype.html#torch.set_default_dtype" title="torch.set_default_dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_default_dtype</span></code></a></p></td>
<td><p>Sets the default floating point dtype to <code class="xref py py-attr docutils literal notranslate"><span class="pre">d</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.get_default_dtype.html#torch.get_default_dtype" title="torch.get_default_dtype"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_default_dtype</span></code></a></p></td>
<td><p>Get the current default floating point <a class="reference internal" href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.set_default_tensor_type.html#torch.set_default_tensor_type" title="torch.set_default_tensor_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_default_tensor_type</span></code></a></p></td>
<td><p>Sets the default <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code> type to floating point tensor type <code class="docutils literal notranslate"><span class="pre">t</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.numel.html#torch.numel" title="torch.numel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numel</span></code></a></p></td>
<td><p>Returns the total number of elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.set_printoptions.html#torch.set_printoptions" title="torch.set_printoptions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_printoptions</span></code></a></p></td>
<td><p>Set options for printing.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.set_flush_denormal.html#torch.set_flush_denormal" title="torch.set_flush_denormal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_flush_denormal</span></code></a></p></td>
<td><p>Disables denormal floating numbers on CPU.</p></td>
</tr>
</tbody>
</table>
<div class="section" id="creation-ops">
<span id="tensor-creation-ops"></span><h3>Creation Ops<a class="headerlink" href="#creation-ops" title="Permalink to this headline">¶</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Random sampling creation ops are listed under <a class="reference internal" href="#random-sampling"><span class="std std-ref">Random sampling</span></a> and
include:
<a class="reference internal" href="generated/torch.rand.html#torch.rand" title="torch.rand"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.rand()</span></code></a>
<a class="reference internal" href="generated/torch.rand_like.html#torch.rand_like" title="torch.rand_like"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.rand_like()</span></code></a>
<a class="reference internal" href="generated/torch.randn.html#torch.randn" title="torch.randn"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.randn()</span></code></a>
<a class="reference internal" href="generated/torch.randn_like.html#torch.randn_like" title="torch.randn_like"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.randn_like()</span></code></a>
<a class="reference internal" href="generated/torch.randint.html#torch.randint" title="torch.randint"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.randint()</span></code></a>
<a class="reference internal" href="generated/torch.randint_like.html#torch.randint_like" title="torch.randint_like"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.randint_like()</span></code></a>
<a class="reference internal" href="generated/torch.randperm.html#torch.randperm" title="torch.randperm"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.randperm()</span></code></a>
You may also use <a class="reference internal" href="generated/torch.empty.html#torch.empty" title="torch.empty"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.empty()</span></code></a> with the <a class="reference internal" href="#inplace-random-sampling"><span class="std std-ref">In-place random sampling</span></a>
methods to create <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code></a> s with values sampled from a broader
range of distributions.</p>
</div>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.tensor.html#torch.tensor" title="torch.tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensor</span></code></a></p></td>
<td><p>Constructs a tensor with <code class="xref py py-attr docutils literal notranslate"><span class="pre">data</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.sparse_coo_tensor.html#torch.sparse_coo_tensor" title="torch.sparse_coo_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sparse_coo_tensor</span></code></a></p></td>
<td><p>Constructs a sparse tensors in COO(rdinate) format with non-zero elements at the given <code class="xref py py-attr docutils literal notranslate"><span class="pre">indices</span></code> with the given <code class="xref py py-attr docutils literal notranslate"><span class="pre">values</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.as_tensor.html#torch.as_tensor" title="torch.as_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">as_tensor</span></code></a></p></td>
<td><p>Convert the data into a <cite>torch.Tensor</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.as_strided.html#torch.as_strided" title="torch.as_strided"><code class="xref py py-obj docutils literal notranslate"><span class="pre">as_strided</span></code></a></p></td>
<td><p>Create a view of an existing <cite>torch.Tensor</cite> <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> with specified <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">storage_offset</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.from_numpy.html#torch.from_numpy" title="torch.from_numpy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">from_numpy</span></code></a></p></td>
<td><p>Creates a <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> from a <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.19)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.zeros.html#torch.zeros" title="torch.zeros"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zeros</span></code></a></p></td>
<td><p>Returns a tensor filled with the scalar value <cite>0</cite>, with the shape defined by the variable argument <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.zeros_like.html#torch.zeros_like" title="torch.zeros_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">zeros_like</span></code></a></p></td>
<td><p>Returns a tensor filled with the scalar value <cite>0</cite>, with the same size as <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.ones.html#torch.ones" title="torch.ones"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ones</span></code></a></p></td>
<td><p>Returns a tensor filled with the scalar value <cite>1</cite>, with the shape defined by the variable argument <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.ones_like.html#torch.ones_like" title="torch.ones_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ones_like</span></code></a></p></td>
<td><p>Returns a tensor filled with the scalar value <cite>1</cite>, with the same size as <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.arange.html#torch.arange" title="torch.arange"><code class="xref py py-obj docutils literal notranslate"><span class="pre">arange</span></code></a></p></td>
<td><p>Returns a 1-D tensor of size <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mo fence="true">⌈</mo><mfrac><mrow><mtext>end</mtext><mo>−</mo><mtext>start</mtext></mrow><mrow><mtext>step</mtext></mrow></mfrac><mo fence="true">⌉</mo></mrow></mrow><annotation encoding="application/x-tex">\left\lceil \frac{\text{end} - \text{start}}{\text{step}} \right\rceil</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.15em;"></span><span class="strut bottom" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="base"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">⌈</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mathrm mtight">step</span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mathrm mtight">end</span></span><span class="mbin mtight">−</span><span class="mord text mtight"><span class="mord mathrm mtight">start</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">⌉</span></span></span></span></span></span>
</span> with values from the interval <code class="docutils literal notranslate"><span class="pre">[start,</span> <span class="pre">end)</span></code> taken with common difference <code class="xref py py-attr docutils literal notranslate"><span class="pre">step</span></code> beginning from <cite>start</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.range.html#torch.range" title="torch.range"><code class="xref py py-obj docutils literal notranslate"><span class="pre">range</span></code></a></p></td>
<td><p>Returns a 1-D tensor of size <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mo fence="true">⌊</mo><mfrac><mrow><mtext>end</mtext><mo>−</mo><mtext>start</mtext></mrow><mrow><mtext>step</mtext></mrow></mfrac><mo fence="true">⌋</mo></mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\left\lfloor \frac{\text{end} - \text{start}}{\text{step}} \right\rfloor + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.15em;"></span><span class="strut bottom" style="height:1.80002em;vertical-align:-0.65002em;"></span><span class="base"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">⌊</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801079999999999em;"><span style="top:-2.6550000000000002em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mathrm mtight">step</span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mathrm mtight">end</span></span><span class="mbin mtight">−</span><span class="mord text mtight"><span class="mord mathrm mtight">start</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.481108em;"></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">⌋</span></span></span><span class="mbin">+</span><span class="mord mathrm">1</span></span></span></span>
</span> with values from <code class="xref py py-attr docutils literal notranslate"><span class="pre">start</span></code> to <code class="xref py py-attr docutils literal notranslate"><span class="pre">end</span></code> with step <code class="xref py py-attr docutils literal notranslate"><span class="pre">step</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.linspace.html#torch.linspace" title="torch.linspace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linspace</span></code></a></p></td>
<td><p>Returns a one-dimensional tensor of <code class="xref py py-attr docutils literal notranslate"><span class="pre">steps</span></code> equally spaced points between <code class="xref py py-attr docutils literal notranslate"><span class="pre">start</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">end</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.logspace.html#torch.logspace" title="torch.logspace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logspace</span></code></a></p></td>
<td><p>Returns a one-dimensional tensor of <code class="xref py py-attr docutils literal notranslate"><span class="pre">steps</span></code> points logarithmically spaced with base <code class="xref py py-attr docutils literal notranslate"><span class="pre">base</span></code> between <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mtext>base</mtext><mtext>start</mtext></msup></mrow><annotation encoding="application/x-tex">{\text{base}}^{\text{start}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8778959999999999em;"></span><span class="strut bottom" style="height:0.8778959999999999em;vertical-align:0em;"></span><span class="base"><span class="mord"><span class="mord"><span class="mord text"><span class="mord mathrm">base</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8778959999999999em;"><span style="top:-3.1473400000000002em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mathrm mtight">start</span></span></span></span></span></span></span></span></span></span></span></span></span>
</span> and <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mtext>base</mtext><mtext>end</mtext></msup></mrow><annotation encoding="application/x-tex">{\text{base}}^{\text{end}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.9334479999999998em;"></span><span class="strut bottom" style="height:0.9334479999999998em;vertical-align:0em;"></span><span class="base"><span class="mord"><span class="mord"><span class="mord text"><span class="mord mathrm">base</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9334479999999998em;"><span style="top:-3.1473400000000002em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mathrm mtight">end</span></span></span></span></span></span></span></span></span></span></span></span></span>
</span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.eye.html#torch.eye" title="torch.eye"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eye</span></code></a></p></td>
<td><p>Returns a 2-D tensor with ones on the diagonal and zeros elsewhere.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.empty.html#torch.empty" title="torch.empty"><code class="xref py py-obj docutils literal notranslate"><span class="pre">empty</span></code></a></p></td>
<td><p>Returns a tensor filled with uninitialized data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.empty_like.html#torch.empty_like" title="torch.empty_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">empty_like</span></code></a></p></td>
<td><p>Returns an uninitialized tensor with the same size as <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.empty_strided.html#torch.empty_strided" title="torch.empty_strided"><code class="xref py py-obj docutils literal notranslate"><span class="pre">empty_strided</span></code></a></p></td>
<td><p>Returns a tensor filled with uninitialized data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.full.html#torch.full" title="torch.full"><code class="xref py py-obj docutils literal notranslate"><span class="pre">full</span></code></a></p></td>
<td><p>Returns a tensor of size <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> filled with <code class="xref py py-attr docutils literal notranslate"><span class="pre">fill_value</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.full_like.html#torch.full_like" title="torch.full_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">full_like</span></code></a></p></td>
<td><p>Returns a tensor with the same size as <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> filled with <code class="xref py py-attr docutils literal notranslate"><span class="pre">fill_value</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.quantize_per_tensor.html#torch.quantize_per_tensor" title="torch.quantize_per_tensor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantize_per_tensor</span></code></a></p></td>
<td><p>Converts a float tensor to quantized tensor with given scale and zero point.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.quantize_per_channel.html#torch.quantize_per_channel" title="torch.quantize_per_channel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quantize_per_channel</span></code></a></p></td>
<td><p>Converts a float tensor to per-channel quantized tensor with given scales and zero points.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.dequantize.html#torch.dequantize" title="torch.dequantize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dequantize</span></code></a></p></td>
<td><p>Given a quantized Tensor, dequantize it and return an fp32 Tensor</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="indexing-slicing-joining-mutating-ops">
<h3>Indexing, Slicing, Joining, Mutating Ops<a class="headerlink" href="#indexing-slicing-joining-mutating-ops" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.cat.html#torch.cat" title="torch.cat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cat</span></code></a></p></td>
<td><p>Concatenates the given sequence of <code class="xref py py-attr docutils literal notranslate"><span class="pre">seq</span></code> tensors in the given dimension.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.chunk.html#torch.chunk" title="torch.chunk"><code class="xref py py-obj docutils literal notranslate"><span class="pre">chunk</span></code></a></p></td>
<td><p>Splits a tensor into a specific number of chunks.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.gather.html#torch.gather" title="torch.gather"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gather</span></code></a></p></td>
<td><p>Gathers values along an axis specified by <cite>dim</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.index_select.html#torch.index_select" title="torch.index_select"><code class="xref py py-obj docutils literal notranslate"><span class="pre">index_select</span></code></a></p></td>
<td><p>Returns a new tensor which indexes the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor along dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code> using the entries in <code class="xref py py-attr docutils literal notranslate"><span class="pre">index</span></code> which is a <cite>LongTensor</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.masked_select.html#torch.masked_select" title="torch.masked_select"><code class="xref py py-obj docutils literal notranslate"><span class="pre">masked_select</span></code></a></p></td>
<td><p>Returns a new 1-D tensor which indexes the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor according to the boolean mask <code class="xref py py-attr docutils literal notranslate"><span class="pre">mask</span></code> which is a <cite>BoolTensor</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.narrow.html#torch.narrow" title="torch.narrow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">narrow</span></code></a></p></td>
<td><p>Returns a new tensor that is a narrowed version of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.nonzero.html#torch.nonzero" title="torch.nonzero"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nonzero</span></code></a></p></td>
<td><p></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.reshape.html#torch.reshape" title="torch.reshape"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reshape</span></code></a></p></td>
<td><p>Returns a tensor with the same data and number of elements as <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>, but with the specified shape.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.split.html#torch.split" title="torch.split"><code class="xref py py-obj docutils literal notranslate"><span class="pre">split</span></code></a></p></td>
<td><p>Splits the tensor into chunks.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.squeeze.html#torch.squeeze" title="torch.squeeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">squeeze</span></code></a></p></td>
<td><p>Returns a tensor with all the dimensions of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> of size <cite>1</cite> removed.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.stack.html#torch.stack" title="torch.stack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">stack</span></code></a></p></td>
<td><p>Concatenates sequence of tensors along a new dimension.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.t.html#torch.t" title="torch.t"><code class="xref py py-obj docutils literal notranslate"><span class="pre">t</span></code></a></p></td>
<td><p>Expects <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> to be &lt;= 2-D tensor and transposes dimensions 0 and 1.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.take.html#torch.take" title="torch.take"><code class="xref py py-obj docutils literal notranslate"><span class="pre">take</span></code></a></p></td>
<td><p>Returns a new tensor with the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> at the given indices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.transpose.html#torch.transpose" title="torch.transpose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transpose</span></code></a></p></td>
<td><p>Returns a tensor that is a transposed version of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.unbind.html#torch.unbind" title="torch.unbind"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unbind</span></code></a></p></td>
<td><p>Removes a tensor dimension.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.unsqueeze.html#torch.unsqueeze" title="torch.unsqueeze"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unsqueeze</span></code></a></p></td>
<td><p>Returns a new tensor with a dimension of size one inserted at the specified position.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.where.html#torch.where" title="torch.where"><code class="xref py py-obj docutils literal notranslate"><span class="pre">where</span></code></a></p></td>
<td><p>Return a tensor of elements selected from either <code class="xref py py-attr docutils literal notranslate"><span class="pre">x</span></code> or <code class="xref py py-attr docutils literal notranslate"><span class="pre">y</span></code>, depending on <code class="xref py py-attr docutils literal notranslate"><span class="pre">condition</span></code>.</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="generators">
<span id="id1"></span><h2>Generators<a class="headerlink" href="#generators" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.Generator.html#torch.Generator" title="torch.Generator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Generator</span></code></a></p></td>
<td><p>Creates and returns a generator object which manages the state of the algorithm that produces pseudo random numbers.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="random-sampling">
<span id="id2"></span><h2>Random sampling<a class="headerlink" href="#random-sampling" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.seed.html#torch.seed" title="torch.seed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">seed</span></code></a></p></td>
<td><p>Sets the seed for generating random numbers to a non-deterministic random number.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.manual_seed.html#torch.manual_seed" title="torch.manual_seed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">manual_seed</span></code></a></p></td>
<td><p>Sets the seed for generating random numbers.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.initial_seed.html#torch.initial_seed" title="torch.initial_seed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">initial_seed</span></code></a></p></td>
<td><p>Returns the initial seed for generating random numbers as a Python <cite>long</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.get_rng_state.html#torch.get_rng_state" title="torch.get_rng_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_rng_state</span></code></a></p></td>
<td><p>Returns the random number generator state as a <cite>torch.ByteTensor</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.set_rng_state.html#torch.set_rng_state" title="torch.set_rng_state"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_rng_state</span></code></a></p></td>
<td><p>Sets the random number generator state.</p></td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="torch.torch.default_generator">
<code class="sig-prename descclassname">torch.</code><code class="sig-name descname">default_generator</code><em class="property"> Returns the default CPU torch.Generator</em><a class="headerlink" href="#torch.torch.default_generator" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.bernoulli.html#torch.bernoulli" title="torch.bernoulli"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bernoulli</span></code></a></p></td>
<td><p>Draws binary random numbers (0 or 1) from a Bernoulli distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.multinomial.html#torch.multinomial" title="torch.multinomial"><code class="xref py py-obj docutils literal notranslate"><span class="pre">multinomial</span></code></a></p></td>
<td><p>Returns a tensor where each row contains <code class="xref py py-attr docutils literal notranslate"><span class="pre">num_samples</span></code> indices sampled from the multinomial probability distribution located in the corresponding row of tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.normal.html#torch.normal" title="torch.normal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">normal</span></code></a></p></td>
<td><p>Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.poisson.html#torch.poisson" title="torch.poisson"><code class="xref py py-obj docutils literal notranslate"><span class="pre">poisson</span></code></a></p></td>
<td><p>Returns a tensor of the same size as <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> with each element sampled from a Poisson distribution with rate parameter given by the corresponding element in <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> i.e.,</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.rand.html#torch.rand" title="torch.rand"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rand</span></code></a></p></td>
<td><p>Returns a tensor filled with random numbers from a uniform distribution on the interval <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">[0, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mopen">[</span><span class="mord mathrm">0</span><span class="mpunct">,</span><span class="mord mathrm">1</span><span class="mclose">)</span></span></span></span>
</span></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.rand_like.html#torch.rand_like" title="torch.rand_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rand_like</span></code></a></p></td>
<td><p>Returns a tensor with the same size as <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> that is filled with random numbers from a uniform distribution on the interval <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">[0, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mopen">[</span><span class="mord mathrm">0</span><span class="mpunct">,</span><span class="mord mathrm">1</span><span class="mclose">)</span></span></span></span>
</span>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.randint.html#torch.randint" title="torch.randint"><code class="xref py py-obj docutils literal notranslate"><span class="pre">randint</span></code></a></p></td>
<td><p>Returns a tensor filled with random integers generated uniformly between <code class="xref py py-attr docutils literal notranslate"><span class="pre">low</span></code> (inclusive) and <code class="xref py py-attr docutils literal notranslate"><span class="pre">high</span></code> (exclusive).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.randint_like.html#torch.randint_like" title="torch.randint_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">randint_like</span></code></a></p></td>
<td><p>Returns a tensor with the same shape as Tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> filled with random integers generated uniformly between <code class="xref py py-attr docutils literal notranslate"><span class="pre">low</span></code> (inclusive) and <code class="xref py py-attr docutils literal notranslate"><span class="pre">high</span></code> (exclusive).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.randn.html#torch.randn" title="torch.randn"><code class="xref py py-obj docutils literal notranslate"><span class="pre">randn</span></code></a></p></td>
<td><p>Returns a tensor filled with random numbers from a normal distribution with mean <cite>0</cite> and variance <cite>1</cite> (also called the standard normal distribution).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.randn_like.html#torch.randn_like" title="torch.randn_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">randn_like</span></code></a></p></td>
<td><p>Returns a tensor with the same size as <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> that is filled with random numbers from a normal distribution with mean 0 and variance 1.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.randperm.html#torch.randperm" title="torch.randperm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">randperm</span></code></a></p></td>
<td><p>Returns a random permutation of integers from <code class="docutils literal notranslate"><span class="pre">0</span></code> to <code class="docutils literal notranslate"><span class="pre">n</span> <span class="pre">-</span> <span class="pre">1</span></code>.</p></td>
</tr>
</tbody>
</table>
<div class="section" id="in-place-random-sampling">
<span id="inplace-random-sampling"></span><h3>In-place random sampling<a class="headerlink" href="#in-place-random-sampling" title="Permalink to this headline">¶</a></h3>
<p>There are a few more in-place random sampling functions defined on Tensors as well. Click through to refer to their documentation:</p>
<ul class="simple">
<li><p><a class="reference internal" href="tensors.html#torch.Tensor.bernoulli_" title="torch.Tensor.bernoulli_"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.bernoulli_()</span></code></a> - in-place version of <a class="reference internal" href="generated/torch.bernoulli.html#torch.bernoulli" title="torch.bernoulli"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.bernoulli()</span></code></a></p></li>
<li><p><a class="reference internal" href="tensors.html#torch.Tensor.cauchy_" title="torch.Tensor.cauchy_"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.cauchy_()</span></code></a> - numbers drawn from the Cauchy distribution</p></li>
<li><p><a class="reference internal" href="tensors.html#torch.Tensor.exponential_" title="torch.Tensor.exponential_"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.exponential_()</span></code></a> - numbers drawn from the exponential distribution</p></li>
<li><p><a class="reference internal" href="tensors.html#torch.Tensor.geometric_" title="torch.Tensor.geometric_"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.geometric_()</span></code></a> - elements drawn from the geometric distribution</p></li>
<li><p><a class="reference internal" href="tensors.html#torch.Tensor.log_normal_" title="torch.Tensor.log_normal_"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.log_normal_()</span></code></a> - samples from the log-normal distribution</p></li>
<li><p><a class="reference internal" href="tensors.html#torch.Tensor.normal_" title="torch.Tensor.normal_"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.normal_()</span></code></a> - in-place version of <a class="reference internal" href="generated/torch.normal.html#torch.normal" title="torch.normal"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.normal()</span></code></a></p></li>
<li><p><a class="reference internal" href="tensors.html#torch.Tensor.random_" title="torch.Tensor.random_"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.random_()</span></code></a> - numbers sampled from the discrete uniform distribution</p></li>
<li><p><a class="reference internal" href="tensors.html#torch.Tensor.uniform_" title="torch.Tensor.uniform_"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.uniform_()</span></code></a> - numbers sampled from the continuous uniform distribution</p></li>
</ul>
</div>
<div class="section" id="quasi-random-sampling">
<h3>Quasi-random sampling<a class="headerlink" href="#quasi-random-sampling" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine" title="torch.quasirandom.SobolEngine"><code class="xref py py-obj docutils literal notranslate"><span class="pre">quasirandom.SobolEngine</span></code></a></p></td>
<td><p>The <a class="reference internal" href="generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine" title="torch.quasirandom.SobolEngine"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.quasirandom.SobolEngine</span></code></a> is an engine for generating (scrambled) Sobol sequences.</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="serialization">
<h2>Serialization<a class="headerlink" href="#serialization" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.save.html#torch.save" title="torch.save"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save</span></code></a></p></td>
<td><p>Saves an object to a disk file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.load.html#torch.load" title="torch.load"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load</span></code></a></p></td>
<td><p>Loads an object saved with <a class="reference internal" href="generated/torch.save.html#torch.save" title="torch.save"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.save()</span></code></a> from a file.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="parallelism">
<h2>Parallelism<a class="headerlink" href="#parallelism" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.get_num_threads.html#torch.get_num_threads" title="torch.get_num_threads"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_num_threads</span></code></a></p></td>
<td><p>Returns the number of threads used for parallelizing CPU operations</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.set_num_threads.html#torch.set_num_threads" title="torch.set_num_threads"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_num_threads</span></code></a></p></td>
<td><p>Sets the number of threads used for intraop parallelism on CPU.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.get_num_interop_threads.html#torch.get_num_interop_threads" title="torch.get_num_interop_threads"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_num_interop_threads</span></code></a></p></td>
<td><p>Returns the number of threads used for inter-op parallelism on CPU (e.g.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.set_num_interop_threads.html#torch.set_num_interop_threads" title="torch.set_num_interop_threads"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_num_interop_threads</span></code></a></p></td>
<td><p>Sets the number of threads used for interop parallelism (e.g.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="locally-disabling-gradient-computation">
<h2>Locally disabling gradient computation<a class="headerlink" href="#locally-disabling-gradient-computation" title="Permalink to this headline">¶</a></h2>
<p>The context managers <a class="reference internal" href="generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.no_grad()</span></code></a>, <a class="reference internal" href="generated/torch.enable_grad.html#torch.enable_grad" title="torch.enable_grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.enable_grad()</span></code></a>, and
<a class="reference internal" href="generated/torch.set_grad_enabled.html#torch.set_grad_enabled" title="torch.set_grad_enabled"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.set_grad_enabled()</span></code></a> are helpful for locally disabling and enabling
gradient computation. See <a class="reference internal" href="autograd.html#locally-disable-grad"><span class="std std-ref">Locally disabling gradient computation</span></a> for more details on
their usage.  These context managers are thread local, so they won’t
work if you send work to another thread using the <code class="docutils literal notranslate"><span class="pre">threading</span></code> module, etc.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
<span class="gp">... </span>    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">False</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">is_train</span> <span class="o">=</span> <span class="kc">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">is_train</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">False</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># this can also be used as a function</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">True</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="go">False</span>
</pre></div>
</div>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.no_grad.html#torch.no_grad" title="torch.no_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">no_grad</span></code></a></p></td>
<td><p>Context-manager that disabled gradient calculation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.enable_grad.html#torch.enable_grad" title="torch.enable_grad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">enable_grad</span></code></a></p></td>
<td><p>Context-manager that enables gradient calculation.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.set_grad_enabled.html#torch.set_grad_enabled" title="torch.set_grad_enabled"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_grad_enabled</span></code></a></p></td>
<td><p>Context-manager that sets gradient calculation to on or off.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="math-operations">
<h2>Math operations<a class="headerlink" href="#math-operations" title="Permalink to this headline">¶</a></h2>
<div class="section" id="pointwise-ops">
<h3>Pointwise Ops<a class="headerlink" href="#pointwise-ops" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.abs.html#torch.abs" title="torch.abs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">abs</span></code></a></p></td>
<td><p>Computes the element-wise absolute value of the given <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.absolute.html#torch.absolute" title="torch.absolute"><code class="xref py py-obj docutils literal notranslate"><span class="pre">absolute</span></code></a></p></td>
<td><p>Alias for <a class="reference internal" href="generated/torch.abs.html#torch.abs" title="torch.abs"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.abs()</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.acos.html#torch.acos" title="torch.acos"><code class="xref py py-obj docutils literal notranslate"><span class="pre">acos</span></code></a></p></td>
<td><p>Returns a new tensor with the arccosine  of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.acosh.html#torch.acosh" title="torch.acosh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">acosh</span></code></a></p></td>
<td><p>Returns a new tensor with the inverse hyperbolic cosine of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.add.html#torch.add" title="torch.add"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add</span></code></a></p></td>
<td><p>Adds the scalar <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code> to each element of the input <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> and returns a new resulting tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.addcdiv.html#torch.addcdiv" title="torch.addcdiv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">addcdiv</span></code></a></p></td>
<td><p>Performs the element-wise division of <code class="xref py py-attr docutils literal notranslate"><span class="pre">tensor1</span></code> by <code class="xref py py-attr docutils literal notranslate"><span class="pre">tensor2</span></code>, multiply the result by the scalar <code class="xref py py-attr docutils literal notranslate"><span class="pre">value</span></code> and add it to <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.addcmul.html#torch.addcmul" title="torch.addcmul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">addcmul</span></code></a></p></td>
<td><p>Performs the element-wise multiplication of <code class="xref py py-attr docutils literal notranslate"><span class="pre">tensor1</span></code> by <code class="xref py py-attr docutils literal notranslate"><span class="pre">tensor2</span></code>, multiply the result by the scalar <code class="xref py py-attr docutils literal notranslate"><span class="pre">value</span></code> and add it to <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.angle.html#torch.angle" title="torch.angle"><code class="xref py py-obj docutils literal notranslate"><span class="pre">angle</span></code></a></p></td>
<td><p>Computes the element-wise angle (in radians) of the given <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.asin.html#torch.asin" title="torch.asin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">asin</span></code></a></p></td>
<td><p>Returns a new tensor with the arcsine  of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.asinh.html#torch.asinh" title="torch.asinh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">asinh</span></code></a></p></td>
<td><p>Returns a new tensor with the inverse hyperbolic sine of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.atan.html#torch.atan" title="torch.atan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">atan</span></code></a></p></td>
<td><p>Returns a new tensor with the arctangent  of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.atanh.html#torch.atanh" title="torch.atanh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">atanh</span></code></a></p></td>
<td><p>Returns a new tensor with the inverse hyperbolic tangent of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.atan2.html#torch.atan2" title="torch.atan2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">atan2</span></code></a></p></td>
<td><p>Element-wise arctangent of <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mtext>input</mtext><mi>i</mi></msub><mi mathvariant="normal">/</mi><msub><mtext>other</mtext><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\text{input}_{i} / \text{other}_{i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mord"><span class="mord text"><span class="mord mathrm">input</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.21752399999999997em;"><span style="top:-2.4558600000000004em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.24414em;"></span></span></span></span></span><span class="mord mathrm">/</span><span class="mord"><span class="mord text"><span class="mord mathrm">other</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>
</span> with consideration of the quadrant.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.bitwise_not.html#torch.bitwise_not" title="torch.bitwise_not"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_not</span></code></a></p></td>
<td><p>Computes the bitwise NOT of the given input tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.bitwise_and.html#torch.bitwise_and" title="torch.bitwise_and"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_and</span></code></a></p></td>
<td><p>Computes the bitwise AND of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.bitwise_or.html#torch.bitwise_or" title="torch.bitwise_or"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_or</span></code></a></p></td>
<td><p>Computes the bitwise OR of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.bitwise_xor.html#torch.bitwise_xor" title="torch.bitwise_xor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bitwise_xor</span></code></a></p></td>
<td><p>Computes the bitwise XOR of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.ceil.html#torch.ceil" title="torch.ceil"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ceil</span></code></a></p></td>
<td><p>Returns a new tensor with the ceil of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>, the smallest integer greater than or equal to each element.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.clamp.html#torch.clamp" title="torch.clamp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clamp</span></code></a></p></td>
<td><p>Clamp all elements in <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> into the range <cite>[</cite> <a class="reference internal" href="generated/torch.min.html#torch.min" title="torch.min"><code class="xref py py-attr docutils literal notranslate"><span class="pre">min</span></code></a>, <a class="reference internal" href="generated/torch.max.html#torch.max" title="torch.max"><code class="xref py py-attr docutils literal notranslate"><span class="pre">max</span></code></a> <cite>]</cite> and return a resulting tensor:</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.conj.html#torch.conj" title="torch.conj"><code class="xref py py-obj docutils literal notranslate"><span class="pre">conj</span></code></a></p></td>
<td><p>Computes the element-wise conjugate of the given <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.cos.html#torch.cos" title="torch.cos"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cos</span></code></a></p></td>
<td><p>Returns a new tensor with the cosine  of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.cosh.html#torch.cosh" title="torch.cosh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cosh</span></code></a></p></td>
<td><p>Returns a new tensor with the hyperbolic cosine  of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.deg2rad.html#torch.deg2rad" title="torch.deg2rad"><code class="xref py py-obj docutils literal notranslate"><span class="pre">deg2rad</span></code></a></p></td>
<td><p>Returns a new tensor with each of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> converted from angles in degrees to radians.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.div.html#torch.div" title="torch.div"><code class="xref py py-obj docutils literal notranslate"><span class="pre">div</span></code></a></p></td>
<td><p>Divides each element of the input <code class="docutils literal notranslate"><span class="pre">input</span></code> with the scalar <code class="docutils literal notranslate"><span class="pre">other</span></code> and returns a new resulting tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.digamma.html#torch.digamma" title="torch.digamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">digamma</span></code></a></p></td>
<td><p>Computes the logarithmic derivative of the gamma function on <cite>input</cite>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.erf.html#torch.erf" title="torch.erf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">erf</span></code></a></p></td>
<td><p>Computes the error function of each element.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.erfc.html#torch.erfc" title="torch.erfc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">erfc</span></code></a></p></td>
<td><p>Computes the complementary error function of each element of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.erfinv.html#torch.erfinv" title="torch.erfinv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">erfinv</span></code></a></p></td>
<td><p>Computes the inverse error function of each element of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.exp.html#torch.exp" title="torch.exp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">exp</span></code></a></p></td>
<td><p>Returns a new tensor with the exponential of the elements of the input tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.expm1.html#torch.expm1" title="torch.expm1"><code class="xref py py-obj docutils literal notranslate"><span class="pre">expm1</span></code></a></p></td>
<td><p>Returns a new tensor with the exponential of the elements minus 1 of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.floor.html#torch.floor" title="torch.floor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor</span></code></a></p></td>
<td><p>Returns a new tensor with the floor of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>, the largest integer less than or equal to each element.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.floor_divide.html#torch.floor_divide" title="torch.floor_divide"><code class="xref py py-obj docutils literal notranslate"><span class="pre">floor_divide</span></code></a></p></td>
<td><p>Return the division of the inputs rounded down to the nearest integer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.fmod.html#torch.fmod" title="torch.fmod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fmod</span></code></a></p></td>
<td><p>Computes the element-wise remainder of division.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.frac.html#torch.frac" title="torch.frac"><code class="xref py py-obj docutils literal notranslate"><span class="pre">frac</span></code></a></p></td>
<td><p>Computes the fractional portion of each element in <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.imag.html#torch.imag" title="torch.imag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">imag</span></code></a></p></td>
<td><p>Returns a new tensor containing imaginary values of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.lerp.html#torch.lerp" title="torch.lerp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lerp</span></code></a></p></td>
<td><p>Does a linear interpolation of two tensors <code class="xref py py-attr docutils literal notranslate"><span class="pre">start</span></code> (given by <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>) and <code class="xref py py-attr docutils literal notranslate"><span class="pre">end</span></code> based on a scalar or tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">weight</span></code> and returns the resulting <code class="xref py py-attr docutils literal notranslate"><span class="pre">out</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.lgamma.html#torch.lgamma" title="torch.lgamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lgamma</span></code></a></p></td>
<td><p>Computes the logarithm of the gamma function on <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.log.html#torch.log" title="torch.log"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log</span></code></a></p></td>
<td><p>Returns a new tensor with the natural logarithm of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.log10.html#torch.log10" title="torch.log10"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log10</span></code></a></p></td>
<td><p>Returns a new tensor with the logarithm to the base 10 of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.log1p.html#torch.log1p" title="torch.log1p"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log1p</span></code></a></p></td>
<td><p>Returns a new tensor with the natural logarithm of (1 + <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.log2.html#torch.log2" title="torch.log2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">log2</span></code></a></p></td>
<td><p>Returns a new tensor with the logarithm to the base 2 of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.logaddexp.html#torch.logaddexp" title="torch.logaddexp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logaddexp</span></code></a></p></td>
<td><p>Logarithm of the sum of exponentiations of the inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.logaddexp2.html#torch.logaddexp2" title="torch.logaddexp2"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logaddexp2</span></code></a></p></td>
<td><p>Logarithm of the sum of exponentiations of the inputs in base-2.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.logical_and.html#torch.logical_and" title="torch.logical_and"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_and</span></code></a></p></td>
<td><p>Computes the element-wise logical AND of the given input tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.logical_not.html#torch.logical_not" title="torch.logical_not"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_not</span></code></a></p></td>
<td><p>Computes the element-wise logical NOT of the given input tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.logical_or.html#torch.logical_or" title="torch.logical_or"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_or</span></code></a></p></td>
<td><p>Computes the element-wise logical OR of the given input tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.logical_xor.html#torch.logical_xor" title="torch.logical_xor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logical_xor</span></code></a></p></td>
<td><p>Computes the element-wise logical XOR of the given input tensors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.mul.html#torch.mul" title="torch.mul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mul</span></code></a></p></td>
<td><p>Multiplies each element of the input <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> with the scalar <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code> and returns a new resulting tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.mvlgamma.html#torch.mvlgamma" title="torch.mvlgamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mvlgamma</span></code></a></p></td>
<td><p>Computes the <a class="reference external" href="https://en.wikipedia.org/wiki/Multivariate_gamma_function">multivariate log-gamma function</a>) with dimension <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord mathit">p</span></span></span></span>
</span> element-wise, given by</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.neg.html#torch.neg" title="torch.neg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">neg</span></code></a></p></td>
<td><p>Returns a new tensor with the negative of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.polygamma.html#torch.polygamma" title="torch.polygamma"><code class="xref py py-obj docutils literal notranslate"><span class="pre">polygamma</span></code></a></p></td>
<td><p>Computes the <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>n</mi><mrow><mi>t</mi><mi>h</mi></mrow></msup></mrow><annotation encoding="application/x-tex">n^{th}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.849108em;"></span><span class="strut bottom" style="height:0.849108em;vertical-align:0em;"></span><span class="base"><span class="mord"><span class="mord mathit">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">t</span><span class="mord mathit mtight">h</span></span></span></span></span></span></span></span></span></span></span></span>
</span> derivative of the digamma function on <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.pow.html#torch.pow" title="torch.pow"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pow</span></code></a></p></td>
<td><p>Takes the power of each element in <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> with <code class="xref py py-attr docutils literal notranslate"><span class="pre">exponent</span></code> and returns a tensor with the result.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.rad2deg.html#torch.rad2deg" title="torch.rad2deg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rad2deg</span></code></a></p></td>
<td><p>Returns a new tensor with each of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> converted from angles in radians to degrees.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.real.html#torch.real" title="torch.real"><code class="xref py py-obj docutils literal notranslate"><span class="pre">real</span></code></a></p></td>
<td><p>Returns a new tensor containing real values of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">self</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.reciprocal.html#torch.reciprocal" title="torch.reciprocal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reciprocal</span></code></a></p></td>
<td><p>Returns a new tensor with the reciprocal of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.remainder.html#torch.remainder" title="torch.remainder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">remainder</span></code></a></p></td>
<td><p>Computes the element-wise remainder of division.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.round.html#torch.round" title="torch.round"><code class="xref py py-obj docutils literal notranslate"><span class="pre">round</span></code></a></p></td>
<td><p>Returns a new tensor with each of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> rounded to the closest integer.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.rsqrt.html#torch.rsqrt" title="torch.rsqrt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rsqrt</span></code></a></p></td>
<td><p>Returns a new tensor with the reciprocal of the square-root of each of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.sigmoid.html#torch.sigmoid" title="torch.sigmoid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sigmoid</span></code></a></p></td>
<td><p>Returns a new tensor with the sigmoid of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.sign.html#torch.sign" title="torch.sign"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sign</span></code></a></p></td>
<td><p>Returns a new tensor with the signs of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.sin.html#torch.sin" title="torch.sin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sin</span></code></a></p></td>
<td><p>Returns a new tensor with the sine of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.sinh.html#torch.sinh" title="torch.sinh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sinh</span></code></a></p></td>
<td><p>Returns a new tensor with the hyperbolic sine of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.sqrt.html#torch.sqrt" title="torch.sqrt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sqrt</span></code></a></p></td>
<td><p>Returns a new tensor with the square-root of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.square.html#torch.square" title="torch.square"><code class="xref py py-obj docutils literal notranslate"><span class="pre">square</span></code></a></p></td>
<td><p>Returns a new tensor with the square of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.tan.html#torch.tan" title="torch.tan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tan</span></code></a></p></td>
<td><p>Returns a new tensor with the tangent of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.tanh.html#torch.tanh" title="torch.tanh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tanh</span></code></a></p></td>
<td><p>Returns a new tensor with the hyperbolic tangent of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.true_divide.html#torch.true_divide" title="torch.true_divide"><code class="xref py py-obj docutils literal notranslate"><span class="pre">true_divide</span></code></a></p></td>
<td><p>Performs “true division” that always computes the division in floating point.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.trunc.html#torch.trunc" title="torch.trunc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">trunc</span></code></a></p></td>
<td><p>Returns a new tensor with the truncated integer values of the elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="reduction-ops">
<h3>Reduction Ops<a class="headerlink" href="#reduction-ops" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.argmax.html#torch.argmax" title="torch.argmax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">argmax</span></code></a></p></td>
<td><p>Returns the indices of the maximum value of all elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.argmin.html#torch.argmin" title="torch.argmin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">argmin</span></code></a></p></td>
<td><p>Returns the indices of the minimum value of all elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.dist.html#torch.dist" title="torch.dist"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dist</span></code></a></p></td>
<td><p>Returns the p-norm of (<code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> - <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code>)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.logsumexp.html#torch.logsumexp" title="torch.logsumexp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logsumexp</span></code></a></p></td>
<td><p>Returns the log of summed exponentials of each row of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor in the given dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.mean.html#torch.mean" title="torch.mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mean</span></code></a></p></td>
<td><p>Returns the mean value of all elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.median.html#torch.median" title="torch.median"><code class="xref py py-obj docutils literal notranslate"><span class="pre">median</span></code></a></p></td>
<td><p>Returns the median value of all elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.mode.html#torch.mode" title="torch.mode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mode</span></code></a></p></td>
<td><p>Returns a namedtuple <code class="docutils literal notranslate"><span class="pre">(values,</span> <span class="pre">indices)</span></code> where <code class="docutils literal notranslate"><span class="pre">values</span></code> is the mode value of each row of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor in the given dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code>, i.e.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.norm.html#torch.norm" title="torch.norm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">norm</span></code></a></p></td>
<td><p>Returns the matrix norm or vector norm of a given tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.prod.html#torch.prod" title="torch.prod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prod</span></code></a></p></td>
<td><p>Returns the product of all elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.std.html#torch.std" title="torch.std"><code class="xref py py-obj docutils literal notranslate"><span class="pre">std</span></code></a></p></td>
<td><p>Returns the standard-deviation of all elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.std_mean.html#torch.std_mean" title="torch.std_mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">std_mean</span></code></a></p></td>
<td><p>Returns the standard-deviation and mean of all elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.sum.html#torch.sum" title="torch.sum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sum</span></code></a></p></td>
<td><p>Returns the sum of all elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.unique.html#torch.unique" title="torch.unique"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unique</span></code></a></p></td>
<td><p>Returns the unique elements of the input tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.unique_consecutive.html#torch.unique_consecutive" title="torch.unique_consecutive"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unique_consecutive</span></code></a></p></td>
<td><p>Eliminates all but the first element from every consecutive group of equivalent elements.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.var.html#torch.var" title="torch.var"><code class="xref py py-obj docutils literal notranslate"><span class="pre">var</span></code></a></p></td>
<td><p>Returns the variance of all elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.var_mean.html#torch.var_mean" title="torch.var_mean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">var_mean</span></code></a></p></td>
<td><p>Returns the variance and mean of all elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="comparison-ops">
<h3>Comparison Ops<a class="headerlink" href="#comparison-ops" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.allclose.html#torch.allclose" title="torch.allclose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">allclose</span></code></a></p></td>
<td><p>This function checks if all <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code> satisfy the condition:</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.argsort.html#torch.argsort" title="torch.argsort"><code class="xref py py-obj docutils literal notranslate"><span class="pre">argsort</span></code></a></p></td>
<td><p>Returns the indices that sort a tensor along a given dimension in ascending order by value.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.eq.html#torch.eq" title="torch.eq"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eq</span></code></a></p></td>
<td><p>Computes element-wise equality</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.equal.html#torch.equal" title="torch.equal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">equal</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">True</span></code> if two tensors have the same size and elements, <code class="docutils literal notranslate"><span class="pre">False</span></code> otherwise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.ge.html#torch.ge" title="torch.ge"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ge</span></code></a></p></td>
<td><p>Computes <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>input</mtext><mo>≥</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} \geq \text{other}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord text"><span class="mord mathrm">input</span></span><span class="mrel">≥</span><span class="mord text"><span class="mord mathrm">other</span></span></span></span></span>
</span> element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.gt.html#torch.gt" title="torch.gt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">gt</span></code></a></p></td>
<td><p>Computes <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>input</mtext><mo>&gt;</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} &gt; \text{other}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord text"><span class="mord mathrm">input</span></span><span class="mrel">&gt;</span><span class="mord text"><span class="mord mathrm">other</span></span></span></span></span>
</span> element-wise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.isclose.html#torch.isclose" title="torch.isclose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">isclose</span></code></a></p></td>
<td><p>Returns a new tensor with boolean elements representing if each element of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> is “close” to the corresponding element of <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.isfinite.html#torch.isfinite" title="torch.isfinite"><code class="xref py py-obj docutils literal notranslate"><span class="pre">isfinite</span></code></a></p></td>
<td><p>Returns a new tensor with boolean elements representing if each element is <cite>finite</cite> or not.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.isinf.html#torch.isinf" title="torch.isinf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">isinf</span></code></a></p></td>
<td><p>Returns a new tensor with boolean elements representing if each element is <cite>+/-INF</cite> or not.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.isnan.html#torch.isnan" title="torch.isnan"><code class="xref py py-obj docutils literal notranslate"><span class="pre">isnan</span></code></a></p></td>
<td><p>Returns a new tensor with boolean elements representing if each element is <cite>NaN</cite> or not.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.kthvalue.html#torch.kthvalue" title="torch.kthvalue"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kthvalue</span></code></a></p></td>
<td><p>Returns a namedtuple <code class="docutils literal notranslate"><span class="pre">(values,</span> <span class="pre">indices)</span></code> where <code class="docutils literal notranslate"><span class="pre">values</span></code> is the <code class="xref py py-attr docutils literal notranslate"><span class="pre">k</span></code> th smallest element of each row of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor in the given dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.le.html#torch.le" title="torch.le"><code class="xref py py-obj docutils literal notranslate"><span class="pre">le</span></code></a></p></td>
<td><p>Computes <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>input</mtext><mo>≤</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} \leq \text{other}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord text"><span class="mord mathrm">input</span></span><span class="mrel">≤</span><span class="mord text"><span class="mord mathrm">other</span></span></span></span></span>
</span> element-wise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.lt.html#torch.lt" title="torch.lt"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lt</span></code></a></p></td>
<td><p>Computes <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>input</mtext><mo>&lt;</mo><mtext>other</mtext></mrow><annotation encoding="application/x-tex">\text{input} &lt; \text{other}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord text"><span class="mord mathrm">input</span></span><span class="mrel">&lt;</span><span class="mord text"><span class="mord mathrm">other</span></span></span></span></span>
</span> element-wise.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.max.html#torch.max" title="torch.max"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max</span></code></a></p></td>
<td><p>Returns the maximum value of all elements in the <code class="docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.min.html#torch.min" title="torch.min"><code class="xref py py-obj docutils literal notranslate"><span class="pre">min</span></code></a></p></td>
<td><p>Returns the minimum value of all elements in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.ne.html#torch.ne" title="torch.ne"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ne</span></code></a></p></td>
<td><p>Computes <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>≠</mo><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">input \neq other</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.716em;"></span><span class="strut bottom" style="height:0.9309999999999999em;vertical-align:-0.215em;"></span><span class="base"><span class="mord mathit">i</span><span class="mord mathit">n</span><span class="mord mathit">p</span><span class="mord mathit">u</span><span class="mord mathit">t</span><span class="mrel">≠</span><span class="mord mathit">o</span><span class="mord mathit">t</span><span class="mord mathit">h</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span></span></span></span>
</span> element-wise.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.sort.html#torch.sort" title="torch.sort"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sort</span></code></a></p></td>
<td><p>Sorts the elements of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor along a given dimension in ascending order by value.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.topk.html#torch.topk" title="torch.topk"><code class="xref py py-obj docutils literal notranslate"><span class="pre">topk</span></code></a></p></td>
<td><p>Returns the <code class="xref py py-attr docutils literal notranslate"><span class="pre">k</span></code> largest elements of the given <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor along a given dimension.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="spectral-ops">
<h3>Spectral Ops<a class="headerlink" href="#spectral-ops" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.fft.html#torch.fft" title="torch.fft"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fft</span></code></a></p></td>
<td><p>Complex-to-complex Discrete Fourier Transform</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.ifft.html#torch.ifft" title="torch.ifft"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ifft</span></code></a></p></td>
<td><p>Complex-to-complex Inverse Discrete Fourier Transform</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.rfft.html#torch.rfft" title="torch.rfft"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rfft</span></code></a></p></td>
<td><p>Real-to-complex Discrete Fourier Transform</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.irfft.html#torch.irfft" title="torch.irfft"><code class="xref py py-obj docutils literal notranslate"><span class="pre">irfft</span></code></a></p></td>
<td><p>Complex-to-real Inverse Discrete Fourier Transform</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.stft.html#torch.stft" title="torch.stft"><code class="xref py py-obj docutils literal notranslate"><span class="pre">stft</span></code></a></p></td>
<td><p>Short-time Fourier transform (STFT).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.istft.html#torch.istft" title="torch.istft"><code class="xref py py-obj docutils literal notranslate"><span class="pre">istft</span></code></a></p></td>
<td><p>Inverse short time Fourier Transform.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.bartlett_window.html#torch.bartlett_window" title="torch.bartlett_window"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bartlett_window</span></code></a></p></td>
<td><p>Bartlett window function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.blackman_window.html#torch.blackman_window" title="torch.blackman_window"><code class="xref py py-obj docutils literal notranslate"><span class="pre">blackman_window</span></code></a></p></td>
<td><p>Blackman window function.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.hamming_window.html#torch.hamming_window" title="torch.hamming_window"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hamming_window</span></code></a></p></td>
<td><p>Hamming window function.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.hann_window.html#torch.hann_window" title="torch.hann_window"><code class="xref py py-obj docutils literal notranslate"><span class="pre">hann_window</span></code></a></p></td>
<td><p>Hann window function.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="other-operations">
<h3>Other Operations<a class="headerlink" href="#other-operations" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.bincount.html#torch.bincount" title="torch.bincount"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bincount</span></code></a></p></td>
<td><p>Count the frequency of each value in an array of non-negative ints.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.block_diag.html#torch.block_diag" title="torch.block_diag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">block_diag</span></code></a></p></td>
<td><p>Create a block diagonal matrix from provided tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.broadcast_tensors.html#torch.broadcast_tensors" title="torch.broadcast_tensors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">broadcast_tensors</span></code></a></p></td>
<td><p>Broadcasts the given tensors according to <a class="reference internal" href="notes/broadcasting.html#broadcasting-semantics"><span class="std std-ref">Broadcasting semantics</span></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.bucketize.html#torch.bucketize" title="torch.bucketize"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bucketize</span></code></a></p></td>
<td><p>Returns the indices of the buckets to which each value in the <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> belongs, where the boundaries of the buckets are set by <code class="xref py py-attr docutils literal notranslate"><span class="pre">boundaries</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.cartesian_prod.html#torch.cartesian_prod" title="torch.cartesian_prod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cartesian_prod</span></code></a></p></td>
<td><p>Do cartesian product of the given sequence of tensors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.cdist.html#torch.cdist" title="torch.cdist"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cdist</span></code></a></p></td>
<td><p>Computes batched the p-norm distance between each pair of the two collections of row vectors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.combinations.html#torch.combinations" title="torch.combinations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">combinations</span></code></a></p></td>
<td><p>Compute combinations of length <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">r</span></span></span></span>
</span> of the given tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.cross.html#torch.cross" title="torch.cross"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cross</span></code></a></p></td>
<td><p>Returns the cross product of vectors in dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code> of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">other</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.cummax.html#torch.cummax" title="torch.cummax"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cummax</span></code></a></p></td>
<td><p>Returns a namedtuple <code class="docutils literal notranslate"><span class="pre">(values,</span> <span class="pre">indices)</span></code> where <code class="docutils literal notranslate"><span class="pre">values</span></code> is the cumulative maximum of elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> in the dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.cummin.html#torch.cummin" title="torch.cummin"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cummin</span></code></a></p></td>
<td><p>Returns a namedtuple <code class="docutils literal notranslate"><span class="pre">(values,</span> <span class="pre">indices)</span></code> where <code class="docutils literal notranslate"><span class="pre">values</span></code> is the cumulative minimum of elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> in the dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.cumprod.html#torch.cumprod" title="torch.cumprod"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cumprod</span></code></a></p></td>
<td><p>Returns the cumulative product of elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> in the dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.cumsum.html#torch.cumsum" title="torch.cumsum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cumsum</span></code></a></p></td>
<td><p>Returns the cumulative sum of elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> in the dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.diag.html#torch.diag" title="torch.diag"><code class="xref py py-obj docutils literal notranslate"><span class="pre">diag</span></code></a></p></td>
<td><p><ul class="simple">
<li><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> is a vector (1-D tensor), then returns a 2-D square tensor</p></li>
</ul>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.diag_embed.html#torch.diag_embed" title="torch.diag_embed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">diag_embed</span></code></a></p></td>
<td><p>Creates a tensor whose diagonals of certain 2D planes (specified by <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim1</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim2</span></code>) are filled by <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.diagflat.html#torch.diagflat" title="torch.diagflat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">diagflat</span></code></a></p></td>
<td><p><ul class="simple">
<li><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> is a vector (1-D tensor), then returns a 2-D square tensor</p></li>
</ul>
</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.diagonal.html#torch.diagonal" title="torch.diagonal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">diagonal</span></code></a></p></td>
<td><p>Returns a partial view of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> with the its diagonal elements with respect to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim1</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim2</span></code> appended as a dimension at the end of the shape.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.einsum.html#torch.einsum" title="torch.einsum"><code class="xref py py-obj docutils literal notranslate"><span class="pre">einsum</span></code></a></p></td>
<td><p>This function provides a way of computing multilinear expressions (i.e.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.flatten.html#torch.flatten" title="torch.flatten"><code class="xref py py-obj docutils literal notranslate"><span class="pre">flatten</span></code></a></p></td>
<td><p>Flattens a contiguous range of dims in a tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.flip.html#torch.flip" title="torch.flip"><code class="xref py py-obj docutils literal notranslate"><span class="pre">flip</span></code></a></p></td>
<td><p>Reverse the order of a n-D tensor along given axis in dims.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.fliplr.html#torch.fliplr" title="torch.fliplr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fliplr</span></code></a></p></td>
<td><p>Flip array in the left/right direction, returning a new tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.flipud.html#torch.flipud" title="torch.flipud"><code class="xref py py-obj docutils literal notranslate"><span class="pre">flipud</span></code></a></p></td>
<td><p>Flip array in the up/down direction, returning a new tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.rot90.html#torch.rot90" title="torch.rot90"><code class="xref py py-obj docutils literal notranslate"><span class="pre">rot90</span></code></a></p></td>
<td><p>Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.histc.html#torch.histc" title="torch.histc"><code class="xref py py-obj docutils literal notranslate"><span class="pre">histc</span></code></a></p></td>
<td><p>Computes the histogram of a tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.meshgrid.html#torch.meshgrid" title="torch.meshgrid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">meshgrid</span></code></a></p></td>
<td><p>Take <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.10903em;">N</span></span></span></span>
</span> tensors, each of which can be either scalar or 1-dimensional vector, and create <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.10903em;">N</span></span></span></span>
</span> N-dimensional grids, where the <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.65952em;"></span><span class="strut bottom" style="height:0.65952em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">i</span></span></span></span>
</span> <sup>th</sup> grid is defined by expanding the <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.65952em;"></span><span class="strut bottom" style="height:0.65952em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">i</span></span></span></span>
</span> <sup>th</sup> input over dimensions defined by other inputs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.logcumsumexp.html#torch.logcumsumexp" title="torch.logcumsumexp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logcumsumexp</span></code></a></p></td>
<td><p>Returns the logarithm of the cumulative summation of the exponentiation of elements of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> in the dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.renorm.html#torch.renorm" title="torch.renorm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">renorm</span></code></a></p></td>
<td><p>Returns a tensor where each sub-tensor of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> along dimension <code class="xref py py-attr docutils literal notranslate"><span class="pre">dim</span></code> is normalized such that the <cite>p</cite>-norm of the sub-tensor is lower than the value <code class="xref py py-attr docutils literal notranslate"><span class="pre">maxnorm</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.repeat_interleave.html#torch.repeat_interleave" title="torch.repeat_interleave"><code class="xref py py-obj docutils literal notranslate"><span class="pre">repeat_interleave</span></code></a></p></td>
<td><p>Repeat elements of a tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.roll.html#torch.roll" title="torch.roll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">roll</span></code></a></p></td>
<td><p>Roll the tensor along the given dimension(s).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.searchsorted.html#torch.searchsorted" title="torch.searchsorted"><code class="xref py py-obj docutils literal notranslate"><span class="pre">searchsorted</span></code></a></p></td>
<td><p>Find the indices from the <em>innermost</em> dimension of <code class="xref py py-attr docutils literal notranslate"><span class="pre">sorted_sequence</span></code> such that, if the corresponding values in <code class="xref py py-attr docutils literal notranslate"><span class="pre">values</span></code> were inserted before the indices, the order of the corresponding <em>innermost</em> dimension within <code class="xref py py-attr docutils literal notranslate"><span class="pre">sorted_sequence</span></code> would be preserved.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.tensordot.html#torch.tensordot" title="torch.tensordot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensordot</span></code></a></p></td>
<td><p>Returns a contraction of a and b over multiple dimensions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.trace.html#torch.trace" title="torch.trace"><code class="xref py py-obj docutils literal notranslate"><span class="pre">trace</span></code></a></p></td>
<td><p>Returns the sum of the elements of the diagonal of the input 2-D matrix.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.tril.html#torch.tril" title="torch.tril"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tril</span></code></a></p></td>
<td><p>Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>, the other elements of the result tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">out</span></code> are set to 0.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.tril_indices.html#torch.tril_indices" title="torch.tril_indices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tril_indices</span></code></a></p></td>
<td><p>Returns the indices of the lower triangular part of a <code class="xref py py-attr docutils literal notranslate"><span class="pre">row</span></code>-by- <code class="xref py py-attr docutils literal notranslate"><span class="pre">col</span></code> matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.triu.html#torch.triu" title="torch.triu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">triu</span></code></a></p></td>
<td><p>Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>, the other elements of the result tensor <code class="xref py py-attr docutils literal notranslate"><span class="pre">out</span></code> are set to 0.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.triu_indices.html#torch.triu_indices" title="torch.triu_indices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">triu_indices</span></code></a></p></td>
<td><p>Returns the indices of the upper triangular part of a <code class="xref py py-attr docutils literal notranslate"><span class="pre">row</span></code> by <code class="xref py py-attr docutils literal notranslate"><span class="pre">col</span></code> matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.vander.html#torch.vander" title="torch.vander"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vander</span></code></a></p></td>
<td><p>Generates a Vandermonde matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.view_as_real.html#torch.view_as_real" title="torch.view_as_real"><code class="xref py py-obj docutils literal notranslate"><span class="pre">view_as_real</span></code></a></p></td>
<td><p>Returns a view of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> as a real tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.view_as_complex.html#torch.view_as_complex" title="torch.view_as_complex"><code class="xref py py-obj docutils literal notranslate"><span class="pre">view_as_complex</span></code></a></p></td>
<td><p>Returns a view of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> as a complex tensor.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="blas-and-lapack-operations">
<h3>BLAS and LAPACK Operations<a class="headerlink" href="#blas-and-lapack-operations" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.addbmm.html#torch.addbmm" title="torch.addbmm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">addbmm</span></code></a></p></td>
<td><p>Performs a batch matrix-matrix product of matrices stored in <code class="xref py py-attr docutils literal notranslate"><span class="pre">batch1</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">batch2</span></code>, with a reduced add step (all matrix multiplications get accumulated along the first dimension).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.addmm.html#torch.addmm" title="torch.addmm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">addmm</span></code></a></p></td>
<td><p>Performs a matrix multiplication of the matrices <code class="xref py py-attr docutils literal notranslate"><span class="pre">mat1</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">mat2</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.addmv.html#torch.addmv" title="torch.addmv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">addmv</span></code></a></p></td>
<td><p>Performs a matrix-vector product of the matrix <code class="xref py py-attr docutils literal notranslate"><span class="pre">mat</span></code> and the vector <code class="xref py py-attr docutils literal notranslate"><span class="pre">vec</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.addr.html#torch.addr" title="torch.addr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">addr</span></code></a></p></td>
<td><p>Performs the outer-product of vectors <code class="xref py py-attr docutils literal notranslate"><span class="pre">vec1</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">vec2</span></code> and adds it to the matrix <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.baddbmm.html#torch.baddbmm" title="torch.baddbmm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">baddbmm</span></code></a></p></td>
<td><p>Performs a batch matrix-matrix product of matrices in <code class="xref py py-attr docutils literal notranslate"><span class="pre">batch1</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">batch2</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.bmm.html#torch.bmm" title="torch.bmm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">bmm</span></code></a></p></td>
<td><p>Performs a batch matrix-matrix product of matrices stored in <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">mat2</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.chain_matmul.html#torch.chain_matmul" title="torch.chain_matmul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">chain_matmul</span></code></a></p></td>
<td><p>Returns the matrix product of the <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.10903em;">N</span></span></span></span>
</span> 2-D tensors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.cholesky.html#torch.cholesky" title="torch.cholesky"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cholesky</span></code></a></p></td>
<td><p>Computes the Cholesky decomposition of a symmetric positive-definite matrix <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">A</span></span></span></span>
</span> or for batches of symmetric positive-definite matrices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.cholesky_inverse.html#torch.cholesky_inverse" title="torch.cholesky_inverse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cholesky_inverse</span></code></a></p></td>
<td><p>Computes the inverse of a symmetric positive-definite matrix <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">A</span></span></span></span>
</span> using its Cholesky factor <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">u</span></span></span></span>
</span>: returns matrix <code class="docutils literal notranslate"><span class="pre">inv</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.cholesky_solve.html#torch.cholesky_solve" title="torch.cholesky_solve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cholesky_solve</span></code></a></p></td>
<td><p>Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">u</span></span></span></span>
</span>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.dot.html#torch.dot" title="torch.dot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dot</span></code></a></p></td>
<td><p>Computes the dot product (inner product) of two tensors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.eig.html#torch.eig" title="torch.eig"><code class="xref py py-obj docutils literal notranslate"><span class="pre">eig</span></code></a></p></td>
<td><p>Computes the eigenvalues and eigenvectors of a real square matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.geqrf.html#torch.geqrf" title="torch.geqrf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">geqrf</span></code></a></p></td>
<td><p>This is a low-level function for calling LAPACK directly.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.ger.html#torch.ger" title="torch.ger"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ger</span></code></a></p></td>
<td><p>Outer product of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">vec2</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.inverse.html#torch.inverse" title="torch.inverse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inverse</span></code></a></p></td>
<td><p>Takes the inverse of the square matrix <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.det.html#torch.det" title="torch.det"><code class="xref py py-obj docutils literal notranslate"><span class="pre">det</span></code></a></p></td>
<td><p>Calculates determinant of a square matrix or batches of square matrices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.logdet.html#torch.logdet" title="torch.logdet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">logdet</span></code></a></p></td>
<td><p>Calculates log determinant of a square matrix or batches of square matrices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.slogdet.html#torch.slogdet" title="torch.slogdet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">slogdet</span></code></a></p></td>
<td><p>Calculates the sign and log absolute value of the determinant(s) of a square matrix or batches of square matrices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.lstsq.html#torch.lstsq" title="torch.lstsq"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lstsq</span></code></a></p></td>
<td><p>Computes the solution to the least squares and least norm problems for a full rank matrix <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">A</span></span></span></span>
</span> of size <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>m</mi><mo>×</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(m \times n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mopen">(</span><span class="mord mathit">m</span><span class="mbin">×</span><span class="mord mathit">n</span><span class="mclose">)</span></span></span></span>
</span> and a matrix <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.05017em;">B</span></span></span></span>
</span> of size <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>m</mi><mo>×</mo><mi>k</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(m \times k)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mopen">(</span><span class="mord mathit">m</span><span class="mbin">×</span><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mclose">)</span></span></span></span>
</span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.lu.html#torch.lu" title="torch.lu"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lu</span></code></a></p></td>
<td><p>Computes the LU factorization of a matrix or batches of matrices <code class="xref py py-attr docutils literal notranslate"><span class="pre">A</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.lu_solve.html#torch.lu_solve" title="torch.lu_solve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lu_solve</span></code></a></p></td>
<td><p>Returns the LU solve of the linear system <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mi>x</mi><mo>=</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Ax = b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">A</span><span class="mord mathit">x</span><span class="mrel">=</span><span class="mord mathit">b</span></span></span></span>
</span> using the partially pivoted LU factorization of A from <a class="reference internal" href="generated/torch.lu.html#torch.lu" title="torch.lu"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.lu()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.lu_unpack.html#torch.lu_unpack" title="torch.lu_unpack"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lu_unpack</span></code></a></p></td>
<td><p>Unpacks the data and pivots from a LU factorization of a tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.matmul.html#torch.matmul" title="torch.matmul"><code class="xref py py-obj docutils literal notranslate"><span class="pre">matmul</span></code></a></p></td>
<td><p>Matrix product of two tensors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.matrix_power.html#torch.matrix_power" title="torch.matrix_power"><code class="xref py py-obj docutils literal notranslate"><span class="pre">matrix_power</span></code></a></p></td>
<td><p>Returns the matrix raised to the power <code class="xref py py-attr docutils literal notranslate"><span class="pre">n</span></code> for square matrices.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.matrix_rank.html#torch.matrix_rank" title="torch.matrix_rank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">matrix_rank</span></code></a></p></td>
<td><p>Returns the numerical rank of a 2-D tensor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.mm.html#torch.mm" title="torch.mm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mm</span></code></a></p></td>
<td><p>Performs a matrix multiplication of the matrices <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">mat2</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.mv.html#torch.mv" title="torch.mv"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mv</span></code></a></p></td>
<td><p>Performs a matrix-vector product of the matrix <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> and the vector <code class="xref py py-attr docutils literal notranslate"><span class="pre">vec</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.orgqr.html#torch.orgqr" title="torch.orgqr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">orgqr</span></code></a></p></td>
<td><p>Computes the orthogonal matrix <cite>Q</cite> of a QR factorization, from the <cite>(input, input2)</cite> tuple returned by <a class="reference internal" href="generated/torch.geqrf.html#torch.geqrf" title="torch.geqrf"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.geqrf()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.ormqr.html#torch.ormqr" title="torch.ormqr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ormqr</span></code></a></p></td>
<td><p>Multiplies <cite>mat</cite> (given by <code class="xref py py-attr docutils literal notranslate"><span class="pre">input3</span></code>) by the orthogonal <cite>Q</cite> matrix of the QR factorization formed by <a class="reference internal" href="generated/torch.geqrf.html#torch.geqrf" title="torch.geqrf"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.geqrf()</span></code></a> that is represented by <cite>(a, tau)</cite> (given by (<code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">input2</span></code>)).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.pinverse.html#torch.pinverse" title="torch.pinverse"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pinverse</span></code></a></p></td>
<td><p>Calculates the pseudo-inverse (also known as the Moore-Penrose inverse) of a 2D tensor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.qr.html#torch.qr" title="torch.qr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">qr</span></code></a></p></td>
<td><p>Computes the QR decomposition of a matrix or a batch of matrices <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>, and returns a namedtuple (Q, R) of tensors such that <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mtext>input</mtext><mo>=</mo><mi>Q</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">\text{input} = Q R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord text"><span class="mord mathrm">input</span></span><span class="mrel">=</span><span class="mord mathit">Q</span><span class="mord mathit" style="margin-right:0.00773em;">R</span></span></span></span>
</span> with <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord mathit">Q</span></span></span></span>
</span> being an orthogonal matrix or batch of orthogonal matrices and <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.00773em;">R</span></span></span></span>
</span> being an upper triangular matrix or batch of upper triangular matrices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.solve.html#torch.solve" title="torch.solve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">solve</span></code></a></p></td>
<td><p>This function returns the solution to the system of linear equations represented by <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mi>X</mi><mo>=</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">AX = B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">A</span><span class="mord mathit" style="margin-right:0.07847em;">X</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.05017em;">B</span></span></span></span>
</span> and the LU factorization of A, in order as a namedtuple <cite>solution, LU</cite>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.svd.html#torch.svd" title="torch.svd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">svd</span></code></a></p></td>
<td><p>This function returns a namedtuple <code class="docutils literal notranslate"><span class="pre">(U,</span> <span class="pre">S,</span> <span class="pre">V)</span></code> which is the singular value decomposition of a input real matrix or batches of real matrices <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> such that <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>i</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>=</mo><mi>U</mi><mo>×</mo><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo>(</mo><mi>S</mi><mo>)</mo><mo>×</mo><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">input = U \times diag(S) \times V^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8413309999999999em;"></span><span class="strut bottom" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="base"><span class="mord mathit">i</span><span class="mord mathit">n</span><span class="mord mathit">p</span><span class="mord mathit">u</span><span class="mord mathit">t</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.10903em;">U</span><span class="mbin">×</span><span class="mord mathit">d</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mbin">×</span><span class="mord"><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>
</span>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.svd_lowrank.html#torch.svd_lowrank" title="torch.svd_lowrank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">svd_lowrank</span></code></a></p></td>
<td><p>Return the singular value decomposition <code class="docutils literal notranslate"><span class="pre">(U,</span> <span class="pre">S,</span> <span class="pre">V)</span></code> of a matrix, batches of matrices, or a sparse matrix <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">A</span></span></span></span>
</span> such that <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mo>≈</mo><mi>U</mi><mi>d</mi><mi>i</mi><mi>a</mi><mi>g</mi><mo>(</mo><mi>S</mi><mo>)</mo><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A \approx U diag(S) V^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8413309999999999em;"></span><span class="strut bottom" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="base"><span class="mord mathit">A</span><span class="mrel">≈</span><span class="mord mathit" style="margin-right:0.10903em;">U</span><span class="mord mathit">d</span><span class="mord mathit">i</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mord"><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span>
</span>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.pca_lowrank.html#torch.pca_lowrank" title="torch.pca_lowrank"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pca_lowrank</span></code></a></p></td>
<td><p>Performs linear Principal Component Analysis (PCA) on a low-rank matrix, batches of such matrices, or sparse matrix.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.symeig.html#torch.symeig" title="torch.symeig"><code class="xref py py-obj docutils literal notranslate"><span class="pre">symeig</span></code></a></p></td>
<td><p>This function returns eigenvalues and eigenvectors of a real symmetric matrix <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> or a batch of real symmetric matrices, represented by a namedtuple (eigenvalues, eigenvectors).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.lobpcg.html#torch.lobpcg" title="torch.lobpcg"><code class="xref py py-obj docutils literal notranslate"><span class="pre">lobpcg</span></code></a></p></td>
<td><p>Find the k largest (or smallest) eigenvalues and the corresponding eigenvectors of a symmetric positive defined generalized eigenvalue problem using matrix-free LOBPCG methods.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.trapz.html#torch.trapz" title="torch.trapz"><code class="xref py py-obj docutils literal notranslate"><span class="pre">trapz</span></code></a></p></td>
<td><p>Estimate <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>∫</mo><mi>y</mi><mspace width="0.16667em"></mspace><mi>d</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">\int y\,dx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.805em;"></span><span class="strut bottom" style="height:1.11112em;vertical-align:-0.30612em;"></span><span class="base"><span class="mop op-symbol small-op" style="margin-right:0.19445em;position:relative;top:-0.0005599999999999772em;">∫</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mord mathit"><span class="mspace thinspace"></span><span class="mord mathit">d</span></span><span class="mord mathit">x</span></span></span></span>
</span> along <cite>dim</cite>, using the trapezoid rule.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.triangular_solve.html#torch.triangular_solve" title="torch.triangular_solve"><code class="xref py py-obj docutils literal notranslate"><span class="pre">triangular_solve</span></code></a></p></td>
<td><p>Solves a system of equations with a triangular coefficient matrix <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">A</span></span></span></span>
</span> and multiple right-hand sides <span class="math"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">b</span></span></span></span>
</span>.</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Permalink to this headline">¶</a></h2>
<table class="longtable docutils colwidths-auto align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.compiled_with_cxx11_abi.html#torch.compiled_with_cxx11_abi" title="torch.compiled_with_cxx11_abi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compiled_with_cxx11_abi</span></code></a></p></td>
<td><p>Returns whether PyTorch was built with _GLIBCXX_USE_CXX11_ABI=1</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.result_type.html#torch.result_type" title="torch.result_type"><code class="xref py py-obj docutils literal notranslate"><span class="pre">result_type</span></code></a></p></td>
<td><p>Returns the <a class="reference internal" href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code></a> that would result from performing an arithmetic operation on the provided input tensors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/torch.can_cast.html#torch.can_cast" title="torch.can_cast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">can_cast</span></code></a></p></td>
<td><p>Determines if a type conversion is allowed under PyTorch casting rules described in the type promotion <a class="reference internal" href="tensor_attributes.html#type-promotion-doc"><span class="std std-ref">documentation</span></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/torch.promote_types.html#torch.promote_types" title="torch.promote_types"><code class="xref py py-obj docutils literal notranslate"><span class="pre">promote_types</span></code></a></p></td>
<td><p>Returns the <a class="reference internal" href="tensor_attributes.html#torch.torch.dtype" title="torch.torch.dtype"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code></a> with the smallest size and scalar kind that is not smaller nor of lower kind than either <cite>type1</cite> or <cite>type2</cite>.</p></td>
</tr>
</tbody>
</table>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="generated/torch.is_tensor.html" class="btn btn-neutral float-right" title="torch.is_tensor" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="cpp_index.html" class="btn btn-neutral" title="C++" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torch</a><ul>
<li><a class="reference internal" href="#tensors">Tensors</a><ul>
<li><a class="reference internal" href="#creation-ops">Creation Ops</a></li>
<li><a class="reference internal" href="#indexing-slicing-joining-mutating-ops">Indexing, Slicing, Joining, Mutating Ops</a></li>
</ul>
</li>
<li><a class="reference internal" href="#generators">Generators</a></li>
<li><a class="reference internal" href="#random-sampling">Random sampling</a><ul>
<li><a class="reference internal" href="#in-place-random-sampling">In-place random sampling</a></li>
<li><a class="reference internal" href="#quasi-random-sampling">Quasi-random sampling</a></li>
</ul>
</li>
<li><a class="reference internal" href="#serialization">Serialization</a></li>
<li><a class="reference internal" href="#parallelism">Parallelism</a></li>
<li><a class="reference internal" href="#locally-disabling-gradient-computation">Locally disabling gradient computation</a></li>
<li><a class="reference internal" href="#math-operations">Math operations</a><ul>
<li><a class="reference internal" href="#pointwise-ops">Pointwise Ops</a></li>
<li><a class="reference internal" href="#reduction-ops">Reduction Ops</a></li>
<li><a class="reference internal" href="#comparison-ops">Comparison Ops</a></li>
<li><a class="reference internal" href="#spectral-ops">Spectral Ops</a></li>
<li><a class="reference internal" href="#other-operations">Other Operations</a></li>
<li><a class="reference internal" href="#blas-and-lapack-operations">BLAS and LAPACK Operations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#utilities">Utilities</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-1', 'auto');
  ga('send', 'pageview');

</script>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>

<script>
  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>