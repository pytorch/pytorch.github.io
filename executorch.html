---
layout: default
title: PyTorch ExecuTorch
body-class: announcement
background-class: announcement-background
permalink: /executorch-overview
---

<div class="container">
  <div class="row hero-content">
    <div class="col-md-8">
      <h1 class="small">ExecuTorch</h1>
      <p class="lead pt-3">End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
    </div>
    <div class="col-md-2 d-none d-lg-block">
      <img width=100 src="/assets/images/executorch-arrows.svg">
    </div>
  </div>
</div>

<div class="container-fluid light-background-section">
  <div class="container mb-5">
    <div class="row">
      <div class="col-md-10">
        <p class="mt-4"><strong>IMPORTANT NOTE: This is a preview version of Executorch and should be used for testing and evaluation purposes only. It is not recommended for use in production settings. We welcome any feedback, suggestions, and bug reports from the community to help us improve the technology.</strong></p>

        <h2 class="mt-5 mb-2" id="what-is-executorch">What is ExecuTorch?</h2>
        <p>ExecuTorch is an end-to-end solution for enabling on-device inference capabilities across mobile and edge devices including wearables, embedded devices and microcontrollers. It is part of the PyTorch Edge ecosystem and enables efficient deployment of PyTorch models to edge devices. Key value propositions of ExecuTorch are:</p>
        
        <div class="container">
          <div class="row mt-3">
            <div class="col-sm-2 pr-0 text-right">
              <img src="/assets/images/mobile-icon.svg" alt="Mobile icon" height="50" />
            </div>
            <div class="col-sm-8 pl-0 align-middle">
              <strong>Portability</strong>: Compatibility with a wide variety of computing platforms, from high-end mobile phones to highly constrained embedded systems and microcontrollers.
            </div>
          </div>
          <div class="row mt-4">
            <div class="col-sm-2 pr-0 text-right">
              <img src="/assets/images/chip-icon.svg" alt="Chip icon" height="50" />
            </div>
            <div class="col-sm-8 pl-0 align-middle">
              <strong>Productivity</strong>: Enabling developers to use the same toolchains and SDK from PyTorch model authoring and conversion, to debugging and deployment to a wide variety of platforms.
            </div>
          </div>
          <div class="row mt-4">
            <div class="col-sm-2 pr-0 text-right">
              <img src="/assets/images/stopwatch-icon.svg" alt="Stopwatch icon" height="50" />
            </div>
            <div class="col-sm-8 pl-0 align-middle">
              <strong>Performance</strong>: Providing end users with a seamless and high-performance experience due to a lightweight runtime and utilizing full hardware capabilities such as CPUs, NPUs and DSPs.
            </div>
          </div>
        </div>

        <h2 class="mt-5 mb-2" id="explore-executorch">Explore ExecuTorch</h2>
        
        <p>We are excited to see how the community leverages our all new on-device AI stack. You can learn more about  <a href="https://resplendent-gnome-14e531.netlify.app/getting-started-architecture">key components</a> of ExecuTorch and its architecture, <a href="https://resplendent-gnome-14e531.netlify.app/intro-how-it-works">how it works</a>, and explore <a href="/executorch">documentation page</a> and <a href="https://resplendent-gnome-14e531.netlify.app/#tutorials-and-examples:~:text=Getting%20Started-,Tutorials%20and%20Examples,-Docs">detailed tutorials</a>.</p>
        
        <p>
          <a href="/executorch" class="btn btn-lg with-right-arrow">
            ExecuTorch Documentation
          </a>
        </p>
        
        <h2 class="mt-5 mb-2" id="why-executorch">Why ExecuTorch?</h2>
        
        <p>Supporting on-device AI presents unique challenges with diverse hardware, critical power requirements, low/no internet connectivity, and realtime processing needs. These constraints have historically prevented or slowed down the creation of scalable and performant on-device AI solutions. We designed ExecuTorch, backed by our industry leaders like Meta, Arm, Apple, and Qualcomm, to be highly portable and provide superior developer productivity without losing on performance.</p>
        
        <h2 class="mt-5 mb-2" id="how-is-executorch-different-from-pytorch-mobile-lite-interpreter">How is ExecuTorch Different from <a href="/mobile/home/">PyTorch Mobile (Lite Interpreter)</a>?</h2>
        
        <p>PyTorch Mobile uses TorchScript to allow PyTorch models to run on devices with limited resources. ExecuTorch has a significantly smaller memory size and a dynamic memory footprint resulting in superior performance compared to PyTorch Mobile. Also ExecuTorch does not rely on TorchScript, and instead leverages PyTorch 2.0 compiler and export functionality for on-device execution of PyTorch models.</p>

      </div>
  </div>
</div>
